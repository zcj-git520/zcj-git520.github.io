<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on Chengji Zhao&#39;s blog</title>
    <link>https://zcj-git520.github.io/categories/ai/</link>
    <description>Recent content in AI on Chengji Zhao&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 25 Mar 2025 22:00:38 +0800</lastBuildDate><atom:link href="https://zcj-git520.github.io/categories/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LangChain 自定义工具</title>
      <link>https://zcj-git520.github.io/p/langchain-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Tue, 25 Mar 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/langchain-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7/</guid>
      <description>LangChain 自定义工具 引言 在构建 LangChain 代理时，工具(Tools)是核心组件之一。工具允许代理与外部世界交互，执行特定任务。本文将深入探讨如何在 LangChain 中创建和使用自定义工具，包括内置工具的使用和自定义工具的多种实现方式。
工具的基本组成 每个工具都包含几个关键组件：
 name (str): 必需且必须在工具集中唯一 description (str): 可选但建议提供，代理用它来决定如何使用工具 return_direct (bool): 默认为 False args_schema (Pydantic BaseModel): 可选但建议提供，可用于验证参数或提供few-shot示例  内置工具的使用 LangChain 提供了许多内置工具，请访问工具集成查看可用工具列表，在使用第三方工具时，请确保您了解工具的工作原理、权限情况：
维基百科查询工具 def get_wikipedia(query): api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100) tool = WikipediaQueryRun(api_wrapper=api_wrapper) result = tool.run(query) return result Google 文字转语音工具 def google_tts(text): tts = GoogleCloudTextToSpeechTool() speech_file = tts.run(text) return speech_file 自定义工具的实现方式 1. 使用 @tool 装饰器 这是定义自定义工具最简单的方式：
from langchain_core.tools import tool @tool def search_city_tool(city: str) -&amp;gt; str: &amp;#34;&amp;#34;&amp;#34;搜索城市信息&amp;#34;&amp;#34;&amp;#34; url = f&amp;#34;https://api.</description>
    </item>
    
    <item>
      <title>LangChain 多模态输入处理</title>
      <link>https://zcj-git520.github.io/p/langchain-%E5%A4%9A%E6%A8%A1%E6%80%81%E8%BE%93%E5%85%A5%E5%A4%84%E7%90%86/</link>
      <pubDate>Tue, 25 Feb 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/langchain-%E5%A4%9A%E6%A8%A1%E6%80%81%E8%BE%93%E5%85%A5%E5%A4%84%E7%90%86/</guid>
      <description>LangChain 多模态输入处理 引言 随着大模型技术的发展，多模态能力已成为AI应用的重要方向。LangChain提供了强大的多模态处理能力，允许开发者将文本、图像、PDF等多种输入类型结合使用。本文将深入探讨LangChain中的多模态输入处理机制。
多模态基础概念 多模态(Multimodality)是指模型能够同时处理和生成多种类型的数据，包括但不限于：
 文本(Text) 图像(Image) 音频(Audio) 视频(Video) 文档(Document)  LangChain多模态架构 LangChain的多模态处理主要基于以下组件：
 HumanMessage: 承载多模态内容的核心消息类 内容类型标识(type字段): 标识不同媒体类型 数据来源标识(source_type字段): 区分本地base64或URL  多模态输入实现方式 1. 基于Base64的本地文件输入 def input_by_base64(self, prompt_txt, image_data, type): try: message = HumanMessage( content=json.dumps([ {&amp;#34;type&amp;#34;: &amp;#34;text&amp;#34;, &amp;#34;text&amp;#34;: prompt_txt}, {&amp;#34;type&amp;#34;: type, &amp;#34;data&amp;#34;: image_data, &amp;#34;source_type&amp;#34;: &amp;#34;base64&amp;#34;}, ]) ) china = self.model.qwen_llm() return china.invoke([message]).content except Exception as e: print(e) return &amp;#34;&amp;#34; 使用场景：
 处理本地存储的图片、PDF等文件 需要数据隐私保护的场景 离线应用环境  2. 基于URL的网络资源输入 def input_by_url(self, prompt_txt, url, type): try: message = HumanMessage( content=json.</description>
    </item>
    
    <item>
      <title>LangServe</title>
      <link>https://zcj-git520.github.io/p/langserve/</link>
      <pubDate>Sat, 25 Jan 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/langserve/</guid>
      <description>LangServe 实践 核心功能 LangServe 是一个专为 LangChain 设计的部署工具，可将 LangChain 可运行对象和链快速转化为 REST API，主要特点包括：
 自动化 API 生成
通过 FastAPI + Pydantic 自动推断输入/输出模型，生成带数据验证的 REST 端点 多协议支持
提供 /invoke（单次调用）、/batch（批量处理）、/stream（实时流）等标准化端点 调试友好  /stream_log 实时流式传输中间步骤 0.0.40+ 版本新增 /stream_events 简化流式处理   生产级架构
基于 uvloop 和 asyncio 实现高并发，支持 Swagger 自动文档  技术优势    特性 说明     声明式验证 通过 Pydantic 模型自动生成 JSON Schema，提供类型检查和清晰错误提示   无缝集成 内置 LangChain.js 客户端，支持 Python/JavaScript 调用   零模板代码 自动生成 API 文档和 Playground 调试界面    典型工作流 定义 LangChain 对象</description>
    </item>
    
    <item>
      <title>LCEL与LangChain流式处理指南</title>
      <link>https://zcj-git520.github.io/p/lcel%E4%B8%8Elangchain%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sat, 25 Jan 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/lcel%E4%B8%8Elangchain%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86%E6%8C%87%E5%8D%97/</guid>
      <description>LCEL与LangChain流式处理指南 什么是LCEL？ LCEL（LangChain Expression Language）是一种强大的工作流编排工具，能够从基本组件构建复杂任务链条(chain)，并具有以下生产级特性：
 🚀 一流的流式支持：直接从LLM流式传输标记到输出解析器 ⚡ 异步支持：同一代码可同步/异步运行，适合原型到生产 🔀 优化的并行执行：自动并行可并行步骤 🔄 重试和回退：配置可靠性机制 🔍 中间结果访问：实时监控和调试 📐 输入输出模式：自动生成Pydantic/JSONSchema验证  Runnable接口标准 LangChain组件通过Runnable协议实现标准化调用：
同步方法  stream(): 流式返回响应块 invoke(): 调用链处理输入 batch(): 批量处理输入列表  异步方法  astream(): 异步流式响应 ainvoke(): 异步调用 abatch(): 异步批量处理 astream_log(): 流式中间步骤+最终结果 astream_events(): 流式链事件(Beta)  组件I/O类型    组件 输入类型 输出类型     提示 字典 提示值   聊天模型 字符串/消息列表/提示值 聊天消息   LLM 字符串/消息列表/提示值 字符串   输出解析器 LLM/聊天模型输出 解析器特定   检索器 字符串 文档列表   工具 字符串/字典 工具特定    流式处理(Stream) 核心方法  同步流式：stream() 异步流式：astream()  关键特性  实时返回每个处理块 要求所有步骤支持流式处理 复杂度范围：  简单：LLM令牌流 复杂：部分JSON结果流    最佳实践 建议从LLM组件开始逐步构建流式处理链。</description>
    </item>
    
    <item>
      <title>LangChain 框架解析</title>
      <link>https://zcj-git520.github.io/p/langchain-%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Sat, 18 Jan 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/langchain-%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/</guid>
      <description>LangChain 框架解析 一、简介  定义：开源Python AI应用开发框架 核心价值：降低基于LLM的AI应用开发门槛 核心功能：  LLM集成（文本生成/问答/翻译/对话） 创意应用构建 标准化AI工作流    二、核心特性    特性 功能描述 应用场景     LLM &amp;amp; 提示管理 统一API抽象层 + 提示模板 标准化模型调用   链(Chain) 预封装任务工作流 问答系统/SQL生成   LCEL 表达式语言编排任务流 自定义AI流程   RAG 外部数据增强生成 知识库问答   Agents LLM决策+外部系统调用 自动化任务执行   模型记忆 对话历史记忆 多轮对话系统    LangChain 特性：
● LLM 和提示（Prompt）：LangChain 对所有 LLM 大模型进行了 API 抽象，统一了大模型访问 API，同时提供了 Prompt 提示模板管理机制。</description>
    </item>
    
  </channel>
</rss>
