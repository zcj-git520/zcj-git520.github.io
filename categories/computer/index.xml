<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>知识学习 on Chengji Zhao&#39;s blog</title>
    <link>https://zcj-git520.github.io/categories/computer/</link>
    <description>Recent content in 知识学习 on Chengji Zhao&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 12 Dec 2021 12:00:38 +0800</lastBuildDate><atom:link href="https://zcj-git520.github.io/categories/computer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>io多路复用</title>
      <link>https://zcj-git520.github.io/p/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</link>
      <pubDate>Sun, 12 Dec 2021 12:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</guid>
      <description>常见的IO类型 同步阻塞IO  用户线程通过调用系统命令发起io操作，由用户态复制到内核态空间，内核态一直在等待， 直到获取到数据时，将接收到的数据拷贝到用户态空间，用户线程在获取数据。整个过程用户线程 处于阻塞的状态，直到有数据为止。  同步非阻塞IO  在同步阻塞io的基础上，用户线程发起io操作后，就立刻返回。由于是非阻塞的方式，就存在返回时 没有数据，就需要不断的轮询发起io请求，直到接收到数据为止。  IO多路复用  io多路复用是一种同步的io模型。实现在内核态中一个线程监视多个io(文件句柄)，一旦某个io就绪后， 就通知用户线程进行相关的操作。没有io就绪时就阻塞用户线程，将交出cpu。多路是指网络连接，复用是指 用一个线程。  信号驱动IO  用户线程发起一个io操作后，会向内核注册一个信号处理函数，然后返回，当内核中有数据时，就会发送一个 信号给用户线程，用户态的线程在调用io请求，获取到数据。  异步IO  用户线程发起io操作后就返回。由内核态的线程处理，当内核线程获取到数据后，主动将数据拷贝到用户态， 并告知用户线程io操作也完成。   io多路复用的三种实现方式 select  select是采用数组的存储的结构存储io(fd文件句柄)，默认的最大的fd为32位系统1024，64位系统是2048(可设置),用户线程将fd集合拷贝到 内核态并开始监控，当有fd就绪或者过了设置超时时间，就将fd集合中所有未就绪的fd清空(将bitmap置为0)，将就id集合返回到用户态， 用户态的线程通过轮询返回的fd集合找到就绪的fd,进行相关的io操作获取数据。再一次监控时，需要将之前清空的fd 添加到fd集合中进行新一轮的监控。  #include &amp;lt;sys/select.h&amp;gt; #include &amp;lt;sys/time.h&amp;gt; #define FD_SETSIZE 1024 #define NFDBITS (8 * sizeof(unsigned long)) #define __FDSET_LONGS (FD_SETSIZE/NFDBITS) // 数据结构 (bitmap) typedef struct { unsigned long fds_bits[__FDSET_LONGS]; } fd_set; // API int select( int max_fd, // 最大的文件文件描述符fd fd_set *readset, // 读文件描述符集合 fd_set *writeset, // 写文件描述符集合 fd_set *exceptset, // 异常的文件描述符集合 struct timeval *timeout // 超时时间 ) // 返回值就绪描述符的数目 FD_ZERO(int fd, fd_set* fds) // 清空集合 FD_SET(int fd, fd_set* fds) // 将给定的描述符加入集合 FD_ISSET(int fd, fd_set* fds) // 判断指定描述符是否在集合中 FD_CLR(int fd, fd_set* fds) // 将给定的描述符从文件中删除 //select使用示例 int main() { /* * 这里进行一些初始化的设置， * 包括socket建立，地址的设置等, */ fd_set read_fs, write_fs; struct timeval timeout; int max = 0; // 用于记录最大的fd，在轮询中时刻更新即可 // 初始化比特位 FD_ZERO(&amp;amp;read_fs); FD_ZERO(&amp;amp;write_fs); int nfds = 0; // 记录就绪的事件，可以减少遍历的次数 while (1) { // 阻塞获取 // 每次需要把fd从用户态拷贝到内核态 nfds = select(max + 1, &amp;amp;read_fd, &amp;amp;write_fd, NULL, &amp;amp;timeout); // 每次需要遍历所有fd，判断有无读写事件发生 for (int i = 0; i &amp;lt;= max &amp;amp;&amp;amp; nfds; ++i) { if (i == listenfd) { --nfds; // 这里处理accept事件 FD_SET(i, &amp;amp;read_fd);//将客户端socket加入到集合中 } if (FD_ISSET(i, &amp;amp;read_fd)) { --nfds; // 这里处理read事件 } if (FD_ISSET(i, &amp;amp;write_fd)) { --nfds; // 这里处理write事件 } } }</description>
    </item>
    
    <item>
      <title>redis进阶</title>
      <link>https://zcj-git520.github.io/p/redis%E8%BF%9B%E9%98%B6/</link>
      <pubDate>Wed, 08 Dec 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/redis%E8%BF%9B%E9%98%B6/</guid>
      <description>redis的网络协议  redis是基于tcp/ip协议，即客户端与服务器保持双工连接，通过序列化的协议(resp协议)进行数据的交互，在Redis中，协议数据分为不同的类型， 每种类型的数据均以CRLF（\r\n）结束，通过数据的首字符区分类型  redis服务器是一个事件驱动系统主要分为：文件事件(io事件)和时间事件 文件驱动：socket的读取事件(io事件)是由；连接(三次握手)、请求、响应(数据返回)、断开连接(四次挥手)组成，redis是采用单线程 和epoll(io多路复用)的机制处理相关的文件事件。 时间事件：可分为定时事件(程序在指定时间后执行相关的操作)和周期事件(程序每隔一段时间运行相关的操作)  redis客户端与服务器交互模式 串行的请求/交互模式  客户端与服务器建立长连接，通过心跳检测(ping-pong)ack应答，即客户端发送请求，服务器在进行响应。 在单连接下。大部分时间都是处于网络等待上(客户端在发送请求命令，并监听socket返回，通常以阻塞模式等待服务器端的响应)，这种模式下 的性能较低   管道技术(pipeline)双工的请求/响应模式  将一批命令进行打包，然后发送给服务器，服务器获取数据后按顺序打包返回，即批量请求，批量响应。以次来减少网络等待的延时，提高性能   原子化的批量请求/响应(事务)模式  客户端将请求的命令发送发到服务器，服务器经这些请求暂存在服务器的请求队列中，这过程也称为：请求入队列。服务器在从请求队列中 拿去所有的请求执行，然后再将数据返回给客户端，这过程称为执行阶段。 服务器在执行过程中不会在接收其他客户端发送的请求。所有的操作都是原子操作，即请求都执行或都不执行。 事务的步骤为：开始事务-&amp;gt;请求入队列-&amp;gt;执行请求   发布/订阅(pub/sub)模式  发布者(pub)发送消息，订阅者(sub)接收消息，发布者和订阅者通过(通道)channel关联，所有的channel都是由一个map维护，map的key是 channel的名字，value是所有的订阅者的指针链表。客户端可以订阅任意的数量的频道，也可以进行发布。 发布者和订阅者都是客户端，服务器只是进行数据的中转。即发布者着向服务端发起请求，服务端将请求的数据推送给订阅者。   redis的持久化机制  redis的持久化机制主要是有：RDB(快照)和AOF(日志)两种持久化的方式。持久的化的作用在于：故障恢复和数据恢复  RDB(快照)持久化机制  快照是redis默认的持久化方案，在指定时间间隔内生成数据集的时间点，即在指定的时间段内将内存的数据写入磁盘，在磁盘 上生成一个rdb的备份文件。在redis重启时加载rdb文件进行数据的恢复。 快照的持久化提供自动备份：需要修改配置文件redis.conf。也提供save和bysave(后台子进程)进行主动备份  RDB(快照)的工作流程：  主进程会单独创建子进程，将主进程的数据库的数据复制到子进程。 子进程将数据写入到临时文件中进行持久化，在经临时文件替换之前的rdb文件,子进程退出，释放内存中的数据 主进程不进行持久化，即不进行任何的io操作，确保redis的极高的性能  RDB(快照)的优缺点 优点  单一的紧凑文件保存了莫一段时间的数据集，比较适合做数据的备份尤其的冷备份 在对数据完整性不敏感下，适合大规模的数据的恢复，因直接从磁盘获取数据，恢复数据快 由子进程进行持久化，主进程不进行持久化，即不进行任何的io操作，确保redis的极高的性能  缺点  不能保障数据的完整性，若redis出现宕机，就不会出现最近的数据未持久化，导致数据的丢失。 当持久化的数据量较大时，会导致持久化的子进程就会很耗时，即使主线程在不参与持久化也可能导致服务器在毫秒级内不能响应 客户端的请求，若数据巨大时且cpu的性能不佳时，会出现秒级不能响应客户端的请求。  AOF(日志)持久化  通过将每个写操作记录到日志中且以追加文件不修改文件的模式，重启时更具根据日志文件从头到未执行一遍即恢复数据。，因AOF采用的是经操作记录以追加模式下写入日志文件中，会导致AOF文件越来越大。AOF引入了重写机制。 AOF引入了重写机制：当文件AOF是上次重写大小的一倍且文件大于64MB时就创建一个子进程遍历服务器的键值对，转换成一系列 Redis 的操作 指令，序列化到一个新的AOF日志文件中，再替换旧的AOF日志文件。可以修改配置文件设定持久化策略。  AOF 提供了三种持久化策略：  no: 无 fsync，由系统保证数据刷新到磁盘，速度最快，但很不安全（通常不使用）； always: 每次 fsync，每一个修改内存的 Redis 指令都会执行一次 fsync，速度很慢（通常不使用）； everysec: 每秒进行一次 fsync，有可能丢失一秒的 fsync 的数据。通常选择 everysec 策略，兼顾安全性和效率。  AOF(日志)的优缺点 优点  可以采用everysec的持久化策略，能确保数据的完整性  缺点  AOF的日志文件通常是比rdb文件大 在数据的恢复时，需要遍历日志文件，将日志文件的数据操作命令在执行一遍，导致数据恢复相对于快照(rdb)较慢，尤其在大数据下。  redis 缓存中的状况于解决方案 缓存雪崩  数据未加载到内存或者同一时间发生大规模的key失效，从而导致所有的请求都直接在查数据库。导致数据库和cpu负载过高，甚至宕机  解决方案  加锁计数，限制并发的数量，避免出现并发出现大量的请求访问到数据库，降低服务器的吞吐量 设置热点key永不失效，均匀过期，避免出现大面积的key同时失效 设置缓存服务器的主备  缓存穿透  指客户端请求的数据在缓存和数据库中均没有，导致客户端在每次请求都需要去数据库查询。若在并发时，也会导致数据库和cpu的负载过高， 导致数据库的宕机  解决方案  若查询数据库不存在，直接在缓存中保存一个默认的值，并设置较短的过期时间，下次请求直接从缓存中返回。 使用布隆过滤器，阻挡无效的请求。  缓存并发  在并发情况下，一个缓存失效，在高并发下访问数据库，缓存更新，也会导致数据的压力变大。  解决方案  对缓存加锁，若key不存在，就加锁，当查询数据库的数据写入缓存在解锁  缓存预热  在系统运行前，将数据加载到缓存中  解决方案  数据量不大，直接加载 数据量大时，设置定时的脚本进行缓存的刷新 数据量巨大时，优先保障热点数据提前加载到缓存中  缓存降级  指缓存失效或者缓存服务器宕机时，不去访问数据库，直接返回默认值或访问内存数据  分布锁  使用setnx加锁，并设置超时时间，过了超时时间就解锁，并删除锁  参考文献 Redis 客户端服务端交互1 客户端/服务端协议</description>
    </item>
    
    <item>
      <title>初识redis(数据结构分析)</title>
      <link>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</link>
      <pubDate>Sun, 05 Dec 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</guid>
      <description>redis  redis 是一个开源（BSD许可）的，数据结构为key-value的存储系统。它可以用作分布式数据库、缓存 和消息队列（消息中间件）。数据保存在内存中，存取速度快，并发能力强。 redis 支持多种数据结构，如字符串、map(哈希)、列表、集合、有序集合等数据类型。数据都是原子操作， 数据都缓存在内存中，会定期将数据更新到磁盘或者修改操作写入追加记录。再次基础上实现了主从（master-slave）  redis 数据结构 字符串(string)类型  字符串类型是redis最基础的数据结构，可以存储简单的字符串也可存储复杂的xml、json、二进制数据（如图像、音频） value内部以保存整数的int和保存字符的sds组成的数据存储结构。sds内部结构为：  struct sdshdr { int len; // 记录着buf中也使用的字符串数量 int free; // 记录着buf中未使用的字符串数量 char buh[]; // 字符串数组，用于保存字符串 } 
字符串类型特性  分配冗余空间：采用预先分配冗余空间的方式来减少内存的频繁分配 自动扩容： 当字符串所占空间小于1MB时，redis会按照字符串（len + addLen）*2倍数存储空间增加， 当字符串的存储空间超过所占空间的1MB时，每次自会增加1MB的存储空间扩容，最大扩容为512MB的存储空间 二进制的安全性，兼容c语言函数库中字符串以\0结束。  字符串常用的场景  缓存功能： 基于redis作为缓存再配合其他的数据库最为存储层，利用redis的数据存储在内存和支持高并发的特点，可以大大加快 系统的读写速度以及降低后端数据库的压力。（单值缓存、对象缓存、分布式锁等） 计数器： 使用redis作为系统的实时计数器，可以加快计数和查询功能。 共享用户的session：利用redis将用户的session集中管理，这种模式确保redis的高可用。每次用户的session的更新和获取快速完成  列表(list)  list类型的value对象内部采用的quicklist(快速列表)或者ziplist(压缩列表)承载。当list的元素和单个元素较小时采用ziplist实现来减少内存的 占用否则采用quicklist结构进行存储。 ziplist所有内容都存放在来连续的内存中。zipbytes表示ziplist的总长度， zltail表示指向最末的元素，zllen表示元素个数， entryX表示元素自身内容， zlend是ziplist的定界符 ziplist的内部结构为：  typedef struct ziplist{ /*ziplist分配的内存大小*/ uint32_t bytes; /*达到尾部的偏移量*/ uint32_t tail_offset; /*存储元素实体个数*/ uint16_t length; /*存储内容实体元素*/ unsigned char* content[]; /*尾部标识*/ unsigned char end; }ziplist; /*元素实体所有信息, 仅仅是描述使用, 内存中并非如此存储*/ typedef struct zlentry { /*前一个元素长度需要空间和前一个元素长度*/ unsigned int prevrawlensize, prevrawlen; /*元素长度需要空间和元素长度*/ unsigned int lensize, len; /*头部长度即prevrawlensize + lensize*/ unsigned int headersize; /*元素内容编码*/ unsigned char encoding; /*元素实际内容*/ unsigned char *p; }zlentry;</description>
    </item>
    
    <item>
      <title>初探jwt(json web Token)</title>
      <link>https://zcj-git520.github.io/p/%E5%88%9D%E6%8E%A2jwtjson-web-token/</link>
      <pubDate>Tue, 30 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%88%9D%E6%8E%A2jwtjson-web-token/</guid>
      <description>jwt  jwt 它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息，是最流行的跨域认证的解决方案  传统跨域认证  客服端向服务器发送用用户名和密码，服务器验证通过后，把当前对话的session里保存 相关数据，并写在客户端的cookie, 向客户端返回一个session id。客户端再次通过cookie, 经session id 传回服务器，服务器通过session id得知访问客户端的身份。 存在的问题：扩展性不佳，服务器集群或者跨域的服务导向架构，就需要共享session共享数据 解决方案：1. 将session 数据保存在数据库中或者其他的持久层，服务器访问持久层的session数据 2. 服务器不保存session数据，所有的数据保存在客户端，每次请求都发回服务器  jwt的原理  服务器认证以后，生成一个json对象，返回给客户端之后，客户端与服务器靠这个json对象认证，会会 加上签名来防止客户端修该json 对象  jwt的数据结构  jwt的数据结构为：Header(头部)、payload(负载)、signature(签名)
  Header(头部)  Header部分是一个json对象，描述jwt的元素据。声明类型，这里是jwt声明加密的算法 通常直接使用 HMAC SHA256，结构如下：  { &#39;typ&#39;: &#39;JWT&#39;, &#39;alg&#39;: &#39;HS256&#39; } payload(负载)  payload 也是一个json对象，用来存放实际需要的传递的数据，iss：发行人，exp：到期时间，sub：主题，aud：用户， nbf：在此之前不可用，iat：发布时间，jti：JWT ID用于标识该JWT  { &amp;quot;sub&amp;quot;: &amp;quot;1234567890&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;John Doe&amp;quot;, &amp;quot;admin&amp;quot;: true } signature(签名)  是对前两部分进行签名，防止篡改。在服务器上指明一个密钥，在根据header中指定的算法， 按照格式产生签名，header (base64后的)、payload (base64后的)、secret。其格式如下：  // javascript var encodedString = base64UrlEncode(header) + &#39;.</description>
    </item>
    
    <item>
      <title>初识Nginx</title>
      <link>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86nginx/</link>
      <pubDate>Wed, 24 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86nginx/</guid>
      <description>Nginx  nginx 是轻量级高并发web服务器，是基于Rest架构风格。通过http协议提供各种网络服务
其高并发是基于事件驱动架构，io多路复用的epoll,使得可以轻松支持百万计的icp连接。
轻量级主要体现在：采用插件化开发，cup亲和，将cpu与nginx工作进程绑定，减少cpu切换带来的消耗  代理  代理是客户端与服务器之间的一层服务器，将客户端的请求转发给服务器，然后服务器的响应转发给客户端  正向代理  客户端向代理服务器转发请求和指定目标服务器，代理服务器向目标服务器发送请求，并将结果返回给客户端。 对客户端是透明的，即客户端知道访问的是目标服务器，对目标服务器来说是非透明的，并不知道访问服务器是 客户端还是代理服务器  反向代理  客户端向代理服务器发送请求，代理服务器将请求转发给内部的网络服务器(目标服务器)，在将结果返回给客户端。对于客户端 是非透明的，即客户端不清楚是访问是那一台目标服务器。对于目标服务器是透明的，即目标服务器知道访问的是 代理服务器 nginx反向代理的配置如下：  server { listen 80; server_name www.123.com; location / { proxy_pass http://127.0.0.1:8080; index index.html index.htm index.jsp; } } 我们监听80端口，访问域名为www.123.com，不加端口号时默认为80端口，故访问该域名时会跳转到127.0.0.1:8080路径上
负载均衡  当请求过大时，将请求分发给各个服务器。负载均衡的分配策略为：weight(权重)轮询，fair(智能调整调度) nginx轮询配置(所有请求都按照时间顺序分配到不同的服务上)  upstream dalaoyang-server { server localhost:10001; server localhost:10002; }  nginx权重配置(权重轮询：代理服务器接收到请求，按照设定的权重，请求分配到不同的后端服务器，如果发现后端服务器宕机时， 代理服务器会将其剔除出队列)  upstream dalaoyang-server { server localhost:10001 weight=1; server localhost:10002 weight=2; }  nginx iphash 配置(每个请求都根据访问ip的hash结果分配)  upstream dalaoyang-server { ip_hash; server localhost:10001 weight=1; server localhost:10002 weight=2; }  最少连接(将请求分配到连接数最少的服务上)  upstream dalaoyang-server { least_conn; server localhost:10001 weight=1; server localhost:10002 weight=2; }  far 智能调整调度算法：动态根据后端服务器的请求处理到响应时间进行均衡分配。即响应时间短，处理效率高的服务器 分配到请求的概率高。响应时间长，效率低的服务器分配到请求的概率低。 far 配置文件如下：  upstream dalaoyang-server { server localhost:10001 weight=1; server localhost:10002 weight=2; fair; } 流量控制  限流实际就是限制流入请求的数量：有计数器固定窗口算法、令牌桶算法、漏桶算法和限制并发连接数限制</description>
    </item>
    
    <item>
      <title>http协议底层分析</title>
      <link>https://zcj-git520.github.io/p/http%E5%8D%8F%E8%AE%AE%E5%BA%95%E5%B1%82%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 18 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/http%E5%8D%8F%E8%AE%AE%E5%BA%95%E5%B1%82%E5%88%86%E6%9E%90/</guid>
      <description>HTTP  HTTP是(Hyper Text Transfer Protocol)超文本传输协议, 基于tcp的应用层传输协议（请求-响应）协议 影响HTTP网络请求的主要因素带宽和延迟  延迟的种类:  浏览器阻塞(超过浏览器连接数限制的后续请求都会被阻塞) DNS查询 (将域名解析造成的延迟，可以通过缓存DNS进行解决) 建立链接 (因HTTP是基于TCP的应用层协议，在建立连接时需要进行)  HTTP1.0 http1.0存在的问题：  短连接：规定客户端与服务器只保持短暂连接，客户端每次请求都需要建立连接，服务器完成请求后 断开连接，服务器不跟踪客户端，不保存客户端的请求记录。 没有host头域：每台服务器都绑定一个唯一的IP地址，请求消息中的URL并没有传递主机名（hostname） 不允许短点续传  HTTP1.1 根据http1.0暴露的问题，http1.1增加优化方案  缓存处理：http1.1增加更多的缓存控制策略 带宽优化及网络连接的使用：http1.1中请求头引入了range头域和支持断点续传的功能 Host头处理：http1.1的请求消息和相应消息虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机(Multi-homed Web Servers),并且它们共享一个IP地址,HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request） 长连接： 支持长连接和流水线处理，默认开始是长连接：keep-alive  http1.1 也带来新的问题：HTTP 队头阻塞(head of line blocking)  因http1.1支持了长连接和使用了管道机制，客户端与服务器建立一次连接，客户端不用等待服务器响应就能发送下一个请求，支持了并行发送多个请求， 但服务器必须按照请求的顺序来相应请求，也就是通过串行响应请求，这就造成了HTTP的队头阻塞。  解决Http 队头阻塞方法  并发连接：一个域名允许分配多个长连接，增加处理请求任务 域名分片：将一个域名分解为多个域名，在进行并发连接  HTTP2.0  HTTP2.0主要是基于SPDY协议。实现了低延时高吞吐量  SPDY协议  是基于TCP协议的应用层协议，其目标是通过头部压缩、多路复用、优先级等作用缩短网页放入加载时间和 优化http的性能，其核心是尽量减少TCP连接数  HTTP 2.0的特性 头部压缩 头部存在大量的信息，而且每次在发送都会降低http的性能，在用HPACK算法对头部进行压缩： 1.在客户端和服务器维持一个头部表来跟踪和存储客户端发来的键值对 2.客户端在请求的时候便只需要发送在表里的索引位置即可 3.HPACK 不仅仅通过索引键值对来降低数据量，同时还会将字符串进行霍夫曼编码来压缩字符串大小</description>
    </item>
    
    <item>
      <title>PRC</title>
      <link>https://zcj-git520.github.io/p/prc/</link>
      <pubDate>Mon, 15 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/prc/</guid>
      <description>RPC  RPC(Remote Procedure Call Protocol)——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务， 而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP/IP或UDP，为通信程序之间携带信息数据。 RPC将原来的本地调用转变为调用远端的服务器上的方法，给系统的处理能力和吞吐量带来了近似于无限制提升的可能。 在OSI网络通信模型中，RPC跨域了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易 RPC采用客户机/服务器(client-server)模式,也是一种请求/响应(request-response)模式，可以通过TCP/UDP以及HTTP 协议进行传输  RPC 架构  CAll ID 映射：客户端通过ID传输给服务器，服务器通过ID调用相应的函数返回 序列化与烦序列化：客户端与服务器通过序列化与反序列化进行传参 一个完整的RPC架构里面包含了四个核心的组件，分别是Client，Client Stub，Server以及Server Stub，这个Stub可以理解为存根。   客户端(Client)，服务的调用方。 客户端存根(Client Stub)，存放服务端的地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程发送给服务方。 服务端(Server)，真正的服务提供者。 服务端存根(Server Stub)，接收客户端发送过来的消息，将消息解包，并调用本地的方法。  RPC调用过程  客户端（client）以本地调用方式（即以接口的方式）调用服务； 客户端存根（client stub）接收到调用后，负责将方法、参数等组装成能够进行网络传输的消息体（将消息体对象序列化为二进制）； 客户端通过sockets将消息发送到服务端； 服务端存根( server stub）收到消息后进行解码（将消息对象反序列化）； 服务端存根( server stub）根据解码结果调用本地的服务； 本地服务执行并将结果返回给服务端存根( server stub）； 服务端存根( server stub）将返回结果打包成消息（将结果消息对象序列化）； 服务端（server）通过sockets将消息发送到客户端； 客户端存根（client stub）接收到结果消息，并进行解码（将结果消息发序列化）； 客户端（client）得到最终结果。
RPC的目标是要把2、3、4、7、8、9这些步骤都封装起来。   注意：无论是何种类型的数据，最终都需要转换成二进制流在网络上进行传输，数据的发送方需要将对象转换为二进制流，而数据的接收方则需要把二进制流再恢复为对象。   gPRC  gRPC 是一种现代开源高性能远程过程调用 (RPC) 框架，可以在任何环境中运行。它可以通过对负载平衡、跟踪、健康检查和身份验证的可插拔支持，有效地连接数据中心内和数据中心之间的服务。它还适用于分布式计算的最后一英里，将设备、移动应用程序和浏览器连接到后端服务。 gRPC 是基于HTTP2.0(多路复用,消除了线头阻塞)标准协议色设计的基于ProtoBuf序列化的高性能框架。 《gRPC 官方文档中文版》  Protocol Buffers  Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据序列化，很适合做数据存储或 RPC 数据交换格式。它可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式 序列化：将数据结构或对象转换成能被传输或者存储（如二进制格式）的过程。 反序列化：将在序列化过程中所生成的(格式)转换成数据结构或者对象的过程。  参考文献： RPC原理解析</description>
    </item>
    
    <item>
      <title>RestfulAPI</title>
      <link>https://zcj-git520.github.io/p/restfulapi/</link>
      <pubDate>Wed, 10 Nov 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/restfulapi/</guid>
      <description>Restful API  rest是Representational state Transfer 的缩写（表述性转态传递） api是应用程序接口 Restful API是一种软件结构风格，设计风格，让软件更加清晰、简洁、易维护。是一种流行的软件API 设计风格  Rest的指导风格  客户端-服务器：通过将用户接口问题与数据存储问题分开，简化服务器组件来提高跨平台放入用户接口的 可移植性性并提高可伸缩性 无转态：从客户端到服务器的每个请求都必须包含理解请求所需的所有信息，并且不能利用服务器上任何存储的上下文。因此，会话状态完全保留在客户端上。 可缓存：缓存约束要求将对请求的响应中的数据隐式或显式标记为可缓存或不可缓存。如果响应是可缓存的，则客户端缓存有权重用该响应数据以用于以后的等效请求。 统一接口：通过将通用性的软件工程原理应用于组件接口，简化了整个系统架构，提高了交互的可见性。为了获得统一的接口，需要多个架构约束来指导组件的行为。REST由四个接口约束定义：资源识别; 通过陈述来处理资源; 自我描述性的信息; 并且，超媒体作为应用程序状态的引擎 分层系统：分层系统风格允许通过约束组件行为来使体系结构由分层层组成，这样每个组件都不能“看到”超出与它们交互的直接层。 按需编码（可选）： REST允许通过以小程序或脚本的形式下载和执行代码来扩展客户端功能。这通过减少预先实现所需的功能数量来简化客户端  RestFul 架构  资源：网络的实体或者是具体的信息，使用URI(统一资源定位符)，URI是每一个资源的地址或者独一无二的是识别符 表现层： 对资源的外在表现，如：json、xml、txt、二进制等 转态转化：互联网是一种无转态的协议，所有的状态都是保存在服务器上，客户端通过 HTTP的操作方式(GET,POST,PUT,DELETE)等改变服务器的“状态变化”   RESTful API接口规范 接口风格  路径和变量均采用小驼峰式，例如deviceId 使用HTTP动词作为action操作URL资源，动词一律大写。  GET：读取\查询（Read） POST：新建（Create） PUT：更新（Update） PATCH：更新（Update），通常是部分更新 DELETE：删除（Delete） HEAD：获取资源的元数据。 OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。 5种请求动作中，GET、PUT、PATCH、DELETE均是幂等的；只有POST是非幂等的。幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。是非幂等是判断接口使用POST还是PUT的决定条件。幂等的理解见本文附录。   参数：  PATH（路径）：  版本号放入PATH，且在最前  尽量使用名词，不使用动词，把每个URL看成一个资源，名称都用复数 微服务名称不放入PATH中     Query参数：主要用在GET查询中，简单的PUT动作，也用Query参数 Headers参数：公共参数通过header传递，content-type、authorization认证必填，其他统一按调用链规范、速率限制规范填写。content-type应该固定为application/json。 Body：  统一使用json格式，所有返回都是json格式  POST所有参数通过JSON传递 GET请求不允许有body， 所有参数通过拼接在URL之后传递，所有的请求参数都要进行遵循RFC 3986的URL Encode。 DELETE删除单个资源时，资源标识通过path传递，批量删除时，通过在body中传递JSON。       返回结果  状态码：HTTP状态码标准用法，见后状态码规范 Body返回，只提供json返回格式 GET：返回资源对象，完整对象或通过Query参数可过滤 POST：返回新生成的资源对象，可能是ID或完整的资源对象 PUT：返回完整的资源对象 DELETE：返回一个空文档   过滤信息：查询及查询结果使用  pageNo：分页查询标识第几页 pageSize：分页查询标识每页多少条数据 begin：录像/截图开始时间，Unix时间戳，单位秒 end：录像/截图结束时间，Unix时间戳，单位秒 orderby：排序规则，desc或asc q：搜索关键字（uri encode之后的） totalCount：总记录数，分页查询，返回json携带 totalPages：总页数，分页查询，返回json携带，等于page时，表示当前是最后一页   微服务内部使用http协议，对外使用https协议  详细设计要求  输入参数要精简有效  不能把内部对象作为接口参数，通过DTO进行转换； required的字段尽可能少   CRUD的U(POST)要通过业务分析（领域建模）具体化操作，不要提供灵活但是支持不全面的接口 查询尽可能提供丰富的查询条件，可以返回尽可能详细的信息 同类资源尽可能统一接口 避免多级 URL，比如获取某个作者的某一类文章： GET /authors/12/categories/2 这种 URL 不利于扩展，语义也不明确，往往要想一会，才能明白含义。 更好的做法是，除了第一级，其他级别都用查询字符串表达。 GET /authors/12?</description>
    </item>
    
    <item>
      <title>Docker知识总览</title>
      <link>https://zcj-git520.github.io/p/docker%E7%9F%A5%E8%AF%86%E6%80%BB%E8%A7%88/</link>
      <pubDate>Fri, 05 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/docker%E7%9F%A5%E8%AF%86%E6%80%BB%E8%A7%88/</guid>
      <description>概念知识 Docker镜像 Docker镜像是由文件和元数据组成的。
 文件：语言环境、库、执行文件  由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。   元数据：环境变量、端口映射、卷等 镜像信息：  RESPOSITORY：仓库名 TAG：标签 IMAGE ID：镜像ID CREATED：创建时间 SIZE：所占用的空间   虚悬镜像(dangling image)  RESPOSITROY及TAG都为 使用docker image prune 可以删除    容器 容器是从镜像中创建，继承了他们的文件系统，并使用他们的元数据来确定其启动配置。
 启动时，运行一个进程，不过可派生其他进程。 文件的变更通过写时复制存储在容器中，基础镜像不会受影响。  数据卷 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：
 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷  Docker网络 当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。</description>
    </item>
    
    <item>
      <title>内存管理</title>
      <link>https://zcj-git520.github.io/p/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
      <pubDate>Mon, 18 Oct 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
      <description>虚拟地址空间布局  程序通过编译成为一堆的机器指令写入可执行文件，程序在运行是会将可执行文件加载在计算机的内存中 在虚拟地址空间分布中处于代码段。 程序中的局部变量、函数的参数、函数的返回值等数据会保存在虚拟地址的栈中(栈是先进后出的数据结构) 栈空间的编译器分配和释放。 程序的全局变量和静态变量会保存在虚拟地址的数据段 动态分配内存的地址会保存在虚拟地址空间的堆上。堆空间是动态开辟的内存空间，需要主动开辟和释放。或者 调用GC释放   堆内存管理  堆内存空间不是编译器分配，而是有程序动态分配的内存空间。  手动垃圾回收  需要程序主动释放没有用的数据所在的堆空间。如：c++中调用new()函数向计算机申请开辟内存空间后，使用delete或delete[]释放不需要的 堆内存空间。这一类是手动内存分配和释放。手动内存分配使用不恰当也会造成：内存泄露 悬挂指针的问题   过早释放会造成悬挂指针（野指针）：提前释放了动态的堆内存的空间，当程序访问这段地址时会报错。因为这段提前释放的内存空间被清空、 重新分配或者被操作系统回收。释放指针时将指针赋值为NULL，在访问时对指针进行判断是否为NULL 不释放内存会造成内存泄漏：堆内存需要手动释放，当程序运行结束不释放，这段内存就会被一直占用。如果 一直在分配不释放会一直占用计算机的内存，直到内存被占完。将new与delete配套使用，使用工具检测或者打印出堆信息  自动垃圾回收（GC）  在程序运行过程中自动释放没有用的数据所在的堆空间（垃圾回收).在虚拟内存空间中能从栈或者数据段的根节点追踪不到的数据为没用的数据 （内存垃圾），常用的算法：标记法, 计数法  标记法回收  标记法：将栈或者数据段作为根（root）进行追踪,将能追踪得的数据（堆空间）进行标记。没有被标记的数据 （堆空间）就是垃圾，将这部分垃圾进行回收。三色抽象：   垃圾回收开始时，将所有数据为白色 垃圾回收开始时，将所有的栈或者数据段的根节点设置为灰色 在根据根节点进行追踪，直到所有的数据节点追踪结束后将根节点置为黑色，在将根节点的下一节点作为根节点进行追踪 所有的数据节点都追踪完后，会剩下黑色和白色的数据节点。黑色表示有用的数据。白色为无用的数据。将白色的数据进行回收（堆空间的释放）    标记法实现简单，但是会造成内存的碎片化(内存块中是可使用小内存块，造成大内存块不能使用这块内存，这些小小内存块也不能使用) 因为内存碎片化的问题诞生了   标记整理法，就是标记法之后，将有用的数据堆内存空间移动在一起，释放更多连续的堆空间,但是这种做法带来 很大的开销，因为需要不断的扫描内存和移动内存 复制回收法。将堆内存分为from和To两个相同的堆内存空间。程序执行时，使用from的堆空间。垃圾回收时会扫描from 的堆内存空间，将有用的数据复制到To的堆空间上。垃圾回收结束时，将To堆空间设置为From堆空间。将原来的from 堆空间全部回收后置为Ton堆空间。但是复制回收法只会使用一般的堆内存空间，造成堆内存空间利用率不高  分代法回收：大部分对象都会在年轻时候死亡（弱分代假说）把新建的对象称之为新生代对象。经过特定次数的GC(垃圾回收)数据依然有用的对象称为 老年代对象。而大部分会在新生代对象就会垃圾回收了，在结合复制回收法使用   计数法回收  引用计数指的是对象被引用的次数，程序在运行过程中会更新引用次数。对象引用越多，计数越大，当计数为0时，回收该对象（堆内存空间） 引用计数法可以在运行中更新对象的计数，可以及时判断计数为 0的对象，然后对其及时回收， 但是频繁的更新引用计数也会带来资源消耗   垃圾回收模式  增量式的垃圾回收模式：SWT是用户承程序停下工作处理垃圾回收，但是为了提高cpu执行效率，会减少SWT的时间，经垃圾回收工作分多次进行（用户程序与垃圾回收交替执行） 三色不变式：在增量式垃圾回收模式在进行垃圾回收时，会造成用户程序对标色的数据进行更改，当在次执行垃圾回收时，可能会将有用的数据当作垃圾回收了，在标色法中，当黑色数据节点可以引用白色的数据节点，但是没有灰色节点能引用这个白色节点，白色数据节点就被当作垃圾被回收 避免这样的发生，在垃圾回收时建立读写屏障。在三色中确保黑色的数据节点不引用白色的数据节点，就不会误判有用的数据当作垃圾回收了，这种叫做：强三色不变式 如果当黑色的数据节点能引用白色数据节点，同时确保回收节点也能引用白色节点，也能避免有用的数据被当作垃圾回收，这叫：弱三色不变式  并行垃圾回收：在多核下，使用多线程对垃圾回收，需要做好的负载均衡和规避数重复处理带来的问题，如在复制回收中，可能将同样的数据从from复制到to 并发垃圾回收：垃圾回收与用户程序并发执行，可能会造成垃圾回收与用户程序的资源竞争等问题等 主体并发回收：在时刻使用swt回收，在莫时刻又使用并发垃圾回收 主体并发增量式回收: 是融合了增量式的垃圾回收模式和主体并发回收模式   参考文献 1.</description>
    </item>
    
    <item>
      <title>进程、线程、协程</title>
      <link>https://zcj-git520.github.io/p/c/c-/</link>
      <pubDate>Tue, 28 Sep 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/c/c-/</guid>
      <description>理解进程与线程 进程  进程是程序一次动态执行过程、进程是操作系统分配资源(内存、io资源、cpu等)和资源调度的基本单位。程序是指令、数据及其组织形式的描述，进程是程序的实体。 进程是由 进程控制块PCB、相关程序段和该程序段进行操作的数据结构集三个部分组成。 进程的五中状态：创建、就绪、运行、阻塞、终止 五种状态转换如图所示：   线程  线程是cup调度和分配的基本单位也是cup执行的最小单位, 有独立的栈空间，共享堆空间。  进程与线程的关系  一个进程可以创建和撤销多个线程， 一个进程必须有一个线程(主线程), 线程共享进程所有资源，进程是线程的容器，关系如图所示：
  并发与并行 并发  并发：多进程(线程)程序在一个核cup串行运行，当一个进程(线程)阻塞的时候，切换到另外等待执行的进程(线程) 如图
  并行  并行：多线程程序在多核cup并行运行，如图
  用户态和内核态(用户空间和内核空间) 特权级划分  cpu一共有0～4四个特权级，R0级最高，R3级最低。用户态指的是：程序运行在R3级以上，通常在应用程序中运行，内核态是指：程序运行在R0级以上，通常在内核中运行。一般来说，我们写的应用程序就是运行在R3级衣以上。  3中种用户态与内核态的切换   系统调用：用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。
  异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。
  外围设备的中断： 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作的完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。
  用户态与内核态结构如图：

  用户态与内核态的切换是需要开销
  来源：linux用户态和内核态理解(https://www.cnblogs.com/weifeng1463/p/11660260.html)
  进程与线程用户态到内核态的开销   多进程(线程)可以提高cpu的利用率，减少程序阻塞带来cpu闲置的情况，也就是提升cpu的运行时间片，但是过多的创建进程(线程)也会花费额外的cpu时间片进行进程(线程)的花销。进程的创建、就绪、运行、阻塞、终止，这些都会带来cup花销。例如在32位的操作系统中创建一个进程需要开辟4GB的虚拟内存空间，创建一个线程需要占用约4MB的内存。</description>
    </item>
    
    <item>
      <title>syslog日志转发配置</title>
      <link>https://zcj-git520.github.io/p/syslog%E6%97%A5%E5%BF%97%E8%BD%AC%E5%8F%91%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 20 Sep 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/syslog%E6%97%A5%E5%BF%97%E8%BD%AC%E5%8F%91%E9%85%8D%E7%BD%AE/</guid>
      <description>服务器配置(服务器平台：x86) Rsyslog简介  Rsyslog是一个 syslogd 的多线程增强版，在syslog的基础上扩展了很多其他功能，如数据库支持(MySQL, PostgreSQL、Oracle等)、日志内容筛选、定义日志格式模板等。除了默认的udp协议外，rsyslog还支持tcp协议来接收日志。 目前的linux的发行版都切换为rsyslog  安装Rsyslog  Linux的发行版中预先安装了Rsyslog,无需安装，rsyslogd –v 查看版本 若未安装，以下是安装步骤： 1.ubuntu：sudo apt install rsyslog 2.CentOS：yum install rsyslog  Rsyslog.conf配置文件详解 配置文件位置：/etc/rsyslog.conf #### MODULES #### #定义日志的模块。 $ModLoad imuxsock #imuxsock为模块名，支持本地系统日志的模块。 $ModLoad imjournal #imjournal为模块名，支持对系统日志的访问。 #$ModLoad imklog #imklog为模块名，支持内核日志的模块。 #$ModLoad immark #immark为模块名，支持日志标记。 # Provides UDP syslog reception #提供udp syslog的接收。 #$ModLoad imudp #imudp为模块名，支持udp协议。 #$UDPServerRun 514 #允许514端口接收使用udp和tcp转发来的日志。 # Provides TCP syslog reception #提供tcp syslog的接收。 #$ModLoad imtcp #imtcp为模块名，支持tcp协议。 #$InputTCPServerRun 514 #### GLOBAL DIRECTIVES #### #定义全局日志格式的指令。 # Where to place auxiliary files $WorkDirectory /var/lib/rsyslog #工作目录。 # Use default timestamp format $ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat #定义日志格式默认模板。 $IncludeConfig /etc/rsyslog.</description>
    </item>
    
    <item>
      <title>我的第一份博客</title>
      <link>https://zcj-git520.github.io/p/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%BB%BD%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Sat, 04 Sep 2021 10:05:40 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%BB%BD%E5%8D%9A%E5%AE%A2/</guid>
      <description>为什么写博客  总结开发中遇到的问题。工作过后发现自己并不擅长对知识点的总结，导致总是遇到相同的问题，过段时间需要重新查找解决方案 记录学习的知识，不断的温习。学的东西过于碎片化，导致知识不成体系。时间长了，碎片的知识也忘记了 提升自己的专业技能。通过写博客提升自己的能力 形成自己的技术栈，遇到的志同道合的朋友  为什么选择hugo来搭建自己的博客  Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 操作简单，使用Markdown直接生成静态网页 免费且以维护, 在github上就可供他人访问，无需购买服务器，维护简单 发表文章直接push到自己仓库即可  下载hogo的源码  git clone https://github.com/gohugoio/hugo.git
git branch 查看单前代码的分支
git branch -a 查看全部分支
git checkout branch 切换分支
git branch 分支名 创建自己的本地分子
 编译源码  在master分支下，在main.go 的目录下使用命令: go build 在目录下生成hugo.exe 在cmd下使用hugo 查看是否编译成功 编译成功 会打印hugo的版本 安装成功  生成站点  使用命令：hugo new site /目录 cd /目录 查看到   ▸ archetypes/ ▸ content/ ▸ layouts/ ▸ static/ config.toml   创建站点成功  创建md文章  使用命令: hugo new 文章名.</description>
    </item>
    
  </channel>
</rss>
