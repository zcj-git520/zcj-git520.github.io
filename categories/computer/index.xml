<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>知识学习 on Chengji Zhao&#39;s blog</title>
    <link>https://zcj-git520.github.io/categories/computer/</link>
    <description>Recent content in 知识学习 on Chengji Zhao&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 25 Jun 2025 22:00:38 +0800</lastBuildDate><atom:link href="https://zcj-git520.github.io/categories/computer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LangGraph预构建Agent</title>
      <link>https://zcj-git520.github.io/p/langgraph%E9%A2%84%E6%9E%84%E5%BB%BAagent/</link>
      <pubDate>Wed, 25 Jun 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/langgraph%E9%A2%84%E6%9E%84%E5%BB%BAagent/</guid>
      <description>LangGraph 预构建 Agent 智能代理（Agent）系统已成为连接用户与复杂功能的重要桥梁。LangGraph 作为一个强大的框架，为开发者提供了构建健壮、可投入生产的代理系统的丰富工具。
一、Agent 核心组件解析 LangGraph 预构建的 Agent 由三个核心部分构成，它们协同工作，使 Agent 能够理解用户需求、执行任务并返回结果：
1.大型语言模型（LLM）
这是 Agent 的 &amp;ldquo;大脑&amp;rdquo;，负责理解文本、生成响应并决定下一步行动。LLM 在一个循环中运行：每次迭代中选择工具、提供输入、接收结果（观察），并根据观察指导下一个动作，直到收集到足够信息响应用户。
2.工具（Tools）
工具是 Agent 可以调用的函数或 API，用于执行特定任务。例如：
  网络搜索工具
  数据库查询工具
  第三方服务调用工具（如天气查询、IP 解析等）
  工具使 Agent 能够突破自身知识局限，获取实时信息或执行复杂操作。
3.提示（Prompt）
提示是指导 LLM 行为的文本指令。它定义了 Agent 的角色、目标和行为准则。例如：&amp;ldquo;你是一个智能小助手，能够使用工具帮助用户查询天气和城市信息&amp;rdquo;。
二、LangGraph 的核心优势 LangGraph 为构建 Agent 系统提供了多项关键功能，使其在实际生产环境中表现出色：
  内存集成：同时支持短期（会话内）和长期（跨会话）内存，实现有状态行为，让 Agent 能够记住历史对话和用户偏好。
  人在回路控制：允许执行过程在任何点暂停，等待人工反馈或审批，支持异步干预，这对于需要人工确认的敏感操作至关重要。
  流式传输支持：能够实时流式传输 Agent 状态、模型输出和工具结果，提升用户体验。
  部署工具：提供完整的测试、调试和部署工具链，简化从开发到生产的流程。
  三、创建和配置 Agent 使用 LangGraph 创建预构建 Agent 非常简单，以下是基本步骤：</description>
    </item>
    
    <item>
      <title>智能知识检索系统</title>
      <link>https://zcj-git520.github.io/p/%E6%99%BA%E8%83%BD%E7%9F%A5%E8%AF%86%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Mon, 02 Jun 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%99%BA%E8%83%BD%E7%9F%A5%E8%AF%86%E6%A3%80%E7%B4%A2%E7%B3%BB%E7%BB%9F/</guid>
      <description>构建智能知识检索系统：基于 Streamlit 与 LangChain 的实现方案 在信息爆炸的时代，如何高效管理和检索文档中的知识成为一项重要需求。本文将介绍一个基于 Streamlit 和 LangChain 构建的智能知识检索系统，该系统支持多种格式文档的上传、解析与检索，能够通过自然语言交互为用户提供精准的知识问答服务。
系统架构概览 该智能知识检索系统主要由以下几个核心模块构成：
 用户界面层：基于 Streamlit 构建的 Web 交互界面 文档处理层：负责解析多种格式的文档内容 向量数据库层：使用 ChromaDB 存储文档向量，支持高效检索 智能问答层：基于 LangChain 的 Agent 机制实现问答逻辑  系统的核心流程是：用户上传文档 → 系统解析并存储文档向量 → 用户提问 → 系统检索相关文档 → 生成回答。

核心代码解析 类结构设计 系统的核心功能封装在KnowledgeBaseSystem类中，该类通过组合模式整合了模型、数据库和文档处理器：
class KnowledgeBaseSystem: def __init__(self, model, chromadb: ChromaDB, document_processor: Knowledge): self.chromadb = chromadb self.model = model self.document_processor = document_processor 页面配置与初始化 setup_page_config方法负责初始化 Streamlit 页面配置和会话状态：
def setup_page_config(self): &amp;#34;&amp;#34;&amp;#34;设置页面配置&amp;#34;&amp;#34;&amp;#34; st.set_page_config( page_title=&amp;#34;智能知识检索系统&amp;#34;, layout=&amp;#34;wide&amp;#34;, page_icon=&amp;#34;📚&amp;#34; ) st.</description>
    </item>
    
    <item>
      <title>检索增强生成（RAG）</title>
      <link>https://zcj-git520.github.io/p/%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag/</link>
      <pubDate>Sun, 25 May 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag/</guid>
      <description>检索增强生成（RAG）：从原理到工程实践的深度解析 在大语言模型（LLM）快速迭代的今天，如何让模型既具备通用智能，又能精准调用特定领域知识，成为企业级 AI 应用的核心挑战。检索增强生成（Retrieval-Augmented Generation，RAG）技术通过 &amp;ldquo;检索 + 生成&amp;rdquo; 的协同模式，成功解决了纯 LLM 在知识时效性、准确性和领域适配性上的短板，成为连接通用 AI 与垂直业务的关键桥梁。本文将从技术原理出发，结合实战代码，全面剖析 RAG 的实现路径与工程实践。
一、RAG 的基本概念和原理 RAG 技术的核心思想源于信息检索与自然语言生成的融合：在生成回答前，先从外部知识库中检索与问题相关的事实性信息，再让模型基于这些 &amp;ldquo;证据&amp;rdquo; 进行推理生成。这种机制将 LLM 的 &amp;ldquo;闭卷考试&amp;rdquo; 模式转变为 &amp;ldquo;开卷考试&amp;rdquo;，从根本上解决了三个核心问题：
 知识时效性局限：LLM 训练数据存在截止日期，无法应对动态更新的业务知识（如 2025 年的新法规、企业内部文档更新）； 幻觉生成风险：模型可能编造不存在的事实（如虚构产品参数、学术引用），在医疗、法律等领域可能引发严重后果； 领域知识壁垒：通用模型对专业领域（如网络安全、金融风控）的深度知识掌握不足，难以生成精准回答。  从技术本质看，RAG 是一种混合增强架构：通过检索模块将外部知识引入生成过程，形成 &amp;ldquo;知识输入 - 模型推理 - 结果输出&amp;rdquo; 的闭环。这种架构既保留了 LLM 的上下文理解与自然语言生成能力，又通过外部知识库实现了知识的可控更新与精准调用。
流程图
可以加密文本块和向量（向量也可能泄露原始语义），从而使用密文进行存储与网络传输。对于向量加密需采用特殊加密算法使得加密后向量仍能进行相似度检索。 加密流程图
二、RAG 的工作流程 一个完整的 RAG 系统可分为离线知识库构建与在线问答交互两大阶段，包含五个核心步骤：
1. 离线知识库构建  文档采集：收集结构化（如 Excel 表格）、半结构化（如 PDF 手册）和非结构化（如图片、音频转文本）数据； 文档预处理：对原始数据进行清洗（去噪、格式统一）、拆分（按语义单元切割长文档）； 向量编码：通过嵌入模型（Embedding Model）将文本片段转化为高维向量，捕捉语义特征； 向量存储：将向量及关联文本存入向量数据库，建立可检索的知识索引。</description>
    </item>
    
    <item>
      <title>LangChain 自定义工具</title>
      <link>https://zcj-git520.github.io/p/langchain-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Tue, 25 Mar 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/langchain-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B7%A5%E5%85%B7/</guid>
      <description>LangChain 自定义工具 引言 在构建 LangChain 代理时，工具(Tools)是核心组件之一。工具允许代理与外部世界交互，执行特定任务。本文将深入探讨如何在 LangChain 中创建和使用自定义工具，包括内置工具的使用和自定义工具的多种实现方式。
工具的基本组成 每个工具都包含几个关键组件：
 name (str): 必需且必须在工具集中唯一 description (str): 可选但建议提供，代理用它来决定如何使用工具 return_direct (bool): 默认为 False args_schema (Pydantic BaseModel): 可选但建议提供，可用于验证参数或提供few-shot示例  内置工具的使用 LangChain 提供了许多内置工具，请访问工具集成查看可用工具列表，在使用第三方工具时，请确保您了解工具的工作原理、权限情况：
维基百科查询工具 def get_wikipedia(query): api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100) tool = WikipediaQueryRun(api_wrapper=api_wrapper) result = tool.run(query) return result Google 文字转语音工具 def google_tts(text): tts = GoogleCloudTextToSpeechTool() speech_file = tts.run(text) return speech_file 自定义工具的实现方式 1. 使用 @tool 装饰器 这是定义自定义工具最简单的方式：
from langchain_core.tools import tool @tool def search_city_tool(city: str) -&amp;gt; str: &amp;#34;&amp;#34;&amp;#34;搜索城市信息&amp;#34;&amp;#34;&amp;#34; url = f&amp;#34;https://api.</description>
    </item>
    
    <item>
      <title>LangChain 多模态输入处理</title>
      <link>https://zcj-git520.github.io/p/langchain-%E5%A4%9A%E6%A8%A1%E6%80%81%E8%BE%93%E5%85%A5%E5%A4%84%E7%90%86/</link>
      <pubDate>Tue, 25 Feb 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/langchain-%E5%A4%9A%E6%A8%A1%E6%80%81%E8%BE%93%E5%85%A5%E5%A4%84%E7%90%86/</guid>
      <description>LangChain 多模态输入处理 引言 随着大模型技术的发展，多模态能力已成为AI应用的重要方向。LangChain提供了强大的多模态处理能力，允许开发者将文本、图像、PDF等多种输入类型结合使用。本文将深入探讨LangChain中的多模态输入处理机制。
多模态基础概念 多模态(Multimodality)是指模型能够同时处理和生成多种类型的数据，包括但不限于：
 文本(Text) 图像(Image) 音频(Audio) 视频(Video) 文档(Document)  LangChain多模态架构 LangChain的多模态处理主要基于以下组件：
 HumanMessage: 承载多模态内容的核心消息类 内容类型标识(type字段): 标识不同媒体类型 数据来源标识(source_type字段): 区分本地base64或URL  多模态输入实现方式 1. 基于Base64的本地文件输入 def input_by_base64(self, prompt_txt, image_data, type): try: message = HumanMessage( content=json.dumps([ {&amp;#34;type&amp;#34;: &amp;#34;text&amp;#34;, &amp;#34;text&amp;#34;: prompt_txt}, {&amp;#34;type&amp;#34;: type, &amp;#34;data&amp;#34;: image_data, &amp;#34;source_type&amp;#34;: &amp;#34;base64&amp;#34;}, ]) ) china = self.model.qwen_llm() return china.invoke([message]).content except Exception as e: print(e) return &amp;#34;&amp;#34; 使用场景：
 处理本地存储的图片、PDF等文件 需要数据隐私保护的场景 离线应用环境  2. 基于URL的网络资源输入 def input_by_url(self, prompt_txt, url, type): try: message = HumanMessage( content=json.</description>
    </item>
    
    <item>
      <title>LangServe</title>
      <link>https://zcj-git520.github.io/p/langserve/</link>
      <pubDate>Sat, 25 Jan 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/langserve/</guid>
      <description>LangServe 实践 核心功能 LangServe 是一个专为 LangChain 设计的部署工具，可将 LangChain 可运行对象和链快速转化为 REST API，主要特点包括：
 自动化 API 生成
通过 FastAPI + Pydantic 自动推断输入/输出模型，生成带数据验证的 REST 端点 多协议支持
提供 /invoke（单次调用）、/batch（批量处理）、/stream（实时流）等标准化端点 调试友好  /stream_log 实时流式传输中间步骤 0.0.40+ 版本新增 /stream_events 简化流式处理   生产级架构
基于 uvloop 和 asyncio 实现高并发，支持 Swagger 自动文档  技术优势    特性 说明     声明式验证 通过 Pydantic 模型自动生成 JSON Schema，提供类型检查和清晰错误提示   无缝集成 内置 LangChain.js 客户端，支持 Python/JavaScript 调用   零模板代码 自动生成 API 文档和 Playground 调试界面    典型工作流 定义 LangChain 对象</description>
    </item>
    
    <item>
      <title>LCEL与LangChain流式处理指南</title>
      <link>https://zcj-git520.github.io/p/lcel%E4%B8%8Elangchain%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sat, 25 Jan 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/lcel%E4%B8%8Elangchain%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86%E6%8C%87%E5%8D%97/</guid>
      <description>LCEL与LangChain流式处理指南 什么是LCEL？ LCEL（LangChain Expression Language）是一种强大的工作流编排工具，能够从基本组件构建复杂任务链条(chain)，并具有以下生产级特性：
 🚀 一流的流式支持：直接从LLM流式传输标记到输出解析器 ⚡ 异步支持：同一代码可同步/异步运行，适合原型到生产 🔀 优化的并行执行：自动并行可并行步骤 🔄 重试和回退：配置可靠性机制 🔍 中间结果访问：实时监控和调试 📐 输入输出模式：自动生成Pydantic/JSONSchema验证  Runnable接口标准 LangChain组件通过Runnable协议实现标准化调用：
同步方法  stream(): 流式返回响应块 invoke(): 调用链处理输入 batch(): 批量处理输入列表  异步方法  astream(): 异步流式响应 ainvoke(): 异步调用 abatch(): 异步批量处理 astream_log(): 流式中间步骤+最终结果 astream_events(): 流式链事件(Beta)  组件I/O类型    组件 输入类型 输出类型     提示 字典 提示值   聊天模型 字符串/消息列表/提示值 聊天消息   LLM 字符串/消息列表/提示值 字符串   输出解析器 LLM/聊天模型输出 解析器特定   检索器 字符串 文档列表   工具 字符串/字典 工具特定    流式处理(Stream) 核心方法  同步流式：stream() 异步流式：astream()  关键特性  实时返回每个处理块 要求所有步骤支持流式处理 复杂度范围：  简单：LLM令牌流 复杂：部分JSON结果流    最佳实践 建议从LLM组件开始逐步构建流式处理链。</description>
    </item>
    
    <item>
      <title>LangChain 框架解析</title>
      <link>https://zcj-git520.github.io/p/langchain-%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Sat, 18 Jan 2025 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/langchain-%E6%A1%86%E6%9E%B6%E8%A7%A3%E6%9E%90/</guid>
      <description>LangChain 框架解析 一、简介  定义：开源Python AI应用开发框架 核心价值：降低基于LLM的AI应用开发门槛 核心功能：  LLM集成（文本生成/问答/翻译/对话） 创意应用构建 标准化AI工作流    二、核心特性    特性 功能描述 应用场景     LLM &amp;amp; 提示管理 统一API抽象层 + 提示模板 标准化模型调用   链(Chain) 预封装任务工作流 问答系统/SQL生成   LCEL 表达式语言编排任务流 自定义AI流程   RAG 外部数据增强生成 知识库问答   Agents LLM决策+外部系统调用 自动化任务执行   模型记忆 对话历史记忆 多轮对话系统    LangChain 特性：
● LLM 和提示（Prompt）：LangChain 对所有 LLM 大模型进行了 API 抽象，统一了大模型访问 API，同时提供了 Prompt 提示模板管理机制。</description>
    </item>
    
    <item>
      <title>后端的安全和加密</title>
      <link>https://zcj-git520.github.io/p/%E5%90%8E%E7%AB%AF%E7%9A%84%E5%AE%89%E5%85%A8%E5%92%8C%E5%8A%A0%E5%AF%86/</link>
      <pubDate>Sun, 15 Jan 2023 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%90%8E%E7%AB%AF%E7%9A%84%E5%AE%89%E5%85%A8%E5%92%8C%E5%8A%A0%E5%AF%86/</guid>
      <description>后端的安全  在后端的应用程序中的安全问题都是亲信了第三方提供的数据造成的，例如：对于用户输入的数据。在对其进行验证之前都应该视为不安全的数据，把不安全的数据用于数据库的查询就可能会造成sql注入的问题  预防CSRF攻击 CSRF(跨站请求伪造)：攻击者可以盗用你的登录信息，以你的身份模拟发送各种请求，所以遇到CSRF攻击时，将对终端用户数据和操作指令构成严重的威胁，当受攻击的终端具备管理账号时，CSRF攻击都会危及整个后端的应用
​	
CSRF的工作原理：   CSRF攻击主要是因为web的隐式身份验证机制，web的身份验证机制可以保证一个请求是来自某一个服务器。但却无法保证该请求是用户批准发送的
  CSRF的攻击过程可分为：
 登录受信任的网站A,并在本地生成cookie 在不退出A的情况下，访问了危险的网站B    CSRF的预防  可以从服务端和客户端两个方向入手  服务端的预防：  正确的使用GET,POST,和COOKie 在非GET请求中增加伪随机数 在非GET方式的请求中增加伪随机数有三种方式： 为每一个用户生成唯一的cookie token，所有的表单都包含同一个伪随机数 每一个请求使用的验证码 在不同表单包含一个不同的伪随机数   确保输入的过滤：过滤用户数据是后后端的基础，它是验证数据的合法性的过程：  识别数据，即确定数据的来源 过滤数据，即确保需要的数据入库 确定数据，即确定数据的安全      避免XSS的攻击 ​	xss(跨站脚本攻击)：是一种常见的web安全漏洞，它允许攻击者将恶意代码植入到提供给其他用户使用的页面中，不同于大多数攻击一般只涉及攻击者和受害者，xss涉及到三方，即攻击者，客户端和后端服务器，xss攻击目标为盗取存储在客户端的cookie或者其他网站用户识别客户端身份的敏感信息，一旦获取到合法的用户信息后，攻击者甚至可以假冒合法于网站进行交互
xss 分类   存储型xss:主要是出现让用户输入数据，应用程序从数据库查数据，在页面中显示，攻击者在相关页面中输入恶意的脚本数据后，用户浏览时，就可能会受到攻击

  反射性xss:主要做法是将脚本代码加入url地址的请求参数中，请求参数进入程序后在页面直接输出，用户点击类似链接可能会受到攻击

  xss原理  后端应用在未对用户提交请求的数据做充分的检查过滤，允许用户在提交数据中参入html代码，并将未经过转义的恶意的代码输出到第三方的应用的浏览器解释执行，是导致xss漏洞的主要产生原因  预防xss  坚决不要相信用户的任何输入并过滤输入中的所有特殊字符，目前有两种方法：  过滤特殊字符 使用http头指定类型    避免sql注入  sql注入是后端开发中最常见的一种安全漏洞，可以使用它获取数据库中的获取敏感的信息，或者利用数据库的热特性执行添加用户，导出文件等一系列恶意，操作甚至可能获取数据库或者系统的用户的最高权限 造成sql注入的原因是因为程序没有有效的过滤，用户输入时攻击者成功向服务器提交恶意代码的sql查询代码，程序在接收到错误后的将攻击者的输入作为查询语句的一部分，导致原始查询逻辑被迫改变。额外执行供攻击者精心构造的恶意代码 sql查询是可以被修改，sql查询是可以绕开访问的控制，从而绕过身份验证和权限检查，有可能sql查询去与运行主机系统级别的命令  预防sql  严格限制后端应用的数据库的权限，给用户提供满足功能即可 检查输入的数据是否具有所有的期望格式。严格控制变量类型 对数据库的特殊字符进行转义处理，或者编码转换 所有的查询语句，建议使用数据库提供哦那个的参数化的接口。而不是将输入的变量嵌入到sql语句中，即不要拼接sql语句 在应用发布前，建议使用专业的sql注入检查工具进行检测以及时修补并发现sql注入的漏洞 避免前端打印sql错误，比如类型错误，子段不匹配等暴露sql语句  存储密码  普通方案：常用的密码存储方案是将明文密码做单向的哈希后存错，单向哈希算法有一特征：无法通过哈希后的摘要恢复出原始数据，常用的额单向哈希算法包括：SHA-256,SHA-1  单向哈希的两大特性：  同一密码进行哈希后，得到的唯一确定的摘要 计算速度快   结合单向哈希的两大特性：攻击者可以将所有的密码常见的组合进行单向哈希，得到一个摘要组合(rainbow table), 然后于数据库中的进行对比即可得到密码   进阶方案：先将用户输入的密码进行单向哈希加密，在将获取的摘要的前后加上只有管理员知道的随机数，在进行单向哈希 专家方案：故意增加密码计算所消耗的资源和时间，使得任何人都不可能获取到相同的资源，建立所需要的(rainbow table)  </description>
    </item>
    
    <item>
      <title>linux 性能调试技术</title>
      <link>https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Thu, 15 Sep 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF/</guid>
      <description>linux 常用查看可执行工具   readelf：可以查看可执行文件相关信息
 readif -h 查看头信息  readelf –d 查看动态库依赖     File:
 file [可行政文件] 执行文件架构信息、动态、静态  ldd 查看动态库     Strip
 -I &amp;ndash;input-target= 假定输入文件的格式为 -O &amp;ndash;output-target= 以格式创建输出文件 -F &amp;ndash;target= 设置输入、输出的文件格式为 -p &amp;ndash;preserve-dates 复制上次修改或者操作的时间到输出文件中 -R &amp;ndash;remove-section= 删除输出文件中段信息 -s &amp;ndash;strip-all 删除所有符号信息和重定位信息 -g -S -d &amp;ndash;strip-debug 删除所有调试信息和段信息 &amp;ndash;strip-unneeded 删除所有重定位中不需要的符号信息 &amp;ndash;only-keep-debug 删除调试信息以外的其他所有信息 -N &amp;ndash;strip-symbol= 不拷贝符号信息 -K &amp;ndash;keep-symbol= 不去除符号信息 -w &amp;ndash;wildcard 在符号中使用通配符 -x &amp;ndash;discard-all 去除所有非全局符号    Linux 进程调试工具  pidof 查命令对应的进程编号 (pidof bash)  Ps  基础参数  -A, -e 选择所有进程 -a 选择除了会话领导和与终端无关的进程以外的所有进程。 a BSD格式，通常与x同时出现，显示所有进程   选择性参数  -C 根据cmdlist中的命令 输出 -p, &amp;ndash;pid 根据进程id进行选择输出 &amp;ndash;ppid 根据父进程ID选择输出 -U, &amp;ndash;User 根据真实用户ID(RUID)或用户名选择   显示线程  -L 显示线程相关信息   杂项  L 列出所以支持的格式（应用与-o中的输出格式） e 输出环境变量（在指令后面）   得到线程信息  ps -eLf      Pstree  查看进程之间的父子关系    top    第一行显示的是系统的概况：</description>
    </item>
    
    <item>
      <title>proto3 语法学习</title>
      <link>https://zcj-git520.github.io/p/proto3-%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Fri, 05 Aug 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/proto3-%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0/</guid>
      <description>proto3 语法学习 基本规范   文件以.proto为文件后缀，除了结构体外，其他语句以分号结束
  结构定义可以包含：message、service、enum
  rpc方法定义结尾的分号可有可无
  Message命名采用驼峰命名方式，字段命名采用小写字母加下划线分隔方式；举例：
message ServerMessage{	required string server_name = server1;}  Enums类型名采用驼峰命名方式，字段名采用带大写字母加下划线分隔方式；举例：
enum Sought{	FIRST_VALUE = 100;	SECONED_VALUE = 1200;}  Service类型采用驼峰命名方式；举例：
service UserService{ rpc Login(LoginRequest)return(LoginResponse);}字段规则   字段格式：限定修饰符|数据类型|字段名称|=|字段编码值|[字段默认值]
  限定修饰符号 required\optional\repeated
 required:表示是一个必须的字段，必须要发送给对方，在发送之前必须设置该字段的值，对于接收方，必须能够识别该字段的意思，在发送之前没有设置required字段或者无法识别该字段都会引起编码异常，导致消息被丢弃 optional:表示为可选字段，对于发送方，在发送消息时，可以选择性设置或者不设置该字段值，对于接收方，如果能够识别可选字段就进行相应的处理，如果无法识别，则就忽略该字段，消息中的其他字段正常处理。因为optional字段的特性，很多接口在升级版本中把后面添加大的字段都统一设置为optional字段，这样在老版本无法升级的时，也能正常于新的软件进行通信，只不过新的字段无法识别而已，因为并不是每个节点都需要新的功能，因此可以做到按需升级和平滑过渡 repeated:表示该字段可以包含0-n个元素，其特性和optional一样，但是每一次可以包含个多个值，可以看作是在传递一个数组的值    数据类型：protobuf定义了一套基本的数据类型，几乎可以映射到c++\java等语言的基础数据类型

    字段名称
 字段名称的命名与c、c++、java等语言的变量命名方式几乎相同 protobuf建议字段的命名采用采用下滑线分割的驼峰式    字段编码值
 有了字段编码值，通信双方才能互相识别对方的字段，相同的编码值，其限定修饰符和数据类型必须相同，编码值的范围为：1-2^32 其中1-15的编码时间和空间效率都很高，编码值越大，其编码的是时间和空间效率就越低，所以建议把经常要传递的值把其字段编码设置为1-15之前的值 1900-2000编码值为Google protobuf系统内部保留值，建议不要使用    字段默认值</description>
    </item>
    
    <item>
      <title>设置自己的编辑器</title>
      <link>https://zcj-git520.github.io/p/%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%B7%B1%E7%9A%84%E7%BC%96%E8%BE%91%E5%99%A8/</link>
      <pubDate>Sat, 23 Jul 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%B7%B1%E7%9A%84%E7%BC%96%E8%BE%91%E5%99%A8/</guid>
      <description>设置自己的编辑器 简单介绍  基于vim 设计自己的编辑器 使用vim插件 以下是编辑器的.vimrc  配置如下 set nocompatible &amp;quot; be iMproved, required filetype off &amp;quot; required &amp;quot; set the runtime path to include Vundle and initialize set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() &amp;quot; alternatively, pass a path where Vundle should install plugins &amp;quot;call vundle#begin(&#39;~/some/path/here&#39;) &amp;quot; let Vundle manage Vundle, required Plugin &#39;VundleVim/Vundle.vim&#39; Plugin &#39;dense-analysis/ale&#39; Plugin &#39;preservim/nerdtree&#39; Plugin &#39;preservim/nerdcommenter&#39; Plugin &#39;ludovicchabant/vim-gutentags&#39; Plugin &#39;Valloric/YouCompleteMe&#39; Plugin &#39;Shougo/neocomplete.vim&#39; Plugin &#39;vim-scripts/taglist.vim&#39; &amp;quot; Plugin &#39;rstacruz/sparkup&#39;, {&#39;rtp&#39;: &#39;vim/&#39;} call vundle#end() &amp;quot; required filetype plugin indent on &amp;quot; required set sw=4 set ts=4 set et set smarttab set smartindent set lbr set fo+=mB set sm set selection=inclusive set wildmenu set mousemodel=popup &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;ale &amp;quot;始终开启标志列 let g:ale_sign_column_always = 1 let g:ale_set_highlights = 0 &amp;quot;自定义error和warning图标 let g:ale_sign_error = &#39;✗&#39; let g:ale_sign_warning = &#39;⚡&#39; &amp;quot;在vim自带的状态栏中整合ale let g:ale_statusline_format = [&#39;✗ %d&#39;, &#39;⚡ %d&#39;, &#39;✔ OK&#39;] &amp;quot;显示Linter名称,出错或警告等相关信息 let g:ale_echo_msg_error_str = &#39;E&#39; let g:ale_echo_msg_warning_str = &#39;W&#39; let g:ale_echo_msg_format = &#39;[%linter%] %s [%severity%]&#39; &amp;quot;普通模式下，sp前往上一个错误或警告，sn前往下一个错误或警告 nmap sp (ale_previous_wrap) nmap sn (ale_next_wrap) &amp;quot;s触发/关闭语法检查 nmap s :ALEToggle &amp;quot;a查看错误或警告的详细信息 nmap a :ALEDetail let g:ale_linters = { \ &#39;c++&#39;: [&#39;clang&#39;], \ &#39;c&#39;: [&#39;clang&#39;], \ &#39;python&#39;: [&#39;pylint&#39;], \ &#39;golang&#39;:[&#39;golangci-lint&#39;], \} &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot; &amp;quot;将该配置写进.</description>
    </item>
    
    <item>
      <title>redis 常用命令的实践</title>
      <link>https://zcj-git520.github.io/p/redis-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%9A%84%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 01 Jul 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/redis-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%9A%84%E5%AE%9E%E8%B7%B5/</guid>
      <description>redis 常用命令的实践 结构化与非结构化   关系型数据库
 结构化 关联性 sql查询 满足事务的ACID  ![](C:\Users\90953\AppData\Roaming
  非关系型数据
 非结构化 无关联性 非sql base(基础性的事务)    
redis 通用命令 通用指令是部分数据类型的，都可以使用的指令，常见的有：
 KEYS:查看符合模板的所有key del：删除指定的key exists:判读key是否存在 expire:给一个可以设置有效期（单位时间为s），有效期到时会自动删除key ttl:查看key的有效期  
string 类型常用命令 string类型是redis中最简单的存储类型，其value是字符串，字符串可以分为3类：
  string:普通字符串
  int：整数类型，可以自增或自减
  float:浮点型，可以自增或自减
无论是哪一种格式，底层都是字节数组形式存储，只不过是编码不同，字符串类型的最大空间不超过512M

  常用的命令有：   set:添加或者修改也存在的的一个string类型的键值对
  get:根据key获取string类型的value
  mset:批量添加多个stingl类型的键值对
  mget:根据多个key获取多个string类型的value
  incr:让一个int的key自增1</description>
    </item>
    
    <item>
      <title>Linux-mdadm工具学习</title>
      <link>https://zcj-git520.github.io/p/linux-mdadm%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Sun, 12 Jun 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/linux-mdadm%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/</guid>
      <description>mdadm mdadm是linux下的一款标准的RAID的管理工具
基本语法 mdadm [mode] [option] 目前支持 RAID0(striping), RAID1(mirroring), RAID4, RAID5, RAID6, RAID10, MULTIPATH和FAULTY
模式  Assemble：加入一个以前定义的阵列 Build：创建一个没有超级块的阵列 Create：创建一个新的阵列，每个设备具有超级块； -l,&amp;ndash;level: RAID级别 -n,&amp;ndash;raid-devices: 活动设备个数 -a {yes|no}: 是否自动为其创建设备文件 -c,&amp;ndash;chunk: CHUNK大小, 默认为64K，重要的参数,决定了一次向阵列中每个磁盘写入数据的大小 -x,&amp;ndash;spare-devices: 备用盘个数 Manage： 管理阵列(如添加和删除) Misc：允许单独对阵列中的某个设备进行操作(如停止阵列) Follow or Monitor:监控RAID的状态 Grow：改变RAID的容量或阵列中的设备数目 ；-n,&amp;ndash;raid-devices=: 活动设备个数-x,&amp;ndash;spare-devices=：备用盘个数-c,&amp;ndash;chunk=: CHUNK大小, 默认为64K，重要的参数,决定了一次向阵列中每个磁盘写入数据的大小-z,&amp;ndash;size=：阵列中从每个磁盘获取的空间总数-l,&amp;ndash;level=: RAID级别-p,&amp;ndash;layout=：设定raid5 和raid10的奇偶校验规则；并且控制故障的故障模式&amp;ndash;parity: 类似于&amp;ndash;layout&amp;ndash;assume-clean:目前仅用于 &amp;ndash;build 选项-R &amp;ndash;run: 强制激活RAID，使用这个选项，设备上有旧的元数据信息的提示会被忽略-N &amp;ndash;name=: 设定阵列的名称–-rounding：在linear array中的rounding factor，等于条带大小。  可用的[options]  -A，&amp;ndash;assemble：加入一个以前定义的阵列 -B,&amp;ndash;build:Build a legacy array without superblocks . -C，&amp;ndash;create：创建一个新的阵列 -Q&amp;ndash;query：查看一个device，判断它为一个md device或是一个md阵列的一部分 -D，&amp;ndash;detail：打印一个或多个md device的详细信息 -E，&amp;ndash;examine：打印device上的md superblock 的内容 -F，&amp;ndash;follow，&amp;ndash;monitor：选择Monitor模式 -G，&amp;ndash;grow：改变在用阵列的大小或形态 -h，&amp;ndash;help：帮助信息，用在以上选项后，则显示该选项信息&amp;ndash;help-options -V,&amp;ndash;version -V，&amp;ndash;verbose：显示细节 -b,&amp;ndash;brief：较少的细节。用于&amp;ndash;detail和&amp;ndash;examine选项 -f,&amp;ndash;force -c，&amp;ndash;config=：指定配置文件，缺省为/etc/mdadm/mdadm.</description>
    </item>
    
    <item>
      <title>Linux-Multi-Disk (MD)模块</title>
      <link>https://zcj-git520.github.io/p/linux-multi-disk-md%E6%A8%A1%E5%9D%97/</link>
      <pubDate>Mon, 30 May 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/linux-multi-disk-md%E6%A8%A1%E5%9D%97/</guid>
      <description>概述 Linux内核在多块设备的基础上，注册了一块特殊的设备，称为为MD设备。这个MD设备形成一个逻辑层，支持不同的RAID技术

MD模块是一个虚拟块设备，它属于块i/o子系统中的块设备驱动层，架构于物理块设备层；其有两层：RAID共性层和RAID个性层
 RAID共性层：它提取出各种级别的RAID的公共特性，依照块设备的实现模板向上层注册，同时向RAID个性层提供公共函数，以及接口注册函数 RAID个性层：是各种级别RAID的个性体现，它向RAID公共层注册个性接口，利用RAID公共层提供的公共函数，基于低层实现个性化功能  RAID模块对象   核心MD设备结构mddev及其成员磁盘设备结构mdk_rdev_t是系统中的两个关键结构。核心MD设备结构mddev_t是内核中RAID设备保存自身信息的结构体，它包括了完整的RAID设备的信息。成员磁盘设备结构mdk_rdev_t反映了组成MD设备的底层块设备的信息；
  MD设备处理可以有不同的特性，它指向一个MD个性结构体，有个性ND设备的操作表和操作的最终数据
  MD设备通过块设备号和块设备描述符（block_device）关联起来，低层成员磁盘也指向和它相对应的块设备描述符正是以块设备描述符为“纽带”，使得MD可以构建在其他的物理或虚拟磁盘设备之上，成为一个“栈式”块设备；

  MD模块初始化   MD模块加载时，它的初始化函数md_init将被执行;
  __register_blkdev函数:是维护主设备号和块设备名之间的关联,所有块设备模块初始化时，都应该调用这个函数
static void md_geninit(void) { pr_debug(&amp;quot;md: sizeof(mdp_super_t) = %d\n&amp;quot;, (int)sizeof(mdp_super_t)); proc_create(&amp;quot;mdstat&amp;quot;, S_IRUGO, NULL, &amp;amp;mdstat_proc_ops); } static int __init md_init(void) { int ret = -ENOMEM; md_wq = alloc_workqueue(&amp;quot;md&amp;quot;, WQ_MEM_RECLAIM, 0); if (!md_wq) goto err_wq; md_misc_wq = alloc_workqueue(&amp;quot;md_misc&amp;quot;, 0, 0); if (!md_misc_wq) goto err_misc_wq; md_rdev_misc_wq = alloc_workqueue(&amp;quot;md_rdev_misc&amp;quot;, 0, 0); if (!</description>
    </item>
    
    <item>
      <title>Linux-raid5学习</title>
      <link>https://zcj-git520.github.io/p/linux-raid5%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Sun, 15 May 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/linux-raid5%E5%AD%A6%E4%B9%A0/</guid>
      <description>RAID5模块 RAID5模块的对象，模块的执行过程及其同步和恢复过程
RAID5模块对象 对于RAID5，MD设备描述符（mddev）的private域指向RAID5私有配置结构r5conf。后者包含一个成员磁盘 数组，每一项都指向对应的成员磁盘描述符（mdk_rdev_t），而这些成员磁盘描述符被链入MD设备描述符的成员磁盘链表，并且有指针指向MD设备；

RAID5支持冗余，在条带中采用了校验和技术。对RAID5设备的正常读／写和同步／恢复／扩展等操作都是以条带为基本单位处理的，条带管理结构为“条带头”（stripe_head）。每个RAID5设备分配有固定数目的条带头，随着系统运行，这些条带头可能被挂载到RAID5设备的不同链表，被条带使用中的条带头结构还会链入RAID5的哈希表以便于查找
每个RAID5设备被分配一定数目的条带用于处理提交给它的请求，最大条带数目由max_nr_stripes域给出。这些条带根据其状态被链入到不同的链表。RAID5设备有以下五个不同的链表
 inactive_list为空闲的条带列表：在RAID5开始运行之初，所有的条带都在inactive_list中。在有请求到达时，为它分配并关联一个条带。条带处理完成，又被释放回到这个链表； handle_list为需要处理的条带列表：要处理的条带都会被添加到handle_list链表，RAID5守护线程就是根据这个链表进行处理的。条带被处理时，会被从链表中删除，暂时处于“游离”状态。一个条带需要多轮处理，每一轮处理完成之后，都被重新加入某个链表，最终又会被重新加入handle_list链表，开始新一轮处理。 bitmap_list为因等待位图更新而延迟的条带链表：如果在对RAID5设备进行写操作时突然掉电，就可能造成某些条带的不同步，有可能数据已经被写入成员磁盘，而校验和还没有被写入，又或者校验和已经被写入，而某些数据还没有被写入成员磁盘。当RAID5再次被重组以后，就需要进行同步处478理，而这需要我们知道哪些条带需要被同步，否则只能进行全面的同步，这样做显然开销非常大。位图就是为此目的而引入的。如果RAID5支持位图，每一个块会对应一个位图位，在进行写操作的时候，会先将对应的位图位置成1，这时写请求也被放入bitmap_list链表，只有在该位图位被成功冲刷到磁盘之后，才能处理这个写请求。当进行同步操作的时候，根据位图位，只同步那些被置为1的条带。采用位图策略最大的优点是减少了无谓的同步操作，提高了同步操作效率。 delayed_list为被延迟处理的条带链表：在有写请求到达条带的某个成员磁盘时，并不是立即将请求放handle_list准备处理，而是先放入delayed_list链表延迟一段时间，延迟的目的是为了等待“可能有”更多针对这个条带的其他成员磁盘的写请求到来，这样做可以从整体上减少“预读”（无论是重构写还是读改写）的次数。只有当条带被“激活读”后，才开始将delayed_list链表中的条带转移到其他链表进行处理。 hold_list为准备好预读的条带链表：当前的Linux内核版本为了防止delayed_list一股脑儿将所有的条带转移到handle_list，在其中引入hold_list链表，延迟的条带先被保存到hold_list链表以进一步延迟，根据特定的算法，hold_list被绕过，也有可能被转移到handle_list而得到处理。事实证明，这样做可以改进写性能  
请求执行过程 RAID5作为一个独立的模块，在初始化时调用raid5_init，在卸载时调用raid5_exit。而raid5_init则是通过调用register_md_personality注册RAID5个性化，包括模块名和一些个性化方法信息。在raid5_exit中则调用unregister_md_personality注销RAID5个性化；
 接收上层提交请求：上层提交给MD设备的请求，会被传递给raid5_make_request函数； md_write_start函数，它和后面的md_write_end互为对应，都是MD模块提供的公共函数，供RAID5等支持冗余的个性模块调用; chunk_aligned_read函数处理对齐读。所谓对齐读（AlignedRead），是指要读的数据在一个Chunk边界内，因此只需要从某个成员磁盘读取即可，不涉及整个条带的配合;函数根据请求是否在一个Chunk边界内，以及目标成员磁盘是否处在同步状态等，判断是否可以按对齐读处理 raid5_compute_sector:函数输入一个相对RAID5设备的“大的”扇区编号，输出数据磁盘和校验磁盘的编号，以及其上的扇区编号，即条带编号，根据扇区编号计算数据磁盘和校验磁盘的编号及在其上的扇区编号 raids_compute_sector函数有五个参数：第一个为指向r5conf描述符的指针；第二个为目标扇区编号（相对于RAID5设备）；第三个为1表示根据变更前的参数进行计算，为0表示根据变更后的参数进行计算；第四个为输出参数，通过它返回数据单元在条带中的编号；第五个为指向对应stripe_head描述符的指针，这时计算好的P校验单元编号、Q校验单元编号、ddf_layout标志将被保存在它的对应域，或为NULL。函数返回对应扇区在成员磁盘上的扇区编号，即条带编号  RAID5校验盘和数据盘编号与算法 假设数据单元标号为chunk_number，RAID磁盘数为raid_disks，数据盘数为data_disks，所在条带编号为stripe=chunk_number/data_disks。然后计算在条带内的数据磁盘和校验磁盘编号
RAID5的算法如下：
  向左不对称算法：校验盘编号为data_disks-stripe%raid_disks。数据盘编号为chunk_number%data_disks，如果该值大于或等于校验盘编号，则还需要加1；
  向右不对称算法：校验盘编号为stripe%raid_disks。数据盘编号为chunk_number%data_disks，如果该值大于或等于校验盘编号，则还需要加1；
  向左对称算法：校验盘编号为data_disks-stripe%raid_disks，而数据盘编号为（校验盘编号＋1＋chunk_number%data_disks）%raid_disks；
  向右对称算法：校验盘编号为stripe%raid_disks，而数据盘编号为（校验盘编号＋1＋chunk_number%data_disks）%raid_disks。
  最后，目标扇区在数据盘和校验盘上的扇区编号为stripe*sectors_per_chunk＋ chunk_offset。

  管理RAID5条带资源 条带头是在RAID5开始运行的时候开辟的缓冲区，这是一个有限的资源，除了在数据处理过程中需要调度以外，还需要一套完整的机制去使得这些有限的资源能够满足数据请求处理所需
 raid5_get_active_stripe：函数有五个参数：第一个为指向RAID5私有数据描述符的指针；第二个为条带编号；第三个为1表示根据变更前的参数进行计算，为0表示根据变更后的参数进行计算；第四个为1表示不要阻塞，为0表示阻塞，直到获得一个活动条带；第五个为noquiesce。函数返回指向条带头描述符的指针，或者在失败时返回NULL __find_stripe：在哈希表中找看指定扇区的条带是否已经存在。如果不存在，函数会返回NULL get_free_stripe从inactive_list链表尝试获得一个条带； 当条带使用完毕后，也就是没有条带的时候，会先将inactive_blocked域置1，然后调用wait_event_lock_irq开始等待； wait_event_lock_irq：四个参数：第一个为等待队列；第二个为条件；第三个为锁；第四个为命令。它的解释为：如果条件不满足，就将当前线程加入到等待队列，当时在放弃执行之前，还会执行一个命令，这通常就是督促其他部分去赶紧处理，使得等待的条件尽早满足；等待条件是：1.RAID5的inactive_list链表不为空；2.RAID5的活动条带数域小于其最大条带数目的3/4，或者RAID5的inactive_blocked为0  RAID5守护线程处理 每个RAID4/5/6设备可以同时存在两个MD线程：一个名字为md#_raid5，称为RAID5守护线程，它执行的处理函数为raid5d；另一个名字为resync或reshape，笼统地称为RAID5同步线程，它执行的处理函数为md_do_sync
RAID5守护线程，它负责条带各个轮次的处理，从接受上层请求时开始，处理过程中不断推进条带状态的变化，直至最终完成</description>
    </item>
    
    <item>
      <title>Linux-文件系统(简阅)</title>
      <link>https://zcj-git520.github.io/p/linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E9%98%85/</link>
      <pubDate>Thu, 12 May 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E9%98%85/</guid>
      <description>概述 文件系统是存储和组织文件，以便可以访问和查找的一种机制；不同的文件系统有不同的存储和组织方式；基于磁盘的有一下几种存储方式：
 连续存储：把数据作为连续的数据块存储到磁盘上；这一方案简单、容易实现，记录文件用到的磁盘块仅需记住第一块的地址，并且性能较好，一次操作就可读出整个文件。但是，它有一个致命的缺陷。在创建文件时，必须知道文件的最大长度，否则无法确定需要为它保留多少磁盘空间。因此，连续存储主要适合于文件数据一次性写入的系统（例如romfs） 连接表存储：将每个文件用磁盘块顺序连接起来；虽然用于链接磁盘块的指针可以使用磁盘块本身的空间，但这将使得每个磁盘块实际存储的数据字节数不再是2的幂，给上层应用程序带来不便。文件系统从磁盘块中取出一些指针，作为索引存放在文件分配表FAT。只需要记录文件的起始磁盘块编号，顺着文件分配表中索引指针组织成的链表，就可以找到文件的所有磁盘块。 inode存储：每个文件都有一个称为node的表；通过它获取所有磁盘的编号；小文件的所有磁盘块编号都直接存放在inode内。稍大的一些文件，inode记录了一个称为一次间接块的磁盘块编号，这个磁盘块存放着文件的其他磁 盘块编号。如果文件再扩大，可以在inode中记录二次间接块编号，二次间接块存放着多个一次间接块的编号，而每个一次间接块又存放着文件的其他磁盘块编号。如果这也不够的话，还可以使用三次间接块。本章要讨论的Minix文件系统，就使用的这种分配方案  Linux将文件系统分为两层：
  上层为虚拟文件系统开关层，简称为虚拟文件系统：它是具体文件系统和上层应用之间的接口层，将各种不同文件系统的操作和管理纳入一个统一的框架，使得用户不需要关心各种不同文件系统的实现细节。VFS由超级块、inode、dentry、vfsmount等信息组成
  下层为具体文件系统实现，如Minix、EXT2/3/4、sysfs等。具体文件系统实现代码组织成模块形式，向Linux VFS注册回调函数，处理和具体文件系统密切相关的细节操作

  文件系统对象 Linux文件系统对象之间的关系可以概括为文件系统类型、超级块、inode、dentry和vfsmount之间的关系；
Linux有一颗全局文件系统树，反映了Linux VFS对象之间的关系；

每个文件系统装载实例有四个必备元素：vfsmount、超级块、根inode和根dentry。
装载文件系统 文件系统要被使用就应该被装载。体现一个文件系统装载实例要素是：vfsmount、super_block、根dentry和根inode；

在内核角度，装载过程中，文件系统类型中的get_sb将被调用，它将生成一个新的文件系统装载对象vfsmount，并和该文件系统类型的一个超级块实例关联起来；</description>
    </item>
    
    <item>
      <title>Linux-raid学习</title>
      <link>https://zcj-git520.github.io/p/linux-raid%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Sat, 30 Apr 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/linux-raid%E5%AD%A6%E4%B9%A0/</guid>
      <description>raid是什么 raid是廉价冗余磁盘阵列，简称磁盘阵列。
raid:是一种把多块独立的物理磁盘按不同的技术组合起来的形成的一个磁盘组，在逻辑上看起来是一块大的磁盘，可以提供比较单个的物理磁盘更大的存储容量或更高的存储性能，同时有能提供不同级别数据的冗余备份的一种技术
raid的级别 把多个物理磁盘通过不同的技术方式组成的磁盘阵列，不同的技术称为raid级别。
级别一般有：raid0,raid1,raid0+1(raid10),raid2,raid3,raid4,raid5,raid6,raid7,raid53
生产环境常用的级别为：raid0,raid1,raid10,raid5
raid级别的比较    raid级别 优点 缺点 实际使用场景     raid0 读写速度快 没有冗余 mysql slave,集群的节点rs   raid1 100%冗余，镜像 读写性能一般，成本高 单独的，数据重要，且宕机的业务，监控，系统盘   raid5 具备一定的性能和冗余，可坏一块盘，读写性能不错 写入性能不高 用于一般的业务   raid10 读写速度快，100%冗余 成本高 性能和冗余的业务要求高的业务    raid技术分类 软raid技术 在linux中，通过自带软件就能实现软raid功能，它的配置高，管理方便，可以是实现将将几个物理盘合成一个更大的虚拟设备，从而到达性能的改进合数据的冗余的目的
硬raid技术 基于硬件的raid解决方案比基于软件的raid技术在使用的性能合服务器上更好，具体表现在检测和修复多位错误的能力，错误的磁盘自动检测和阵列重建等方面，从安全性上考虑，基于硬件的raid的解决方案更加的安全
raid0原理及特点 
特点：  读写性能高 没有冗余 可用空间N*min（s1,S2&amp;hellip;） 最少磁盘数为，2，2+  raid1特点 
特点  读性能提升，写性能降低 可用空间为：min（s1,S2&amp;hellip;） 可冗余 最少磁盘数为：2，2+  raid5特点</description>
    </item>
    
    <item>
      <title>Linux存储技术学习笔记</title>
      <link>https://zcj-git520.github.io/p/linux%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Fri, 15 Apr 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/linux%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</guid>
      <description>存储设备 磁盘柜 磁盘柜一般分为磁盘阵列（disk array）和磁盘族（jbod）两种；
RAID（Redundant Array of Independent Disks），即“独立磁盘冗余阵列”或者简称 为“磁盘阵列”，基本思想就是把多个独立的磁盘组合起来，成为一个磁盘阵列组，以 获得一个或多个方面的好处：增加容量（Capacity）、提升性能（Performance）、增强 容错性（Redundancy）和降低成本（Cost）。 JBOD（Just a Bundle Of Disks）译成中文可以是“简单磁盘捆绑”或者“磁盘簇”。在 Linux中，它相当于Linear RAID模式，但这不是标准的RAID级别，JBOD在逻辑上把几 个物理磁盘一个接一个串联到一起，从而提供一个大的逻辑磁盘。
NAS存储设备 NAS是一种将存储设备和应用服务器分开的机制，它使用CIFS和NFS向客服端提供文件级服务。
图(1)
iSCSI存储设备 isCSI存储设备既以硬件方式或者软件方式实现IsCSI协议目标端的存储设备。
iSCSI，即Internet SCSI或SCSI over TCP/IP，是IETF制定的一项基于IP的存储网络标 准，用于连接数据存储设备。透过在IP网络上传输SCSI命令，iSCSI可以摆脱SCSI总线 的距离限制。iSCSI被用于在局域网（LAN）、广域网（WAN）或者Internet上传输数 据，实现位置无关的数据存储及检索。iSCSI是一个广为流行的存储区域网络协议，允 许企业将存储归并到数据中心，同时向应用服务器提供无区别于本地磁盘的幻想。和 传统的Fibre Channel不同，iSCSI不需要专用的线缆，可以在现有的网络基础设施上长 距离传输。
图(2)
NAS/iSCSI集成存储设备 NAS/iSCSI集成存储设备结合了NAS存储设备和iSCSI存储 设备的优势，同时支持iSCSI磁盘和本地磁盘，对外支持CIFS协议和iSCSI协议，即支 持块数据和文件数据，理论上可以整合无限的存储容量，构建RAID和LVM，灵活配置 成纯文件服务器、纯iSCSI目标器，或者将存储空间分别用于文件服务和块服务。
图(3)
Linux 驱动模型 Linux内核基于kobject内核对象机制将系统中的总线、设备和驱动设备分别用bus_type、device和device_driver等对象描述将其组织成一个层次结构的系统，统一管理各种内别的设备以其接口，同时借助sysdfs文件系统将其内核所见的设备展给用户空间，提供一个完全层次结构的用户视图。
图(4)
Linux驱动模型的核心内容综合如下：
 以内核对象为基础 用sysfs文件系统导出到用户空间 将Linux子系统表达为总线类型/驱动/设备/类/接口的关系，分别用bus_type、device、device_driver、class和class_interface结构表示  引用计数 引用计数的主要功能为：
 防止内存泄漏：确保已分配的对象最终会被释放； 防止访问已释放的内存：确保不会使用已经被释放的对象  Linux内核提供了相关函数进行操作：
 void kref_init (struct kref *kref);初始化对象，将对象引用次数设置为1，而不是0；这是因为生成该对象的代码也需要最初的引用，以防止其他部分在调用kref_put时释放该对象 void kref_get (struct kref *kref); 递增对象的引用计数。在这之前，确保引用次数不为0，否则答应一条警告信息。这可以防止常见的错误：不先调用kref_init，而直接调用kref_get。 int kref_put (struct kref *kref, void (*release) (struct kref *kref));递减对象的引用计数。如果该计数减为0，则表明是该对象的最后一个引用，因此传入的release函数被调用，以回收这个对象用到的内存。  内核对象及集合 Linux驱动模型的基础是内核对象。它将总线类型、设备、驱动等都看作是内核对 象。表示内核对象的结构是kobject，相当于Linux驱动模型的“基类”</description>
    </item>
    
    <item>
      <title>Linux内核中设备驱动</title>
      <link>https://zcj-git520.github.io/p/linux%E5%86%85%E6%A0%B8%E4%B8%AD%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/</link>
      <pubDate>Sat, 02 Apr 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/linux%E5%86%85%E6%A0%B8%E4%B8%AD%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/</guid>
      <description>基本概念 块设备（block device） 是一种有一定结构的随机存取的设备，对于这种设备的读写是按块进行的，他使用的缓冲区来存放暂时的数据，达到一定条件后。从缓存一次性写入设备或者从设备一次性读到缓冲区
字符设备（character device） 是一种顺序的数据设备，对于这种设备的读写是按字符进行的，连续的字符组成数据流，是没有缓冲区，是只用实时的读写设备；
块设备与字符设备之间的区别  读写数据的单元不同：块设备是以块为读写单元，而字符设备是以字符为读写单元 块设备是可以随机访问，而字符设备只能顺序访问  扇区（sectors） 是块设备硬件对数据处理的基本单位，通常1扇区=512byte
块（blocks） 是Linux种制定对内核或文件系统等数据处理的基本单位，通常1块=1个或多个扇区
段（segments） 是由若干个相邻的块组成。是linux内存管理机制中一个内存页或者内存页中的一部分
页、段、块、扇区之间的关系如图 图(1)
块设备的层次 图(2)
  Linux是支持多种不同存储介质，在内核中间都要适配有块设备驱动程序来读写块设备。
  往上是io调度层，将文件系统的读写请求进行编排，合并用以提高磁盘的读写效率。
  通用块层，对应与bio结构。是将io请求的抽象，描述对应的io操作涉及到多个页
块设备的应用在linux中是一个完整的子系统 在linux中，驱动对块设备的中输入或者输出（io）操作都会向块设备发出请求，在驱动中使用request结构体描述。
对于一些磁盘设备请求的速度很慢，内核提供一种队列的机制，将这些io请求添加到队列中（即：请求队列），在驱动中使用request_queue结构体进行描述。在向块设备提交这些请求前内核会先执行请求合并和排序的预操作，以提高访问的效率，然后在由内核中的io调度程序子系统来负责提交io请求，调度程序将磁盘分配给系统中所有挂起的块io请求，其工作是管理块设备的请求队列。
在由通用层（generic block layer）负责维持一个io请求在上层文件系统与底层物理磁盘之间的关系，在通用层中，通常用一个bio结构体来对应一个io请求。
linux提供一个gendisk数据结构体，用来表示一个独立的磁盘设备或者是分区，用来对底层物理磁盘的访问。在gendisk中有一个类似于字符设备中的file_operations的硬件操作结构指针，是block_device_operations结构体。
当多个请求在提交块设备时。执行的效率依赖于请求的顺序。如果请求的速度是同一方向，执行效率最大。内核在调用块设备驱动程序请求之前，先收集io请求并将请求进行排序，然后将连续扇区操作的请求进行合并以提高执行效率。
块设备的缓冲区和缓冲区头 缓冲区对应一个磁盘块，当磁盘块被调入内存时，就存储在缓冲区；块包含一个或多个扇区，且不大于一个页，所以一个页可以容纳一个或者多个块，并存储一些控制信息。控制信息一般是使用结构体buff-head来表示，结构体如下：
  struct buffer_head{ unsigned long b_state; /* 标志位 */ struct buffer_head *b_this_page; /* 页面中的缓冲区 */ struct page *b_page; /* 当前页面 */ sector_t b_blocknr; /* 起始块号 */ size_t size; /* 映像的大小 */ char *b_data; /* 数据指针 */ struct block_device *b_bdev; /* 关联的块设备 */ atomic_t b_count; /* 使用计数 */ .</description>
    </item>
    
    <item>
      <title>linux 性能优化(二)</title>
      <link>https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%BA%8C/</link>
      <pubDate>Tue, 15 Mar 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%BA%8C/</guid>
      <description>性能  高并发和快响应的性能指标是指：吞吐和延时 性能的本质：系统资源已经到达瓶颈时，处理请求不够快，不足以处理更多的请求。 性能分析：找到系统或者应用的瓶颈，尽最大的可能避免或者缓解这样的瓶颈。 常用的性能分析工具：   cup上下文切换  cup上下文切换：将上一个任务cup的上下文保存系统的内核中休眠，然后将新任务的cup上下文进行加载，然后执行这个新任务。 cup的上下文切换可分为：线程上下文切换、进程上下文切换和中断上下文切换。在内核中中断的等级与进程和线程的等级高，所以保证了中断上下文 切换与进程和线程上下文切换不同时发生。 通过vmstat可以查看系统总体的上下文切换情况   进程上下切换   linux进程按照等级权限将进程的运行空间分为内核空间和用户态空间。其中用户态向内核态转换需要进行系统调用。执行一次系统调用 需要进行两次cpu的上下文切换分别为：
   CPU寄存器中用户态的指令位置先保存起来，CPU寄存器更新为内核态指令的位置，跳转到内核态运行内核任务；
系统调用结束后，CPU寄存器恢复原来保存的用户态数据，再切换到用户空间继续运行。
   进程是由内核管理和调度的，进程上下文切换只能发生在内核态。因此相比系统调用来说，在保存当前进程的内核状态和CPU寄存器之前，需要先把该进程的虚拟内存，栈保存下来。再加载新进程的内核态后，还要刷新进程的虚拟内存和用户栈。
  进程只有在调度到CPU上运行时才需要切换上下文，有以下几种场景：CPU时间片轮流分配，系统资源不足导致进程挂起，进程通过sleep函数主动挂起，高优先级进程抢占时间片，硬件中断时CPU上的进程被挂起转而执行内核中的中断服务。
  线程上下文切换  在同一进程中的线程进行上下文切换，切换时，只需要切换线程的私有数据、寄存器等，消耗资源少。 在不同进程的中的线程进行上下文切换，切换与进程的上下文切换一致。  中断上下文切换  中断上下文切换只包括内核态中断服务程序执行所需要的状态（CPU寄存器，内核堆栈，硬件中断参数等）（CPU寄存器，内核堆栈，硬件中断参数等）  参考文献： 极限好文！Linux 性能优化全景指南</description>
    </item>
    
    <item>
      <title>linux 性能优化(一)</title>
      <link>https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%80/</link>
      <pubDate>Sat, 05 Mar 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%80/</guid>
      <description>Linux常用的性能查看命令 CPU CPU的性能指标  cup的使用率分为：    用户CPU使用率，主要包括用户态和低优先级用户态，反应的是应用程序的cpu的使用情况 系统CPU使用率，cpu在内核态运行的时间百分比,不包含中断。反应的是内核的使用情况 等待IO的CPU使用率，反应的是系统与硬件IO的交互的情况 软/硬中断CPU的使用率，反应的中断的发生的情况 steal CPU / guest CPU, 表示虚拟机占用的CPU百分比.    在理想情况下，平均负载等于逻辑CPU个数(几核的CPU),表示每个CUP都被充分使用。大于这个逻辑CPU个数表示负载较大 CUP缓存率指的是CPU缓存的复用情况。命中率越高表示性能越好，其中L1/L2常用在单核,L3则用在多核中  CPU的优化  用户态的优化，即应用程序的的优化，尽可能的减少cpu的上下文的切换 内核态的优化，即内核的优化，可以CPU绑定，调整有优先级，中断的负载均衡等  性能工具  根据不同的性能指标来找合适的工具
 根据指标查找   CPU性能查看  使用ps查看正在运行的进程   使用top查看各cup的使用情况、对应内存以及个进程占cpu和使用内存的情况  vmstat命令：查看CPU负载   内存使用情况查看  除了使用top可以查看内存使用情况外，还可以使用free命令进行查看   磁盘I/O性能查看  可以使用df 或者 df -h 查看磁盘占用用情况  iostat -d 进行查看   查看网络情况  使用ifconfig查看或者修改网络  netstat命令：-i 查看网络接口信息，-r 检测系统路由表信息   动态监控性能  使用watch命令：动态监控，默认2秒钟执行一次，执行结果更新在屏幕上    </description>
    </item>
    
    <item>
      <title>io多路复用</title>
      <link>https://zcj-git520.github.io/p/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</link>
      <pubDate>Sun, 12 Dec 2021 12:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</guid>
      <description>常见的IO类型 同步阻塞IO  用户线程通过调用系统命令发起io操作，由用户态复制到内核态空间，内核态一直在等待， 直到获取到数据时，将接收到的数据拷贝到用户态空间，用户线程在获取数据。整个过程用户线程 处于阻塞的状态，直到有数据为止。  同步非阻塞IO  在同步阻塞io的基础上，用户线程发起io操作后，就立刻返回。由于是非阻塞的方式，就存在返回时 没有数据，就需要不断的轮询发起io请求，直到接收到数据为止。  IO多路复用  io多路复用是一种同步的io模型。实现在内核态中一个线程监视多个io(文件句柄)，一旦某个io就绪后， 就通知用户线程进行相关的操作。没有io就绪时就阻塞用户线程，将交出cpu。多路是指网络连接，复用是指 用一个线程。  信号驱动IO  用户线程发起一个io操作后，会向内核注册一个信号处理函数，然后返回，当内核中有数据时，就会发送一个 信号给用户线程，用户态的线程在调用io请求，获取到数据。  异步IO  用户线程发起io操作后就返回。由内核态的线程处理，当内核线程获取到数据后，主动将数据拷贝到用户态， 并告知用户线程io操作也完成。   io多路复用的三种实现方式 select  select是采用数组的存储的结构存储io(fd文件句柄)，默认的最大的fd为32位系统1024，64位系统是2048(可设置),用户线程将fd集合拷贝到 内核态并开始监控，当有fd就绪或者过了设置超时时间，就将fd集合中所有未就绪的fd清空(将bitmap置为0)，将就id集合返回到用户态， 用户态的线程通过轮询返回的fd集合找到就绪的fd,进行相关的io操作获取数据。再一次监控时，需要将之前清空的fd 添加到fd集合中进行新一轮的监控。  #include &amp;lt;sys/select.h&amp;gt; #include &amp;lt;sys/time.h&amp;gt; #define FD_SETSIZE 1024 #define NFDBITS (8 * sizeof(unsigned long)) #define __FDSET_LONGS (FD_SETSIZE/NFDBITS) // 数据结构 (bitmap) typedef struct { unsigned long fds_bits[__FDSET_LONGS]; } fd_set; // API int select( int max_fd, // 最大的文件文件描述符fd fd_set *readset, // 读文件描述符集合 fd_set *writeset, // 写文件描述符集合 fd_set *exceptset, // 异常的文件描述符集合 struct timeval *timeout // 超时时间 ) // 返回值就绪描述符的数目 FD_ZERO(int fd, fd_set* fds) // 清空集合 FD_SET(int fd, fd_set* fds) // 将给定的描述符加入集合 FD_ISSET(int fd, fd_set* fds) // 判断指定描述符是否在集合中 FD_CLR(int fd, fd_set* fds) // 将给定的描述符从文件中删除 //select使用示例 int main() { /* * 这里进行一些初始化的设置， * 包括socket建立，地址的设置等, */ fd_set read_fs, write_fs; struct timeval timeout; int max = 0; // 用于记录最大的fd，在轮询中时刻更新即可 // 初始化比特位 FD_ZERO(&amp;amp;read_fs); FD_ZERO(&amp;amp;write_fs); int nfds = 0; // 记录就绪的事件，可以减少遍历的次数 while (1) { // 阻塞获取 // 每次需要把fd从用户态拷贝到内核态 nfds = select(max + 1, &amp;amp;read_fd, &amp;amp;write_fd, NULL, &amp;amp;timeout); // 每次需要遍历所有fd，判断有无读写事件发生 for (int i = 0; i &amp;lt;= max &amp;amp;&amp;amp; nfds; ++i) { if (i == listenfd) { --nfds; // 这里处理accept事件 FD_SET(i, &amp;amp;read_fd);//将客户端socket加入到集合中 } if (FD_ISSET(i, &amp;amp;read_fd)) { --nfds; // 这里处理read事件 } if (FD_ISSET(i, &amp;amp;write_fd)) { --nfds; // 这里处理write事件 } } }</description>
    </item>
    
    <item>
      <title>redis进阶</title>
      <link>https://zcj-git520.github.io/p/redis%E8%BF%9B%E9%98%B6/</link>
      <pubDate>Wed, 08 Dec 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/redis%E8%BF%9B%E9%98%B6/</guid>
      <description>redis的网络协议  redis是基于tcp/ip协议，即客户端与服务器保持双工连接，通过序列化的协议(resp协议)进行数据的交互，在Redis中，协议数据分为不同的类型， 每种类型的数据均以CRLF（\r\n）结束，通过数据的首字符区分类型  redis服务器是一个事件驱动系统主要分为：文件事件(io事件)和时间事件 文件驱动：socket的读取事件(io事件)是由；连接(三次握手)、请求、响应(数据返回)、断开连接(四次挥手)组成，redis是采用单线程 和epoll(io多路复用)的机制处理相关的文件事件。 时间事件：可分为定时事件(程序在指定时间后执行相关的操作)和周期事件(程序每隔一段时间运行相关的操作)  redis客户端与服务器交互模式 串行的请求/交互模式  客户端与服务器建立长连接，通过心跳检测(ping-pong)ack应答，即客户端发送请求，服务器在进行响应。 在单连接下。大部分时间都是处于网络等待上(客户端在发送请求命令，并监听socket返回，通常以阻塞模式等待服务器端的响应)，这种模式下 的性能较低   管道技术(pipeline)双工的请求/响应模式  将一批命令进行打包，然后发送给服务器，服务器获取数据后按顺序打包返回，即批量请求，批量响应。以次来减少网络等待的延时，提高性能   原子化的批量请求/响应(事务)模式  客户端将请求的命令发送发到服务器，服务器经这些请求暂存在服务器的请求队列中，这过程也称为：请求入队列。服务器在从请求队列中 拿去所有的请求执行，然后再将数据返回给客户端，这过程称为执行阶段。 服务器在执行过程中不会在接收其他客户端发送的请求。所有的操作都是原子操作，即请求都执行或都不执行。 事务的步骤为：开始事务-&amp;gt;请求入队列-&amp;gt;执行请求   发布/订阅(pub/sub)模式  发布者(pub)发送消息，订阅者(sub)接收消息，发布者和订阅者通过(通道)channel关联，所有的channel都是由一个map维护，map的key是 channel的名字，value是所有的订阅者的指针链表。客户端可以订阅任意的数量的频道，也可以进行发布。 发布者和订阅者都是客户端，服务器只是进行数据的中转。即发布者着向服务端发起请求，服务端将请求的数据推送给订阅者。   redis的持久化机制  redis的持久化机制主要是有：RDB(快照)和AOF(日志)两种持久化的方式。持久的化的作用在于：故障恢复和数据恢复  RDB(快照)持久化机制  快照是redis默认的持久化方案，在指定时间间隔内生成数据集的时间点，即在指定的时间段内将内存的数据写入磁盘，在磁盘 上生成一个rdb的备份文件。在redis重启时加载rdb文件进行数据的恢复。 快照的持久化提供自动备份：需要修改配置文件redis.conf。也提供save和bysave(后台子进程)进行主动备份  RDB(快照)的工作流程：  主进程会单独创建子进程，将主进程的数据库的数据复制到子进程。 子进程将数据写入到临时文件中进行持久化，在经临时文件替换之前的rdb文件,子进程退出，释放内存中的数据 主进程不进行持久化，即不进行任何的io操作，确保redis的极高的性能  RDB(快照)的优缺点 优点  单一的紧凑文件保存了莫一段时间的数据集，比较适合做数据的备份尤其的冷备份 在对数据完整性不敏感下，适合大规模的数据的恢复，因直接从磁盘获取数据，恢复数据快 由子进程进行持久化，主进程不进行持久化，即不进行任何的io操作，确保redis的极高的性能  缺点  不能保障数据的完整性，若redis出现宕机，就不会出现最近的数据未持久化，导致数据的丢失。 当持久化的数据量较大时，会导致持久化的子进程就会很耗时，即使主线程在不参与持久化也可能导致服务器在毫秒级内不能响应 客户端的请求，若数据巨大时且cpu的性能不佳时，会出现秒级不能响应客户端的请求。  AOF(日志)持久化  通过将每个写操作记录到日志中且以追加文件不修改文件的模式，重启时更具根据日志文件从头到未执行一遍即恢复数据。，因AOF采用的是经操作记录以追加模式下写入日志文件中，会导致AOF文件越来越大。AOF引入了重写机制。 AOF引入了重写机制：当文件AOF是上次重写大小的一倍且文件大于64MB时就创建一个子进程遍历服务器的键值对，转换成一系列 Redis 的操作 指令，序列化到一个新的AOF日志文件中，再替换旧的AOF日志文件。可以修改配置文件设定持久化策略。  AOF 提供了三种持久化策略：  no: 无 fsync，由系统保证数据刷新到磁盘，速度最快，但很不安全（通常不使用）； always: 每次 fsync，每一个修改内存的 Redis 指令都会执行一次 fsync，速度很慢（通常不使用）； everysec: 每秒进行一次 fsync，有可能丢失一秒的 fsync 的数据。通常选择 everysec 策略，兼顾安全性和效率。  AOF(日志)的优缺点 优点  可以采用everysec的持久化策略，能确保数据的完整性  缺点  AOF的日志文件通常是比rdb文件大 在数据的恢复时，需要遍历日志文件，将日志文件的数据操作命令在执行一遍，导致数据恢复相对于快照(rdb)较慢，尤其在大数据下。  redis 缓存中的状况于解决方案 缓存雪崩  数据未加载到内存或者同一时间发生大规模的key失效，从而导致所有的请求都直接在查数据库。导致数据库和cpu负载过高，甚至宕机  解决方案  加锁计数，限制并发的数量，避免出现并发出现大量的请求访问到数据库，降低服务器的吞吐量 设置热点key永不失效，均匀过期，避免出现大面积的key同时失效 设置缓存服务器的主备  缓存穿透  指客户端请求的数据在缓存和数据库中均没有，导致客户端在每次请求都需要去数据库查询。若在并发时，也会导致数据库和cpu的负载过高， 导致数据库的宕机  解决方案  若查询数据库不存在，直接在缓存中保存一个默认的值，并设置较短的过期时间，下次请求直接从缓存中返回。 使用布隆过滤器，阻挡无效的请求。  缓存并发  在并发情况下，一个缓存失效，在高并发下访问数据库，缓存更新，也会导致数据的压力变大。  解决方案  对缓存加锁，若key不存在，就加锁，当查询数据库的数据写入缓存在解锁  缓存预热  在系统运行前，将数据加载到缓存中  解决方案  数据量不大，直接加载 数据量大时，设置定时的脚本进行缓存的刷新 数据量巨大时，优先保障热点数据提前加载到缓存中  缓存降级  指缓存失效或者缓存服务器宕机时，不去访问数据库，直接返回默认值或访问内存数据  分布锁  使用setnx加锁，并设置超时时间，过了超时时间就解锁，并删除锁  参考文献 Redis 客户端服务端交互1 客户端/服务端协议</description>
    </item>
    
    <item>
      <title>初识redis(数据结构分析)</title>
      <link>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</link>
      <pubDate>Sun, 05 Dec 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</guid>
      <description>redis  redis 是一个开源（BSD许可）的，数据结构为key-value的存储系统。它可以用作分布式数据库、缓存 和消息队列（消息中间件）。数据保存在内存中，存取速度快，并发能力强。 redis 支持多种数据结构，如字符串、map(哈希)、列表、集合、有序集合等数据类型。数据都是原子操作， 数据都缓存在内存中，会定期将数据更新到磁盘或者修改操作写入追加记录。再次基础上实现了主从（master-slave）  redis 数据结构 字符串(string)类型  字符串类型是redis最基础的数据结构，可以存储简单的字符串也可存储复杂的xml、json、二进制数据（如图像、音频） value内部以保存整数的int和保存字符的sds组成的数据存储结构。sds内部结构为：  struct sdshdr { int len; // 记录着buf中也使用的字符串数量 int free; // 记录着buf中未使用的字符串数量 char buh[]; // 字符串数组，用于保存字符串 } 
字符串类型特性  分配冗余空间：采用预先分配冗余空间的方式来减少内存的频繁分配 自动扩容： 当字符串所占空间小于1MB时，redis会按照字符串（len + addLen）*2倍数存储空间增加， 当字符串的存储空间超过所占空间的1MB时，每次自会增加1MB的存储空间扩容，最大扩容为512MB的存储空间 二进制的安全性，兼容c语言函数库中字符串以\0结束。  字符串常用的场景  缓存功能： 基于redis作为缓存再配合其他的数据库最为存储层，利用redis的数据存储在内存和支持高并发的特点，可以大大加快 系统的读写速度以及降低后端数据库的压力。（单值缓存、对象缓存、分布式锁等） 计数器： 使用redis作为系统的实时计数器，可以加快计数和查询功能。 共享用户的session：利用redis将用户的session集中管理，这种模式确保redis的高可用。每次用户的session的更新和获取快速完成  列表(list)  list类型的value对象内部采用的quicklist(快速列表)或者ziplist(压缩列表)承载。当list的元素和单个元素较小时采用ziplist实现来减少内存的 占用否则采用quicklist结构进行存储。 ziplist所有内容都存放在来连续的内存中。zipbytes表示ziplist的总长度， zltail表示指向最末的元素，zllen表示元素个数， entryX表示元素自身内容， zlend是ziplist的定界符 ziplist的内部结构为：  typedef struct ziplist{ /*ziplist分配的内存大小*/ uint32_t bytes; /*达到尾部的偏移量*/ uint32_t tail_offset; /*存储元素实体个数*/ uint16_t length; /*存储内容实体元素*/ unsigned char* content[]; /*尾部标识*/ unsigned char end; }ziplist; /*元素实体所有信息, 仅仅是描述使用, 内存中并非如此存储*/ typedef struct zlentry { /*前一个元素长度需要空间和前一个元素长度*/ unsigned int prevrawlensize, prevrawlen; /*元素长度需要空间和元素长度*/ unsigned int lensize, len; /*头部长度即prevrawlensize + lensize*/ unsigned int headersize; /*元素内容编码*/ unsigned char encoding; /*元素实际内容*/ unsigned char *p; }zlentry;</description>
    </item>
    
    <item>
      <title>初探jwt(json web Token)</title>
      <link>https://zcj-git520.github.io/p/%E5%88%9D%E6%8E%A2jwtjson-web-token/</link>
      <pubDate>Tue, 30 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%88%9D%E6%8E%A2jwtjson-web-token/</guid>
      <description>jwt  jwt 它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息，是最流行的跨域认证的解决方案  传统跨域认证  客服端向服务器发送用用户名和密码，服务器验证通过后，把当前对话的session里保存 相关数据，并写在客户端的cookie, 向客户端返回一个session id。客户端再次通过cookie, 经session id 传回服务器，服务器通过session id得知访问客户端的身份。 存在的问题：扩展性不佳，服务器集群或者跨域的服务导向架构，就需要共享session共享数据 解决方案：1. 将session 数据保存在数据库中或者其他的持久层，服务器访问持久层的session数据 2. 服务器不保存session数据，所有的数据保存在客户端，每次请求都发回服务器  jwt的原理  服务器认证以后，生成一个json对象，返回给客户端之后，客户端与服务器靠这个json对象认证，会会 加上签名来防止客户端修该json 对象  jwt的数据结构  jwt的数据结构为：Header(头部)、payload(负载)、signature(签名)
  Header(头部)  Header部分是一个json对象，描述jwt的元素据。声明类型，这里是jwt声明加密的算法 通常直接使用 HMAC SHA256，结构如下：  { &#39;typ&#39;: &#39;JWT&#39;, &#39;alg&#39;: &#39;HS256&#39; } payload(负载)  payload 也是一个json对象，用来存放实际需要的传递的数据，iss：发行人，exp：到期时间，sub：主题，aud：用户， nbf：在此之前不可用，iat：发布时间，jti：JWT ID用于标识该JWT  { &amp;quot;sub&amp;quot;: &amp;quot;1234567890&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;John Doe&amp;quot;, &amp;quot;admin&amp;quot;: true } signature(签名)  是对前两部分进行签名，防止篡改。在服务器上指明一个密钥，在根据header中指定的算法， 按照格式产生签名，header (base64后的)、payload (base64后的)、secret。其格式如下：  // javascript var encodedString = base64UrlEncode(header) + &#39;.</description>
    </item>
    
    <item>
      <title>初识Nginx</title>
      <link>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86nginx/</link>
      <pubDate>Wed, 24 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86nginx/</guid>
      <description>Nginx  nginx 是轻量级高并发web服务器，是基于Rest架构风格。通过http协议提供各种网络服务
其高并发是基于事件驱动架构，io多路复用的epoll,使得可以轻松支持百万计的icp连接。
轻量级主要体现在：采用插件化开发，cup亲和，将cpu与nginx工作进程绑定，减少cpu切换带来的消耗  代理  代理是客户端与服务器之间的一层服务器，将客户端的请求转发给服务器，然后服务器的响应转发给客户端  正向代理  客户端向代理服务器转发请求和指定目标服务器，代理服务器向目标服务器发送请求，并将结果返回给客户端。 对客户端是透明的，即客户端知道访问的是目标服务器，对目标服务器来说是非透明的，并不知道访问服务器是 客户端还是代理服务器  反向代理  客户端向代理服务器发送请求，代理服务器将请求转发给内部的网络服务器(目标服务器)，在将结果返回给客户端。对于客户端 是非透明的，即客户端不清楚是访问是那一台目标服务器。对于目标服务器是透明的，即目标服务器知道访问的是 代理服务器 nginx反向代理的配置如下：  server { listen 80; server_name www.123.com; location / { proxy_pass http://127.0.0.1:8080; index index.html index.htm index.jsp; } } 我们监听80端口，访问域名为www.123.com，不加端口号时默认为80端口，故访问该域名时会跳转到127.0.0.1:8080路径上
负载均衡  当请求过大时，将请求分发给各个服务器。负载均衡的分配策略为：weight(权重)轮询，fair(智能调整调度) nginx轮询配置(所有请求都按照时间顺序分配到不同的服务上)  upstream dalaoyang-server { server localhost:10001; server localhost:10002; }  nginx权重配置(权重轮询：代理服务器接收到请求，按照设定的权重，请求分配到不同的后端服务器，如果发现后端服务器宕机时， 代理服务器会将其剔除出队列)  upstream dalaoyang-server { server localhost:10001 weight=1; server localhost:10002 weight=2; }  nginx iphash 配置(每个请求都根据访问ip的hash结果分配)  upstream dalaoyang-server { ip_hash; server localhost:10001 weight=1; server localhost:10002 weight=2; }  最少连接(将请求分配到连接数最少的服务上)  upstream dalaoyang-server { least_conn; server localhost:10001 weight=1; server localhost:10002 weight=2; }  far 智能调整调度算法：动态根据后端服务器的请求处理到响应时间进行均衡分配。即响应时间短，处理效率高的服务器 分配到请求的概率高。响应时间长，效率低的服务器分配到请求的概率低。 far 配置文件如下：  upstream dalaoyang-server { server localhost:10001 weight=1; server localhost:10002 weight=2; fair; } 流量控制  限流实际就是限制流入请求的数量：有计数器固定窗口算法、令牌桶算法、漏桶算法和限制并发连接数限制</description>
    </item>
    
    <item>
      <title>http协议底层分析</title>
      <link>https://zcj-git520.github.io/p/http%E5%8D%8F%E8%AE%AE%E5%BA%95%E5%B1%82%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 18 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/http%E5%8D%8F%E8%AE%AE%E5%BA%95%E5%B1%82%E5%88%86%E6%9E%90/</guid>
      <description>HTTP  HTTP是(Hyper Text Transfer Protocol)超文本传输协议, 基于tcp的应用层传输协议（请求-响应）协议 影响HTTP网络请求的主要因素带宽和延迟  延迟的种类:  浏览器阻塞(超过浏览器连接数限制的后续请求都会被阻塞) DNS查询 (将域名解析造成的延迟，可以通过缓存DNS进行解决) 建立链接 (因HTTP是基于TCP的应用层协议，在建立连接时需要进行)  HTTP1.0 http1.0存在的问题：  短连接：规定客户端与服务器只保持短暂连接，客户端每次请求都需要建立连接，服务器完成请求后 断开连接，服务器不跟踪客户端，不保存客户端的请求记录。 没有host头域：每台服务器都绑定一个唯一的IP地址，请求消息中的URL并没有传递主机名（hostname） 不允许短点续传  HTTP1.1 根据http1.0暴露的问题，http1.1增加优化方案  缓存处理：http1.1增加更多的缓存控制策略 带宽优化及网络连接的使用：http1.1中请求头引入了range头域和支持断点续传的功能 Host头处理：http1.1的请求消息和相应消息虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机(Multi-homed Web Servers),并且它们共享一个IP地址,HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request） 长连接： 支持长连接和流水线处理，默认开始是长连接：keep-alive  http1.1 也带来新的问题：HTTP 队头阻塞(head of line blocking)  因http1.1支持了长连接和使用了管道机制，客户端与服务器建立一次连接，客户端不用等待服务器响应就能发送下一个请求，支持了并行发送多个请求， 但服务器必须按照请求的顺序来相应请求，也就是通过串行响应请求，这就造成了HTTP的队头阻塞。  解决Http 队头阻塞方法  并发连接：一个域名允许分配多个长连接，增加处理请求任务 域名分片：将一个域名分解为多个域名，在进行并发连接  HTTP2.0  HTTP2.0主要是基于SPDY协议。实现了低延时高吞吐量  SPDY协议  是基于TCP协议的应用层协议，其目标是通过头部压缩、多路复用、优先级等作用缩短网页放入加载时间和 优化http的性能，其核心是尽量减少TCP连接数  HTTP 2.0的特性 头部压缩 头部存在大量的信息，而且每次在发送都会降低http的性能，在用HPACK算法对头部进行压缩： 1.在客户端和服务器维持一个头部表来跟踪和存储客户端发来的键值对 2.客户端在请求的时候便只需要发送在表里的索引位置即可 3.HPACK 不仅仅通过索引键值对来降低数据量，同时还会将字符串进行霍夫曼编码来压缩字符串大小</description>
    </item>
    
    <item>
      <title>PRC</title>
      <link>https://zcj-git520.github.io/p/prc/</link>
      <pubDate>Mon, 15 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/prc/</guid>
      <description>RPC  RPC(Remote Procedure Call Protocol)——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务， 而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP/IP或UDP，为通信程序之间携带信息数据。 RPC将原来的本地调用转变为调用远端的服务器上的方法，给系统的处理能力和吞吐量带来了近似于无限制提升的可能。 在OSI网络通信模型中，RPC跨域了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易 RPC采用客户机/服务器(client-server)模式,也是一种请求/响应(request-response)模式，可以通过TCP/UDP以及HTTP 协议进行传输  RPC 架构  CAll ID 映射：客户端通过ID传输给服务器，服务器通过ID调用相应的函数返回 序列化与烦序列化：客户端与服务器通过序列化与反序列化进行传参 一个完整的RPC架构里面包含了四个核心的组件，分别是Client，Client Stub，Server以及Server Stub，这个Stub可以理解为存根。   客户端(Client)，服务的调用方。 客户端存根(Client Stub)，存放服务端的地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程发送给服务方。 服务端(Server)，真正的服务提供者。 服务端存根(Server Stub)，接收客户端发送过来的消息，将消息解包，并调用本地的方法。  RPC调用过程  客户端（client）以本地调用方式（即以接口的方式）调用服务； 客户端存根（client stub）接收到调用后，负责将方法、参数等组装成能够进行网络传输的消息体（将消息体对象序列化为二进制）； 客户端通过sockets将消息发送到服务端； 服务端存根( server stub）收到消息后进行解码（将消息对象反序列化）； 服务端存根( server stub）根据解码结果调用本地的服务； 本地服务执行并将结果返回给服务端存根( server stub）； 服务端存根( server stub）将返回结果打包成消息（将结果消息对象序列化）； 服务端（server）通过sockets将消息发送到客户端； 客户端存根（client stub）接收到结果消息，并进行解码（将结果消息发序列化）； 客户端（client）得到最终结果。
RPC的目标是要把2、3、4、7、8、9这些步骤都封装起来。   注意：无论是何种类型的数据，最终都需要转换成二进制流在网络上进行传输，数据的发送方需要将对象转换为二进制流，而数据的接收方则需要把二进制流再恢复为对象。   gPRC  gRPC 是一种现代开源高性能远程过程调用 (RPC) 框架，可以在任何环境中运行。它可以通过对负载平衡、跟踪、健康检查和身份验证的可插拔支持，有效地连接数据中心内和数据中心之间的服务。它还适用于分布式计算的最后一英里，将设备、移动应用程序和浏览器连接到后端服务。 gRPC 是基于HTTP2.0(多路复用,消除了线头阻塞)标准协议色设计的基于ProtoBuf序列化的高性能框架。 《gRPC 官方文档中文版》  Protocol Buffers  Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据序列化，很适合做数据存储或 RPC 数据交换格式。它可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式 序列化：将数据结构或对象转换成能被传输或者存储（如二进制格式）的过程。 反序列化：将在序列化过程中所生成的(格式)转换成数据结构或者对象的过程。  参考文献： RPC原理解析</description>
    </item>
    
    <item>
      <title>RestfulAPI</title>
      <link>https://zcj-git520.github.io/p/restfulapi/</link>
      <pubDate>Wed, 10 Nov 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/restfulapi/</guid>
      <description>Restful API  rest是Representational state Transfer 的缩写（表述性转态传递） api是应用程序接口 Restful API是一种软件结构风格，设计风格，让软件更加清晰、简洁、易维护。是一种流行的软件API 设计风格  Rest的指导风格  客户端-服务器：通过将用户接口问题与数据存储问题分开，简化服务器组件来提高跨平台放入用户接口的 可移植性性并提高可伸缩性 无转态：从客户端到服务器的每个请求都必须包含理解请求所需的所有信息，并且不能利用服务器上任何存储的上下文。因此，会话状态完全保留在客户端上。 可缓存：缓存约束要求将对请求的响应中的数据隐式或显式标记为可缓存或不可缓存。如果响应是可缓存的，则客户端缓存有权重用该响应数据以用于以后的等效请求。 统一接口：通过将通用性的软件工程原理应用于组件接口，简化了整个系统架构，提高了交互的可见性。为了获得统一的接口，需要多个架构约束来指导组件的行为。REST由四个接口约束定义：资源识别; 通过陈述来处理资源; 自我描述性的信息; 并且，超媒体作为应用程序状态的引擎 分层系统：分层系统风格允许通过约束组件行为来使体系结构由分层层组成，这样每个组件都不能“看到”超出与它们交互的直接层。 按需编码（可选）： REST允许通过以小程序或脚本的形式下载和执行代码来扩展客户端功能。这通过减少预先实现所需的功能数量来简化客户端  RestFul 架构  资源：网络的实体或者是具体的信息，使用URI(统一资源定位符)，URI是每一个资源的地址或者独一无二的是识别符 表现层： 对资源的外在表现，如：json、xml、txt、二进制等 转态转化：互联网是一种无转态的协议，所有的状态都是保存在服务器上，客户端通过 HTTP的操作方式(GET,POST,PUT,DELETE)等改变服务器的“状态变化”   RESTful API接口规范 接口风格  路径和变量均采用小驼峰式，例如deviceId 使用HTTP动词作为action操作URL资源，动词一律大写。  GET：读取\查询（Read） POST：新建（Create） PUT：更新（Update） PATCH：更新（Update），通常是部分更新 DELETE：删除（Delete） HEAD：获取资源的元数据。 OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。 5种请求动作中，GET、PUT、PATCH、DELETE均是幂等的；只有POST是非幂等的。幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。是非幂等是判断接口使用POST还是PUT的决定条件。幂等的理解见本文附录。   参数：  PATH（路径）：  版本号放入PATH，且在最前  尽量使用名词，不使用动词，把每个URL看成一个资源，名称都用复数 微服务名称不放入PATH中     Query参数：主要用在GET查询中，简单的PUT动作，也用Query参数 Headers参数：公共参数通过header传递，content-type、authorization认证必填，其他统一按调用链规范、速率限制规范填写。content-type应该固定为application/json。 Body：  统一使用json格式，所有返回都是json格式  POST所有参数通过JSON传递 GET请求不允许有body， 所有参数通过拼接在URL之后传递，所有的请求参数都要进行遵循RFC 3986的URL Encode。 DELETE删除单个资源时，资源标识通过path传递，批量删除时，通过在body中传递JSON。       返回结果  状态码：HTTP状态码标准用法，见后状态码规范 Body返回，只提供json返回格式 GET：返回资源对象，完整对象或通过Query参数可过滤 POST：返回新生成的资源对象，可能是ID或完整的资源对象 PUT：返回完整的资源对象 DELETE：返回一个空文档   过滤信息：查询及查询结果使用  pageNo：分页查询标识第几页 pageSize：分页查询标识每页多少条数据 begin：录像/截图开始时间，Unix时间戳，单位秒 end：录像/截图结束时间，Unix时间戳，单位秒 orderby：排序规则，desc或asc q：搜索关键字（uri encode之后的） totalCount：总记录数，分页查询，返回json携带 totalPages：总页数，分页查询，返回json携带，等于page时，表示当前是最后一页   微服务内部使用http协议，对外使用https协议  详细设计要求  输入参数要精简有效  不能把内部对象作为接口参数，通过DTO进行转换； required的字段尽可能少   CRUD的U(POST)要通过业务分析（领域建模）具体化操作，不要提供灵活但是支持不全面的接口 查询尽可能提供丰富的查询条件，可以返回尽可能详细的信息 同类资源尽可能统一接口 避免多级 URL，比如获取某个作者的某一类文章： GET /authors/12/categories/2 这种 URL 不利于扩展，语义也不明确，往往要想一会，才能明白含义。 更好的做法是，除了第一级，其他级别都用查询字符串表达。 GET /authors/12?</description>
    </item>
    
    <item>
      <title>Docker知识总览</title>
      <link>https://zcj-git520.github.io/p/docker%E7%9F%A5%E8%AF%86%E6%80%BB%E8%A7%88/</link>
      <pubDate>Fri, 05 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/docker%E7%9F%A5%E8%AF%86%E6%80%BB%E8%A7%88/</guid>
      <description>概念知识 Docker镜像 Docker镜像是由文件和元数据组成的。
 文件：语言环境、库、执行文件  由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。   元数据：环境变量、端口映射、卷等 镜像信息：  RESPOSITORY：仓库名 TAG：标签 IMAGE ID：镜像ID CREATED：创建时间 SIZE：所占用的空间   虚悬镜像(dangling image)  RESPOSITROY及TAG都为 使用docker image prune 可以删除    容器 容器是从镜像中创建，继承了他们的文件系统，并使用他们的元数据来确定其启动配置。
 启动时，运行一个进程，不过可派生其他进程。 文件的变更通过写时复制存储在容器中，基础镜像不会受影响。  数据卷 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：
 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷  Docker网络 当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。</description>
    </item>
    
    <item>
      <title>内存管理</title>
      <link>https://zcj-git520.github.io/p/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
      <pubDate>Mon, 18 Oct 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
      <description>虚拟地址空间布局  程序通过编译成为一堆的机器指令写入可执行文件，程序在运行是会将可执行文件加载在计算机的内存中 在虚拟地址空间分布中处于代码段。 程序中的局部变量、函数的参数、函数的返回值等数据会保存在虚拟地址的栈中(栈是先进后出的数据结构) 栈空间的编译器分配和释放。 程序的全局变量和静态变量会保存在虚拟地址的数据段 动态分配内存的地址会保存在虚拟地址空间的堆上。堆空间是动态开辟的内存空间，需要主动开辟和释放。或者 调用GC释放   堆内存管理  堆内存空间不是编译器分配，而是有程序动态分配的内存空间。  手动垃圾回收  需要程序主动释放没有用的数据所在的堆空间。如：c++中调用new()函数向计算机申请开辟内存空间后，使用delete或delete[]释放不需要的 堆内存空间。这一类是手动内存分配和释放。手动内存分配使用不恰当也会造成：内存泄露 悬挂指针的问题   过早释放会造成悬挂指针（野指针）：提前释放了动态的堆内存的空间，当程序访问这段地址时会报错。因为这段提前释放的内存空间被清空、 重新分配或者被操作系统回收。释放指针时将指针赋值为NULL，在访问时对指针进行判断是否为NULL 不释放内存会造成内存泄漏：堆内存需要手动释放，当程序运行结束不释放，这段内存就会被一直占用。如果 一直在分配不释放会一直占用计算机的内存，直到内存被占完。将new与delete配套使用，使用工具检测或者打印出堆信息  自动垃圾回收（GC）  在程序运行过程中自动释放没有用的数据所在的堆空间（垃圾回收).在虚拟内存空间中能从栈或者数据段的根节点追踪不到的数据为没用的数据 （内存垃圾），常用的算法：标记法, 计数法  标记法回收  标记法：将栈或者数据段作为根（root）进行追踪,将能追踪得的数据（堆空间）进行标记。没有被标记的数据 （堆空间）就是垃圾，将这部分垃圾进行回收。三色抽象：   垃圾回收开始时，将所有数据为白色 垃圾回收开始时，将所有的栈或者数据段的根节点设置为灰色 在根据根节点进行追踪，直到所有的数据节点追踪结束后将根节点置为黑色，在将根节点的下一节点作为根节点进行追踪 所有的数据节点都追踪完后，会剩下黑色和白色的数据节点。黑色表示有用的数据。白色为无用的数据。将白色的数据进行回收（堆空间的释放）    标记法实现简单，但是会造成内存的碎片化(内存块中是可使用小内存块，造成大内存块不能使用这块内存，这些小小内存块也不能使用) 因为内存碎片化的问题诞生了   标记整理法，就是标记法之后，将有用的数据堆内存空间移动在一起，释放更多连续的堆空间,但是这种做法带来 很大的开销，因为需要不断的扫描内存和移动内存 复制回收法。将堆内存分为from和To两个相同的堆内存空间。程序执行时，使用from的堆空间。垃圾回收时会扫描from 的堆内存空间，将有用的数据复制到To的堆空间上。垃圾回收结束时，将To堆空间设置为From堆空间。将原来的from 堆空间全部回收后置为Ton堆空间。但是复制回收法只会使用一般的堆内存空间，造成堆内存空间利用率不高  分代法回收：大部分对象都会在年轻时候死亡（弱分代假说）把新建的对象称之为新生代对象。经过特定次数的GC(垃圾回收)数据依然有用的对象称为 老年代对象。而大部分会在新生代对象就会垃圾回收了，在结合复制回收法使用   计数法回收  引用计数指的是对象被引用的次数，程序在运行过程中会更新引用次数。对象引用越多，计数越大，当计数为0时，回收该对象（堆内存空间） 引用计数法可以在运行中更新对象的计数，可以及时判断计数为 0的对象，然后对其及时回收， 但是频繁的更新引用计数也会带来资源消耗   垃圾回收模式  增量式的垃圾回收模式：SWT是用户承程序停下工作处理垃圾回收，但是为了提高cpu执行效率，会减少SWT的时间，经垃圾回收工作分多次进行（用户程序与垃圾回收交替执行） 三色不变式：在增量式垃圾回收模式在进行垃圾回收时，会造成用户程序对标色的数据进行更改，当在次执行垃圾回收时，可能会将有用的数据当作垃圾回收了，在标色法中，当黑色数据节点可以引用白色的数据节点，但是没有灰色节点能引用这个白色节点，白色数据节点就被当作垃圾被回收 避免这样的发生，在垃圾回收时建立读写屏障。在三色中确保黑色的数据节点不引用白色的数据节点，就不会误判有用的数据当作垃圾回收了，这种叫做：强三色不变式 如果当黑色的数据节点能引用白色数据节点，同时确保回收节点也能引用白色节点，也能避免有用的数据被当作垃圾回收，这叫：弱三色不变式  并行垃圾回收：在多核下，使用多线程对垃圾回收，需要做好的负载均衡和规避数重复处理带来的问题，如在复制回收中，可能将同样的数据从from复制到to 并发垃圾回收：垃圾回收与用户程序并发执行，可能会造成垃圾回收与用户程序的资源竞争等问题等 主体并发回收：在时刻使用swt回收，在莫时刻又使用并发垃圾回收 主体并发增量式回收: 是融合了增量式的垃圾回收模式和主体并发回收模式   内存逃逸  悬挂指针：因内存回收错误导致  例如：int *suspend_pointer{int i= 2; return &amp;amp;i;}   内存逃逸分析：程序在编译阶段根据代码中的数据流，对代码中的那些变量需要在栈中分配 那些在堆上分配进行静态分配的方法 逃逸分析的两个原则：  指向栈对象的指针不能存活在堆中 指向栈对象的指针不能在栈对象回收后存活    参考文献 1.</description>
    </item>
    
    <item>
      <title>进程、线程、协程</title>
      <link>https://zcj-git520.github.io/p/c/c-/</link>
      <pubDate>Tue, 28 Sep 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/c/c-/</guid>
      <description>理解进程与线程 进程  进程是程序一次动态执行过程、进程是操作系统分配资源(内存、io资源、cpu等)和资源调度的基本单位。程序是指令、数据及其组织形式的描述，进程是程序的实体。 进程是由 进程控制块PCB、相关程序段和该程序段进行操作的数据结构集三个部分组成。 进程的五中状态：创建、就绪、运行、阻塞、终止 五种状态转换如图所示：   线程  线程是cup调度和分配的基本单位也是cup执行的最小单位, 有独立的栈空间，共享堆空间。  进程与线程的关系  一个进程可以创建和撤销多个线程， 一个进程必须有一个线程(主线程), 线程共享进程所有资源，进程是线程的容器，关系如图所示：
  并发与并行 并发  并发：多进程(线程)程序在一个核cup串行运行，当一个进程(线程)阻塞的时候，切换到另外等待执行的进程(线程) 如图
  并行  并行：多线程程序在多核cup并行运行，如图
  用户态和内核态(用户空间和内核空间) 特权级划分  cpu一共有0～4四个特权级，R0级最高，R3级最低。用户态指的是：程序运行在R3级以上，通常在应用程序中运行，内核态是指：程序运行在R0级以上，通常在内核中运行。一般来说，我们写的应用程序就是运行在R3级衣以上。  3中种用户态与内核态的切换   系统调用：用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。
  异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。
  外围设备的中断： 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作的完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。
  用户态与内核态结构如图：

  用户态与内核态的切换是需要开销
  来源：linux用户态和内核态理解(https://www.cnblogs.com/weifeng1463/p/11660260.html)
  进程与线程用户态到内核态的开销   多进程(线程)可以提高cpu的利用率，减少程序阻塞带来cpu闲置的情况，也就是提升cpu的运行时间片，但是过多的创建进程(线程)也会花费额外的cpu时间片进行进程(线程)的花销。进程的创建、就绪、运行、阻塞、终止，这些都会带来cup花销。例如在32位的操作系统中创建一个进程需要开辟4GB的虚拟内存空间，创建一个线程需要占用约4MB的内存。</description>
    </item>
    
    <item>
      <title>syslog日志转发配置</title>
      <link>https://zcj-git520.github.io/p/syslog%E6%97%A5%E5%BF%97%E8%BD%AC%E5%8F%91%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 20 Sep 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/syslog%E6%97%A5%E5%BF%97%E8%BD%AC%E5%8F%91%E9%85%8D%E7%BD%AE/</guid>
      <description>服务器配置(服务器平台：x86) Rsyslog简介  Rsyslog是一个 syslogd 的多线程增强版，在syslog的基础上扩展了很多其他功能，如数据库支持(MySQL, PostgreSQL、Oracle等)、日志内容筛选、定义日志格式模板等。除了默认的udp协议外，rsyslog还支持tcp协议来接收日志。 目前的linux的发行版都切换为rsyslog  安装Rsyslog  Linux的发行版中预先安装了Rsyslog,无需安装，rsyslogd –v 查看版本 若未安装，以下是安装步骤： 1.ubuntu：sudo apt install rsyslog 2.CentOS：yum install rsyslog  Rsyslog.conf配置文件详解 配置文件位置：/etc/rsyslog.conf #### MODULES #### #定义日志的模块。 $ModLoad imuxsock #imuxsock为模块名，支持本地系统日志的模块。 $ModLoad imjournal #imjournal为模块名，支持对系统日志的访问。 #$ModLoad imklog #imklog为模块名，支持内核日志的模块。 #$ModLoad immark #immark为模块名，支持日志标记。 # Provides UDP syslog reception #提供udp syslog的接收。 #$ModLoad imudp #imudp为模块名，支持udp协议。 #$UDPServerRun 514 #允许514端口接收使用udp和tcp转发来的日志。 # Provides TCP syslog reception #提供tcp syslog的接收。 #$ModLoad imtcp #imtcp为模块名，支持tcp协议。 #$InputTCPServerRun 514 #### GLOBAL DIRECTIVES #### #定义全局日志格式的指令。 # Where to place auxiliary files $WorkDirectory /var/lib/rsyslog #工作目录。 # Use default timestamp format $ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat #定义日志格式默认模板。 $IncludeConfig /etc/rsyslog.</description>
    </item>
    
    <item>
      <title>我的第一份博客</title>
      <link>https://zcj-git520.github.io/p/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%BB%BD%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Sat, 04 Sep 2021 10:05:40 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%BB%BD%E5%8D%9A%E5%AE%A2/</guid>
      <description>为什么写博客  总结开发中遇到的问题。工作过后发现自己并不擅长对知识点的总结，导致总是遇到相同的问题，过段时间需要重新查找解决方案 记录学习的知识，不断的温习。学的东西过于碎片化，导致知识不成体系。时间长了，碎片的知识也忘记了 提升自己的专业技能。通过写博客提升自己的能力 形成自己的技术栈，遇到的志同道合的朋友  为什么选择hugo来搭建自己的博客  Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 操作简单，使用Markdown直接生成静态网页 免费且以维护, 在github上就可供他人访问，无需购买服务器，维护简单 发表文章直接push到自己仓库即可  下载hogo的源码  git clone https://github.com/gohugoio/hugo.git
git branch 查看单前代码的分支
git branch -a 查看全部分支
git checkout branch 切换分支
git branch 分支名 创建自己的本地分子
 编译源码  在master分支下，在main.go 的目录下使用命令: go build 在目录下生成hugo.exe 在cmd下使用hugo 查看是否编译成功 编译成功 会打印hugo的版本 安装成功  生成站点  使用命令：hugo new site /目录 cd /目录 查看到   ▸ archetypes/ ▸ content/ ▸ layouts/ ▸ static/ config.toml   创建站点成功  创建md文章  使用命令: hugo new 文章名.</description>
    </item>
    
  </channel>
</rss>
