<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Chengji Zhao&#39;s blog</title>
    <link>https://zcj-git520.github.io/post/</link>
    <description>Recent content in Posts on Chengji Zhao&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 01 Mar 2022 22:00:38 +0800</lastBuildDate><atom:link href="https://zcj-git520.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>mysql性能调优-分库分表</title>
      <link>https://zcj-git520.github.io/p/mysql%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</link>
      <pubDate>Tue, 01 Mar 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/mysql%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</guid>
      <description>数据切分  当数据库中的数据或者单表数据过大时，会影响对数据库查询等操作的效率。此时可以减轻数据库的负担 可以将数据库进行拆分，即分库分表。来提高数据库的效率。 数据库有两种拆分方式：水平切分和垂直切分  垂直切分 垂直分库  垂直分库：根据业务解耦，以表为单位，将相同业务的表存储在同一数据库中。将大数据库拆分为不同的小数据库。 小数据库的结构和存储的数据不一样。小数据库的并集为大数据库。  使用场景高并发时，将数据分类到不同数据库中，提升数据库的查询效率  垂直分表  垂直分表：是以字段为单位，将表中的不常用的字段和字段名较长的字段拆分到扩展表中，其余放入到主表中。也可以经热数据放入主表，冷 数据放入拓展表。主表和拓展表的数据结构和存储的数据是不一样。将表中的进行冷热数据的拆分，减少了对磁盘io的操作，提升数据库的效率  使用场景：表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈  优缺点  优点：业务解耦合，方便对不同业务进行管理，提升数据库的效率 缺点：部分表不能join,表中的热数据太多  水平切分 水平分库和分表  都是以字段为单位，通过哈希和随机等策略，将数据分到不同的子库或者子表中。 所有的子库和子表的数据结构一样和数据不一致，即所有子库的数据等于数据库中的数据。形成分布式的效果。  使用场景：数据量行数巨大，存在单库读写、存储性能瓶颈，数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。  优缺点  优点：提升系统稳定性和负载能力 缺点：事务一致性难以保证  数据库的瓶颈  数据库的瓶颈可分为：io瓶颈和cpu瓶颈  io瓶颈  磁盘读写io瓶颈：当热数据过多时，数据库内存(buffer Pool)保存不下时，会产生大量的io。此时就需要进行分库和垂直分表。 网络io瓶颈：请求的数据太多，网络带宽不够，此时就需要分库。  CPU瓶颈  sql中使用了大量的cpu运算的操作。此时需要优化sql,如增加索引 单表数据量大时，且进行全表扫描，查询效率低时，需要水平分表分库。   参考文献： 数据库分库分表思路</description>
    </item>
    
    <item>
      <title>mysql事务实现基本原理</title>
      <link>https://zcj-git520.github.io/p/mysql%E4%BA%8B%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/</link>
      <pubDate>Fri, 25 Feb 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/mysql%E4%BA%8B%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/</guid>
      <description>事务  事务就是一组原子性的SQL语句.  buffer Pool  当启动mysql会开启默认为128M的内存空间来保存从磁盘获取的页的数据到这块内存空间。  InnoDB通过free链表来管理buffer Pool中的空闲页，通过控制块来指向空白页.即从磁盘中的获取的页数据通过 控制块放入到buffer Pool中对应的空闲页中。 通过flush链表来管理buffer Poll中的脏页(通过事务修改过的页)。通过链表中控制块指向脏页。 通过lru链表来对Buffer Pool中的页进行淘汰。通过头插法将最新的页插入到链表中的控制块。当buffer Pool中的页满后，删除链表最后的控制块。 也存在当全表扫描时，也造成数据的覆盖，性能下降。因此链表被划分为热数据区域(5/8)和冷数据区域(3/8)。当两次访问页的时间大于1秒时，把页放入到热数据的控制块 ，否则就放入冷数据页，避免了全表扫描造成热数据被覆盖。生成redo log后，mysql通过后台进程经将脏页持久化到磁盘。当MySQL挂了之后， 会通过redo log恢复数据。    事务具有的ACID的特性  原子性:事务中所有的操作那么全部提交成功，要么全部失败回滚 一致性：数据库总是从一个一致性状态转换到另一个一致性的状态 隔离性：一个事务在所做修改在提交前对其他事务是不可见的 持久性：一旦事务提交，说有的修改都会永久保存在数据库中  事务的隔离级别  读未提交：事务中的修改即使未提交也是对其他事务可见，这级别的事务隔离有脏读、重复读、幻读的问题。 读也提交：事务提交后所做的修改才会被另一个事务所看见，可能产生一个事务中两次查询的结果不同。 可重复读： 只有当前事务提交才能看见另一个事务的修改结果。解决了一个事务中两次查询的结果不同的问题。 可串行化：只有一个事务提交之后才会执行另一个事务。   死锁  死锁：两个或多个事务在同一资源上相互占用并请求锁定对方占用的资源，从而导致恶性循环的现象。MySQL的部分存储引擎能够检测到死锁的循环依赖并产生相应的错误。InnoDB引擎解决死锁的方案是将持有最少排它锁的事务进行回滚  MVCC原理  mvcc 多版本并发控制：指在读取数据时通过一种类似快照的方式将数据保存下来，这样读锁和写锁不冲突。是 innodb 实现事务并发与回滚的重要功能。  版本链  每次更新后，都会将旧值放到一条 undo log 中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被roll_ptr 属性连接成一个链表，我们把这个链表称之为版本链，版本链的头节点就是当前记录最新的值   trx_id：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务id赋值给trx_id隐藏列。 roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。
 ReadView  InnoDB提出了一个ReadView的概念，这个ReadView 中有个 id 列表 trx_ids 来存储系统中当前活跃着的读写事务，也就是 begin 了还未 commit 或 rollback 的事务  参考文献： MySQL运行原理与基础架构</description>
    </item>
    
    <item>
      <title>mysql底层基本原理</title>
      <link>https://zcj-git520.github.io/p/mysql%E5%BA%95%E5%B1%82%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/</link>
      <pubDate>Sun, 20 Feb 2022 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/mysql%E5%BA%95%E5%B1%82%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/</guid>
      <description>索引  索引是帮助数据库获取有序数据的数据结构，实现快速检索  数据库索引的数据结构 哈希表(hash)  通过哈希函数，实现key-value的存储，同时可以使用开放地址法和拉链法解决哈希冲突，对查询单个值的 时间复杂度为O(1)，例如查找id=1：select * from user where id=1 ,但对范围查询十分的不友好,例如查找范围id&amp;gt;100的值：select * from user where id &amp;gt;100;  二叉树  二叉树的数据结构左小右大，可以通过中序遍历直接获取所有升序的数据，二叉树的查询的时间复杂度为 O(lgn),缺点是二叉树容易退化链表，增加数据的查找的时间。在最坏的情况下的时间复杂度为O(n)  平衡二叉树(AVL)和红黑树  通过左旋和右旋以及节点颜色的改变等方式调整树避免退化为链表，使二叉树保持平衡转态，保证树的查找性能 即时间复杂度在O(lgn)。但是二叉树不适合用做数据的底层数据结构原因如下：   1.数据库的查询的瓶颈在于对磁盘io的操作，当存储大量数据的情况下，要保证树的平衡的时候，树的高度 是在不断的增加，在对每一个节点的操作时，就是对磁盘io的操作，即对磁盘io的操作过于的频繁，增加了对数据库 查询等时间。 2 每个节点的分配的内存是16kb的数据量，对于二叉树的节点保持的数据是下于16KB,当数据过低时，也会造成内存的浪费
 B树  B树是一种平衡多分树，节点最多含有N颗子树(指针)，N-1个关键字(数据存储空间) (N&amp;gt;=2);除了根节点和叶子节点外，其它每个节点至少有M=N/2个子节点，M向上取整，即分裂的时候从中间分开，分成M棵子树； 若根节点不是叶子结点，则至少有两颗子树。B树解决了二叉树的高度问题，即减少了对磁盘io的操作，减少了数据库的时间,查询的时间复杂度为 h*O(lgn),h为树的高度。但是也存在一下问题   1.不太适合范围的查询，存在索引的失效 2.稳定性较弱，节点存储的数据较大，占用的内存空间较大
 B+树  B+树和B树类似,B+树的非叶子节点不会存储数据，只存储索引值(指针地址)，所有的数据都是存储在叶子节点，其目的是为了增加系统的稳定性。 应为节点存储的索引，叶子节点存储数据，叶子节点用了链表连接起来，这个链表本身就是有序的，在数据范围查找时，更具备效率 ，保证了存储空间的使用。高度不高，减少了对磁盘的io的操作，保证了查询的效率。  存储引擎 InnoDB引擎 引擎特点 1.将数据存储在表空间中，表空间由一系列的数据文件组成，由InnoDB管理；
2.支持每个表的数据和索引存放在单独文件中(innodb_file_per_table)；
3.支持事务，采用MVCC来控制并发，并实现标准的4个事务隔离级别，支持外键；
4.索引基于聚簇索引建立，对于主键查询有较高性能；
5.数据文件的平台无关性，支持数据在不同的架构平台移植；
6.能够通过一些工具支持真正的热备。如XtraBackup等；
7.内部进行自身优化如采取可预测性预读，能够自动在内存中创建hash索引等。
引擎实现  InnoDB是采用的是B+树作为索引的结构，其存储文件分别是.frm表的定义文件和.idb的数据文件。InnoDB是支持行锁和表锁的。InnoDB 支持事务，且支持四种隔离级别（读未提交、读已提交、可重复读、串行化），默认的为可重复读 表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。   MyISAM引擎 引擎特点 1.</description>
    </item>
    
    <item>
      <title>数据结构-AVL tree go实现</title>
      <link>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-avl-tree-go%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Tue, 15 Feb 2022 21:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-avl-tree-go%E5%AE%9E%E7%8E%B0/</guid>
      <description>平衡二叉树 数据结构定义 // 定义树的节点type AVLTreeNode struct {info int // 定义存储的内容height int // 树的高度right *AVLTreeNode // 右节点left *AVLTreeNode // 左节点}// 定义树type AVLTree struct {root *AVLTreeNode // 定义根节点}// 创建节点func creatNode(data int) *AVLTreeNode{return &amp;amp;AVLTreeNode{info: data,height: -1,right: nil,left: nil,}}数据操作  增删改查  数据的插入 // 数据的插入func getHeight(node *AVLTreeNode) int {if node == nil{return -1}return node.</description>
    </item>
    
    <item>
      <title>数据结构-AVL tree c&#43;&#43;实现</title>
      <link>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-avl-tree-c-%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Mon, 10 Jan 2022 21:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-avl-tree-c-%E5%AE%9E%E7%8E%B0/</guid>
      <description>平衡二叉树 数据结构定义 // 定义树的节点template&amp;lt;class T&amp;gt;class AvrTreeNode{public:AvrTreeNode(){};AvrTreeNode(T data){this-&amp;gt;data = data;left = 0;right = 0;hight = -1;}~AvrTreeNode(){};T data; // 存储的数据AvrTreeNode *left; // 左子树AvrTreeNode *right; // 右子树int hight; // 高度 };// 定义树template&amp;lt;class T&amp;gt;class AvrTree{private:AvrTreeNode&amp;lt;T&amp;gt; *root; // 定义根节点// 插入节点void inseartNode(AvrTreeNode&amp;lt;T&amp;gt;*&amp;amp; node, const T data);void deleteNodeAll(AvrTreeNode&amp;lt;T&amp;gt; *node); // 删除所有节点// 显示节点void DLR(AvrTreeNode&amp;lt;T&amp;gt; *node);void LDR(AvrTreeNode&amp;lt;T&amp;gt; *node);void LRD(AvrTreeNode&amp;lt;T&amp;gt; *node);// 删除*&amp;amp;代表指针引用bool deleteNode(AvrTreeNode&amp;lt;T&amp;gt;*&amp;amp; node, const T data);// void deleteNodeByMerge(AvrTreeNode&amp;lt;T&amp;gt;*&amp;amp; node); // 合并删除// void deleteNodeByCopy(AvrTreeNode&amp;lt;T&amp;gt;*&amp;amp; node); // 复制删除// 单右旋void LL(AvrTreeNode&amp;lt;T&amp;gt; *&amp;amp;node);// 单左旋void RR(AvrTreeNode&amp;lt;T&amp;gt; *&amp;amp;node);// 左右旋void RLR(AvrTreeNode&amp;lt;T&amp;gt; *&amp;amp;node);// 右左旋void LRR(AvrTreeNode&amp;lt;T&amp;gt; *&amp;amp;node);// 求高度的最大值int maxHight(int h1, int h2){return h1&amp;gt;h2 ?</description>
    </item>
    
    <item>
      <title>数据结构-Binary search tree go实现</title>
      <link>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-binary-search-tree-go%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Wed, 05 Jan 2022 21:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-binary-search-tree-go%E5%AE%9E%E7%8E%B0/</guid>
      <description>二叉查找树 数据结构定义 // 定义树的节点type binarySearchTreeNode struct {info int // 定义存储的内容left *binarySearchTreeNode // 左节点right *binarySearchTreeNode // 右节点}// 定义树type BinarySearchTree struct {root *binarySearchTreeNode // 定义根节点numNodes int // 节点树}// 创建节点func creatNode(data int) *binarySearchTreeNode{return &amp;amp;binarySearchTreeNode{info: data,left: nil,right: nil,}}// 节点的数量func (b *BinarySearchTree)GetNodeNum()int{return b.numNodes}数据操作  增删改查  数据的插入 // 节点的插入func (b *BinarySearchTree) InsertNode(data int) {newNode := creatNode(data)// 如果为空树if b.</description>
    </item>
    
    <item>
      <title>数据结构-Binary search tree c&#43;&#43;实现</title>
      <link>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-binary-search-tree-c-%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sat, 01 Jan 2022 21:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-binary-search-tree-c-%E5%AE%9E%E7%8E%B0/</guid>
      <description>二叉查找树 数据结构定义 // 节点的定义template&amp;lt;class T&amp;gt;class BinarySearchTreeNode{public:BinarySearchTreeNode(){left = 0;right = 0;}BinarySearchTreeNode(T data){this-&amp;gt;data = data;left = 0;right = 0;}~BinarySearchTreeNode(){};T data; // 保存的节点的数据BinarySearchTreeNode *left; // 指向左节点BinarySearchTreeNode *right; // 指向右节点};// 树的定义template&amp;lt;class T&amp;gt;class BinarySearchTree{private:BinarySearchTreeNode&amp;lt;T&amp;gt; *root; // 定义头节点int treeNodeNum; // 树的节点数void deleteNodeAll(BinarySearchTreeNode&amp;lt;T&amp;gt; *node); // 删除所有节点// 显示节点void DLR(BinarySearchTreeNode&amp;lt;T&amp;gt; *node);void LDR(BinarySearchTreeNode&amp;lt;T&amp;gt; *node);void LRD(BinarySearchTreeNode&amp;lt;T&amp;gt; *node);// 删除*&amp;amp;代表指针引用void deleteNodeByMerge(BinarySearchTreeNode&amp;lt;T&amp;gt;*&amp;amp; node); // 合并删除void deleteNodeByCopy(BinarySearchTreeNode&amp;lt;T&amp;gt;*&amp;amp; node); // 复制删除public:BinarySearchTree(){root = 0;treeNodeNum = 0;};~BinarySearchTree();// 清空树void clear();// 节点的个数int Nodes(){return treeNodeNum;}// 是否为空树bool isEmpty(){return root == 0;}// 插入数据void inseartNode(const T data);// 深度优先遍历树// 前序遍历(DLR 根-&amp;gt;左-&amp;gt;右)void showNodeByDLR();// 中序遍历(LDR 左-&amp;gt;根-&amp;gt;右)void showNodeByLDR();// 后序遍历(LRD 左-&amp;gt;右-&amp;gt;根)void showNodeByLRD();// 删除节点的数据// 合并删除bool removeNodeMerge(const T data);// 复制删除bool removeNodeCopy(const T data);// 查找数据bool SearchData(const T data);};数据操作  增删改查  数据的插入 template&amp;lt;class T&amp;gt;void BinarySearchTree&amp;lt;T&amp;gt; ::inseartNode(const T data){BinarySearchTreeNode&amp;lt;T&amp;gt; *new_node = new BinarySearchTreeNode&amp;lt;T&amp;gt;(data);// 如果为空树if(isEmpty()){root = new_node; // 新建节点设置为root 节点treeNodeNum ++; // 树的节点数+1return;}BinarySearchTreeNode&amp;lt;T&amp;gt; *node = root;// 遍历树， 找到插入的节点的位置while (node !</description>
    </item>
    
    <item>
      <title>数据结构-栈(基于单项链表)&amp;&amp;队列(基于双向链表)go实现</title>
      <link>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E5%9F%BA%E4%BA%8E%E5%8D%95%E9%A1%B9%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97%E5%9F%BA%E4%BA%8E%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8go%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Fri, 31 Dec 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E5%9F%BA%E4%BA%8E%E5%8D%95%E9%A1%B9%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97%E5%9F%BA%E4%BA%8E%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8go%E5%AE%9E%E7%8E%B0/</guid>
      <description>栈 基于单向链表实现
数据结构定义 type stackData struct {list *Singly_linked_list.LinkedList}// 获得栈的长度func (s *stackData)Len() int{return s.list.Len()}数据操作 // 将数据插入栈顶func (s *stackData)Push(data interface{}) {s.list.AddToHead(data)}// 将数据从栈顶取出，并删除数据func (s *stackData)Pop()interface{}{data := s.list.QuireIndex(0)// 栈不为空, 删除栈顶数据if data != nil{s.list.DeleteToHead()}return data}// 将数据取出，不删除数据func (s *stackData)GetTopValue()interface{}{return s.list.QuireIndex(0)}// 展示栈func (s *stackData)ShowStack() {s.list.QuireAll()}创建栈 func NewStackData()*stackData{return &amp;amp;stackData{list:Singly_linked_list.NewLinkedList()}}队列  基于双向链表实现  数据结构定义 type queueData struct {list *double_linked_list.</description>
    </item>
    
    <item>
      <title>数据结构-栈(基于单项链表)&amp;&amp;队列(基于双向链表)c&#43;&#43;实现</title>
      <link>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E5%9F%BA%E4%BA%8E%E5%8D%95%E9%A1%B9%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97%E5%9F%BA%E4%BA%8E%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8c-%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Fri, 31 Dec 2021 21:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E5%9F%BA%E4%BA%8E%E5%8D%95%E9%A1%B9%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97%E5%9F%BA%E4%BA%8E%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8c-%E5%AE%9E%E7%8E%B0/</guid>
      <description>栈 基于单向链表实现
数据结构定义 template&amp;lt;class T&amp;gt;class Stack{private:SinglyList&amp;lt;T&amp;gt; list; // 存储数据的链表public:Stack(/* args */){};~Stack();// 获得栈的长度int len(){return list.getlen();}// 清空栈void clear();// 判断栈是否为空sbool isEmpty();// 将数据放入栈顶void push(T data);// 获取栈顶数据，并删除数据bool pop(T *info);// 获取栈顶数据但不删除数据bool getTopValue(T *info);// 显示所有栈的数据void showStack();};数据操作 template&amp;lt;class T&amp;gt;void Stack&amp;lt;T&amp;gt; ::clear(){list.clear();}template&amp;lt;class T&amp;gt;void Stack&amp;lt;T&amp;gt; ::push(T data){list.</description>
    </item>
    
    <item>
      <title>数据结构-双向链表&amp;&amp;循环双向链表go语言实现</title>
      <link>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E5%BE%AA%E7%8E%AF%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Thu, 30 Dec 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E5%BE%AA%E7%8E%AF%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/</guid>
      <description>双向链表 数据结构的定义 // 双向链表的节点定义type doubleLinkedNode struct {info interface{} // 存储的数据prev *doubleLinkedNode // 指向先驱节点next *doubleLinkedNode // 指向后驱几点}// 双向链表定义type DoubleList struct {Head *doubleLinkedNode // 头节点Tail *doubleLinkedNode // 尾节点len int // 链表长度}创建节点 func createNode(data interface{}) *doubleLinkedNode {return &amp;amp;doubleLinkedNode{info: data,prev: nil,next: nil,}}链表的长度 // 链表的长度func(d *DoubleList)Len() int{return d.len}数据的插入 单个节点的插入 // 链表的尾插法func (d *DoubleList)AddToTail(info interface{}) *DoubleList {newNode := createNode(info) // 创建新节点// 链表为空, 头尾节点都指向该节点if d.</description>
    </item>
    
    <item>
      <title>数据结构-双向链表&amp;&amp;循环双向链表 c&#43;&#43;实现</title>
      <link>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E5%BE%AA%E7%8E%AF%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8-c-%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Thu, 30 Dec 2021 21:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E5%BE%AA%E7%8E%AF%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8-c-%E5%AE%9E%E7%8E%B0/</guid>
      <description>双向链表 数据结构的定义 template&amp;lt;class T&amp;gt;class TwoWayLinkedNode{public:TwoWayLinkedNode(/* args */){}; TwoWayLinkedNode(T data){this-&amp;gt;data = data;this-&amp;gt;prev = 0;this-&amp;gt;next = 0;}~TwoWayLinkedNode(){};T data; // 数据TwoWayLinkedNode *next; // 指向后继节点TwoWayLinkedNode *prev; // 指向前驱};template&amp;lt;class T&amp;gt;class TwoWayList{private:/* data */TwoWayLinkedNode&amp;lt;T&amp;gt; *head; // 头节点TwoWayLinkedNode&amp;lt;T&amp;gt; *tail; // 尾节点int len; // 链表长度public:TwoWayList(){head = 0;tail = 0;len = 0;};~TwoWayList();// 链表的长度+1void setlen(int len){this-&amp;gt;len += len;}; // 返回链表的长度int getlen(){return len;};// 清空链表void clear();// 链表是否为空bool isEmpty(){return head == 0;}// 插入到链表的头部void inseartToHead(T data); // 插入到链表的尾部void inseartTotail(T data); // 插入到链表的indexvoid inseartToindex(int index, T data); // 删除链表的头部元素void deleteToHead();// 删除链表的尾部元素void deleteToTail();// 删除链表的index元素void deleteToIndex(int index);// 查询链表的所有值void queryAll();// 返回index的值bool queryIndex(int index, T *data);// 判断value是否存在bool queryValue(T data);};数据的操作 template&amp;lt;class T&amp;gt;void TwoWayList&amp;lt;T&amp;gt; ::inseartToHead(T data){TwoWayLinkedNode&amp;lt;T&amp;gt; *new_Node = new TwoWayLinkedNode&amp;lt;T&amp;gt;(data); // 链表为空if (isEmpty()){head = tail = new_Node;}else{new_Node-&amp;gt;next = head; // 新节点的后驱指向头节点head-&amp;gt;prev = new_Node; // 头节点的前驱指向新节点head = new_Node; // 将新节点设置新的头节点}setlen(addOne);}template&amp;lt;class T&amp;gt;void TwoWayList&amp;lt;T&amp;gt; ::inseartTotail(T data){TwoWayLinkedNode&amp;lt;T&amp;gt; *new_Node = new TwoWayLinkedNode&amp;lt;T&amp;gt;(data);if(isEmpty()){head = tail = new_Node;}else{tail-&amp;gt;next = new_Node; // 尾节点的next指向新节点new_Node-&amp;gt;prev = tail; // 新节点的前驱指向尾节点tail = new_Node; // 将新节点设置为新的尾节点}setlen(addOne);}template&amp;lt;class T&amp;gt;void TwoWayList&amp;lt;T&amp;gt; ::inseartToindex(int index, T data){int len = getlen();if(index == 0){inseartToHead(data);return;}// 链表为空，当index 小于0 或者大于等于链表数，采用尾插法if (isEmpty() || index &amp;lt; 0 || index &amp;gt;= len){inseartTotail(data);return;}TwoWayLinkedNode&amp;lt;T&amp;gt; *node = head;int __index = 1;while (__index !</description>
    </item>
    
    <item>
      <title>数据结构-单向链表c&#43;&#43;语言实现</title>
      <link>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8c-%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Mon, 27 Dec 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8c-%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/</guid>
      <description>单向链表 数据结构的定义 数据节点的类的定义 class SinglyLinkedNode{public:SinglyLinkedNode(){next = 0;};// 创建新的nodeSinglyLinkedNode(int data){this-&amp;gt;data = data;next = 0;};~SinglyLinkedNode(){};int data; // 链表的数据SinglyLinkedNode *next; // 指向下一个节点};链表的数据结构(类的定义) class SinglyList{private:/* data */SinglyLinkedNode *head; // 头节点SinglyLinkedNode *tail; // 尾节点int len; // 链表长度public:SinglyList(){head = 0;tail = 0;len = 0;};~SinglyList();// 链表的长度+1void setlen(int len){this-&amp;gt;len += len;}; // 返回链表的长度int getlen(){return len;};// 链表是否为空bool ismpty(){return head == 0;}// 插入到链表的头部void inseartToHead(int data); // 插入到链表的尾部void inseartTotail(int data); // 插入到链表的indexvoid inseartToindex(int index, int data); // 删除链表的头部元素void deleteToHead();// 删除链表的尾部元素void deleteToTail();// 删除链表的index元素void deleteToIndex(int index);// 查询链表的所有值void queryAll();// 返回index的值int queryIndex(int index);// 判断value是否存在bool queryValue(int data);};数据的插入 插入到链表的尾部 void SinglyList::inseartTotail(int data){// 定义nodeSinglyLinkedNode *new_node;new_node = new SinglyLinkedNode(data);// 链表为空if (ismpty()){head = tail = new_node; // 头尾节点都指向新创节点setlen(addOne); // 节点数+1return;}tail-&amp;gt;next = new_node;tail = tail-&amp;gt;next;setlen(addOne);}插入到链表的头部 void SinglyList::inseartToHead(int data){SinglyLinkedNode *node;node = new SinglyLinkedNode(data);if (ismpty()){head = tail = node;setlen(addOne);return ;}node-&amp;gt;next = head;head = node;setlen(addOne);}插入到链表的index void SinglyList::inseartToindex(int index, int data){int len;len = getlen()-1;// 如果链表为空, 或者插入到末尾,或者index &amp;lt;0 采用尾插法添加到链表中if (ismpty() || index ==len || index &amp;lt; 0){inseartTotail(data);return;}if(index == 0){inseartToHead(data);return;}SinglyLinkedNode *node;node = new SinglyLinkedNode(data);int __index = 1;for (node = head; node !</description>
    </item>
    
    <item>
      <title>数据结构-单向链表go语言实现</title>
      <link>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sat, 25 Dec 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/</guid>
      <description>单向链表 数据结构的定义 单项链表节点的定义type singlyLinkedNode struct {info interface{} // 存储任意数据next *singlyLinkedNode // 指向下一节点}type linkedList struct {len int // 链表长度Head *singlyLinkedNode // 头节点Tail *singlyLinkedNode // 尾节点}创建节点 func createNode(info interface{}) *singlyLinkedNode {node := &amp;amp;singlyLinkedNode{info: info,next: nil,}return node}链表的长度 func(l *linkedList)Len() int{return l.len}数据的插入 单个节点的插入 // 链表的尾插法func (l *linkedList)AddToTail(info interface{}) *linkedList {newNode := createNode(info) // 创建新节点// 链表为空, 头尾节点都指向该节点if l.</description>
    </item>
    
    <item>
      <title>超时重试机制-host_try</title>
      <link>https://zcj-git520.github.io/p/%E8%B6%85%E6%97%B6%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6-host_try/</link>
      <pubDate>Mon, 20 Dec 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E8%B6%85%E6%97%B6%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6-host_try/</guid>
      <description>host_try  host_try：主要是目的是在单个或者多个host的下，连接超时或者连接失败下的重试机制 host_try: 提供三种退避策略：1. 尝试等待时间指数增长 2. 以相同时间进行尝试 3.随机时间进行尝试 三种尝试策略可一起使用 host_try: 提供三种重试方式：1. 轮询host进行重连, 重连次数达到后,在将换下一host, 直到重新连接成功或所有的host都重连完成结束 2.每一个host进行重连, 在将换下一host, 所有的host失败了,在进行下一次重连。直到重新连接成功或重连次数达到后结束 3. 重试直到成功 host_try 只是提供重试连接的接口，具体请求的方法需要自己写  host_try的工作原理  存在多个host的请求提供相同的服务如(ntp)，存在连接超时的情况，需要不断的尝试连接， 只要一个host连接请求成功就返回  host_try的配置结构 type tryConfig struct {attemptNum uint // 尝试的重连的次数nowAttempt uint // 现在第几次重连hosts []string // 连接的host组successHost string // 连接成功的hosterrorHost map[string]string // 连接失败的host和错误原因attemptType string // 重连方式attemptStatus bool // 最终重连的状态delay time.Duration // 延时时间maxDelay time.Duration // 最大延时时间maxJitter time.</description>
    </item>
    
    <item>
      <title>timerTask 定时任务包</title>
      <link>https://zcj-git520.github.io/p/timertask-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%8C%85/</link>
      <pubDate>Wed, 15 Dec 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/timertask-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%8C%85/</guid>
      <description>timerTask 定时任务：可以定时执行单个或者对个任务：
 定时定时任务 停止定时任务 重置定时时间，并执行定时任务 定时开启定时任务 定时结束定时任务  timerTask结构 type timerConfig struct {timing time.Duration // 定时时间startTiming time.Duration // 定时开启定时任务时间stopTiming time.Duration // 定时停止定时任务时间running bool // 定时器运行的状态,运作中为true/没有运行为falsetasks []func() // 定时任务stopChan chan struct{} // 停止定时器日任务runningMu sync.MutexWaiter sync.WaitGroup}定时任务的开始和结束 函数原型：NewTimerTask(d time.Duration, tasks []func(), opts ... Option) *timerConfig参数为：统一的定时任务时间,定时任务集, 可选参数【定时开启定时任务时间(SetTimerStart(d time.Duration)), 定时停止定时任务时间(SetTimerStop(d time.Duration))】Start()开始定时任务, Stop()结束定时任务 使用
t1 := 1 * time.Secondtasks := []func(){printTest1, printTest2, printTest3, printTest4, printTest5}timer := NewTimerTask(t1, tasks)timer.</description>
    </item>
    
    <item>
      <title>io多路复用</title>
      <link>https://zcj-git520.github.io/p/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</link>
      <pubDate>Sun, 12 Dec 2021 12:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/</guid>
      <description>常见的IO类型 同步阻塞IO  用户线程通过调用系统命令发起io操作，由用户态复制到内核态空间，内核态一直在等待， 直到获取到数据时，将接收到的数据拷贝到用户态空间，用户线程在获取数据。整个过程用户线程 处于阻塞的状态，直到有数据为止。  同步非阻塞IO  在同步阻塞io的基础上，用户线程发起io操作后，就立刻返回。由于是非阻塞的方式，就存在返回时 没有数据，就需要不断的轮询发起io请求，直到接收到数据为止。  IO多路复用  io多路复用是一种同步的io模型。实现在内核态中一个线程监视多个io(文件句柄)，一旦某个io就绪后， 就通知用户线程进行相关的操作。没有io就绪时就阻塞用户线程，将交出cpu。多路是指网络连接，复用是指 用一个线程。  信号驱动IO  用户线程发起一个io操作后，会向内核注册一个信号处理函数，然后返回，当内核中有数据时，就会发送一个 信号给用户线程，用户态的线程在调用io请求，获取到数据。  异步IO  用户线程发起io操作后就返回。由内核态的线程处理，当内核线程获取到数据后，主动将数据拷贝到用户态， 并告知用户线程io操作也完成。   io多路复用的三种实现方式 select  select是采用数组的存储的结构存储io(fd文件句柄)，默认的最大的fd为32位系统1024，64位系统是2048(可设置),用户线程将fd集合拷贝到 内核态并开始监控，当有fd就绪或者过了设置超时时间，就将fd集合中所有未就绪的fd清空(将bitmap置为0)，将就id集合返回到用户态， 用户态的线程通过轮询返回的fd集合找到就绪的fd,进行相关的io操作获取数据。再一次监控时，需要将之前清空的fd 添加到fd集合中进行新一轮的监控。  #include &amp;lt;sys/select.h&amp;gt; #include &amp;lt;sys/time.h&amp;gt; #define FD_SETSIZE 1024 #define NFDBITS (8 * sizeof(unsigned long)) #define __FDSET_LONGS (FD_SETSIZE/NFDBITS) // 数据结构 (bitmap) typedef struct { unsigned long fds_bits[__FDSET_LONGS]; } fd_set; // API int select( int max_fd, // 最大的文件文件描述符fd fd_set *readset, // 读文件描述符集合 fd_set *writeset, // 写文件描述符集合 fd_set *exceptset, // 异常的文件描述符集合 struct timeval *timeout // 超时时间 ) // 返回值就绪描述符的数目 FD_ZERO(int fd, fd_set* fds) // 清空集合 FD_SET(int fd, fd_set* fds) // 将给定的描述符加入集合 FD_ISSET(int fd, fd_set* fds) // 判断指定描述符是否在集合中 FD_CLR(int fd, fd_set* fds) // 将给定的描述符从文件中删除 //select使用示例 int main() { /* * 这里进行一些初始化的设置， * 包括socket建立，地址的设置等, */ fd_set read_fs, write_fs; struct timeval timeout; int max = 0; // 用于记录最大的fd，在轮询中时刻更新即可 // 初始化比特位 FD_ZERO(&amp;amp;read_fs); FD_ZERO(&amp;amp;write_fs); int nfds = 0; // 记录就绪的事件，可以减少遍历的次数 while (1) { // 阻塞获取 // 每次需要把fd从用户态拷贝到内核态 nfds = select(max + 1, &amp;amp;read_fd, &amp;amp;write_fd, NULL, &amp;amp;timeout); // 每次需要遍历所有fd，判断有无读写事件发生 for (int i = 0; i &amp;lt;= max &amp;amp;&amp;amp; nfds; ++i) { if (i == listenfd) { --nfds; // 这里处理accept事件 FD_SET(i, &amp;amp;read_fd);//将客户端socket加入到集合中 } if (FD_ISSET(i, &amp;amp;read_fd)) { --nfds; // 这里处理read事件 } if (FD_ISSET(i, &amp;amp;write_fd)) { --nfds; // 这里处理write事件 } } }</description>
    </item>
    
    <item>
      <title>redis进阶</title>
      <link>https://zcj-git520.github.io/p/redis%E8%BF%9B%E9%98%B6/</link>
      <pubDate>Wed, 08 Dec 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/redis%E8%BF%9B%E9%98%B6/</guid>
      <description>redis的网络协议  redis是基于tcp/ip协议，即客户端与服务器保持双工连接，通过序列化的协议(resp协议)进行数据的交互，在Redis中，协议数据分为不同的类型， 每种类型的数据均以CRLF（\r\n）结束，通过数据的首字符区分类型  redis服务器是一个事件驱动系统主要分为：文件事件(io事件)和时间事件 文件驱动：socket的读取事件(io事件)是由；连接(三次握手)、请求、响应(数据返回)、断开连接(四次挥手)组成，redis是采用单线程 和epoll(io多路复用)的机制处理相关的文件事件。 时间事件：可分为定时事件(程序在指定时间后执行相关的操作)和周期事件(程序每隔一段时间运行相关的操作)  redis客户端与服务器交互模式 串行的请求/交互模式  客户端与服务器建立长连接，通过心跳检测(ping-pong)ack应答，即客户端发送请求，服务器在进行响应。 在单连接下。大部分时间都是处于网络等待上(客户端在发送请求命令，并监听socket返回，通常以阻塞模式等待服务器端的响应)，这种模式下 的性能较低   管道技术(pipeline)双工的请求/响应模式  将一批命令进行打包，然后发送给服务器，服务器获取数据后按顺序打包返回，即批量请求，批量响应。以次来减少网络等待的延时，提高性能   原子化的批量请求/响应(事务)模式  客户端将请求的命令发送发到服务器，服务器经这些请求暂存在服务器的请求队列中，这过程也称为：请求入队列。服务器在从请求队列中 拿去所有的请求执行，然后再将数据返回给客户端，这过程称为执行阶段。 服务器在执行过程中不会在接收其他客户端发送的请求。所有的操作都是原子操作，即请求都执行或都不执行。 事务的步骤为：开始事务-&amp;gt;请求入队列-&amp;gt;执行请求   发布/订阅(pub/sub)模式  发布者(pub)发送消息，订阅者(sub)接收消息，发布者和订阅者通过(通道)channel关联，所有的channel都是由一个map维护，map的key是 channel的名字，value是所有的订阅者的指针链表。客户端可以订阅任意的数量的频道，也可以进行发布。 发布者和订阅者都是客户端，服务器只是进行数据的中转。即发布者着向服务端发起请求，服务端将请求的数据推送给订阅者。   redis的持久化机制  redis的持久化机制主要是有：RDB(快照)和AOF(日志)两种持久化的方式。持久的化的作用在于：故障恢复和数据恢复  RDB(快照)持久化机制  快照是redis默认的持久化方案，在指定时间间隔内生成数据集的时间点，即在指定的时间段内将内存的数据写入磁盘，在磁盘 上生成一个rdb的备份文件。在redis重启时加载rdb文件进行数据的恢复。 快照的持久化提供自动备份：需要修改配置文件redis.conf。也提供save和bysave(后台子进程)进行主动备份  RDB(快照)的工作流程：  主进程会单独创建子进程，将主进程的数据库的数据复制到子进程。 子进程将数据写入到临时文件中进行持久化，在经临时文件替换之前的rdb文件,子进程退出，释放内存中的数据 主进程不进行持久化，即不进行任何的io操作，确保redis的极高的性能  RDB(快照)的优缺点 优点  单一的紧凑文件保存了莫一段时间的数据集，比较适合做数据的备份尤其的冷备份 在对数据完整性不敏感下，适合大规模的数据的恢复，因直接从磁盘获取数据，恢复数据快 由子进程进行持久化，主进程不进行持久化，即不进行任何的io操作，确保redis的极高的性能  缺点  不能保障数据的完整性，若redis出现宕机，就不会出现最近的数据未持久化，导致数据的丢失。 当持久化的数据量较大时，会导致持久化的子进程就会很耗时，即使主线程在不参与持久化也可能导致服务器在毫秒级内不能响应 客户端的请求，若数据巨大时且cpu的性能不佳时，会出现秒级不能响应客户端的请求。  AOF(日志)持久化  通过将每个写操作记录到日志中且以追加文件不修改文件的模式，重启时更具根据日志文件从头到未执行一遍即恢复数据。，因AOF采用的是经操作记录以追加模式下写入日志文件中，会导致AOF文件越来越大。AOF引入了重写机制。 AOF引入了重写机制：当文件AOF是上次重写大小的一倍且文件大于64MB时就创建一个子进程遍历服务器的键值对，转换成一系列 Redis 的操作 指令，序列化到一个新的AOF日志文件中，再替换旧的AOF日志文件。可以修改配置文件设定持久化策略。  AOF 提供了三种持久化策略：  no: 无 fsync，由系统保证数据刷新到磁盘，速度最快，但很不安全（通常不使用）； always: 每次 fsync，每一个修改内存的 Redis 指令都会执行一次 fsync，速度很慢（通常不使用）； everysec: 每秒进行一次 fsync，有可能丢失一秒的 fsync 的数据。通常选择 everysec 策略，兼顾安全性和效率。  AOF(日志)的优缺点 优点  可以采用everysec的持久化策略，能确保数据的完整性  缺点  AOF的日志文件通常是比rdb文件大 在数据的恢复时，需要遍历日志文件，将日志文件的数据操作命令在执行一遍，导致数据恢复相对于快照(rdb)较慢，尤其在大数据下。  redis 缓存中的状况于解决方案 缓存雪崩  数据未加载到内存或者同一时间发生大规模的key失效，从而导致所有的请求都直接在查数据库。导致数据库和cpu负载过高，甚至宕机  解决方案  加锁计数，限制并发的数量，避免出现并发出现大量的请求访问到数据库，降低服务器的吞吐量 设置热点key永不失效，均匀过期，避免出现大面积的key同时失效 设置缓存服务器的主备  缓存穿透  指客户端请求的数据在缓存和数据库中均没有，导致客户端在每次请求都需要去数据库查询。若在并发时，也会导致数据库和cpu的负载过高， 导致数据库的宕机  解决方案  若查询数据库不存在，直接在缓存中保存一个默认的值，并设置较短的过期时间，下次请求直接从缓存中返回。 使用布隆过滤器，阻挡无效的请求。  缓存并发  在并发情况下，一个缓存失效，在高并发下访问数据库，缓存更新，也会导致数据的压力变大。  解决方案  对缓存加锁，若key不存在，就加锁，当查询数据库的数据写入缓存在解锁  缓存预热  在系统运行前，将数据加载到缓存中  解决方案  数据量不大，直接加载 数据量大时，设置定时的脚本进行缓存的刷新 数据量巨大时，优先保障热点数据提前加载到缓存中  缓存降级  指缓存失效或者缓存服务器宕机时，不去访问数据库，直接返回默认值或访问内存数据  分布锁  使用setnx加锁，并设置超时时间，过了超时时间就解锁，并删除锁  参考文献 Redis 客户端服务端交互1 客户端/服务端协议</description>
    </item>
    
    <item>
      <title>初识redis(数据结构分析)</title>
      <link>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</link>
      <pubDate>Sun, 05 Dec 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/</guid>
      <description>redis  redis 是一个开源（BSD许可）的，数据结构为key-value的存储系统。它可以用作分布式数据库、缓存 和消息队列（消息中间件）。数据保存在内存中，存取速度快，并发能力强。 redis 支持多种数据结构，如字符串、map(哈希)、列表、集合、有序集合等数据类型。数据都是原子操作， 数据都缓存在内存中，会定期将数据更新到磁盘或者修改操作写入追加记录。再次基础上实现了主从（master-slave）  redis 数据结构 字符串(string)类型  字符串类型是redis最基础的数据结构，可以存储简单的字符串也可存储复杂的xml、json、二进制数据（如图像、音频） value内部以保存整数的int和保存字符的sds组成的数据存储结构。sds内部结构为：  struct sdshdr { int len; // 记录着buf中也使用的字符串数量 int free; // 记录着buf中未使用的字符串数量 char buh[]; // 字符串数组，用于保存字符串 } 
字符串类型特性  分配冗余空间：采用预先分配冗余空间的方式来减少内存的频繁分配 自动扩容： 当字符串所占空间小于1MB时，redis会按照字符串（len + addLen）*2倍数存储空间增加， 当字符串的存储空间超过所占空间的1MB时，每次自会增加1MB的存储空间扩容，最大扩容为512MB的存储空间 二进制的安全性，兼容c语言函数库中字符串以\0结束。  字符串常用的场景  缓存功能： 基于redis作为缓存再配合其他的数据库最为存储层，利用redis的数据存储在内存和支持高并发的特点，可以大大加快 系统的读写速度以及降低后端数据库的压力。（单值缓存、对象缓存、分布式锁等） 计数器： 使用redis作为系统的实时计数器，可以加快计数和查询功能。 共享用户的session：利用redis将用户的session集中管理，这种模式确保redis的高可用。每次用户的session的更新和获取快速完成  列表(list)  list类型的value对象内部采用的quicklist(快速列表)或者ziplist(压缩列表)承载。当list的元素和单个元素较小时采用ziplist实现来减少内存的 占用否则采用quicklist结构进行存储。 ziplist所有内容都存放在来连续的内存中。zipbytes表示ziplist的总长度， zltail表示指向最末的元素，zllen表示元素个数， entryX表示元素自身内容， zlend是ziplist的定界符 ziplist的内部结构为：  typedef struct ziplist{ /*ziplist分配的内存大小*/ uint32_t bytes; /*达到尾部的偏移量*/ uint32_t tail_offset; /*存储元素实体个数*/ uint16_t length; /*存储内容实体元素*/ unsigned char* content[]; /*尾部标识*/ unsigned char end; }ziplist; /*元素实体所有信息, 仅仅是描述使用, 内存中并非如此存储*/ typedef struct zlentry { /*前一个元素长度需要空间和前一个元素长度*/ unsigned int prevrawlensize, prevrawlen; /*元素长度需要空间和元素长度*/ unsigned int lensize, len; /*头部长度即prevrawlensize + lensize*/ unsigned int headersize; /*元素内容编码*/ unsigned char encoding; /*元素实际内容*/ unsigned char *p; }zlentry;</description>
    </item>
    
    <item>
      <title>初探jwt(json web Token)</title>
      <link>https://zcj-git520.github.io/p/%E5%88%9D%E6%8E%A2jwtjson-web-token/</link>
      <pubDate>Tue, 30 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%88%9D%E6%8E%A2jwtjson-web-token/</guid>
      <description>jwt  jwt 它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息，是最流行的跨域认证的解决方案  传统跨域认证  客服端向服务器发送用用户名和密码，服务器验证通过后，把当前对话的session里保存 相关数据，并写在客户端的cookie, 向客户端返回一个session id。客户端再次通过cookie, 经session id 传回服务器，服务器通过session id得知访问客户端的身份。 存在的问题：扩展性不佳，服务器集群或者跨域的服务导向架构，就需要共享session共享数据 解决方案：1. 将session 数据保存在数据库中或者其他的持久层，服务器访问持久层的session数据 2. 服务器不保存session数据，所有的数据保存在客户端，每次请求都发回服务器  jwt的原理  服务器认证以后，生成一个json对象，返回给客户端之后，客户端与服务器靠这个json对象认证，会会 加上签名来防止客户端修该json 对象  jwt的数据结构  jwt的数据结构为：Header(头部)、payload(负载)、signature(签名)
  Header(头部)  Header部分是一个json对象，描述jwt的元素据。声明类型，这里是jwt声明加密的算法 通常直接使用 HMAC SHA256，结构如下：  { &#39;typ&#39;: &#39;JWT&#39;, &#39;alg&#39;: &#39;HS256&#39; } payload(负载)  payload 也是一个json对象，用来存放实际需要的传递的数据，iss：发行人，exp：到期时间，sub：主题，aud：用户， nbf：在此之前不可用，iat：发布时间，jti：JWT ID用于标识该JWT  { &amp;quot;sub&amp;quot;: &amp;quot;1234567890&amp;quot;, &amp;quot;name&amp;quot;: &amp;quot;John Doe&amp;quot;, &amp;quot;admin&amp;quot;: true } signature(签名)  是对前两部分进行签名，防止篡改。在服务器上指明一个密钥，在根据header中指定的算法， 按照格式产生签名，header (base64后的)、payload (base64后的)、secret。其格式如下：  // javascript var encodedString = base64UrlEncode(header) + &#39;.</description>
    </item>
    
    <item>
      <title>初识Nginx</title>
      <link>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86nginx/</link>
      <pubDate>Wed, 24 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86nginx/</guid>
      <description>Nginx  nginx 是轻量级高并发web服务器，是基于Rest架构风格。通过http协议提供各种网络服务
其高并发是基于事件驱动架构，io多路复用的epoll,使得可以轻松支持百万计的icp连接。
轻量级主要体现在：采用插件化开发，cup亲和，将cpu与nginx工作进程绑定，减少cpu切换带来的消耗  代理  代理是客户端与服务器之间的一层服务器，将客户端的请求转发给服务器，然后服务器的响应转发给客户端  正向代理  客户端向代理服务器转发请求和指定目标服务器，代理服务器向目标服务器发送请求，并将结果返回给客户端。 对客户端是透明的，即客户端知道访问的是目标服务器，对目标服务器来说是非透明的，并不知道访问服务器是 客户端还是代理服务器  反向代理  客户端向代理服务器发送请求，代理服务器将请求转发给内部的网络服务器(目标服务器)，在将结果返回给客户端。对于客户端 是非透明的，即客户端不清楚是访问是那一台目标服务器。对于目标服务器是透明的，即目标服务器知道访问的是 代理服务器 nginx反向代理的配置如下：  server { listen 80; server_name www.123.com; location / { proxy_pass http://127.0.0.1:8080; index index.html index.htm index.jsp; } } 我们监听80端口，访问域名为www.123.com，不加端口号时默认为80端口，故访问该域名时会跳转到127.0.0.1:8080路径上
负载均衡  当请求过大时，将请求分发给各个服务器。负载均衡的分配策略为：weight(权重)轮询，fair(智能调整调度) nginx轮询配置(所有请求都按照时间顺序分配到不同的服务上)  upstream dalaoyang-server { server localhost:10001; server localhost:10002; }  nginx权重配置(权重轮询：代理服务器接收到请求，按照设定的权重，请求分配到不同的后端服务器，如果发现后端服务器宕机时， 代理服务器会将其剔除出队列)  upstream dalaoyang-server { server localhost:10001 weight=1; server localhost:10002 weight=2; }  nginx iphash 配置(每个请求都根据访问ip的hash结果分配)  upstream dalaoyang-server { ip_hash; server localhost:10001 weight=1; server localhost:10002 weight=2; }  最少连接(将请求分配到连接数最少的服务上)  upstream dalaoyang-server { least_conn; server localhost:10001 weight=1; server localhost:10002 weight=2; }  far 智能调整调度算法：动态根据后端服务器的请求处理到响应时间进行均衡分配。即响应时间短，处理效率高的服务器 分配到请求的概率高。响应时间长，效率低的服务器分配到请求的概率低。 far 配置文件如下：  upstream dalaoyang-server { server localhost:10001 weight=1; server localhost:10002 weight=2; fair; } 流量控制  限流实际就是限制流入请求的数量：有计数器固定窗口算法、令牌桶算法、漏桶算法和限制并发连接数限制</description>
    </item>
    
    <item>
      <title>http协议底层分析</title>
      <link>https://zcj-git520.github.io/p/http%E5%8D%8F%E8%AE%AE%E5%BA%95%E5%B1%82%E5%88%86%E6%9E%90/</link>
      <pubDate>Thu, 18 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/http%E5%8D%8F%E8%AE%AE%E5%BA%95%E5%B1%82%E5%88%86%E6%9E%90/</guid>
      <description>HTTP  HTTP是(Hyper Text Transfer Protocol)超文本传输协议, 基于tcp的应用层传输协议（请求-响应）协议 影响HTTP网络请求的主要因素带宽和延迟  延迟的种类:  浏览器阻塞(超过浏览器连接数限制的后续请求都会被阻塞) DNS查询 (将域名解析造成的延迟，可以通过缓存DNS进行解决) 建立链接 (因HTTP是基于TCP的应用层协议，在建立连接时需要进行)  HTTP1.0 http1.0存在的问题：  短连接：规定客户端与服务器只保持短暂连接，客户端每次请求都需要建立连接，服务器完成请求后 断开连接，服务器不跟踪客户端，不保存客户端的请求记录。 没有host头域：每台服务器都绑定一个唯一的IP地址，请求消息中的URL并没有传递主机名（hostname） 不允许短点续传  HTTP1.1 根据http1.0暴露的问题，http1.1增加优化方案  缓存处理：http1.1增加更多的缓存控制策略 带宽优化及网络连接的使用：http1.1中请求头引入了range头域和支持断点续传的功能 Host头处理：http1.1的请求消息和相应消息虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机(Multi-homed Web Servers),并且它们共享一个IP地址,HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request） 长连接： 支持长连接和流水线处理，默认开始是长连接：keep-alive  http1.1 也带来新的问题：HTTP 队头阻塞(head of line blocking)  因http1.1支持了长连接和使用了管道机制，客户端与服务器建立一次连接，客户端不用等待服务器响应就能发送下一个请求，支持了并行发送多个请求， 但服务器必须按照请求的顺序来相应请求，也就是通过串行响应请求，这就造成了HTTP的队头阻塞。  解决Http 队头阻塞方法  并发连接：一个域名允许分配多个长连接，增加处理请求任务 域名分片：将一个域名分解为多个域名，在进行并发连接  HTTP2.0  HTTP2.0主要是基于SPDY协议。实现了低延时高吞吐量  SPDY协议  是基于TCP协议的应用层协议，其目标是通过头部压缩、多路复用、优先级等作用缩短网页放入加载时间和 优化http的性能，其核心是尽量减少TCP连接数  HTTP 2.0的特性 头部压缩 头部存在大量的信息，而且每次在发送都会降低http的性能，在用HPACK算法对头部进行压缩： 1.在客户端和服务器维持一个头部表来跟踪和存储客户端发来的键值对 2.客户端在请求的时候便只需要发送在表里的索引位置即可 3.HPACK 不仅仅通过索引键值对来降低数据量，同时还会将字符串进行霍夫曼编码来压缩字符串大小</description>
    </item>
    
    <item>
      <title>PRC</title>
      <link>https://zcj-git520.github.io/p/prc/</link>
      <pubDate>Mon, 15 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/prc/</guid>
      <description>RPC  RPC(Remote Procedure Call Protocol)——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务， 而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP/IP或UDP，为通信程序之间携带信息数据。 RPC将原来的本地调用转变为调用远端的服务器上的方法，给系统的处理能力和吞吐量带来了近似于无限制提升的可能。 在OSI网络通信模型中，RPC跨域了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易 RPC采用客户机/服务器(client-server)模式,也是一种请求/响应(request-response)模式，可以通过TCP/UDP以及HTTP 协议进行传输  RPC 架构  CAll ID 映射：客户端通过ID传输给服务器，服务器通过ID调用相应的函数返回 序列化与烦序列化：客户端与服务器通过序列化与反序列化进行传参 一个完整的RPC架构里面包含了四个核心的组件，分别是Client，Client Stub，Server以及Server Stub，这个Stub可以理解为存根。   客户端(Client)，服务的调用方。 客户端存根(Client Stub)，存放服务端的地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程发送给服务方。 服务端(Server)，真正的服务提供者。 服务端存根(Server Stub)，接收客户端发送过来的消息，将消息解包，并调用本地的方法。  RPC调用过程  客户端（client）以本地调用方式（即以接口的方式）调用服务； 客户端存根（client stub）接收到调用后，负责将方法、参数等组装成能够进行网络传输的消息体（将消息体对象序列化为二进制）； 客户端通过sockets将消息发送到服务端； 服务端存根( server stub）收到消息后进行解码（将消息对象反序列化）； 服务端存根( server stub）根据解码结果调用本地的服务； 本地服务执行并将结果返回给服务端存根( server stub）； 服务端存根( server stub）将返回结果打包成消息（将结果消息对象序列化）； 服务端（server）通过sockets将消息发送到客户端； 客户端存根（client stub）接收到结果消息，并进行解码（将结果消息发序列化）； 客户端（client）得到最终结果。
RPC的目标是要把2、3、4、7、8、9这些步骤都封装起来。   注意：无论是何种类型的数据，最终都需要转换成二进制流在网络上进行传输，数据的发送方需要将对象转换为二进制流，而数据的接收方则需要把二进制流再恢复为对象。   gPRC  gRPC 是一种现代开源高性能远程过程调用 (RPC) 框架，可以在任何环境中运行。它可以通过对负载平衡、跟踪、健康检查和身份验证的可插拔支持，有效地连接数据中心内和数据中心之间的服务。它还适用于分布式计算的最后一英里，将设备、移动应用程序和浏览器连接到后端服务。 gRPC 是基于HTTP2.0(多路复用,消除了线头阻塞)标准协议色设计的基于ProtoBuf序列化的高性能框架。 《gRPC 官方文档中文版》  Protocol Buffers  Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据序列化，很适合做数据存储或 RPC 数据交换格式。它可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式 序列化：将数据结构或对象转换成能被传输或者存储（如二进制格式）的过程。 反序列化：将在序列化过程中所生成的(格式)转换成数据结构或者对象的过程。  参考文献： RPC原理解析</description>
    </item>
    
    <item>
      <title>RestfulAPI</title>
      <link>https://zcj-git520.github.io/p/restfulapi/</link>
      <pubDate>Wed, 10 Nov 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/restfulapi/</guid>
      <description>Restful API  rest是Representational state Transfer 的缩写（表述性转态传递） api是应用程序接口 Restful API是一种软件结构风格，设计风格，让软件更加清晰、简洁、易维护。是一种流行的软件API 设计风格  Rest的指导风格  客户端-服务器：通过将用户接口问题与数据存储问题分开，简化服务器组件来提高跨平台放入用户接口的 可移植性性并提高可伸缩性 无转态：从客户端到服务器的每个请求都必须包含理解请求所需的所有信息，并且不能利用服务器上任何存储的上下文。因此，会话状态完全保留在客户端上。 可缓存：缓存约束要求将对请求的响应中的数据隐式或显式标记为可缓存或不可缓存。如果响应是可缓存的，则客户端缓存有权重用该响应数据以用于以后的等效请求。 统一接口：通过将通用性的软件工程原理应用于组件接口，简化了整个系统架构，提高了交互的可见性。为了获得统一的接口，需要多个架构约束来指导组件的行为。REST由四个接口约束定义：资源识别; 通过陈述来处理资源; 自我描述性的信息; 并且，超媒体作为应用程序状态的引擎 分层系统：分层系统风格允许通过约束组件行为来使体系结构由分层层组成，这样每个组件都不能“看到”超出与它们交互的直接层。 按需编码（可选）： REST允许通过以小程序或脚本的形式下载和执行代码来扩展客户端功能。这通过减少预先实现所需的功能数量来简化客户端  RestFul 架构  资源：网络的实体或者是具体的信息，使用URI(统一资源定位符)，URI是每一个资源的地址或者独一无二的是识别符 表现层： 对资源的外在表现，如：json、xml、txt、二进制等 转态转化：互联网是一种无转态的协议，所有的状态都是保存在服务器上，客户端通过 HTTP的操作方式(GET,POST,PUT,DELETE)等改变服务器的“状态变化”   RESTful API接口规范 接口风格  路径和变量均采用小驼峰式，例如deviceId 使用HTTP动词作为action操作URL资源，动词一律大写。  GET：读取\查询（Read） POST：新建（Create） PUT：更新（Update） PATCH：更新（Update），通常是部分更新 DELETE：删除（Delete） HEAD：获取资源的元数据。 OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。 5种请求动作中，GET、PUT、PATCH、DELETE均是幂等的；只有POST是非幂等的。幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。是非幂等是判断接口使用POST还是PUT的决定条件。幂等的理解见本文附录。   参数：  PATH（路径）：  版本号放入PATH，且在最前  尽量使用名词，不使用动词，把每个URL看成一个资源，名称都用复数 微服务名称不放入PATH中     Query参数：主要用在GET查询中，简单的PUT动作，也用Query参数 Headers参数：公共参数通过header传递，content-type、authorization认证必填，其他统一按调用链规范、速率限制规范填写。content-type应该固定为application/json。 Body：  统一使用json格式，所有返回都是json格式  POST所有参数通过JSON传递 GET请求不允许有body， 所有参数通过拼接在URL之后传递，所有的请求参数都要进行遵循RFC 3986的URL Encode。 DELETE删除单个资源时，资源标识通过path传递，批量删除时，通过在body中传递JSON。       返回结果  状态码：HTTP状态码标准用法，见后状态码规范 Body返回，只提供json返回格式 GET：返回资源对象，完整对象或通过Query参数可过滤 POST：返回新生成的资源对象，可能是ID或完整的资源对象 PUT：返回完整的资源对象 DELETE：返回一个空文档   过滤信息：查询及查询结果使用  pageNo：分页查询标识第几页 pageSize：分页查询标识每页多少条数据 begin：录像/截图开始时间，Unix时间戳，单位秒 end：录像/截图结束时间，Unix时间戳，单位秒 orderby：排序规则，desc或asc q：搜索关键字（uri encode之后的） totalCount：总记录数，分页查询，返回json携带 totalPages：总页数，分页查询，返回json携带，等于page时，表示当前是最后一页   微服务内部使用http协议，对外使用https协议  详细设计要求  输入参数要精简有效  不能把内部对象作为接口参数，通过DTO进行转换； required的字段尽可能少   CRUD的U(POST)要通过业务分析（领域建模）具体化操作，不要提供灵活但是支持不全面的接口 查询尽可能提供丰富的查询条件，可以返回尽可能详细的信息 同类资源尽可能统一接口 避免多级 URL，比如获取某个作者的某一类文章： GET /authors/12/categories/2 这种 URL 不利于扩展，语义也不明确，往往要想一会，才能明白含义。 更好的做法是，除了第一级，其他级别都用查询字符串表达。 GET /authors/12?</description>
    </item>
    
    <item>
      <title>Docker知识总览</title>
      <link>https://zcj-git520.github.io/p/docker%E7%9F%A5%E8%AF%86%E6%80%BB%E8%A7%88/</link>
      <pubDate>Fri, 05 Nov 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/docker%E7%9F%A5%E8%AF%86%E6%80%BB%E8%A7%88/</guid>
      <description>概念知识 Docker镜像 Docker镜像是由文件和元数据组成的。
 文件：语言环境、库、执行文件  由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。   元数据：环境变量、端口映射、卷等 镜像信息：  RESPOSITORY：仓库名 TAG：标签 IMAGE ID：镜像ID CREATED：创建时间 SIZE：所占用的空间   虚悬镜像(dangling image)  RESPOSITROY及TAG都为 使用docker image prune 可以删除    容器 容器是从镜像中创建，继承了他们的文件系统，并使用他们的元数据来确定其启动配置。
 启动时，运行一个进程，不过可派生其他进程。 文件的变更通过写时复制存储在容器中，基础镜像不会受影响。  数据卷 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：
 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷  Docker网络 当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。</description>
    </item>
    
    <item>
      <title>Python安全指南</title>
      <link>https://zcj-git520.github.io/p/python%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sat, 30 Oct 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/python%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</guid>
      <description>文章来源 鹅厂(腾讯)代码安全指南
通用 加密算法 【必须】避免使用不安全的对称加密算法  DES和3DES已经不再适用于现代应用程序，应改为使用AES。  程序日志 【建议】对每个重要行为都记录日志  确保重要行为都记录日志，且可靠保存6个月以上。  1.2.2 【建议】禁止将未经验证的用户输入直接记录日志  当日志条目包含未经净化的用户输入时会引发记录注入漏洞。恶意用户会插入伪造的日志数据，从而让系统管理员以为是系统行为。  1.2.3 【建议】避免在日志中保存敏感信息  不能在日志保存密码（包括明文密码和密文密码）、密钥和其它敏感信息  系统口令 【必须】禁止使用空口令、弱口令、已泄露口令 【必须】口令强度要求  口令强度须同时满足：
 密码长度大于14位 必须包含下列元素：大小写英文字母、数字、特殊字符 不得使用各系统、程序的默认初始密码 不能与最近6次使用过的密码重复 不得与其他外部系统使用相同的密码   【必须】口令存储安全  禁止明文存储口令 禁止使用弱密码学算法（如DES和3DES）加密存储口令 使用不可逆算法和随机salt对口令进行加密存储  【必须】禁止传递明文口令 【必须】禁止在不安全的信道中传输口令 配置&amp;amp;环境 Python版本选择 【建议】使用Python 3.6+的版本  新增的项目应使用 Python 3.6+   为什么要这么做？ 由于 Python 2 在 2020 年停止维护，相关组件的漏洞不能得到及时修复与维护
 第三方包安全 【必须】禁止使用不安全的组件 配置信息 【必须】密钥存储安全  在使用对称密码算法时，需要保护好加密密钥。当算法涉及敏感、业务数据时，可通过非对称算法协商加密密钥。其他较为不敏感的数据加密，可以通过变换算法等方式保护密钥。  【必须】禁止硬编码敏感配置  禁止在源码中硬编码AK/SK、IP、数据库账密等配置信息 应使用配置系统或KMS密钥管理系统。  后台 输入验证 【必须】按类型进行数据校验   所有程序外部输入的参数值，应进行数据校验。校验内容包括但不限于：数据长度、数据范围、数据类型与格式。校验不通过，应拒绝。</description>
    </item>
    
    <item>
      <title>c/c&#43;&#43;安全指南</title>
      <link>https://zcj-git520.github.io/p/c/c-%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Thu, 28 Oct 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/c/c-%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</guid>
      <description>文章来源 鹅厂(腾讯)代码安全指南
通用安全指南 C/C++使用错误 【必须】不得直接使用无长度限制的字符拷贝函数 不应直接使用legacy的字符串拷贝、输入函数，如strcpy、strcat、sprintf、wcscpy、mbscpy等，这些函数的特征是：可以输出一长串字符串，而不限制长度。如果环境允许，应当使用其_s安全版本替代，或者使用n版本函数（如：snprintf，vsnprintf）。
若使用形如sscanf之类的函数时，在处理字符串输入时应当通过%10s这样的方式来严格限制字符串长度，同时确保字符串末尾有\0。如果环境允许，应当使用_s安全版本。
但是注意，虽然MSVC 2015时默认引入结尾为0版本的snprintf（行为等同于C99定义的snprintf）。但更早期的版本中，MSVC的snprintf可能是_snprintf的宏。而_snprintf是不保证\0结尾的（见本节后半部分）。
（MSVC） Beginning with the UCRT in Visual Studio 2015 and Windows 10, snprintf is no longer identical to _snprintf. The snprintf function behavior is now C99 standard compliant. 从Visual Studio 2015和Windows 10中的UCRT开始，snprintf不再与_snprintf相同。snprintf函数行为现在符合C99标准。 请参考：https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/snprintf-snprintf-snprintf-l-snwprintf-snwprintf-l?redirectedfrom=MSDN&amp;amp;view=vs-2019 因此，在使用n系列拷贝函数时，要确保正确计算缓冲区长度，同时，如果你不确定是否代码在各个编译器下都能确保末尾有0时，建议可以适当增加1字节输入缓冲区，并将其置为\0，以保证输出的字符串结尾一定有\0。
// Good char buf[101] = {0}; snprintf(buf, sizeof(buf) - 1, &amp;#34;foobar ...&amp;#34;, ...); 一些需要注意的函数，例如strncpy和_snprintf是不安全的。 strncpy不应当被视为strcpy的n系列函数，它只是恰巧与其他n系列函数名字很像而已。strncpy在复制时，如果复制的长度超过n，不会在结尾补\0。
同样，MSVC _snprintf系列函数在超过或等于n时也不会以0结尾。如果后续使用非0结尾的字符串，可能泄露相邻的内容或者导致程序崩溃。
// Bad char a[4] = {0}; _snprintf(a, 4, &amp;#34;%s&amp;#34;, &amp;#34;AAAA&amp;#34;); foo = strlen(a); 上述代码在MSVC中执行后， a[4] == &amp;lsquo;A&amp;rsquo;，因此字符串未以0结尾。a的内容是&amp;quot;AAAA&amp;quot;，调用strlen(a)则会越界访问。因此，正确的操作举例如下：</description>
    </item>
    
    <item>
      <title>Go安全指南</title>
      <link>https://zcj-git520.github.io/p/go%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</link>
      <pubDate>Sun, 24 Oct 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/go%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/</guid>
      <description>文章来源 鹅厂(腾讯)代码安全指南
通用 内存管理 【必须】切片长度校验  在对slice进行操作时，必须判断长度是否合法，防止程序panic  // bad: 未判断data的长度，可导致 index out of range func decode(data []byte) bool { if data[0] == &#39;F&#39; &amp;amp;&amp;amp; data[1] == &#39;U&#39; &amp;amp;&amp;amp; data[2] == &#39;Z&#39; &amp;amp;&amp;amp; data[3] == &#39;Z&#39; &amp;amp;&amp;amp; data[4] == &#39;E&#39; &amp;amp;&amp;amp; data[5] == &#39;R&#39; { fmt.Println(&amp;quot;Bad&amp;quot;) return true } return false } // bad: slice bounds out of range func foo() { var slice = []int{0, 1, 2, 3, 4, 5, 6} fmt.</description>
    </item>
    
    <item>
      <title>Uber go 语言编码规范</title>
      <link>https://zcj-git520.github.io/p/uber-go-%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/</link>
      <pubDate>Wed, 20 Oct 2021 22:00:08 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/uber-go-%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/</guid>
      <description>uber-go/guide 的中文翻译 English Uber go 语言编码规范 Uber 是一家美国硅谷的科技公司，也是 go 语言的早期 adopter。其开源了很多 golang 项目，诸如被 gopher 圈熟知的 zap、jaeger 等。2018 年年末 Uber 将内部的 go 风格规范 开源到 GitHub，经过一年的积累和更新，该规范已经初具规模，并受到广大 gopher 的关注。本文是该规范的中文版本。本版本会根据原版实时更新。
目录  uber- go/guide 的中文翻译 English Uber go 语言编码规范 版本 目录 介绍 指导原则  指向 interface 的指针 Interface 合理性验证 接收器 (receiver) 与接口 零值 Mutex 是有效的 在边界处拷贝 Slices 和 Maps  接收 Slices 和 Maps 返回 slices 或 maps   使用 defer 释放资源 Channel 的 size 要么是 1，要么是无缓冲的 枚举从 1 开始 使用 time 处理时间  使用 time.</description>
    </item>
    
    <item>
      <title>内存管理</title>
      <link>https://zcj-git520.github.io/p/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</link>
      <pubDate>Mon, 18 Oct 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</guid>
      <description>虚拟地址空间布局  程序通过编译成为一堆的机器指令写入可执行文件，程序在运行是会将可执行文件加载在计算机的内存中 在虚拟地址空间分布中处于代码段。 程序中的局部变量、函数的参数、函数的返回值等数据会保存在虚拟地址的栈中(栈是先进后出的数据结构) 栈空间的编译器分配和释放。 程序的全局变量和静态变量会保存在虚拟地址的数据段 动态分配内存的地址会保存在虚拟地址空间的堆上。堆空间是动态开辟的内存空间，需要主动开辟和释放。或者 调用GC释放   堆内存管理  堆内存空间不是编译器分配，而是有程序动态分配的内存空间。  手动垃圾回收  需要程序主动释放没有用的数据所在的堆空间。如：c++中调用new()函数向计算机申请开辟内存空间后，使用delete或delete[]释放不需要的 堆内存空间。这一类是手动内存分配和释放。手动内存分配使用不恰当也会造成：内存泄露 悬挂指针的问题   过早释放会造成悬挂指针（野指针）：提前释放了动态的堆内存的空间，当程序访问这段地址时会报错。因为这段提前释放的内存空间被清空、 重新分配或者被操作系统回收。释放指针时将指针赋值为NULL，在访问时对指针进行判断是否为NULL 不释放内存会造成内存泄漏：堆内存需要手动释放，当程序运行结束不释放，这段内存就会被一直占用。如果 一直在分配不释放会一直占用计算机的内存，直到内存被占完。将new与delete配套使用，使用工具检测或者打印出堆信息  自动垃圾回收（GC）  在程序运行过程中自动释放没有用的数据所在的堆空间（垃圾回收).在虚拟内存空间中能从栈或者数据段的根节点追踪不到的数据为没用的数据 （内存垃圾），常用的算法：标记法, 计数法  标记法回收  标记法：将栈或者数据段作为根（root）进行追踪,将能追踪得的数据（堆空间）进行标记。没有被标记的数据 （堆空间）就是垃圾，将这部分垃圾进行回收。三色抽象：   垃圾回收开始时，将所有数据为白色 垃圾回收开始时，将所有的栈或者数据段的根节点设置为灰色 在根据根节点进行追踪，直到所有的数据节点追踪结束后将根节点置为黑色，在将根节点的下一节点作为根节点进行追踪 所有的数据节点都追踪完后，会剩下黑色和白色的数据节点。黑色表示有用的数据。白色为无用的数据。将白色的数据进行回收（堆空间的释放）    标记法实现简单，但是会造成内存的碎片化(内存块中是可使用小内存块，造成大内存块不能使用这块内存，这些小小内存块也不能使用) 因为内存碎片化的问题诞生了   标记整理法，就是标记法之后，将有用的数据堆内存空间移动在一起，释放更多连续的堆空间,但是这种做法带来 很大的开销，因为需要不断的扫描内存和移动内存 复制回收法。将堆内存分为from和To两个相同的堆内存空间。程序执行时，使用from的堆空间。垃圾回收时会扫描from 的堆内存空间，将有用的数据复制到To的堆空间上。垃圾回收结束时，将To堆空间设置为From堆空间。将原来的from 堆空间全部回收后置为Ton堆空间。但是复制回收法只会使用一般的堆内存空间，造成堆内存空间利用率不高  分代法回收：大部分对象都会在年轻时候死亡（弱分代假说）把新建的对象称之为新生代对象。经过特定次数的GC(垃圾回收)数据依然有用的对象称为 老年代对象。而大部分会在新生代对象就会垃圾回收了，在结合复制回收法使用   计数法回收  引用计数指的是对象被引用的次数，程序在运行过程中会更新引用次数。对象引用越多，计数越大，当计数为0时，回收该对象（堆内存空间） 引用计数法可以在运行中更新对象的计数，可以及时判断计数为 0的对象，然后对其及时回收， 但是频繁的更新引用计数也会带来资源消耗   垃圾回收模式  增量式的垃圾回收模式：SWT是用户承程序停下工作处理垃圾回收，但是为了提高cpu执行效率，会减少SWT的时间，经垃圾回收工作分多次进行（用户程序与垃圾回收交替执行） 三色不变式：在增量式垃圾回收模式在进行垃圾回收时，会造成用户程序对标色的数据进行更改，当在次执行垃圾回收时，可能会将有用的数据当作垃圾回收了，在标色法中，当黑色数据节点可以引用白色的数据节点，但是没有灰色节点能引用这个白色节点，白色数据节点就被当作垃圾被回收 避免这样的发生，在垃圾回收时建立读写屏障。在三色中确保黑色的数据节点不引用白色的数据节点，就不会误判有用的数据当作垃圾回收了，这种叫做：强三色不变式 如果当黑色的数据节点能引用白色数据节点，同时确保回收节点也能引用白色节点，也能避免有用的数据被当作垃圾回收，这叫：弱三色不变式  并行垃圾回收：在多核下，使用多线程对垃圾回收，需要做好的负载均衡和规避数重复处理带来的问题，如在复制回收中，可能将同样的数据从from复制到to 并发垃圾回收：垃圾回收与用户程序并发执行，可能会造成垃圾回收与用户程序的资源竞争等问题等 主体并发回收：在时刻使用swt回收，在莫时刻又使用并发垃圾回收 主体并发增量式回收: 是融合了增量式的垃圾回收模式和主体并发回收模式   参考文献 1.</description>
    </item>
    
    <item>
      <title>Go Channel的深入理解</title>
      <link>https://zcj-git520.github.io/p/go-channel%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</link>
      <pubDate>Fri, 15 Oct 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/go-channel%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</guid>
      <description>go Channel  （Do not communicate by sharing memory; instead, share memory by communicating）  CSP并发模型  CSP 即通信顺序进程、交谈循序程序，又被译为交换消息的循序程序(communicating sequential processes)，它是一种用来描述并发性系统之间进行交互的模型。 go Channe是一种特殊的类型，是有特定类型的队列。是链接goroutine(协程)的通信机制，通过通信共享内存而不是通过共享内存而实现通信. Channel 收发操作均遵循了先进先出的设计，具体规则如下：  先从 Channel 读取数据的 Goroutine 会先接收到数据； 先向 Channel 发送数据的 Goroutine 会得到先发送数据的权利；    
channel 数据结构定义： type hchan struct { // 队列中存储的数量 qcount uint // total data in the queue //环形队列的大小(最大存储数量 ) dataqsiz uint // size of the circular queue // 存放环形队列的数据，数组 buf unsafe.</description>
    </item>
    
    <item>
      <title>go error类型转json</title>
      <link>https://zcj-git520.github.io/p/golang/</link>
      <pubDate>Sat, 09 Oct 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/golang/</guid>
      <description>问题  在收集服务的访问记录时，需要将访问记录保存，定义结构体如下    type accessData struct { RemoteAddr string // 远程访问主机地址 RequestURI string //访问的路由 ServerName string // 访问的服务名称 AccessDate string //访问的时间 RunStatus bool //服务是否正常运行 RunError error //运行报错：报错信息. ServerParam interface{} // 访问服务的参数 }   通过结构体转json，同时通过get请求得到图下结果 
  &amp;ldquo;RunError&amp;rdquo;: {},被json转为{}的字符， 打印结构体，发现错误信息是有的：{192.168.1.101:53364 /v1/alarms/out/d GetOutAlarms 2021-10-12 10:09:42 false 没有这个报警🆔id },说明是error 转json问题
问题分析与解决  问题分析查看error类型定义发现：error类型只是一个接口。它可以包含任何实现它的具体类型的值 解决：将结构体中错误转化为字符串类型，同时用err.Error()返回是错误的字符串  type accessData struct { RemoteAddr string // 远程访问主机地址 RequestURI string //访问的路由 ServerName string // 访问的服务名称 AccessDate string //访问的时间 RunStatus bool //服务是否正常运行 RunError string //运行报错：报错信息.</description>
    </item>
    
    <item>
      <title>go goroutine与gmp模型的深入理解</title>
      <link>https://zcj-git520.github.io/p/go-goroutine%E4%B8%8Egmp%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</link>
      <pubDate>Wed, 06 Oct 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/go-goroutine%E4%B8%8Egmp%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</guid>
      <description>go 协程goroutine  协程是用户级的线程，有用户自己调度，使用协程使得程序调度更加灵活。同时比线程更轻量，占用的栈内存更少。go语言天生支持高并发，go使用协程goroutine的调度器。goroutine 的栈内存最小值为2kb(_StackMin = 2048),它不是固定不变的，可以随需求增大和缩小。goroutine 维护着很大的内存，无需频繁开辟内存，goroutine是使用M:n模型，在用户态切换协程，加上创建协程代价低，使得cpu的利用率大大提升，cup的性能大幅度的被利用。  goroutine 调度器GPM模型 G  G 就是goroutine协程  type g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue.</description>
    </item>
    
    <item>
      <title>进程、线程、协程</title>
      <link>https://zcj-git520.github.io/p/c/c-/</link>
      <pubDate>Tue, 28 Sep 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/c/c-/</guid>
      <description>理解进程与线程 进程  进程是程序一次动态执行过程、进程是操作系统分配资源(内存、io资源、cpu等)和资源调度的基本单位。程序是指令、数据及其组织形式的描述，进程是程序的实体。 进程是由 进程控制块PCB、相关程序段和该程序段进行操作的数据结构集三个部分组成。 进程的五中状态：创建、就绪、运行、阻塞、终止 五种状态转换如图所示：   线程  线程是cup调度和分配的基本单位也是cup执行的最小单位, 有独立的栈空间，共享堆空间。  进程与线程的关系  一个进程可以创建和撤销多个线程， 一个进程必须有一个线程(主线程), 线程共享进程所有资源，进程是线程的容器，关系如图所示：
  并发与并行 并发  并发：多进程(线程)程序在一个核cup串行运行，当一个进程(线程)阻塞的时候，切换到另外等待执行的进程(线程) 如图
  并行  并行：多线程程序在多核cup并行运行，如图
  用户态和内核态(用户空间和内核空间) 特权级划分  cpu一共有0～4四个特权级，R0级最高，R3级最低。用户态指的是：程序运行在R3级以上，通常在应用程序中运行，内核态是指：程序运行在R0级以上，通常在内核中运行。一般来说，我们写的应用程序就是运行在R3级衣以上。  3中种用户态与内核态的切换   系统调用：用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。
  异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。
  外围设备的中断： 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作的完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。
  用户态与内核态结构如图：

  用户态与内核态的切换是需要开销
  来源：linux用户态和内核态理解(https://www.cnblogs.com/weifeng1463/p/11660260.html)
  进程与线程用户态到内核态的开销   多进程(线程)可以提高cpu的利用率，减少程序阻塞带来cpu闲置的情况，也就是提升cpu的运行时间片，但是过多的创建进程(线程)也会花费额外的cpu时间片进行进程(线程)的花销。进程的创建、就绪、运行、阻塞、终止，这些都会带来cup花销。例如在32位的操作系统中创建一个进程需要开辟4GB的虚拟内存空间，创建一个线程需要占用约4MB的内存。</description>
    </item>
    
    <item>
      <title>go map的深入理解</title>
      <link>https://zcj-git520.github.io/p/go-map%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</link>
      <pubDate>Mon, 20 Sep 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/go-map%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</guid>
      <description>goland 基础之map map的内部结构  go map是使用的哈希表构建的 map的结构可分为：hmap的结构体和bmap(桶)，hmap结构体记录这map的基础信息(包括map存储个数， 桶的个数，hash种子，桶的数据，扩容时旧桶的数据以及迁移个数（map扩容不是一次性迁移完）) 源码如下    定义hmap的结构： type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler&#39;s definition. // map 存储元素的计数 count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 // map的状态标识，桶是否在增改，扩容或者缩容 //桶的个数/采用的与运算法计算桶的个数，桶的个数为2的整数次幂 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) //溢出的桶的数量的近似值 noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed //指向桶数据的指针 buckets unsafe.</description>
    </item>
    
    <item>
      <title>syslog日志转发配置</title>
      <link>https://zcj-git520.github.io/p/syslog%E6%97%A5%E5%BF%97%E8%BD%AC%E5%8F%91%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 20 Sep 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/syslog%E6%97%A5%E5%BF%97%E8%BD%AC%E5%8F%91%E9%85%8D%E7%BD%AE/</guid>
      <description>服务器配置(服务器平台：x86) Rsyslog简介  Rsyslog是一个 syslogd 的多线程增强版，在syslog的基础上扩展了很多其他功能，如数据库支持(MySQL, PostgreSQL、Oracle等)、日志内容筛选、定义日志格式模板等。除了默认的udp协议外，rsyslog还支持tcp协议来接收日志。 目前的linux的发行版都切换为rsyslog  安装Rsyslog  Linux的发行版中预先安装了Rsyslog,无需安装，rsyslogd –v 查看版本 若未安装，以下是安装步骤： 1.ubuntu：sudo apt install rsyslog 2.CentOS：yum install rsyslog  Rsyslog.conf配置文件详解 配置文件位置：/etc/rsyslog.conf #### MODULES #### #定义日志的模块。 $ModLoad imuxsock #imuxsock为模块名，支持本地系统日志的模块。 $ModLoad imjournal #imjournal为模块名，支持对系统日志的访问。 #$ModLoad imklog #imklog为模块名，支持内核日志的模块。 #$ModLoad immark #immark为模块名，支持日志标记。 # Provides UDP syslog reception #提供udp syslog的接收。 #$ModLoad imudp #imudp为模块名，支持udp协议。 #$UDPServerRun 514 #允许514端口接收使用udp和tcp转发来的日志。 # Provides TCP syslog reception #提供tcp syslog的接收。 #$ModLoad imtcp #imtcp为模块名，支持tcp协议。 #$InputTCPServerRun 514 #### GLOBAL DIRECTIVES #### #定义全局日志格式的指令。 # Where to place auxiliary files $WorkDirectory /var/lib/rsyslog #工作目录。 # Use default timestamp format $ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat #定义日志格式默认模板。 $IncludeConfig /etc/rsyslog.</description>
    </item>
    
    <item>
      <title>go 切片的深入理解</title>
      <link>https://zcj-git520.github.io/p/go-%E5%88%87%E7%89%87%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</link>
      <pubDate>Wed, 15 Sep 2021 22:00:38 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/go-%E5%88%87%E7%89%87%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/</guid>
      <description>切片的内部结构  切片的结构可分为：数组，数据（元素）的地址&amp;amp;data、也存元素个数len、可以存储多少元素cap 源码如下    定义切片的结构： type slice struct { array unsafe.Pointer len int cap int }  如图所示  avatar
 var data [] int 声明一个切片，相当于生成切片的结构，data地址指针为nil, len和cap都为0。这就很清楚为什么，nil切片不可以直接使用了😄 结构如图  avatar
 使用切片时需要make([]type,len,cap)或者初始化[]type{}才能使用，这是因为在在生成切片的结构时，同时也开辟了一段新的内存，类型为type, 结构长度为cap,同时值进行初始化。 make 源码如下：    func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 判断是否越界 if overflow || mem &amp;gt; maxAlloc || len &amp;lt; 0 || len &amp;gt; cap { // NOTE: Produce a &#39;len out of range&#39; error instead of a // &#39;cap out of range&#39; error when someone does make([]T, bignumber).</description>
    </item>
    
    <item>
      <title>我的第一份博客</title>
      <link>https://zcj-git520.github.io/p/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%BB%BD%E5%8D%9A%E5%AE%A2/</link>
      <pubDate>Sat, 04 Sep 2021 10:05:40 +0800</pubDate>
      
      <guid>https://zcj-git520.github.io/p/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%BB%BD%E5%8D%9A%E5%AE%A2/</guid>
      <description>为什么写博客  总结开发中遇到的问题。工作过后发现自己并不擅长对知识点的总结，导致总是遇到相同的问题，过段时间需要重新查找解决方案 记录学习的知识，不断的温习。学的东西过于碎片化，导致知识不成体系。时间长了，碎片的知识也忘记了 提升自己的专业技能。通过写博客提升自己的能力 形成自己的技术栈，遇到的志同道合的朋友  为什么选择hugo来搭建自己的博客  Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 操作简单，使用Markdown直接生成静态网页 免费且以维护, 在github上就可供他人访问，无需购买服务器，维护简单 发表文章直接push到自己仓库即可  下载hogo的源码  git clone https://github.com/gohugoio/hugo.git
git branch 查看单前代码的分支
git branch -a 查看全部分支
git checkout branch 切换分支
git branch 分支名 创建自己的本地分子
 编译源码  在master分支下，在main.go 的目录下使用命令: go build 在目录下生成hugo.exe 在cmd下使用hugo 查看是否编译成功 编译成功 会打印hugo的版本 安装成功  生成站点  使用命令：hugo new site /目录 cd /目录 查看到   ▸ archetypes/ ▸ content/ ▸ layouts/ ▸ static/ config.toml   创建站点成功  创建md文章  使用命令: hugo new 文章名.</description>
    </item>
    
  </channel>
</rss>
