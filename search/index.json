[{"content":"事务的ACID原则  事务一般要满足ACID原则：  A(atomicity): 原子性 C(consistency): 一致性 I(isolation): 独立性/隔离性 D(Durability): 持久性   原子性：指一个事务组成的一组sql要么全部执行成功，要么全部执行失败 一致性：不管事务发生前后，原本的数据变化都是一致的，也就是数据库中的数据只允许从一个一致性 状态变化为另一个一致性状态，即一个事务中的所有操作，要么一起改变数据库中的数据，要么都不变，对于其他事务而言，数据 变化是一致的 独立性/隔离性: 多个事务之间都是独立的，互不影响，是基于锁的机制和mvcc机制实现的 持久性：指一个事务一旦提交，它会保持永久性，即所有更改数据库中的数据都会被写入磁盘做持久化处理 相关命令：  开启一个事务：start transaction| begin | begin work 回滚事务：rollback 提交事务：commit 关闭或开启自动提交: SET autocommit = 0|1|ON|OFF   事务回滚点：当后续操作失败时，就会回滚到该位置（当前成功的位置）  相关命令：  添加事务回滚点: savepoint point_name 回滚到指定的回滚点：rollback point_name      mysql事务隔离机制  事务隔离机制可分为四个级别：  RU(read uncommitted): 读未提交 RC(read committed): 读已提交 RR(repeatable read): 可重复读 serializable: 序列化/串行化   默认隔离级别为：可重复读 -脏读、幻读、不可重复读、脏写问题  脏读：脏读是指一个事务读到其他事务还没提交的数据，即当前事务读到的数据是其他事务未提交的数据 幻读：指同一个事务内多次查询返回的结果集不一样。比如同一个事务A，在第一次查询表的数据行数时，发现表中有n条行记录，但是第二次以同等条件查询时，却发现有n+1条记录，这就好像产生了幻觉 不可重复读: 是指一个事务中，多次读取同一个数据，先后读取数据不一致 脏写：指同一个事务同时操作同一条数据   事务隔离机制实现  读未提交  处于该级别的数据库，脏读、幻读、不可重复读都可能发生 实现机制：该级别是基于写互斥锁实现的，这个级别在写数据时，采用了互斥锁，解决脏写的问题 但是读操作不是互斥的，导致其他事务可以读到该事务未提交的数据，从而导致了脏读、幻读、不可重复读的发生   读已提交  处于该级别的数据库，解决了脏读的问题，不可重复的和幻读的问题同样存在 实现机制：该级别在基于写互斥锁的基础上，才采用了mvcc多版本并发控制即使进行读操作处理， 即mvcc版本控制不会让另一个事务读取另一个正在修改（未提交）的数据，而是返回修改之间的数据（老版本的数据） 即没有读取数据的时候，mvcc版本机制会根据事务中的查询命令快速创建一个新的readView,读取到的数据就是新的数据   可重读读  处于该级别的数据库，解决了脏读、不可重读读的问题，幻读的问题同样存在 实现机制：级别在基于读已体提交的基础上，对mvcc进行了优化，即在同一个事务中不会根据每一次查询都生成一个新的readView 而是在一个事务中只有第一次查询才创建一个readView,后续查询都使用这个readView的数据,解决了不可重读读的问题   序列化/串行化级别  处于该级别的数据库，解决了脏读、不可重复读、幻读问题 实现机制：序列化意思是将所有的事务按序排队后串行化处理，也就是操作同一张表的事务只能一个一个执行，事务在执行前需要先获取表级别的锁资源，拿到锁资源的事务才能执行，其余事务则陷入阻塞，等待当前事务释放锁     事务隔离机制的命令  查询当前数据库的隔离级别:  SELECT @@tx_isolation; show variables like \u0026lsquo;%tx_isolation%';   设置隔离级别为RU级别（当前连接生效）  set transaction isolation level read uncommitted;   设置隔离级别为RC级别（全局生效）  set global transaction isolation level read committed;   设置隔离级别为RR级别（当前连接生效）  set tx_isolation = \u0026lsquo;repeatable-read\u0026rsquo;;   设置隔离级别为最高的serializable级别（全局生效）  set global.tx_isolation = \u0026lsquo;serializable\u0026rsquo;;      MySQL 日志  常用MySQL日志可分为：undo-log,redo-log,bin-log   undo-log  undo-log是撤销日志，主要实现在事务回滚和mvcc机制中 当写入类型的sql执行时，都会记录undo-log日志，会生成相应的反sql放入undo-log中 在mvcc机制中，undo-log中记录的旧数据并不止是一条，而是可能存在多条不同版本的undo-log记录 ，其内部通过roll_prt回滚指针组成但链表，而该链表也称为版本链   redo-log  redo-log是重做日志，用来实现数据的恢复 redo-log是一种预写式日志，即在向内存写数据之前，先写入日志，当后续数据未被刷到磁盘或 mysql崩溃时可以通过日志来快速恢复数据，确保所有的数据都能被持久化（采用刷盘策略）   bin-log  称为二进制日志，主要记录所有对数据库表结构的变更和表数据的修改的操作     redo-log和bin-log的区别  生效范围不同，redo-log是innodb引擎独有，而bin-log是所有引擎都通用 写入方式不同，redo-log是采用两文件循环写，而bin-log是不断创建新文件后追加 文件格式不同，redo-log是记录所有变更后的数据，而bin-log是记录是变更后的sql 使用场景不同，redo-log主要实现故障情况下的数据恢复，而bin-log则是用于数据灾备同步   日志的主要使用场景：  undo-log: 主要实现事务的ACID和mvcc机制 redo-log: 主要是实现事务的持久性，确保事务提交后不会丢失 bin-log: 主要结合redo-log实现事务原则中的一致性，确保事务提交后数据是一致的    事务总结  undo-log、redo-log日志来看待ACID的四大特性：原子性、一致性、隔离性、持久性   原子性  原子性要求事务中的所有操作要么全部成功，要么全部失败 实现原理：基于undo-log来实现，在该日志中生成相应的反sql,执行失败时，利用该日志回滚所有写操作   持久性  一致性要求所有的数据需要保存在磁盘中 实现原理：这一点是基于redo-log实现   隔离性  隔离性要求一个事务不会受到另一个事务的影响一个事务不会受到另一个事务的影响 -实现原理：通过锁机制和mvcc机制实现   一致性  数据库的整体数据变化，只能从一个一致性状态变为另一个一致性状态，其实前面的原子性、持久性、隔离性都是为了确保这点而存在的    \r\n","date":"2022-09-30T22:00:38+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/1_hu0ba8fce09208969ff6b2aee6fef01bdc_192508_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86/","title":"数据库之事务机制原理"},{"content":"多表查询  多表一般是主表，主要存储数据的地方，每一个字段都可以重复，没有主键， 无法根据某个字段定位到准确的记录 一表一般是从表，主要存储辅助数据，通过主键与主表连接，存储的记录是不可重复的，可以通过主键定位到记录 左连接：左连接是以左表取出所有记录与右表匹配，如果没有匹配以null值代表右边的列 右连接：右连接是以右表取出所有的记录，与左表进行匹配，如果没有匹配以null值代表左边的列 内连接：等值连接，是多表的交集 交叉连接：返回两表的笛卡尔乘积，作用是计算两个表之间可能的存在的组合，结果是集中的记录等于两张各自记录数的乘积  数据库范式  范式：范式是值在设计数据库表时，需要遵循的一些原则，目的是让设计的数据库表结构更为合理和优雅，常见的数据库范式为：数据库三大范式（1NF、2NF、3NF） 和巴斯-科德范式（BCNF）  数据库的三大范式  三大范式为递进关系，即后续范式是前范式为基础上优化或者后续范式是前范式的优化  第一范式  第一范式：确保数据的原子性，也就是存储的数据具备不可在分性 原子性：原子性规定一个字段是原子，不能在进行拆分成多个字段 第一范式除了对列级别的数据生效外，对行级数据处理一样，即行数据之间相不影响，都是独立的整体 若数据库满足第一范式的影响如下：  客户端语言与表之间无法很好的生成映射关系 查询得到的数据在进行数据处理时，需要对字段数据进行额外的拆分 插入数据时，需要对字段值进行额外拼接后才能写入到数据库 \r    第二范式  第二范式：在第一范式的基础上，要求所有的表中的所有列，其数据都需要依赖于主键，也就是一张表只存储同类型的数据，不能存在同张表中存在与主键没有关系的数据 由于数据存在与主键数据之间没有关联性，导致表中的数据存在冗余的情况 第二范式要求：每张表的业务属性具备“唯一性”，避免存在一张表存在多种业务属性的情况，即“一张表只描述一件事情” \r  第三范式  第三范式：在第一，第二范式的基础上，要求表中的每一列数据不能与主键外的字段存在关系 第三范式满足：表中的每个非主键字段与其他非主键字段之间，都是相互独立的，之间不存在相互依赖的关系，所有字段都依赖主键 在设计表结构中，如不满足第三范式，在操作表时就会出现异常，使得表难以维护，相反通过第三范式优化后，表结构会更加优雅灵活，也容易 维护 \r  巴斯-科德范式  在表中除了主键外，还有联合主键，也就是有多个列组成的主键 巴斯-科德范式也称为：3.5范式，它是第三范式的补充，第三范式要求是：任何非主键字段与其他非主键字段之间存在依赖关系，即 要求非主键之间具备独立性，巴斯-科德范式要求：任何主属性不能对其他主键子集存在关系，即联合主键中的某列值，不能与联合主键的 其他列存在依赖关系 巴斯-科德范式规定联合主键之间的不存在依赖，即满足主键的独立性 例如：以classes班级字段、class_adviser班主任字段、name学生姓名字段，组合成一个联合主键，就不符合巴斯-科德范式 \r  范式总结  第一范式：确保原子性，即保证表中的每一列数据都是不可在分的字段 第二范式：确保唯一性，即保证每张表只描述一种义务，一张表只描述一件事情 第三范式：确保非主键字段的独立性，即表中除主键外，每个字段之间不存在任何的依赖性，字段之间是独立的 巴斯-科德范式：确保主键字段(联合字段)的独立性,即任何主属性不能对其它主键存在依赖关系，联合主键之间相互独立  数据库锁机制 数据库锁机制 数据库锁分类  按照颗粒度分类：  表级锁：共享读锁和独占写锁 行级锁：共享锁(s)和排他锁(x) 页级锁   按照使用方式分类：  乐观锁 悲观锁    表级锁  开销小，加锁快，不会发生死锁，锁定颗粒度大，发生锁冲突概率高，并发度最低，mylsam和innoDB都是支持的， 读读不阻，写写阻，读写互斥，读写锁是串行的，写锁优于读锁  行级锁  开销大，加锁慢，会发生死锁，锁定颗粒度小，发生锁冲突概率低，并发度高。innoDB支持，因innodb 的行锁是基于索引的 共享锁(s锁)也叫读锁，允许多个事务读取同一个资源，不允许修改 排他锁(x锁)允许获取排他锁的事务更新数据，阻止其他事务获取相同数据的读锁和排他锁；  乐观锁  不采用数据库自身加锁的方式，通过用户程序来实现，一般采用版本号机制或者时间蹉的机制  悲观锁  对数据被其他事务的修改保持保守状态，会通过数据库自身加锁的机制实现，从而保证数据操作的排他性  间隙锁  使用范围查询而非等值查询时，并请求共享或者排他锁时，会给符合范围条件的已有数据记录的索引加锁，对于键值 在条件范围内，但不存在的记录叫做间隙锁（pap锁） 间隙锁可防止幻读和满足恢复和复制的需要  防止死锁  以固定的顺序访问表和行 大事务进行拆分 同一事务，尽可能的一次锁定 降低隔离级别 为表添加合理的索引 \r  ","date":"2022-09-21T22:00:38+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/5_hu897c59d3d00f9ccd7837ef1ecd5c493a_1058366_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"数据库之基础知识"},{"content":"linux 常用查看可执行工具   readelf：可以查看可执行文件相关信息\n readif -h 查看头信息 \r readelf –d 查看动态库依赖 \r    File:\n file [可行政文件] 执行文件架构信息、动态、静态 \r ldd 查看动态库 \r    Strip\n -I \u0026ndash;input-target= 假定输入文件的格式为 -O \u0026ndash;output-target= 以格式创建输出文件 -F \u0026ndash;target= 设置输入、输出的文件格式为 -p \u0026ndash;preserve-dates 复制上次修改或者操作的时间到输出文件中 -R \u0026ndash;remove-section= 删除输出文件中段信息 -s \u0026ndash;strip-all 删除所有符号信息和重定位信息 -g -S -d \u0026ndash;strip-debug 删除所有调试信息和段信息 \u0026ndash;strip-unneeded 删除所有重定位中不需要的符号信息 \u0026ndash;only-keep-debug 删除调试信息以外的其他所有信息 -N \u0026ndash;strip-symbol= 不拷贝符号信息 -K \u0026ndash;keep-symbol= 不去除符号信息 -w \u0026ndash;wildcard 在符号中使用通配符 -x \u0026ndash;discard-all 去除所有非全局符号    Linux 进程调试工具  pidof 查命令对应的进程编号 (pidof bash) \r Ps  基础参数  -A, -e 选择所有进程 -a 选择除了会话领导和与终端无关的进程以外的所有进程。 a BSD格式，通常与x同时出现，显示所有进程   选择性参数  -C 根据cmdlist中的命令 输出 -p, \u0026ndash;pid 根据进程id进行选择输出 \u0026ndash;ppid 根据父进程ID选择输出 -U, \u0026ndash;User 根据真实用户ID(RUID)或用户名选择   显示线程  -L 显示线程相关信息   杂项  L 列出所以支持的格式（应用与-o中的输出格式） e 输出环境变量（在指令后面）   得到线程信息  ps -eLf \r     Pstree  查看进程之间的父子关系 \r   top \r   第一行显示的是系统的概况：\n 当前时间、系统的运行时间、登录的用户数以及系统的平均负载。 平均负载有3个值：最近1分钟的，最近5分钟的，最近15分钟的平均负载。 load average 数据每隔5秒钟检查一次活跃的进程数，可以看出点问题。 太高肯定不行了。    第二行显示了进程:\n top命令的输出中将进程叫作任务（task）： 总进程，运行、休眠、停止或是僵化状态（僵化状态是指进程完成了，但父进程没有响应）。    第三行显示CPU信息:\n top根据进程的属主（用户还是系统）和进程的状态（运行、 空闲还是等待）将CPU利用率分成几类输出。 0.0%us【user space】— 用户空间占用CPU的百分比。 1.5%sy【sysctl】— 内核空间占用CPU的百分比。 0.0%ni【】— 改变过优先级的进程占用CPU的百分比 98.5%id【idolt】— 空闲CPU百分比 0.0%wa【wait】— IO等待占用CPU的百分比 0.0%hi【Hardware IRQ】— 硬中断占用CPU的百分比 0.0%si【Software Interrupts】— 软中断占用CPU的百分比    第四行显示内存信息：\n total 总内存 free 空闲内存 used 已使用 buff/cache 缓存的内存量    第五行显示swap交换分区信息：\n  total总大小\n  free空闲\n  used 已使用\n  avail Mem 缓冲的交换区总量\n  可用内存=free + buffer + cached\n  PID：进程的ID。\n  USER：进程属主的名字。\n  PR：进程的优先级。\n  NI：进程的谦让度值。\n  VIRT：进程占用的虚拟内存总量。\n  RES：进程占用的物理内存总量。\n  SHR：进程和其他进程共享的内存总量。\n  S：进程的状态（D代表可中断的休眠状态，R代表在运行状态，S代表休眠状态，T代表跟踪状态或停止状态，Z代表僵化状态）。\n  %CPU：进程使用的CPU时间比例。\n  %MEM：进程使用的内存占可用内存的比例。\n  TIME+：自进程启动到目前为止的CPU时间总量。\n  COMMAND：进程所对应的命令行名称，也就是启动的程序名。\n  m：显示内存\n  H: 显示线程\n    其他\n M 根据驻留内存大小进行排序 P 根据CPU使用百分比大小进行排序 T 根据时间/累计时间进行排序 q:退出      linux进程proc详解  进程的完整命令行  /proc/[pid]/cmdline   进程名  /proc/[pid]/comm   进程环境变量  /proc/[pid]/environ   进程可执行文件  /proc/[pid]/exe   打开文件描述符  /proc/[pid]/fd   打开文件信息  /proc/pid/fdinfo   内存映射文件  /proc/[pid]/map_files/   IO文件  /proc/[pid]/io   易于阅读的进程状态信息  /proc/[pid]/status   进程状态信息，用于ps指令  /proc/[pid]/stat   进程内存使用信息  /proc/pid/statm    linux 内存检测工具  Memwatch  双重释放 错误释放 没有释放的内存 溢出和下溢   Yamd  内存泄漏 双重释放 错误释放 越界访问    linux 性能检测工具 进程相关优化工具  ltrace \r  虚拟文件系统相关优化工具  lsof  -a 列出打开文件存在的进程 -c\u0026lt;进程名\u0026gt; 列出指定进程所打开的文件 -g 列出GID号进程详情 -d\u0026lt;文件号\u0026gt; 列出占用该文件号的进程 +d\u0026lt;目录\u0026gt; 列出目录下被打开的文件 +D\u0026lt;目录\u0026gt; 递归列出目录下被打开的文件 -n\u0026lt;目录\u0026gt; 列出使用NFS的文件 -i\u0026lt;条件\u0026gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p\u0026lt;进程号\u0026gt; 列出指定进程号所打开的文件 -u 列出UID号进程详情 -h 显示帮助信息 -v 显示版本信息 \r    网络相关优化工具  netstat  -a 显示所有活动的连接以及本机侦听的TCP、UDP端口 -l 显示监听的server port -n 直接使用IP地址，不通过域名服务器 -p 正在使用Socket的程序PID和程序名称 -r 显示路由表 -t 显示TCP传输协议的连线状况 -u 显示UDP传输协议的连线状况 -w 显示RAW传输协议的连线状况 \r   ss  -a显示所有的sockets-l显示正在监听的 -n显示数字IP和端口，不通过域名服务器 -p显示使用socket的对应的程序 -t只显示TCP sockets-u只显示UDP sockets -4 -6 只显示v4或v6V版本的sockets -s打印出统计信息。 -0 显示PACKET sockets -w 只显示RAW sockets -x只显示UNIX域sockets -r尝试进行域名解析，地址/端口 \r    ","date":"2022-09-15T22:00:38+08:00","image":"https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF/3_hu5bc4d06a19d5d5d7b7fe871d036ee380_38629_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E8%B0%83%E8%AF%95%E6%8A%80%E6%9C%AF/","title":"linux 性能调试技术"},{"content":"查询命令（select）  查看表结构：desc 或则show columns from tables; 查询特定的列：select column, another_column,…… FROM table; 查询所有*：select *from table; 带约束查询：SELECT column, another_column, … FROM table WHERE *condition* AND/OR *another_condition* AND/OR …**; \r \rimage-20221023144431347\r  对查询结果进行筛选和排序：   SQL 提供了一种使用关键字丢弃具有重复列值的行的便捷方法(DISTINCT):\nSELECT**DISTINCT**column,another_column,…FROMmytableWHERE*condition(s)*;  SQL 提供了一种使用子句按给定列按升序或降序对结果进行排序的方法(ORDER BY):\nSELECTcolumn,another_column,…FROMmytableWHERE*condition(s)***ORDERBYcolumnASC/DESC**;  将结果限制为子集(ORDER BYLIMITOFFSETLIMITOFFSET):\nSELECTcolumn,another_column,…FROMmytableWHERE*condition(s)*ORDERBYcolumnASC/DESC**LIMITnum_limitOFFSETnum_offset**;  修改表名：alter table old_table_name rename to new_name_name;\n  增加表注释：alter table table_name comment \u0026ldquo;注释\u0026rdquo;；\n  增加表字段注释：alter table table_name colunm modify 字段名 类型 comment \u0026ldquo;注释\u0026rdquo;；\n  使用 JOIN 的多表查询：共享有关单个实体的信息的表需要具有一个主键，用于在数据库中唯一标识该实体。一种常见的主键类型是自动递增的整数（因为它们节省空间），但它也可以是字符串，散列值，只要它是唯一的。\nSELECTcolumn,another_table_column,…FROMmytableINNERJOINanother_tableONmytable.id=another_table.idWHEREcondition(s)ORDERBYcolumn,…ASC/DESCLIMITnum_limitOFFSETnum_offset;  外部连接：在多个表上使用左/右/全联名选择查询：\nSELECTcolumn,another_column,…FROMmytableINNER/LEFT/RIGHT/FULLJOINanother_tableONmytable.id=another_table.matching_idWHEREcondition(s)ORDERBYcolumn,…ASC/DESCLIMITnum_limitOFFSETnum_offset;  使用表达式进行查询：\n  除了使用 SQL 查询和引用原始列数据外，还可以使用表达式对查询中的列值编写更复杂的逻辑。这些表达式可以使用数学 字符串函数以及基本算术，用于在执行查询时转换值\nSELECTparticle_speed/2.0AShalf_particle_speedFROMphysics_dataWHEREABS(particle_position)*10.0\u0026gt;500;  选择具有表达式别名的查询\nSELECTcol_expressionASexpr_description,…FROMmytable;    使用聚合的查询：SQL 还支持使用 允许您汇总有关一组行的信息的聚合表达式（或函数） 的数据\nSELECTAGG_FUNC(column_or_expression)ASaggregate_description,…FROMmytableWHEREconstraint_expression;\r\n  GROUP BY：指定列中具有相同值的行进行分组\n  SELECTAGG_FUNC(column_or_expression)ASaggregate_description,…FROMmytableWHEREconstraint_expressionGROUPBYcolumn;  HAVING GROUP BY:子句约束的编写方式与子句约束相同，并且 应用于分组行\nSELECTgroup_by_column,AGG_FUNC(column_expression)ASaggregate_result_alias,…FROMmytableWHEREconditionGROUPBYcolumnHAVINGgroup_condition;  插入数据 插入数据：将数据插入数据库时，我们需要使用 anstatement，它声明哪个表 要写入的，我们正在填充的数据列，以及要插入的一行或多行数据。在 通常，插入的每一行数据都应包含表中每个相应列的值。 您可以通过按顺序列出来一次插入多行。INSERT\nINSERTINTOmytableVALUES(value_or_expr,another_value_or_expr,…),(value_or_expr_2,another_value_or_expr_2,…),…;-- 插入具有特定列的语句 INSERTINTOmytable(column,another_column,…)VALUES(value_or_expr,another_value_or_expr,…),(value_or_expr_2,another_value_or_expr_2,…),…;更新数据：UPDATE UPDATEmytableSETcolumn=value_or_expr,other_column=another_value_or_expr,…WHEREcondition;删除行:DELETE,WHERE DELETEFROMmytableWHEREcondition;主键与外键   主键(primary key)：表中唯一标识的一条记录，不能重复，不能为null, 用来保证数据的完整性\n  外键(FOREIGN KEY)：是另一张表中的主键，外键可以重复，可以为null,用来和其他表建立联系，存储引擎为：innodb\n 外键数据类型必须要与父表中的主键的类型完全一致 一张表中的外键名字不能重复 增加外键字段（数据存在），必须保证数据与父表中的主键要求对应    外键的作用：对子表和父表的约束\n 对子表的约束：在子表进行插入（增和修改）操作时，如果对应的外键字段在父表找不到对应的匹配，那么插入会失败 对父表的约束：在父表中进行插入(删和修改：必须是涉及到主键）操作时，如果对应的主键在子表中也被数据所引用，那么插入操作就会失败；    外键的约束，都是针对父表：\n distrist:严格模式（默认）：父表不能进行插入操作时（增加或修改，针对着主键），对应主键在子表中被引用的记录 cascade:级联模式：父表操作后，对应的子表也会跟着删除 set null:置空模式：父表操作后，对应的子表的外键字段也会被设置为空 合理的外键约束模式为：删除时子表设置为空（置空模式），更新时子表级联模式 语法：foreign key(外键字段) references 父表（主键字段）on delete set null on update cascade;    联合查询与子查询   联合查询：将多次查询，在记录上进行拼接（字段不会增加），每一次select 语句获取的字段数必须严格一致（但是字段类型无关）\n 语法：select 语句1 union [union 选项] select 语句 …… union 选项：select选项一样：  All 保留所有（不管重复） distinct 去重（整个重复），默认   意义：  单表查询：查询同一张表，但需求不同 多表查询：多张表的结构和数据（结构）完全是一致   在联合查询中使用order by 时，需要对查询语句使用括号，且需要使用limit    子查询：查询的结构是在某一个查询之上（一天select语句中包含另一条select）\n 子查询分类：  按位置分类：子查询语句（select）在外部查询语句（select）的位置：  from 子查询：子查询跟在from之后 where 子查询：子查询跟在where条件中 exists 子查询：子查询是在exists中   按照结果分类：按照子查询的数据进行分类（查询的结构都可以理解为二维表）  标量子查询：子查询查询的结果为一行一列 列子查询：子查询查询的结构为一列多行 行子查询：子查询查询的结构为一行多列（多行多列），需要够着行元素（多个字段构成：eg(id, name)=(select )）， 以上位置都是在where条件语句中 表子查询：子查询查询的结果为多行多列（位置在from之后）        视图   视图view ：是一种有结构（二维表）但是没结果（结构中不真实存放数据）的虚拟表，结构来源于对应的基表（视图的数据来源）；\n 创建视图：create view view_name as select 语句，创建完成后很生成对应的frm结构文件；  单表视图：基表来源只有一个 多表视图：基表来源至少两个，字段名不能重复；   查看视图：所有查看表的方式都适用于视图 使用视图：主要是查询使用，将视图当作表一样查询即可，本质是执行分装的select语句； 修改视图：视图本身不可修改，但是可以修改视图的来源(select)；alter view view_name as 新的select 语句； 删除视图：drop view view_name; 视图的意义：  节省sql语句，将复杂的sql语句保存为视图，可以直接对视图进行操作 数据安全（相对）：视图操作主要是查询使用，删除视图只是删除结构，不会影响基表的数据；，可以对外提供有用数据，隐藏无用的数据 通常在大项目中使用，而且是在多系统中使用； 视图可以对外友好型，不同的用户使用不同的视图,提供不同的数据； 视图更容易进行权限控制；   视图数据操作：视图可以进行写操作，但是存在限制，数据在视图中进行操作  视图新增数据：直接对视图数据进行新增  多表视图不能新增，删除数据，可更新数据； 可以向单表中插入，更新，删除数据，但是试图中包含的字段必须在基表中所有不能为null或者没有默认值的字段 更新视图限制：with check option,如果对视图更新的时候， 限定了某个字段，那么在视图更新数据的时，系统会进行验证，保证数据在更新之后，数据依然能被实体查询出来，否则不能更新 视图算法：系统对视图以及外部查询视图的select语句的一种解析方式  undefined：未定义（默认） temptable:临时表算法，系统先执行视图的select 语句，然后在执行外部查询语句select merge:合并算法，系统将视图的select语句和外部的查询语句select合并在执行，效率高； 算法指定：在创建视图的时指定create algorithm=指定算法 view view_name as select;          数据的备份与还原   单表备份：每次只能备份一张表，只能备份数据（不能备份表结构），通常将表数据导出到文件；\n  外部导出：select 字段名 into outfile 路径（文件不存在） from 数据源\n  数据导入：load data infile 路径 into table table_name；\u0026ndash; 怎么备份怎么还原\n    sql的备份与还原：系统会对表结构和数据进行处理成sql语句，然后进行备份；还原：执行sql语句即可（主要是备份表结构）；\n  备份：\n  没有对应的指令，需要mysqldump.exe;\n  mysqldump -hPup 数据库名字 [数据表名字 ……] \u0026gt;外部文件目录\n  整个库备份：mysqldump -hPup 数据库名字\n    还原：\n  mysql -hPup 数据库名字 \u0026lt;备份原件；\n  使用sql 指令；source 备份原件;\n    优缺点\n 可以备份结构 浪费空间      增量备份：指定时间段开始备份，备份数据不重复，并且所有的操作都会被备份；\n  事务  事务是一系列要发生的操作 事务安全是保护连续操作同时满足的一种机制 事务安全的意义：保证数据安全的完整性 事务的操作：  自动事务  用户操作完，会自动同步到数据表中； 系统通过：autocommit 变量控制 开启或者关闭：set autocommit = on/1 or off /0   手动事务  开启事务： 所有的事务操作先保存在日志（redo.log）命令：start transaction begin 执行事务：一些列写操作 关闭事务：选择性的将日志文件中的结果同步到数据表或者清空日志文件中的操作  同步事务：同步数据到数据表，命令：commit; 回滚事务：直接清空日志，rollback;   事务原理：开启事务之后，所有的操作都会临时保存在日志文件中，只有在commit 之后才能同步到数据表，其他情况会清空日志 回滚点：当事务开启之后，在某一个操作成功之后，可以设置成功的位置，可以提供后续操作失败后，返回该位置，而非全部回滚，  设置回滚点：savepoint 回滚点名字； 回滚到回滚点：rollback 回滚点名字；        索引   索引是数据库中常用来提高查询性能的工具\n  索引是在存储引擎中实现，而不是在服务层中实现，每种引擎的索引并不相同\n  普通索引normal:\n 直接创建索引：create index index_name on table_name (列名[len()]……) 修改表时创建：alter table table_name add index index_name (列名[len()……]) 创建表时创建：create table table_name (……，index index_name (列名[(len)]……)    唯一索引 unique:创建方式和上方的普通索引类似。即：将普通索引的“index”改为“unique index,区别在：索引的所有列的所有值都必须是唯一\n  主键索引：主键是一种特殊的唯一索引，一般在创建表的时候指定\n  全文索引fulltext:创建方式和上方的普通索引类似。即：将普通索引的“index”改为“fulltext index”。\n  查看索引：show index from table_name;\n  删除索引：drop index index_name on table_name 或者alter table table_name drop index index_name;\n  禁用索引：alter table table_name disable kyes;\n  启用索引：alter table table_name enable keys;\n\rimage-20221113154139517\r\n  \rimage-20221113154151478\r\n\rimage-20221113154538952\r\n\rimage-20221113154558884\r\n","date":"2022-09-01T22:00:38+08:00","image":"https://zcj-git520.github.io/p/mysql-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/image-20221113154558884_hue265424d23ed96ee9701c444ec0fad6e_286244_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/mysql-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/","title":"mysql 常用命令使用"},{"content":"前缀树、也称字典树（Trie） for go  前缀树是一种多叉树结构，经常用来做快速检索 前缀树（Trie树），即字典树，又称单词查找树或键树， 它是一种专门处理字符串匹配的数据结构。 前缀树可以最大限度地减少无谓的字符串比较（空间换时间），提高查询效率。 特点：  根节点不包含任何key 每个子节点包含的key都不相同    代码实现如下 package Trie import ( \u0026#34;fmt\u0026#34; ) // 定义前缀树的节点 通过map  type trieNode struct { ChildNodes map[rune]*trieNode // 定义子节点  //CharCount int // 字符统计  EndNode bool // 是否为子节点  StrData string // 最后节点时，该数据  } // 前缀树的定义  type trieTree struct { root *trieNode // 根节点  WordCount int // 词数的数量  } // 创建节点  func creatNode() *trieNode{ node := make(map[rune]*trieNode) return \u0026amp;trieNode{ ChildNodes: node, //CharCount: 0,  EndNode: false, StrData: \u0026#34;\u0026#34;, } } // 词数的数量  func (t *trieTree)len() int{ return t.WordCount } // 添加节点  func (t *trieTree)insertData(data string) error{ if len(data) == 0{ return fmt.Errorf(\u0026#34;插入数据为空\u0026#34;) } nodeNext := t.root for _, cha := range data{ _, ok := nodeNext.ChildNodes[cha] // 是否存在  if !ok{ // 创建节点  nodeNext.ChildNodes[cha] = creatNode() } nodeNext = nodeNext.ChildNodes[cha] //nodeNext.CharCount++  } // 判断是否为最后的节点  if !nodeNext.EndNode{ nodeNext.EndNode = true nodeNext.StrData = data t.WordCount ++ } return nil } // 查询某个值是否存在  func (t *trieTree)FindData(data string) bool{ if t.root == nil || data == \u0026#34;\u0026#34;{ return false } nodeNext := t.root for _, cha := range data { _, ok := nodeNext.ChildNodes[cha] if !ok{ return false } nodeNext = nodeNext.ChildNodes[cha] } if nodeNext.StrData != data{ return false } return true } // 遍历树  func(t *trieTree)traverseData() ([]string, error){ returnData := make([]string,0) if t.root == nil{ return returnData, fmt.Errorf(\u0026#34;数据为空\u0026#34;) } nodeNext := t.root for _, node := range nodeNext.ChildNodes{ t.getData(node, \u0026amp;returnData) } return returnData, nil } // 使用递归遍历  func (t *trieTree)getData(nodeNext *trieNode, triData *[]string) { if nodeNext.EndNode{ *triData = append(*triData, nodeNext.StrData) if nodeNext.ChildNodes == nil{ return } } for _, node := range nodeNext.ChildNodes{ t.getData(node, triData) } } // 清空树  func (t *trieTree)Clear(){ t.root = nil t.WordCount = 0 } // 删除数据  func (t *trieTree)DeleteData(data string) error{ if t.root == nil || data == \u0026#34;\u0026#34;{ return fmt.Errorf(\u0026#34;数据为空\u0026#34;) } ok := t.FindData(data) if !ok{ return fmt.Errorf(\u0026#34;%v：数据不存在\u0026#34;, data) } nextNode := t.root t.delete(nextNode, data) return nil } func (t *trieTree)delete(node *trieNode, data string) { // 从头开始遍历  for _, cha := range data{ node = node.ChildNodes[cha] // 如果节点为的cha的个数为1时，直接删除节点  if node.ChildNodes == nil { delete(node.ChildNodes, cha) return } // 还存在后续节点时，则将此节点不在设置为尾节点  if node.EndNode{ node.EndNode = false } } } // 根据前缀返回  func (t *trieTree)TrieData(data string) ([]string, error) { returnData := make([]string,0) if t.root == nil || data == \u0026#34;\u0026#34;{ return returnData, fmt.Errorf(\u0026#34;数据为空\u0026#34;) } nodeNext := t.root for _, cha := range data { nodeNext = nodeNext.ChildNodes[cha] } t.getData(nodeNext, \u0026amp;returnData) return returnData, nil } // 初始化树  func InitTrie() *trieTree { node := creatNode() return \u0026amp;trieTree{ root: node, WordCount: 0, } } 测试代码如下 package Trie import ( \u0026#34;fmt\u0026#34; \u0026#34;testing\u0026#34; ) func TestInsertData(t *testing.T) { trie := InitTrie() var testStr = []string{\u0026#34;zc\u0026#34;, \u0026#34;zzc\u0026#34;, \u0026#34;zcj\u0026#34;,\u0026#34;rr\u0026#34;,\u0026#34;好的\u0026#34;, \u0026#34;zdd\u0026#34;, \u0026#34;zcf\u0026#34;, \u0026#34;找车估计\u0026#34;,\u0026#34;张伟\u0026#34;} for _, str := range testStr{ err := trie.insertData(str) if err != nil { t.Error(err) } } //trie.Clear()  dataS, err := trie.traverseData() if err != nil { t.Error(err) } fmt.Println(dataS) ok := trie.FindData(\u0026#34;zcj1\u0026#34;) if !ok { fmt.Println(\u0026#34;zcj is not exist\u0026#34; ) }else{ fmt.Println(\u0026#34;zcj is exist\u0026#34; ) } //err = trie.DeleteData(\u0026#34;rr\u0026#34;)  //if err != nil {  //\tt.Error(err)  //}  dataS, err = trie.traverseData() if err != nil { t.Error(err) } fmt.Println(dataS) fmt.Println(\u0026#34;****************************\u0026#34;) dataS, err = trie.TrieData(\u0026#34;z\u0026#34;) if err != nil { t.Error(err) } fmt.Println(dataS) } 源码  我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForGo/tree/master/tree/Trie  ","date":"2022-08-25T21:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-trie-tree-go%E5%AE%9E%E7%8E%B0/1_hu0a2d209b387a8817d63fbca7ab1b3342_170472_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-trie-tree-go%E5%AE%9E%E7%8E%B0/","title":"数据结构-Trie tree go实现"},{"content":"RSA加密算法的使用  生成公私钥 保存文件或者保存在内存中 设置时间有效期，长期有效或者超时重创建公私钥  代码如下 package zcj_rsa import ( \u0026#34;crypto/rand\u0026#34; \u0026#34;crypto/rsa\u0026#34; \u0026#34;crypto/x509\u0026#34; \u0026#34;encoding/base64\u0026#34; \u0026#34;encoding/pem\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path\u0026#34; \u0026#34;time\u0026#34; ) const ( BITS = 2048 // 证书大小  SAVEKEYPATH = \u0026#34;./\u0026#34; // 默认保存公私钥的路径  ) type signData struct { publicKey string // 公钥  privateKey string // 私钥  generateTime time.Time // 生成时间  isCreate bool // 是否创建公私钥  Timeout int // 证书超时时间 单位时间为分钟 \u0026lt;= 0 表示永久有效  SaveMode bool // true 保存为文件，False保存在内存中  PublicKeyPath string // 保存公钥的路径  PrivateKeyPath string // 保存私钥的路径  } // 创建公私钥对  func (s *signData)creatKey() error { if s.isEffectiveKey(){ return fmt.Errorf(\u0026#34;公私钥已存在\u0026#34;) } // 创建私钥  prvKey, err := rsa.GenerateKey(rand.Reader, BITS) if err != nil { return err } //通过x509标准将得到的ras私钥序列化为ASN.1 的 DER编码字符串  x509PrivateKey := x509.MarshalPKCS1PrivateKey(prvKey) privateKeyBlock := \u0026amp;pem.Block{ Type:\u0026#34;RSA Private key\u0026#34;, Bytes: x509PrivateKey, } //处理公钥,公钥包含在私钥中  pubKey := prvKey.PublicKey //通过x509标准将得到的ras公钥序列化为ASN.1 的 DER编码字符串  x509PublicKey, err := x509.MarshalPKIXPublicKey(\u0026amp;pubKey) if err != nil { return err } publicKeyBlock := \u0026amp;pem.Block{ Type:\u0026#34;RSA Public key\u0026#34;, Bytes: x509PublicKey, } if s.SaveMode{ publicFile, err := os.Create(path.Join(s.PublicKeyPath, \u0026#34;public.pem\u0026#34;)) if err!=nil{ return err } privateKeyFile, err := os.Create(path.Join(s.PrivateKeyPath, \u0026#34;privateKey.pem\u0026#34;)) if err!=nil{ return err } defer publicFile.Close() defer privateKeyFile.Close() //保存到文件  err = pem.Encode(privateKeyFile,privateKeyBlock) if err!=nil{ return err } err = pem.Encode(publicFile,publicKeyBlock) if err!=nil{ return err } }else{ s.publicKey = string(pem.EncodeToMemory(publicKeyBlock)) s.privateKey = string(pem.EncodeToMemory(privateKeyBlock)) } s.generateTime = time.Now() s.isCreate = true return nil } // 判断公私钥是否有效  func (s *signData)isEffectiveKey()bool{ if s.isCreate{ if s.Timeout \u0026lt;= 0{ //log.Info(\u0026#34;公私钥创建，且永久有效\u0026#34;)  return true } duration := time.Now().Sub(s.generateTime).Minutes() if int(duration) \u0026lt;= s.Timeout{ //log.Info(\u0026#34;公私钥创建，且在有效期\u0026#34;)  return true } } return false } // 使用私钥进行解密  func (s *signData)RSADecryption(cipherText string)(string, error){ // 保存在内存中进行判断  if !s.SaveMode \u0026amp;\u0026amp; !s.isEffectiveKey(){ return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;公私钥未创建\u0026#34;) } cipherBuf, err := base64.StdEncoding.DecodeString(cipherText) if err != nil { return \u0026#34;\u0026#34;, err } var buf []byte if s.SaveMode{ file,err:=os.Open(path.Join(s.PrivateKeyPath, \u0026#34;privateKey.pem\u0026#34;)) if err!=nil{ panic(err) } defer file.Close() //读取文件的内容  info, _ := file.Stat() buf =make([]byte,info.Size()) file.Read(buf) }else{ buf = []byte(s.privateKey) } block, _ := pem.Decode(buf) if block == nil{ return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;pem decode fild\u0026#34;) } privateKey, err := x509.ParsePKCS1PrivateKey(block.Bytes) if err != nil { return \u0026#34;\u0026#34;, err } plainText, err := rsa.DecryptPKCS1v15(rand.Reader, privateKey, cipherBuf) if err != nil { return \u0026#34;\u0026#34;, err } return string(plainText), err } // 使用公钥加密  func (s *signData)RSAEncryption(plainText string)(string, error){ // 保存在内存中进行判断  if !s.SaveMode \u0026amp;\u0026amp; !s.isEffectiveKey(){ return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;公私钥未创建\u0026#34;) } var buf []byte if s.SaveMode{ file,err:=os.Open(path.Join(s.PrivateKeyPath, \u0026#34;public.pem\u0026#34;)) if err!=nil{ panic(err) } defer file.Close() //读取文件的内容  info, _ := file.Stat() buf =make([]byte,info.Size()) file.Read(buf) }else{ buf = []byte(s.publicKey) } block, _ := pem.Decode(buf) if block == nil{ return \u0026#34;\u0026#34;, fmt.Errorf(\u0026#34;pem decode fild\u0026#34;) } //x509解码  publicKeyInterface, err := x509.ParsePKIXPublicKey(block.Bytes) if err!=nil{ return \u0026#34;\u0026#34;, nil } //类型断言  publicKey:=publicKeyInterface.(*rsa.PublicKey) //对明文进行加密  cipherText, err := rsa.EncryptPKCS1v15(rand.Reader, publicKey, []byte(plainText)) if err!=nil{ return \u0026#34;\u0026#34;, nil } strCipher := base64.StdEncoding.EncodeToString(cipherText) return strCipher, nil } func RsaInit(saveMode bool, timeOut int, publicKeyPath, privateKeyPath string) *signData { if publicKeyPath == \u0026#34;\u0026#34;{ publicKeyPath = SAVEKEYPATH } if privateKeyPath == \u0026#34;\u0026#34;{ privateKeyPath = SAVEKEYPATH } return \u0026amp;signData{ isCreate:\tfalse, Timeout: timeOut, SaveMode: saveMode, PublicKeyPath: publicKeyPath, PrivateKeyPath: privateKeyPath, } } 测试如下 package zcj_rsa import ( \u0026#34;fmt\u0026#34; \u0026#34;testing\u0026#34; ) // 创建rsa保存在文件  func TestRsaFile(t *testing.T) { rsa := RsaInit(true, 1, \u0026#34;./\u0026#34;, \u0026#34;./\u0026#34;) err := rsa.creatKey() if err != nil { t.Errorf(\u0026#34;公私钥创建失败: %v\u0026#34;, err) } // 加密  cipherText, err := rsa.RSAEncryption(\u0026#34;zcj\u0026#34;) if err != nil { t.Errorf(\u0026#34;加密失败：%v\u0026#34;, err) } // 解密  planinText, err := rsa.RSADecryption(cipherText) if err != nil { t.Errorf(\u0026#34;解密失败：%v\u0026#34;, err) } fmt.Printf(\u0026#34;密文：%v \\n\u0026#34;, cipherText) fmt.Printf(\u0026#34;原码：%v \\n\u0026#34;, planinText) } // 保存rsa在内存  func TestRsa(t *testing.T) { rsa := RsaInit(false, 1, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;) err := rsa.creatKey() if err != nil { t.Errorf(\u0026#34;公私钥创建失败: %v\u0026#34;, err) } // 加密  cipherText, err := rsa.RSAEncryption(\u0026#34;zcj\u0026#34;) if err != nil { t.Errorf(\u0026#34;加密失败：%v\u0026#34;, err) } // 解密  planinText, err := rsa.RSADecryption(cipherText) if err != nil { t.Errorf(\u0026#34;解密失败：%v\u0026#34;, err) } fmt.Printf(\u0026#34;密文：%v \\n\u0026#34;, cipherText) fmt.Printf(\u0026#34;原码：%v \\n\u0026#34;, planinText) } 源码仓库  我的github:https://github.com/zcj-git520/zcj_rsa  ","date":"2022-08-15T22:00:38+08:00","image":"https://zcj-git520.github.io/p/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/1_hu90b9af4bc0d9f7c3043b63f92872793b_76034_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/rsa%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"RSA加密算法的使用"},{"content":"proto3 语法学习 基本规范   文件以.proto为文件后缀，除了结构体外，其他语句以分号结束\n  结构定义可以包含：message、service、enum\n  rpc方法定义结尾的分号可有可无\n  Message命名采用驼峰命名方式，字段命名采用小写字母加下划线分隔方式；举例：\nmessage ServerMessage{\trequired string server_name = server1;}  Enums类型名采用驼峰命名方式，字段名采用带大写字母加下划线分隔方式；举例：\nenum Sought{\tFIRST_VALUE = 100;\tSECONED_VALUE = 1200;}  Service类型采用驼峰命名方式；举例：\nservice UserService{ rpc Login(LoginRequest)return(LoginResponse);}字段规则   字段格式：限定修饰符|数据类型|字段名称|=|字段编码值|[字段默认值]\n  限定修饰符号 required\\optional\\repeated\n required:表示是一个必须的字段，必须要发送给对方，在发送之前必须设置该字段的值，对于接收方，必须能够识别该字段的意思，在发送之前没有设置required字段或者无法识别该字段都会引起编码异常，导致消息被丢弃 optional:表示为可选字段，对于发送方，在发送消息时，可以选择性设置或者不设置该字段值，对于接收方，如果能够识别可选字段就进行相应的处理，如果无法识别，则就忽略该字段，消息中的其他字段正常处理。因为optional字段的特性，很多接口在升级版本中把后面添加大的字段都统一设置为optional字段，这样在老版本无法升级的时，也能正常于新的软件进行通信，只不过新的字段无法识别而已，因为并不是每个节点都需要新的功能，因此可以做到按需升级和平滑过渡 repeated:表示该字段可以包含0-n个元素，其特性和optional一样，但是每一次可以包含个多个值，可以看作是在传递一个数组的值    数据类型：protobuf定义了一套基本的数据类型，几乎可以映射到c++\\java等语言的基础数据类型\n\r\n    字段名称\n 字段名称的命名与c、c++、java等语言的变量命名方式几乎相同 protobuf建议字段的命名采用采用下滑线分割的驼峰式    字段编码值\n 有了字段编码值，通信双方才能互相识别对方的字段，相同的编码值，其限定修饰符和数据类型必须相同，编码值的范围为：1-2^32 其中1-15的编码时间和空间效率都很高，编码值越大，其编码的是时间和空间效率就越低，所以建议把经常要传递的值把其字段编码设置为1-15之前的值 1900-2000编码值为Google protobuf系统内部保留值，建议不要使用    字段默认值\n 当在传递数据时，对于required数据类型，如果用户没有设置值，则使用默认值传递到对端    service定义   如果想要将消息类型用在rpc系统中，可以在.proto文件中定义一个RPC服务接口， protocol buffer 编译器会根据所选择的不同语言生成对应的服务器接口代码\n  例如，想要定义一个RPC服务并具有一个方法，该方法接收SearchRequest并返回一个SearchResponse，此时可以在.proto文件中进行如下定义：\nservice SearchService { rpc Search (SearchRequest) returns (SearchResponse) {} }  生成的接口代码作为客户端与服务器的约定。服务端必须实现定义的所有接口方法，客户端直接调用同名方法向服务端发送请求，值得一提的是，即使业务上不需要参数也必须指定一个请求消息，一般会定义空的message\n  Message定义   一个message类型定义了一个请求或者响应的消息格式，可以包含多种类型的字段\n  字段名用小写，转为go文件时会自动转为大写，message就相当于结构体\n  首行声明使用的protobuf版本为proto3\nsyntax = \u0026#34;proto3\u0026#34;massage SearchRequest{ string name = \u0026#34;zcj\u0026#34;; // 查询的名字  int32 pirce= 600; //价格  int32 producet_num = 1; // 产品编号 }  一个.proto文件中可以定义多个消息类型，一般用于同时定义的多个相关的信息\nsyntax = \u0026#34;proto3\u0026#34;massage SearchRequest{ string name = \u0026#34;zcj\u0026#34;; // 查询的名字  int32 pirce= 600; //价格  int32 producet_num = 1; // 产品编号 }// 响应 message SearchResponse{// 响应信息 }  message 支持嵌套使用，作为另一个message中的字段类型\nmessage Result{ string name = \u0026#34;zcj\u0026#34;; string title = \u0026#34;proto3\u0026#34;; int32 price = 1000;}message SearchResponse{ repeated Result result = 1;}  支持嵌套信息，消息可以包含另一个消息作为字段，也可以在消息内定义一个新的消息\n  内部声明的message类型明显可以在内部直接使用\nmessage SearchReponse{ message Resylt{ string name = \u0026#34;zcj\u0026#34;; string title = \u0026#34;proto3\u0026#34;; int32 price = 1000; } repeated Resylt re = 1;}  proto3的Map类型   proto3支持map类型声明\n  键、值类型可以是内置的类型，也可以是自定义的message类型\n  字段不支持repeated属性\nmap\u0026lt;key_type, value_type\u0026gt;map_filed = N; //支持定义的类型  message Produce{ string name = \u0026#34;zcj\u0026#34;; } map\u0026lt;string, Product\u0026gt; pro = 1;proto3文件编译  通过定义好的.proto文件生成的Java，python，c/c++， GO等语言的代码，需要安装编译器protoc 当使用protocol buffer 编译器允许.proto文件时，编译器生成所选择语言的代码，用于使用在.proto文件中定义的消息类型，服务接口约定等，不同的语言生成代码格式不同：  c++:每个.proto文件生成一个.h和一个.cc文件，每一个消息类型对应一个类 Java：生成一个.Java文件，同样每个消息对应一个类，同时还有一个特殊的Builder类用于创建信息接口 Go：生成一个.pb.go文件，每一个消息类型对应这一个结构体 Python: 姿势不太一样，每个.proto文件中的消息类型生成一个含有静态描述符的模块，该模块与一个元类metaclass在运行时创建需要的Python数据访问类    import导入定义  可以使用import 接口语句导入使用其他描述文件中的声明的类型 protobuf 接口文件可以像C语言的#include或者Java的import的行为大致一致 protocol buffer编译器会在-I /\u0026ndash;proto_path参数指定的目录中查找导入的文件，如果没有指定该参数，默认使用当前的目录查找  包的使用   在proto文件中使用package声明包，避免命名冲突\n  在其他的消息格式定义中可以使用包名+消息名的方式使用类型\n  在不同语言中，包含定义对编译后生成的代码影响不同：\n C++：对应C++命令空间 Java 中：package会作为Java包名，除非指定了option jave_package选项 Python 中：package被忽略 Go 中：默认使用package名作为包名，除非指定了option go_package选项  测试 message 测试   proto 文件内容\nsyntax = \u0026#34;proto3\u0026#34;; // 语法声明 package main; // 默认与go文件中的包名一致 // option go_package = \u0026#34;zcj_proto\u0026#34;; // 不一致时，可以使用go_package // 测试message 采用为驼峰的命令方式  message TestMessage{ string te_name = 1; int32 te_age = 2; int32 te_count = 3; double te_money = 4; float te_score = 5; bool te_fat = 6; bytes te_char = 7; // 枚举类型  enum Status{ OK = 0; FAIL = 1; } message TeChild{ string ch_name = 1; string ch_sex = 2; } TeChild childs = 9; // map类型  map\u0026lt;string, int32\u0026gt; te_map = 10; }  生成go 文件内容\n// Code generated by protoc-gen-go. DO NOT EDIT. // source: proto3.proto  package test_message import ( fmt \u0026#34;fmt\u0026#34; proto \u0026#34;github.com/golang/protobuf/proto\u0026#34; math \u0026#34;math\u0026#34; ) // Reference imports to suppress errors if they are not otherwise used. var _ = proto.Marshal var _ = fmt.Errorf var _ = math.Inf // This is a compile-time assertion to ensure that this generated file // is compatible with the proto package it is being compiled against. // A compilation error at this line likely means your copy of the // proto package needs to be updated. const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package  // 枚举类型 type TestMessage_Status int32 const ( TestMessage_OK TestMessage_Status = 0 TestMessage_FAIL TestMessage_Status = 1 ) var TestMessage_Status_name = map[int32]string{ 0: \u0026#34;OK\u0026#34;, 1: \u0026#34;FAIL\u0026#34;, } var TestMessage_Status_value = map[string]int32{ \u0026#34;OK\u0026#34;: 0, \u0026#34;FAIL\u0026#34;: 1, } func (x TestMessage_Status) String() string { return proto.EnumName(TestMessage_Status_name, int32(x)) } func (TestMessage_Status) EnumDescriptor() ([]byte, []int) { return fileDescriptor_4fee6d65e34a64b6, []int{0, 0} } // 测试message 采用为驼峰的命令方式 type TestMessage struct { TeName string `protobuf:\u0026#34;bytes,1,opt,name=te_name,json=teName,proto3\u0026#34; json:\u0026#34;te_name,omitempty\u0026#34;` TeAge int32 `protobuf:\u0026#34;varint,2,opt,name=te_age,json=teAge,proto3\u0026#34; json:\u0026#34;te_age,omitempty\u0026#34;` TeCount int32 `protobuf:\u0026#34;varint,3,opt,name=te_count,json=teCount,proto3\u0026#34; json:\u0026#34;te_count,omitempty\u0026#34;` TeMoney float64 `protobuf:\u0026#34;fixed64,4,opt,name=te_money,json=teMoney,proto3\u0026#34; json:\u0026#34;te_money,omitempty\u0026#34;` TeScore float32 `protobuf:\u0026#34;fixed32,5,opt,name=te_score,json=teScore,proto3\u0026#34; json:\u0026#34;te_score,omitempty\u0026#34;` TeFat bool `protobuf:\u0026#34;varint,6,opt,name=te_fat,json=teFat,proto3\u0026#34; json:\u0026#34;te_fat,omitempty\u0026#34;` TeChar []byte `protobuf:\u0026#34;bytes,7,opt,name=te_char,json=teChar,proto3\u0026#34; json:\u0026#34;te_char,omitempty\u0026#34;` Childs *TestMessage_TeChild `protobuf:\u0026#34;bytes,9,opt,name=childs,proto3\u0026#34; json:\u0026#34;childs,omitempty\u0026#34;` // map类型  TeMap map[string]int32 `protobuf:\u0026#34;bytes,10,rep,name=te_map,json=teMap,proto3\u0026#34; json:\u0026#34;te_map,omitempty\u0026#34; protobuf_key:\u0026#34;bytes,1,opt,name=key,proto3\u0026#34; protobuf_val:\u0026#34;varint,2,opt,name=value,proto3\u0026#34;` XXX_NoUnkeyedLiteral struct{} `json:\u0026#34;-\u0026#34;` XXX_unrecognized []byte `json:\u0026#34;-\u0026#34;` XXX_sizecache int32 `json:\u0026#34;-\u0026#34;` } func (m *TestMessage) Reset() { *m = TestMessage{} } func (m *TestMessage) String() string { return proto.CompactTextString(m) } func (*TestMessage) ProtoMessage() {} func (*TestMessage) Descriptor() ([]byte, []int) { return fileDescriptor_4fee6d65e34a64b6, []int{0} } func (m *TestMessage) XXX_Unmarshal(b []byte) error { return xxx_messageInfo_TestMessage.Unmarshal(m, b) } func (m *TestMessage) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) { return xxx_messageInfo_TestMessage.Marshal(b, m, deterministic) } func (m *TestMessage) XXX_Merge(src proto.Message) { xxx_messageInfo_TestMessage.Merge(m, src) } func (m *TestMessage) XXX_Size() int { return xxx_messageInfo_TestMessage.Size(m) } func (m *TestMessage) XXX_DiscardUnknown() { xxx_messageInfo_TestMessage.DiscardUnknown(m) } var xxx_messageInfo_TestMessage proto.InternalMessageInfo func (m *TestMessage) GetTeName() string { if m != nil { return m.TeName } return \u0026#34;\u0026#34; } func (m *TestMessage) GetTeAge() int32 { if m != nil { return m.TeAge } return 0 } func (m *TestMessage) GetTeCount() int32 { if m != nil { return m.TeCount } return 0 } func (m *TestMessage) GetTeMoney() float64 { if m != nil { return m.TeMoney } return 0 } func (m *TestMessage) GetTeScore() float32 { if m != nil { return m.TeScore } return 0 } func (m *TestMessage) GetTeFat() bool { if m != nil { return m.TeFat } return false } func (m *TestMessage) GetTeChar() []byte { if m != nil { return m.TeChar } return nil } func (m *TestMessage) GetChilds() *TestMessage_TeChild { if m != nil { return m.Childs } return nil } func (m *TestMessage) GetTeMap() map[string]int32 { if m != nil { return m.TeMap } return nil } type TestMessage_TeChild struct { ChName string `protobuf:\u0026#34;bytes,1,opt,name=ch_name,json=chName,proto3\u0026#34; json:\u0026#34;ch_name,omitempty\u0026#34;` ChSex string `protobuf:\u0026#34;bytes,2,opt,name=ch_sex,json=chSex,proto3\u0026#34; json:\u0026#34;ch_sex,omitempty\u0026#34;` XXX_NoUnkeyedLiteral struct{} `json:\u0026#34;-\u0026#34;` XXX_unrecognized []byte `json:\u0026#34;-\u0026#34;` XXX_sizecache int32 `json:\u0026#34;-\u0026#34;` } func (m *TestMessage_TeChild) Reset() { *m = TestMessage_TeChild{} } func (m *TestMessage_TeChild) String() string { return proto.CompactTextString(m) } func (*TestMessage_TeChild) ProtoMessage() {} func (*TestMessage_TeChild) Descriptor() ([]byte, []int) { return fileDescriptor_4fee6d65e34a64b6, []int{0, 0} } func (m *TestMessage_TeChild) XXX_Unmarshal(b []byte) error { return xxx_messageInfo_TestMessage_TeChild.Unmarshal(m, b) } func (m *TestMessage_TeChild) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) { return xxx_messageInfo_TestMessage_TeChild.Marshal(b, m, deterministic) } func (m *TestMessage_TeChild) XXX_Merge(src proto.Message) { xxx_messageInfo_TestMessage_TeChild.Merge(m, src) } func (m *TestMessage_TeChild) XXX_Size() int { return xxx_messageInfo_TestMessage_TeChild.Size(m) } func (m *TestMessage_TeChild) XXX_DiscardUnknown() { xxx_messageInfo_TestMessage_TeChild.DiscardUnknown(m) } var xxx_messageInfo_TestMessage_TeChild proto.InternalMessageInfo func (m *TestMessage_TeChild) GetChName() string { if m != nil { return m.ChName } return \u0026#34;\u0026#34; } func (m *TestMessage_TeChild) GetChSex() string { if m != nil { return m.ChSex } return \u0026#34;\u0026#34; } func init() { proto.RegisterEnum(\u0026#34;main.TestMessage_Status\u0026#34;, TestMessage_Status_name, TestMessage_Status_value) proto.RegisterType((*TestMessage)(nil), \u0026#34;main.TestMessage\u0026#34;) proto.RegisterMapType((map[string]int32)(nil), \u0026#34;main.TestMessage.TeMapEntry\u0026#34;) proto.RegisterType((*TestMessage_TeChild)(nil), \u0026#34;main.TestMessage.TeChild\u0026#34;) } func init() { proto.RegisterFile(\u0026#34;proto3.proto\u0026#34;, fileDescriptor_4fee6d65e34a64b6) } var fileDescriptor_4fee6d65e34a64b6 = []byte{ // 333 bytes of a gzipped FileDescriptorProto  0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0x6c, 0x51, 0x4d, 0x6f, 0xea, 0x30, 0x10, 0x7c, 0x4e, 0x48, 0x02, 0x0b, 0x07, 0x64, 0xbd, 0xa7, 0x67, 0x50, 0x0f, 0x16, 0x27, 0x9f, 0x22, 0x15, 0x2e, 0xb4, 0x37, 0x84, 0x8a, 0x54, 0xb5, 0x69, 0xa5, 0xc0, 0x3d, 0x72, 0xdd, 0x2d, 0x41, 0x25, 0x1f, 0x4a, 0x96, 0x0a, 0x7e, 0x59, 0xff, 0x5e, 0xe5, 0x34, 0xfd, 0x92, 0x7a, 0xb2, 0x47, 0xb3, 0xbb, 0x33, 0x3b, 0x0b, 0x83, 0xb2, 0x2a, 0xa8, 0x98, 0x85, 0xcd, 0xc3, 0x3b, 0x99, 0xde, 0xe5, 0x93, 0x57, 0x17, 0xfa, 0x1b, 0xac, 0x29, 0xc2, 0xba, 0xd6, 0x5b, 0xe4, 0xff, 0x21, 0x20, 0x4c, 0x72, 0x9d, 0xa1, 0x60, 0x92, 0xa9, 0x5e, 0xec, 0x13, 0xde, 0xe9, 0x0c, 0xf9, 0x3f, 0xf0, 0x09, 0x13, 0xbd, 0x45, 0xe1, 0x48, 0xa6, 0xbc, 0xd8, 0x23, 0x5c, 0x6c, 0x91, 0x8f, 0xa0, 0x4b, 0x98, 0x98, 0xe2, 0x90, 0x93, 0x70, 0x1b, 0x22, 0x20, 0x5c, 0x5a, 0xd8, 0x52, 0x59, 0x91, 0xe3, 0x49, 0x74, 0x24, 0x53, 0xcc, 0x52, 0x91, 0x85, 0x2d, 0x55, 0x9b, 0xa2, 0x42, 0xe1, 0x49, 0xa6, 0x1c, 0x4b, 0xad, 0x2d, 0x6c, 0x75, 0x9e, 0x34, 0x09, 0x5f, 0x32, 0xd5, 0xb5, 0x3a, 0x2b, 0x4d, 0xad, 0x2f, 0x93, 0xea, 0x4a, 0x04, 0x92, 0xa9, 0x81, 0xf5, 0xb5, 0x4c, 0x75, 0xc5, 0xcf, 0xc1, 0x37, 0xe9, 0x6e, 0xff, 0x58, 0x8b, 0x9e, 0x64, 0xaa, 0x3f, 0x1d, 0x85, 0x76, 0xaf, 0xf0, 0xdb, 0x4e, 0xe1, 0x06, 0x97, 0xb6, 0x22, 0x6e, 0x0b, 0xf9, 0xac, 0x91, 0xc8, 0x74, 0x29, 0x40, 0xba, 0xaa, 0x3f, 0x3d, 0xfb, 0xad, 0x25, 0xd2, 0xe5, 0x55, 0x4e, 0xd5, 0xc9, 0x1a, 0x88, 0x74, 0x39, 0xbe, 0x80, 0xa0, 0x9d, 0x63, 0xbd, 0x98, 0xf4, 0x47, 0x46, 0x26, 0xfd, 0xc8, 0xc8, 0xa4, 0x49, 0x8d, 0xc7, 0x26, 0xa3, 0x5e, 0xec, 0x99, 0x74, 0x8d, 0xc7, 0xf1, 0x1c, 0xe0, 0x6b, 0x1e, 0x1f, 0x82, 0xfb, 0x8c, 0xa7, 0xb6, 0xd3, 0x7e, 0xf9, 0x5f, 0xf0, 0x5e, 0xf4, 0xfe, 0xf0, 0x99, 0x6c, 0x03, 0x2e, 0x9d, 0x39, 0x9b, 0x8c, 0xc1, 0x5f, 0x93, 0xa6, 0x43, 0xcd, 0x7d, 0x70, 0xee, 0x6f, 0x86, 0x7f, 0x78, 0x17, 0x3a, 0xab, 0xc5, 0xf5, 0xed, 0x90, 0x3d, 0xf8, 0xef, 0xd7, 0x7c, 0x0b, 0x00, 0x00, 0xff, 0xff, 0x30, 0x6b, 0xfd, 0xd9, 0xd6, 0x01, 0x00, 0x00, }   生成C++ 文件内容\n// Generated by the protocol buffer compiler. DO NOT EDIT!  // source: proto3.proto  #ifndef GOOGLE_PROTOBUF_INCLUDED_proto3_2eproto  #define GOOGLE_PROTOBUF_INCLUDED_proto3_2eproto  #include \u0026lt;limits\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;google/protobuf/port_def.inc\u0026gt; #if PROTOBUF_VERSION \u0026lt; 3021000  #error This file was generated by a newer version of protoc which is  #error incompatible with your Protocol Buffer headers. Please update  #error your headers.  #endif  #if 3021005 \u0026lt; PROTOBUF_MIN_PROTOC_VERSION  #error This file was generated by an older version of protoc which is  #error incompatible with your Protocol Buffer headers. Please  #error regenerate this file with a newer version of protoc.  #endif  #include \u0026lt;google/protobuf/port_undef.inc\u0026gt; #include \u0026lt;google/protobuf/io/coded_stream.h\u0026gt; #include \u0026lt;google/protobuf/arena.h\u0026gt; #include \u0026lt;google/protobuf/arenastring.h\u0026gt; #include \u0026lt;google/protobuf/generated_message_util.h\u0026gt; #include \u0026lt;google/protobuf/metadata_lite.h\u0026gt; #include \u0026lt;google/protobuf/generated_message_reflection.h\u0026gt; #include \u0026lt;google/protobuf/message.h\u0026gt; #include \u0026lt;google/protobuf/repeated_field.h\u0026gt; // IWYU pragma: export #include \u0026lt;google/protobuf/extension_set.h\u0026gt; // IWYU pragma: export #include \u0026lt;google/protobuf/map.h\u0026gt; // IWYU pragma: export #include \u0026lt;google/protobuf/map_entry.h\u0026gt; #include \u0026lt;google/protobuf/map_field_inl.h\u0026gt; #include \u0026lt;google/protobuf/generated_enum_reflection.h\u0026gt; #include \u0026lt;google/protobuf/unknown_field_set.h\u0026gt; // @@protoc_insertion_point(includes)  #include \u0026lt;google/protobuf/port_def.inc\u0026gt; #define PROTOBUF_INTERNAL_EXPORT_proto3_2eproto  PROTOBUF_NAMESPACE_OPEN namespace internal { class AnyMetadata; } // namespace internal  PROTOBUF_NAMESPACE_CLOSE // Internal implementation detail -- do not use these members.  struct TableStruct_proto3_2eproto { static const uint32_t offsets[]; }; extern const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_proto3_2eproto; namespace main { class TestMessage; struct TestMessageDefaultTypeInternal; extern TestMessageDefaultTypeInternal _TestMessage_default_instance_; class TestMessage_TeChild; struct TestMessage_TeChildDefaultTypeInternal; extern TestMessage_TeChildDefaultTypeInternal _TestMessage_TeChild_default_instance_; class TestMessage_TeMapEntry_DoNotUse; struct TestMessage_TeMapEntry_DoNotUseDefaultTypeInternal; extern TestMessage_TeMapEntry_DoNotUseDefaultTypeInternal _TestMessage_TeMapEntry_DoNotUse_default_instance_; } // namespace main  PROTOBUF_NAMESPACE_OPEN template\u0026lt;\u0026gt; ::main::TestMessage* Arena::CreateMaybeMessage\u0026lt;::main::TestMessage\u0026gt;(Arena*); template\u0026lt;\u0026gt; ::main::TestMessage_TeChild* Arena::CreateMaybeMessage\u0026lt;::main::TestMessage_TeChild\u0026gt;(Arena*); template\u0026lt;\u0026gt; ::main::TestMessage_TeMapEntry_DoNotUse* Arena::CreateMaybeMessage\u0026lt;::main::TestMessage_TeMapEntry_DoNotUse\u0026gt;(Arena*); PROTOBUF_NAMESPACE_CLOSE namespace main { enum TestMessage_Status : int { TestMessage_Status_OK = 0, TestMessage_Status_FAIL = 1, TestMessage_Status_TestMessage_Status_INT_MIN_SENTINEL_DO_NOT_USE_ = std::numeric_limits\u0026lt;int32_t\u0026gt;::min(), TestMessage_Status_TestMessage_Status_INT_MAX_SENTINEL_DO_NOT_USE_ = std::numeric_limits\u0026lt;int32_t\u0026gt;::max() }; bool TestMessage_Status_IsValid(int value); constexpr TestMessage_Status TestMessage_Status_Status_MIN = TestMessage_Status_OK; constexpr TestMessage_Status TestMessage_Status_Status_MAX = TestMessage_Status_FAIL; constexpr int TestMessage_Status_Status_ARRAYSIZE = TestMessage_Status_Status_MAX + 1; const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* TestMessage_Status_descriptor(); template\u0026lt;typename T\u0026gt; inline const std::string\u0026amp; TestMessage_Status_Name(T enum_t_value) { static_assert(::std::is_same\u0026lt;T, TestMessage_Status\u0026gt;::value || ::std::is_integral\u0026lt;T\u0026gt;::value, \u0026#34;Incorrect type passed to function TestMessage_Status_Name.\u0026#34;); return ::PROTOBUF_NAMESPACE_ID::internal::NameOfEnum( TestMessage_Status_descriptor(), enum_t_value); } inline bool TestMessage_Status_Parse( ::PROTOBUF_NAMESPACE_ID::ConstStringParam name, TestMessage_Status* value) { return ::PROTOBUF_NAMESPACE_ID::internal::ParseNamedEnum\u0026lt;TestMessage_Status\u0026gt;( TestMessage_Status_descriptor(), name, value); } // ===================================================================  class TestMessage_TeChild final : public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:main.TestMessage.TeChild) */ { public: inline TestMessage_TeChild() : TestMessage_TeChild(nullptr) {} ~TestMessage_TeChild() override; explicit PROTOBUF_CONSTEXPR TestMessage_TeChild(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized); TestMessage_TeChild(const TestMessage_TeChild\u0026amp; from); TestMessage_TeChild(TestMessage_TeChild\u0026amp;\u0026amp; from) noexcept : TestMessage_TeChild() { *this = ::std::move(from); } inline TestMessage_TeChild\u0026amp; operator=(const TestMessage_TeChild\u0026amp; from) { CopyFrom(from); return *this; } inline TestMessage_TeChild\u0026amp; operator=(TestMessage_TeChild\u0026amp;\u0026amp; from) noexcept { if (this == \u0026amp;from) return *this; if (GetOwningArena() == from.GetOwningArena() #ifdef PROTOBUF_FORCE_COPY_IN_MOVE  \u0026amp;\u0026amp; GetOwningArena() != nullptr #endif // !PROTOBUF_FORCE_COPY_IN_MOVE  ) { InternalSwap(\u0026amp;from); } else { CopyFrom(from); } return *this; } static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() { return GetDescriptor(); } static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() { return default_instance().GetMetadata().descriptor; } static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() { return default_instance().GetMetadata().reflection; } static const TestMessage_TeChild\u0026amp; default_instance() { return *internal_default_instance(); } static inline const TestMessage_TeChild* internal_default_instance() { return reinterpret_cast\u0026lt;const TestMessage_TeChild*\u0026gt;( \u0026amp;_TestMessage_TeChild_default_instance_); } static constexpr int kIndexInFileMessages = 0; friend void swap(TestMessage_TeChild\u0026amp; a, TestMessage_TeChild\u0026amp; b) { a.Swap(\u0026amp;b); } inline void Swap(TestMessage_TeChild* other) { if (other == this) return; #ifdef PROTOBUF_FORCE_COPY_IN_SWAP  if (GetOwningArena() != nullptr \u0026amp;\u0026amp; GetOwningArena() == other-\u0026gt;GetOwningArena()) { #else // PROTOBUF_FORCE_COPY_IN_SWAP  if (GetOwningArena() == other-\u0026gt;GetOwningArena()) { #endif // !PROTOBUF_FORCE_COPY_IN_SWAP  InternalSwap(other); } else { ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other); } } void UnsafeArenaSwap(TestMessage_TeChild* other) { if (other == this) return; GOOGLE_DCHECK(GetOwningArena() == other-\u0026gt;GetOwningArena()); InternalSwap(other); } // implements Message ----------------------------------------------  TestMessage_TeChild* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final { return CreateMaybeMessage\u0026lt;TestMessage_TeChild\u0026gt;(arena); } using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom; void CopyFrom(const TestMessage_TeChild\u0026amp; from); using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom; void MergeFrom( const TestMessage_TeChild\u0026amp; from) { TestMessage_TeChild::MergeImpl(*this, from); } private: static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message\u0026amp; to_msg, const ::PROTOBUF_NAMESPACE_ID::Message\u0026amp; from_msg); public: PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final; bool IsInitialized() const final; size_t ByteSizeLong() const final; const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final; uint8_t* _InternalSerialize( uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final; int GetCachedSize() const final { return _impl_._cached_size_.Get(); } private: void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned); void SharedDtor(); void SetCachedSize(int size) const final; void InternalSwap(TestMessage_TeChild* other); private: friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata; static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() { return \u0026#34;main.TestMessage.TeChild\u0026#34;; } protected: explicit TestMessage_TeChild(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned = false); public: static const ClassData _class_data_; const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final; ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final; // nested types ----------------------------------------------------  // accessors -------------------------------------------------------  enum : int { kChNameFieldNumber = 1, kChSexFieldNumber = 2, }; // string ch_name = 1;  void clear_ch_name(); const std::string\u0026amp; ch_name() const; template \u0026lt;typename ArgT0 = const std::string\u0026amp;, typename... ArgT\u0026gt; void set_ch_name(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args); std::string* mutable_ch_name(); PROTOBUF_NODISCARD std::string* release_ch_name(); void set_allocated_ch_name(std::string* ch_name); private: const std::string\u0026amp; _internal_ch_name() const; inline PROTOBUF_ALWAYS_INLINE void _internal_set_ch_name(const std::string\u0026amp; value); std::string* _internal_mutable_ch_name(); public: // string ch_sex = 2;  void clear_ch_sex(); const std::string\u0026amp; ch_sex() const; template \u0026lt;typename ArgT0 = const std::string\u0026amp;, typename... ArgT\u0026gt; void set_ch_sex(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args); std::string* mutable_ch_sex(); PROTOBUF_NODISCARD std::string* release_ch_sex(); void set_allocated_ch_sex(std::string* ch_sex); private: const std::string\u0026amp; _internal_ch_sex() const; inline PROTOBUF_ALWAYS_INLINE void _internal_set_ch_sex(const std::string\u0026amp; value); std::string* _internal_mutable_ch_sex(); public: // @@protoc_insertion_point(class_scope:main.TestMessage.TeChild)  private: class _Internal; template \u0026lt;typename T\u0026gt; friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper; typedef void InternalArenaConstructable_; typedef void DestructorSkippable_; struct Impl_ { ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr ch_name_; ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr ch_sex_; mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_; }; union { Impl_ _impl_; }; friend struct ::TableStruct_proto3_2eproto; }; // -------------------------------------------------------------------  class TestMessage_TeMapEntry_DoNotUse : public ::PROTOBUF_NAMESPACE_ID::internal::MapEntry\u0026lt;TestMessage_TeMapEntry_DoNotUse, std::string, int32_t, ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING, ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_INT32\u0026gt; { public: typedef ::PROTOBUF_NAMESPACE_ID::internal::MapEntry\u0026lt;TestMessage_TeMapEntry_DoNotUse, std::string, int32_t, ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING, ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_INT32\u0026gt; SuperType; TestMessage_TeMapEntry_DoNotUse(); explicit PROTOBUF_CONSTEXPR TestMessage_TeMapEntry_DoNotUse( ::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized); explicit TestMessage_TeMapEntry_DoNotUse(::PROTOBUF_NAMESPACE_ID::Arena* arena); void MergeFrom(const TestMessage_TeMapEntry_DoNotUse\u0026amp; other); static const TestMessage_TeMapEntry_DoNotUse* internal_default_instance() { return reinterpret_cast\u0026lt;const TestMessage_TeMapEntry_DoNotUse*\u0026gt;(\u0026amp;_TestMessage_TeMapEntry_DoNotUse_default_instance_); } static bool ValidateKey(std::string* s) { return ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(s-\u0026gt;data(), static_cast\u0026lt;int\u0026gt;(s-\u0026gt;size()), ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::PARSE, \u0026#34;main.TestMessage.TeMapEntry.key\u0026#34;); } static bool ValidateValue(void*) { return true; } using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom; ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final; friend struct ::TableStruct_proto3_2eproto; }; // -------------------------------------------------------------------  class TestMessage final : public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:main.TestMessage) */ { public: inline TestMessage() : TestMessage(nullptr) {} ~TestMessage() override; explicit PROTOBUF_CONSTEXPR TestMessage(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized); TestMessage(const TestMessage\u0026amp; from); TestMessage(TestMessage\u0026amp;\u0026amp; from) noexcept : TestMessage() { *this = ::std::move(from); } inline TestMessage\u0026amp; operator=(const TestMessage\u0026amp; from) { CopyFrom(from); return *this; } inline TestMessage\u0026amp; operator=(TestMessage\u0026amp;\u0026amp; from) noexcept { if (this == \u0026amp;from) return *this; if (GetOwningArena() == from.GetOwningArena() #ifdef PROTOBUF_FORCE_COPY_IN_MOVE  \u0026amp;\u0026amp; GetOwningArena() != nullptr #endif // !PROTOBUF_FORCE_COPY_IN_MOVE  ) { InternalSwap(\u0026amp;from); } else { CopyFrom(from); } return *this; } static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() { return GetDescriptor(); } static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() { return default_instance().GetMetadata().descriptor; } static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() { return default_instance().GetMetadata().reflection; } static const TestMessage\u0026amp; default_instance() { return *internal_default_instance(); } static inline const TestMessage* internal_default_instance() { return reinterpret_cast\u0026lt;const TestMessage*\u0026gt;( \u0026amp;_TestMessage_default_instance_); } static constexpr int kIndexInFileMessages = 2; friend void swap(TestMessage\u0026amp; a, TestMessage\u0026amp; b) { a.Swap(\u0026amp;b); } inline void Swap(TestMessage* other) { if (other == this) return; #ifdef PROTOBUF_FORCE_COPY_IN_SWAP  if (GetOwningArena() != nullptr \u0026amp;\u0026amp; GetOwningArena() == other-\u0026gt;GetOwningArena()) { #else // PROTOBUF_FORCE_COPY_IN_SWAP  if (GetOwningArena() == other-\u0026gt;GetOwningArena()) { #endif // !PROTOBUF_FORCE_COPY_IN_SWAP  InternalSwap(other); } else { ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other); } } void UnsafeArenaSwap(TestMessage* other) { if (other == this) return; GOOGLE_DCHECK(GetOwningArena() == other-\u0026gt;GetOwningArena()); InternalSwap(other); } // implements Message ----------------------------------------------  TestMessage* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final { return CreateMaybeMessage\u0026lt;TestMessage\u0026gt;(arena); } using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom; void CopyFrom(const TestMessage\u0026amp; from); using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom; void MergeFrom( const TestMessage\u0026amp; from) { TestMessage::MergeImpl(*this, from); } private: static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message\u0026amp; to_msg, const ::PROTOBUF_NAMESPACE_ID::Message\u0026amp; from_msg); public: PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final; bool IsInitialized() const final; size_t ByteSizeLong() const final; const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final; uint8_t* _InternalSerialize( uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final; int GetCachedSize() const final { return _impl_._cached_size_.Get(); } private: void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned); void SharedDtor(); void SetCachedSize(int size) const final; void InternalSwap(TestMessage* other); private: friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata; static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() { return \u0026#34;main.TestMessage\u0026#34;; } protected: explicit TestMessage(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned = false); private: static void ArenaDtor(void* object); public: static const ClassData _class_data_; const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final; ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final; // nested types ----------------------------------------------------  typedef TestMessage_TeChild TeChild; typedef TestMessage_Status Status; static constexpr Status OK = TestMessage_Status_OK; static constexpr Status FAIL = TestMessage_Status_FAIL; static inline bool Status_IsValid(int value) { return TestMessage_Status_IsValid(value); } static constexpr Status Status_MIN = TestMessage_Status_Status_MIN; static constexpr Status Status_MAX = TestMessage_Status_Status_MAX; static constexpr int Status_ARRAYSIZE = TestMessage_Status_Status_ARRAYSIZE; static inline const ::PROTOBUF_NAMESPACE_ID::EnumDescriptor* Status_descriptor() { return TestMessage_Status_descriptor(); } template\u0026lt;typename T\u0026gt; static inline const std::string\u0026amp; Status_Name(T enum_t_value) { static_assert(::std::is_same\u0026lt;T, Status\u0026gt;::value || ::std::is_integral\u0026lt;T\u0026gt;::value, \u0026#34;Incorrect type passed to function Status_Name.\u0026#34;); return TestMessage_Status_Name(enum_t_value); } static inline bool Status_Parse(::PROTOBUF_NAMESPACE_ID::ConstStringParam name, Status* value) { return TestMessage_Status_Parse(name, value); } // accessors -------------------------------------------------------  enum : int { kTeMapFieldNumber = 10, kTeNameFieldNumber = 1, kTeCharFieldNumber = 7, kChildsFieldNumber = 9, kTeAgeFieldNumber = 2, kTeCountFieldNumber = 3, kTeMoneyFieldNumber = 4, kTeScoreFieldNumber = 5, kTeFatFieldNumber = 6, }; // map\u0026lt;string, int32\u0026gt; te_map = 10;  int te_map_size() const; private: int _internal_te_map_size() const; public: void clear_te_map(); private: const ::PROTOBUF_NAMESPACE_ID::Map\u0026lt; std::string, int32_t \u0026gt;\u0026amp; _internal_te_map() const; ::PROTOBUF_NAMESPACE_ID::Map\u0026lt; std::string, int32_t \u0026gt;* _internal_mutable_te_map(); public: const ::PROTOBUF_NAMESPACE_ID::Map\u0026lt; std::string, int32_t \u0026gt;\u0026amp; te_map() const; ::PROTOBUF_NAMESPACE_ID::Map\u0026lt; std::string, int32_t \u0026gt;* mutable_te_map(); // string te_name = 1;  void clear_te_name(); const std::string\u0026amp; te_name() const; template \u0026lt;typename ArgT0 = const std::string\u0026amp;, typename... ArgT\u0026gt; void set_te_name(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args); std::string* mutable_te_name(); PROTOBUF_NODISCARD std::string* release_te_name(); void set_allocated_te_name(std::string* te_name); private: const std::string\u0026amp; _internal_te_name() const; inline PROTOBUF_ALWAYS_INLINE void _internal_set_te_name(const std::string\u0026amp; value); std::string* _internal_mutable_te_name(); public: // bytes te_char = 7;  void clear_te_char(); const std::string\u0026amp; te_char() const; template \u0026lt;typename ArgT0 = const std::string\u0026amp;, typename... ArgT\u0026gt; void set_te_char(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args); std::string* mutable_te_char(); PROTOBUF_NODISCARD std::string* release_te_char(); void set_allocated_te_char(std::string* te_char); private: const std::string\u0026amp; _internal_te_char() const; inline PROTOBUF_ALWAYS_INLINE void _internal_set_te_char(const std::string\u0026amp; value); std::string* _internal_mutable_te_char(); public: // .main.TestMessage.TeChild childs = 9;  bool has_childs() const; private: bool _internal_has_childs() const; public: void clear_childs(); const ::main::TestMessage_TeChild\u0026amp; childs() const; PROTOBUF_NODISCARD ::main::TestMessage_TeChild* release_childs(); ::main::TestMessage_TeChild* mutable_childs(); void set_allocated_childs(::main::TestMessage_TeChild* childs); private: const ::main::TestMessage_TeChild\u0026amp; _internal_childs() const; ::main::TestMessage_TeChild* _internal_mutable_childs(); public: void unsafe_arena_set_allocated_childs( ::main::TestMessage_TeChild* childs); ::main::TestMessage_TeChild* unsafe_arena_release_childs(); // int32 te_age = 2;  void clear_te_age(); int32_t te_age() const; void set_te_age(int32_t value); private: int32_t _internal_te_age() const; void _internal_set_te_age(int32_t value); public: // int32 te_count = 3;  void clear_te_count(); int32_t te_count() const; void set_te_count(int32_t value); private: int32_t _internal_te_count() const; void _internal_set_te_count(int32_t value); public: // double te_money = 4;  void clear_te_money(); double te_money() const; void set_te_money(double value); private: double _internal_te_money() const; void _internal_set_te_money(double value); public: // float te_score = 5;  void clear_te_score(); float te_score() const; void set_te_score(float value); private: float _internal_te_score() const; void _internal_set_te_score(float value); public: // bool te_fat = 6;  void clear_te_fat(); bool te_fat() const; void set_te_fat(bool value); private: bool _internal_te_fat() const; void _internal_set_te_fat(bool value); public: // @@protoc_insertion_point(class_scope:main.TestMessage)  private: class _Internal; template \u0026lt;typename T\u0026gt; friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper; typedef void InternalArenaConstructable_; typedef void DestructorSkippable_; struct Impl_ { ::PROTOBUF_NAMESPACE_ID::internal::MapField\u0026lt; TestMessage_TeMapEntry_DoNotUse, std::string, int32_t, ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_STRING, ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::TYPE_INT32\u0026gt; te_map_; ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr te_name_; ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr te_char_; ::main::TestMessage_TeChild* childs_; int32_t te_age_; int32_t te_count_; double te_money_; float te_score_; bool te_fat_; mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_; }; union { Impl_ _impl_; }; friend struct ::TableStruct_proto3_2eproto; }; // ===================================================================  // ===================================================================  #ifdef __GNUC__  #pragma GCC diagnostic push  #pragma GCC diagnostic ignored \u0026#34;-Wstrict-aliasing\u0026#34;  #endif // __GNUC__  // TestMessage_TeChild  // string ch_name = 1;  inline void TestMessage_TeChild::clear_ch_name() { _impl_.ch_name_.ClearToEmpty(); } inline const std::string\u0026amp; TestMessage_TeChild::ch_name() const { // @@protoc_insertion_point(field_get:main.TestMessage.TeChild.ch_name)  return _internal_ch_name(); } template \u0026lt;typename ArgT0, typename... ArgT\u0026gt; inline PROTOBUF_ALWAYS_INLINE void TestMessage_TeChild::set_ch_name(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args) { _impl_.ch_name_.Set(static_cast\u0026lt;ArgT0 \u0026amp;\u0026amp;\u0026gt;(arg0), args..., GetArenaForAllocation()); // @@protoc_insertion_point(field_set:main.TestMessage.TeChild.ch_name)  } inline std::string* TestMessage_TeChild::mutable_ch_name() { std::string* _s = _internal_mutable_ch_name(); // @@protoc_insertion_point(field_mutable:main.TestMessage.TeChild.ch_name)  return _s; } inline const std::string\u0026amp; TestMessage_TeChild::_internal_ch_name() const { return _impl_.ch_name_.Get(); } inline void TestMessage_TeChild::_internal_set_ch_name(const std::string\u0026amp; value) { _impl_.ch_name_.Set(value, GetArenaForAllocation()); } inline std::string* TestMessage_TeChild::_internal_mutable_ch_name() { return _impl_.ch_name_.Mutable(GetArenaForAllocation()); } inline std::string* TestMessage_TeChild::release_ch_name() { // @@protoc_insertion_point(field_release:main.TestMessage.TeChild.ch_name)  return _impl_.ch_name_.Release(); } inline void TestMessage_TeChild::set_allocated_ch_name(std::string* ch_name) { if (ch_name != nullptr) { } else { } _impl_.ch_name_.SetAllocated(ch_name, GetArenaForAllocation()); #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING  if (_impl_.ch_name_.IsDefault()) { _impl_.ch_name_.Set(\u0026#34;\u0026#34;, GetArenaForAllocation()); } #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING  // @@protoc_insertion_point(field_set_allocated:main.TestMessage.TeChild.ch_name)  } // string ch_sex = 2;  inline void TestMessage_TeChild::clear_ch_sex() { _impl_.ch_sex_.ClearToEmpty(); } inline const std::string\u0026amp; TestMessage_TeChild::ch_sex() const { // @@protoc_insertion_point(field_get:main.TestMessage.TeChild.ch_sex)  return _internal_ch_sex(); } template \u0026lt;typename ArgT0, typename... ArgT\u0026gt; inline PROTOBUF_ALWAYS_INLINE void TestMessage_TeChild::set_ch_sex(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args) { _impl_.ch_sex_.Set(static_cast\u0026lt;ArgT0 \u0026amp;\u0026amp;\u0026gt;(arg0), args..., GetArenaForAllocation()); // @@protoc_insertion_point(field_set:main.TestMessage.TeChild.ch_sex)  } inline std::string* TestMessage_TeChild::mutable_ch_sex() { std::string* _s = _internal_mutable_ch_sex(); // @@protoc_insertion_point(field_mutable:main.TestMessage.TeChild.ch_sex)  return _s; } inline const std::string\u0026amp; TestMessage_TeChild::_internal_ch_sex() const { return _impl_.ch_sex_.Get(); } inline void TestMessage_TeChild::_internal_set_ch_sex(const std::string\u0026amp; value) { _impl_.ch_sex_.Set(value, GetArenaForAllocation()); } inline std::string* TestMessage_TeChild::_internal_mutable_ch_sex() { return _impl_.ch_sex_.Mutable(GetArenaForAllocation()); } inline std::string* TestMessage_TeChild::release_ch_sex() { // @@protoc_insertion_point(field_release:main.TestMessage.TeChild.ch_sex)  return _impl_.ch_sex_.Release(); } inline void TestMessage_TeChild::set_allocated_ch_sex(std::string* ch_sex) { if (ch_sex != nullptr) { } else { } _impl_.ch_sex_.SetAllocated(ch_sex, GetArenaForAllocation()); #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING  if (_impl_.ch_sex_.IsDefault()) { _impl_.ch_sex_.Set(\u0026#34;\u0026#34;, GetArenaForAllocation()); } #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING  // @@protoc_insertion_point(field_set_allocated:main.TestMessage.TeChild.ch_sex)  } // -------------------------------------------------------------------  // -------------------------------------------------------------------  // TestMessage  // string te_name = 1;  inline void TestMessage::clear_te_name() { _impl_.te_name_.ClearToEmpty(); } inline const std::string\u0026amp; TestMessage::te_name() const { // @@protoc_insertion_point(field_get:main.TestMessage.te_name)  return _internal_te_name(); } template \u0026lt;typename ArgT0, typename... ArgT\u0026gt; inline PROTOBUF_ALWAYS_INLINE void TestMessage::set_te_name(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args) { _impl_.te_name_.Set(static_cast\u0026lt;ArgT0 \u0026amp;\u0026amp;\u0026gt;(arg0), args..., GetArenaForAllocation()); // @@protoc_insertion_point(field_set:main.TestMessage.te_name)  } inline std::string* TestMessage::mutable_te_name() { std::string* _s = _internal_mutable_te_name(); // @@protoc_insertion_point(field_mutable:main.TestMessage.te_name)  return _s; } inline const std::string\u0026amp; TestMessage::_internal_te_name() const { return _impl_.te_name_.Get(); } inline void TestMessage::_internal_set_te_name(const std::string\u0026amp; value) { _impl_.te_name_.Set(value, GetArenaForAllocation()); } inline std::string* TestMessage::_internal_mutable_te_name() { return _impl_.te_name_.Mutable(GetArenaForAllocation()); } inline std::string* TestMessage::release_te_name() { // @@protoc_insertion_point(field_release:main.TestMessage.te_name)  return _impl_.te_name_.Release(); } inline void TestMessage::set_allocated_te_name(std::string* te_name) { if (te_name != nullptr) { } else { } _impl_.te_name_.SetAllocated(te_name, GetArenaForAllocation()); #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING  if (_impl_.te_name_.IsDefault()) { _impl_.te_name_.Set(\u0026#34;\u0026#34;, GetArenaForAllocation()); } #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING  // @@protoc_insertion_point(field_set_allocated:main.TestMessage.te_name)  } // int32 te_age = 2;  inline void TestMessage::clear_te_age() { _impl_.te_age_ = 0; } inline int32_t TestMessage::_internal_te_age() const { return _impl_.te_age_; } inline int32_t TestMessage::te_age() const { // @@protoc_insertion_point(field_get:main.TestMessage.te_age)  return _internal_te_age(); } inline void TestMessage::_internal_set_te_age(int32_t value) { _impl_.te_age_ = value; } inline void TestMessage::set_te_age(int32_t value) { _internal_set_te_age(value); // @@protoc_insertion_point(field_set:main.TestMessage.te_age)  } // int32 te_count = 3;  inline void TestMessage::clear_te_count() { _impl_.te_count_ = 0; } inline int32_t TestMessage::_internal_te_count() const { return _impl_.te_count_; } inline int32_t TestMessage::te_count() const { // @@protoc_insertion_point(field_get:main.TestMessage.te_count)  return _internal_te_count(); } inline void TestMessage::_internal_set_te_count(int32_t value) { _impl_.te_count_ = value; } inline void TestMessage::set_te_count(int32_t value) { _internal_set_te_count(value); // @@protoc_insertion_point(field_set:main.TestMessage.te_count)  } // double te_money = 4;  inline void TestMessage::clear_te_money() { _impl_.te_money_ = 0; } inline double TestMessage::_internal_te_money() const { return _impl_.te_money_; } inline double TestMessage::te_money() const { // @@protoc_insertion_point(field_get:main.TestMessage.te_money)  return _internal_te_money(); } inline void TestMessage::_internal_set_te_money(double value) { _impl_.te_money_ = value; } inline void TestMessage::set_te_money(double value) { _internal_set_te_money(value); // @@protoc_insertion_point(field_set:main.TestMessage.te_money)  } // float te_score = 5;  inline void TestMessage::clear_te_score() { _impl_.te_score_ = 0; } inline float TestMessage::_internal_te_score() const { return _impl_.te_score_; } inline float TestMessage::te_score() const { // @@protoc_insertion_point(field_get:main.TestMessage.te_score)  return _internal_te_score(); } inline void TestMessage::_internal_set_te_score(float value) { _impl_.te_score_ = value; } inline void TestMessage::set_te_score(float value) { _internal_set_te_score(value); // @@protoc_insertion_point(field_set:main.TestMessage.te_score)  } // bool te_fat = 6;  inline void TestMessage::clear_te_fat() { _impl_.te_fat_ = false; } inline bool TestMessage::_internal_te_fat() const { return _impl_.te_fat_; } inline bool TestMessage::te_fat() const { // @@protoc_insertion_point(field_get:main.TestMessage.te_fat)  return _internal_te_fat(); } inline void TestMessage::_internal_set_te_fat(bool value) { _impl_.te_fat_ = value; } inline void TestMessage::set_te_fat(bool value) { _internal_set_te_fat(value); // @@protoc_insertion_point(field_set:main.TestMessage.te_fat)  } // bytes te_char = 7;  inline void TestMessage::clear_te_char() { _impl_.te_char_.ClearToEmpty(); } inline const std::string\u0026amp; TestMessage::te_char() const { // @@protoc_insertion_point(field_get:main.TestMessage.te_char)  return _internal_te_char(); } template \u0026lt;typename ArgT0, typename... ArgT\u0026gt; inline PROTOBUF_ALWAYS_INLINE void TestMessage::set_te_char(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args) { _impl_.te_char_.SetBytes(static_cast\u0026lt;ArgT0 \u0026amp;\u0026amp;\u0026gt;(arg0), args..., GetArenaForAllocation()); // @@protoc_insertion_point(field_set:main.TestMessage.te_char)  } inline std::string* TestMessage::mutable_te_char() { std::string* _s = _internal_mutable_te_char(); // @@protoc_insertion_point(field_mutable:main.TestMessage.te_char)  return _s; } inline const std::string\u0026amp; TestMessage::_internal_te_char() const { return _impl_.te_char_.Get(); } inline void TestMessage::_internal_set_te_char(const std::string\u0026amp; value) { _impl_.te_char_.Set(value, GetArenaForAllocation()); } inline std::string* TestMessage::_internal_mutable_te_char() { return _impl_.te_char_.Mutable(GetArenaForAllocation()); } inline std::string* TestMessage::release_te_char() { // @@protoc_insertion_point(field_release:main.TestMessage.te_char)  return _impl_.te_char_.Release(); } inline void TestMessage::set_allocated_te_char(std::string* te_char) { if (te_char != nullptr) { } else { } _impl_.te_char_.SetAllocated(te_char, GetArenaForAllocation()); #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING  if (_impl_.te_char_.IsDefault()) { _impl_.te_char_.Set(\u0026#34;\u0026#34;, GetArenaForAllocation()); } #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING  // @@protoc_insertion_point(field_set_allocated:main.TestMessage.te_char)  } // .main.TestMessage.TeChild childs = 9;  inline bool TestMessage::_internal_has_childs() const { return this != internal_default_instance() \u0026amp;\u0026amp; _impl_.childs_ != nullptr; } inline bool TestMessage::has_childs() const { return _internal_has_childs(); } inline void TestMessage::clear_childs() { if (GetArenaForAllocation() == nullptr \u0026amp;\u0026amp; _impl_.childs_ != nullptr) { delete _impl_.childs_; } _impl_.childs_ = nullptr; } inline const ::main::TestMessage_TeChild\u0026amp; TestMessage::_internal_childs() const { const ::main::TestMessage_TeChild* p = _impl_.childs_; return p != nullptr ? *p : reinterpret_cast\u0026lt;const ::main::TestMessage_TeChild\u0026amp;\u0026gt;( ::main::_TestMessage_TeChild_default_instance_); } inline const ::main::TestMessage_TeChild\u0026amp; TestMessage::childs() const { // @@protoc_insertion_point(field_get:main.TestMessage.childs)  return _internal_childs(); } inline void TestMessage::unsafe_arena_set_allocated_childs( ::main::TestMessage_TeChild* childs) { if (GetArenaForAllocation() == nullptr) { delete reinterpret_cast\u0026lt;::PROTOBUF_NAMESPACE_ID::MessageLite*\u0026gt;(_impl_.childs_); } _impl_.childs_ = childs; if (childs) { } else { } // @@protoc_insertion_point(field_unsafe_arena_set_allocated:main.TestMessage.childs)  } inline ::main::TestMessage_TeChild* TestMessage::release_childs() { ::main::TestMessage_TeChild* temp = _impl_.childs_; _impl_.childs_ = nullptr; #ifdef PROTOBUF_FORCE_COPY_IN_RELEASE  auto* old = reinterpret_cast\u0026lt;::PROTOBUF_NAMESPACE_ID::MessageLite*\u0026gt;(temp); temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp); if (GetArenaForAllocation() == nullptr) { delete old; } #else // PROTOBUF_FORCE_COPY_IN_RELEASE  if (GetArenaForAllocation() != nullptr) { temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp); } #endif // !PROTOBUF_FORCE_COPY_IN_RELEASE  return temp; } inline ::main::TestMessage_TeChild* TestMessage::unsafe_arena_release_childs() { // @@protoc_insertion_point(field_release:main.TestMessage.childs)  ::main::TestMessage_TeChild* temp = _impl_.childs_; _impl_.childs_ = nullptr; return temp; } inline ::main::TestMessage_TeChild* TestMessage::_internal_mutable_childs() { if (_impl_.childs_ == nullptr) { auto* p = CreateMaybeMessage\u0026lt;::main::TestMessage_TeChild\u0026gt;(GetArenaForAllocation()); _impl_.childs_ = p; } return _impl_.childs_; } inline ::main::TestMessage_TeChild* TestMessage::mutable_childs() { ::main::TestMessage_TeChild* _msg = _internal_mutable_childs(); // @@protoc_insertion_point(field_mutable:main.TestMessage.childs)  return _msg; } inline void TestMessage::set_allocated_childs(::main::TestMessage_TeChild* childs) { ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation(); if (message_arena == nullptr) { delete _impl_.childs_; } if (childs) { ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena = ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(childs); if (message_arena != submessage_arena) { childs = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage( message_arena, childs, submessage_arena); } } else { } _impl_.childs_ = childs; // @@protoc_insertion_point(field_set_allocated:main.TestMessage.childs)  } // map\u0026lt;string, int32\u0026gt; te_map = 10;  inline int TestMessage::_internal_te_map_size() const { return _impl_.te_map_.size(); } inline int TestMessage::te_map_size() const { return _internal_te_map_size(); } inline void TestMessage::clear_te_map() { _impl_.te_map_.Clear(); } inline const ::PROTOBUF_NAMESPACE_ID::Map\u0026lt; std::string, int32_t \u0026gt;\u0026amp; TestMessage::_internal_te_map() const { return _impl_.te_map_.GetMap(); } inline const ::PROTOBUF_NAMESPACE_ID::Map\u0026lt; std::string, int32_t \u0026gt;\u0026amp; TestMessage::te_map() const { // @@protoc_insertion_point(field_map:main.TestMessage.te_map)  return _internal_te_map(); } inline ::PROTOBUF_NAMESPACE_ID::Map\u0026lt; std::string, int32_t \u0026gt;* TestMessage::_internal_mutable_te_map() { return _impl_.te_map_.MutableMap(); } inline ::PROTOBUF_NAMESPACE_ID::Map\u0026lt; std::string, int32_t \u0026gt;* TestMessage::mutable_te_map() { // @@protoc_insertion_point(field_mutable_map:main.TestMessage.te_map)  return _internal_mutable_te_map(); } #ifdef __GNUC__  #pragma GCC diagnostic pop  #endif // __GNUC__  // -------------------------------------------------------------------  // -------------------------------------------------------------------  // @@protoc_insertion_point(namespace_scope)  } // namespace main  PROTOBUF_NAMESPACE_OPEN template \u0026lt;\u0026gt; struct is_proto_enum\u0026lt; ::main::TestMessage_Status\u0026gt; : ::std::true_type {}; template \u0026lt;\u0026gt; inline const EnumDescriptor* GetEnumDescriptor\u0026lt; ::main::TestMessage_Status\u0026gt;() { return ::main::TestMessage_Status_descriptor(); } PROTOBUF_NAMESPACE_CLOSE // @@protoc_insertion_point(global_scope)  #include \u0026lt;google/protobuf/port_undef.inc\u0026gt; #endif // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_proto3_2eproto   生成python 文件内容\n# -*- coding: utf-8 -*- # Generated by the protocol buffer compiler. DO NOT EDIT! # source: proto3.proto \u0026#34;\u0026#34;\u0026#34;Generated protocol buffer code.\u0026#34;\u0026#34;\u0026#34; from google.protobuf.internal import builder as _builder from google.protobuf import descriptor as _descriptor from google.protobuf import descriptor_pool as _descriptor_pool from google.protobuf import symbol_database as _symbol_database # @@protoc_insertion_point(imports) _sym_db = _symbol_database.Default() DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b\u0026#39;\\n\\x0cproto3.proto\\x12\\x04main\\\u0026#34;\\xd4\\x02\\n\\x0bTestMessage\\x12\\x0f\\n\\x07te_name\\x18\\x01\\x01(\\t\\x12\\x0e\\n\\x06te_age\\x18\\x02\\x01(\\x05\\x12\\x10\\n\\x08te_count\\x18\\x03\\x01(\\x05\\x12\\x10\\n\\x08te_money\\x18\\x04\\x01(\\x01\\x12\\x10\\n\\x08te_score\\x18\\x05\\x01(\\x02\\x12\\x0e\\n\\x06te_fat\\x18\\x06\\x01(\\x08\\x12\\x0f\\n\\x07te_char\\x18\\x07\\x01(\\x0c\\x12)\\n\\x06\\x63hilds\\x18\\t\\x01(\\x0b\\x32\\x19.main.TestMessage.TeChild\\x12,\\n\\x06te_map\\x18\\n\\x03(\\x0b\\x32\\x1c.main.TestMessage.TeMapEntry\\x1a*\\n\\x07TeChild\\x12\\x0f\\n\\x07\\x63h_name\\x18\\x01\\x01(\\t\\x12\\x0e\\n\\x06\\x63h_sex\\x18\\x02\\x01(\\t\\x1a,\\n\\nTeMapEntry\\x12\\x0b\\n\\x03key\\x18\\x01\\x01(\\t\\x12\\r\\n\\x05value\\x18\\x02\\x01(\\x05:\\x02\\x38\\x01\\\u0026#34;\\x1a\\n\\x06Status\\x12\\x06\\n\\x02OK\\x10\\x00\\x12\\x08\\n\\x04\\x46\\x41IL\\x10\\x01\\x62\\x06proto3\u0026#39;) _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals()) _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, \u0026#39;proto3_pb2\u0026#39;, globals()) if _descriptor._USE_C_DESCRIPTORS == False: DESCRIPTOR._options = None _TESTMESSAGE_TEMAPENTRY._options = None _TESTMESSAGE_TEMAPENTRY._serialized_options = b\u0026#39;8\\001\u0026#39; _TESTMESSAGE._serialized_start=23 _TESTMESSAGE._serialized_end=363 _TESTMESSAGE_TECHILD._serialized_start=247 _TESTMESSAGE_TECHILD._serialized_end=289 _TESTMESSAGE_TEMAPENTRY._serialized_start=291 _TESTMESSAGE_TEMAPENTRY._serialized_end=335 _TESTMESSAGE_STATUS._serialized_start=337 _TESTMESSAGE_STATUS._serialized_end=363 # @@protoc_insertion_point(module_scope)   service 测试   proto 文件内容\nsyntax = \u0026#34;proto3\u0026#34;; // 语法声明  package main; // 包声明  service TestService{ // 测试方法  rpc TestServer(Request) returns (Response){} } // request 请求结构体  message Request{ string te_name = 1; } // response 响应结构体  message Response{ string message = 1; }  生成go 文件内容\n// Code generated by protoc-gen-go. DO NOT EDIT.  // source: service.proto  package main import ( fmt \u0026#34;fmt\u0026#34; proto \u0026#34;github.com/golang/protobuf/proto\u0026#34; math \u0026#34;math\u0026#34; ) // Reference imports to suppress errors if they are not otherwise used.  var _ = proto.Marshal var _ = fmt.Errorf var _ = math.Inf // This is a compile-time assertion to ensure that this generated file  // is compatible with the proto package it is being compiled against.  // A compilation error at this line likely means your copy of the  // proto package needs to be updated.  const _ = proto.ProtoPackageIsVersion3 // please upgrade the proto package  // request 请求结构体  type Request struct { TeName string `protobuf:\u0026#34;bytes,1,opt,name=te_name,json=teName,proto3\u0026#34; json:\u0026#34;te_name,omitempty\u0026#34;` XXX_NoUnkeyedLiteral struct{} `json:\u0026#34;-\u0026#34;` XXX_unrecognized []byte `json:\u0026#34;-\u0026#34;` XXX_sizecache int32 `json:\u0026#34;-\u0026#34;` } func (m *Request) Reset() { *m = Request{} } func (m *Request) String() string { return proto.CompactTextString(m) } func (*Request) ProtoMessage() {} func (*Request) Descriptor() ([]byte, []int) { return fileDescriptor_a0b84a42fa06f626, []int{0} } func (m *Request) XXX_Unmarshal(b []byte) error { return xxx_messageInfo_Request.Unmarshal(m, b) } func (m *Request) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) { return xxx_messageInfo_Request.Marshal(b, m, deterministic) } func (m *Request) XXX_Merge(src proto.Message) { xxx_messageInfo_Request.Merge(m, src) } func (m *Request) XXX_Size() int { return xxx_messageInfo_Request.Size(m) } func (m *Request) XXX_DiscardUnknown() { xxx_messageInfo_Request.DiscardUnknown(m) } var xxx_messageInfo_Request proto.InternalMessageInfo func (m *Request) GetTeName() string { if m != nil { return m.TeName } return \u0026#34;\u0026#34; } // response 响应结构体  type Response struct { Message string `protobuf:\u0026#34;bytes,1,opt,name=message,proto3\u0026#34; json:\u0026#34;message,omitempty\u0026#34;` XXX_NoUnkeyedLiteral struct{} `json:\u0026#34;-\u0026#34;` XXX_unrecognized []byte `json:\u0026#34;-\u0026#34;` XXX_sizecache int32 `json:\u0026#34;-\u0026#34;` } func (m *Response) Reset() { *m = Response{} } func (m *Response) String() string { return proto.CompactTextString(m) } func (*Response) ProtoMessage() {} func (*Response) Descriptor() ([]byte, []int) { return fileDescriptor_a0b84a42fa06f626, []int{1} } func (m *Response) XXX_Unmarshal(b []byte) error { return xxx_messageInfo_Response.Unmarshal(m, b) } func (m *Response) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) { return xxx_messageInfo_Response.Marshal(b, m, deterministic) } func (m *Response) XXX_Merge(src proto.Message) { xxx_messageInfo_Response.Merge(m, src) } func (m *Response) XXX_Size() int { return xxx_messageInfo_Response.Size(m) } func (m *Response) XXX_DiscardUnknown() { xxx_messageInfo_Response.DiscardUnknown(m) } var xxx_messageInfo_Response proto.InternalMessageInfo func (m *Response) GetMessage() string { if m != nil { return m.Message } return \u0026#34;\u0026#34; } func init() { proto.RegisterType((*Request)(nil), \u0026#34;main.Request\u0026#34;) proto.RegisterType((*Response)(nil), \u0026#34;main.Response\u0026#34;) } func init() { proto.RegisterFile(\u0026#34;service.proto\u0026#34;, fileDescriptor_a0b84a42fa06f626) } var fileDescriptor_a0b84a42fa06f626 = []byte{ // 147 bytes of a gzipped FileDescriptorProto  0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xe2, 0xe2, 0x2d, 0x4e, 0x2d, 0x2a, 0xcb, 0x4c, 0x4e, 0xd5, 0x2b, 0x28, 0xca, 0x2f, 0xc9, 0x17, 0x62, 0xc9, 0x4d, 0xcc, 0xcc, 0x53, 0x52, 0xe2, 0x62, 0x0f, 0x4a, 0x2d, 0x2c, 0x4d, 0x2d, 0x2e, 0x11, 0x12, 0xe7, 0x62, 0x2f, 0x49, 0x8d, 0xcf, 0x4b, 0xcc, 0x4d, 0x95, 0x60, 0x54, 0x60, 0xd4, 0xe0, 0x0c, 0x62, 0x2b, 0x49, 0xf5, 0x4b, 0xcc, 0x4d, 0x55, 0x52, 0xe1, 0xe2, 0x08, 0x4a, 0x2d, 0x2e, 0xc8, 0xcf, 0x2b, 0x4e, 0x15, 0x92, 0xe0, 0x62, 0xcf, 0x4d, 0x2d, 0x2e, 0x4e, 0x4c, 0x87, 0x29, 0x82, 0x71, 0x8d, 0x6c, 0xb8, 0xb8, 0x43, 0x52, 0x8b, 0x4b, 0x82, 0x21, 0x96, 0x08, 0xe9, 0x72, 0x71, 0xc1, 0xb8, 0xa9, 0x45, 0x42, 0xbc, 0x7a, 0x20, 0xdb, 0xf4, 0xa0, 0x56, 0x49, 0xf1, 0xc1, 0xb8, 0x10, 0x53, 0x95, 0x18, 0x92, 0xd8, 0xc0, 0x8e, 0x32, 0x06, 0x04, 0x00, 0x00, 0xff, 0xff, 0xc6, 0x10, 0x76, 0x3d, 0xa5, 0x00, 0x00, 0x00, }   生成C++ 文件内容\n// Generated by the protocol buffer compiler. DO NOT EDIT!  // source: service.proto  #ifndef GOOGLE_PROTOBUF_INCLUDED_service_2eproto  #define GOOGLE_PROTOBUF_INCLUDED_service_2eproto  #include \u0026lt;limits\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;google/protobuf/port_def.inc\u0026gt; #if PROTOBUF_VERSION \u0026lt; 3021000  #error This file was generated by a newer version of protoc which is  #error incompatible with your Protocol Buffer headers. Please update  #error your headers.  #endif  #if 3021005 \u0026lt; PROTOBUF_MIN_PROTOC_VERSION  #error This file was generated by an older version of protoc which is  #error incompatible with your Protocol Buffer headers. Please  #error regenerate this file with a newer version of protoc.  #endif  #include \u0026lt;google/protobuf/port_undef.inc\u0026gt; #include \u0026lt;google/protobuf/io/coded_stream.h\u0026gt; #include \u0026lt;google/protobuf/arena.h\u0026gt; #include \u0026lt;google/protobuf/arenastring.h\u0026gt; #include \u0026lt;google/protobuf/generated_message_util.h\u0026gt; #include \u0026lt;google/protobuf/metadata_lite.h\u0026gt; #include \u0026lt;google/protobuf/generated_message_reflection.h\u0026gt; #include \u0026lt;google/protobuf/message.h\u0026gt; #include \u0026lt;google/protobuf/repeated_field.h\u0026gt; // IWYU pragma: export #include \u0026lt;google/protobuf/extension_set.h\u0026gt; // IWYU pragma: export #include \u0026lt;google/protobuf/unknown_field_set.h\u0026gt; // @@protoc_insertion_point(includes)  #include \u0026lt;google/protobuf/port_def.inc\u0026gt; #define PROTOBUF_INTERNAL_EXPORT_service_2eproto  PROTOBUF_NAMESPACE_OPEN namespace internal { class AnyMetadata; } // namespace internal  PROTOBUF_NAMESPACE_CLOSE // Internal implementation detail -- do not use these members.  struct TableStruct_service_2eproto { static const uint32_t offsets[]; }; extern const ::PROTOBUF_NAMESPACE_ID::internal::DescriptorTable descriptor_table_service_2eproto; namespace main { class Request; struct RequestDefaultTypeInternal; extern RequestDefaultTypeInternal _Request_default_instance_; class Response; struct ResponseDefaultTypeInternal; extern ResponseDefaultTypeInternal _Response_default_instance_; } // namespace main  PROTOBUF_NAMESPACE_OPEN template\u0026lt;\u0026gt; ::main::Request* Arena::CreateMaybeMessage\u0026lt;::main::Request\u0026gt;(Arena*); template\u0026lt;\u0026gt; ::main::Response* Arena::CreateMaybeMessage\u0026lt;::main::Response\u0026gt;(Arena*); PROTOBUF_NAMESPACE_CLOSE namespace main { // ===================================================================  class Request final : public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:main.Request) */ { public: inline Request() : Request(nullptr) {} ~Request() override; explicit PROTOBUF_CONSTEXPR Request(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized); Request(const Request\u0026amp; from); Request(Request\u0026amp;\u0026amp; from) noexcept : Request() { *this = ::std::move(from); } inline Request\u0026amp; operator=(const Request\u0026amp; from) { CopyFrom(from); return *this; } inline Request\u0026amp; operator=(Request\u0026amp;\u0026amp; from) noexcept { if (this == \u0026amp;from) return *this; if (GetOwningArena() == from.GetOwningArena() #ifdef PROTOBUF_FORCE_COPY_IN_MOVE  \u0026amp;\u0026amp; GetOwningArena() != nullptr #endif // !PROTOBUF_FORCE_COPY_IN_MOVE  ) { InternalSwap(\u0026amp;from); } else { CopyFrom(from); } return *this; } static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() { return GetDescriptor(); } static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() { return default_instance().GetMetadata().descriptor; } static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() { return default_instance().GetMetadata().reflection; } static const Request\u0026amp; default_instance() { return *internal_default_instance(); } static inline const Request* internal_default_instance() { return reinterpret_cast\u0026lt;const Request*\u0026gt;( \u0026amp;_Request_default_instance_); } static constexpr int kIndexInFileMessages = 0; friend void swap(Request\u0026amp; a, Request\u0026amp; b) { a.Swap(\u0026amp;b); } inline void Swap(Request* other) { if (other == this) return; #ifdef PROTOBUF_FORCE_COPY_IN_SWAP  if (GetOwningArena() != nullptr \u0026amp;\u0026amp; GetOwningArena() == other-\u0026gt;GetOwningArena()) { #else // PROTOBUF_FORCE_COPY_IN_SWAP  if (GetOwningArena() == other-\u0026gt;GetOwningArena()) { #endif // !PROTOBUF_FORCE_COPY_IN_SWAP  InternalSwap(other); } else { ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other); } } void UnsafeArenaSwap(Request* other) { if (other == this) return; GOOGLE_DCHECK(GetOwningArena() == other-\u0026gt;GetOwningArena()); InternalSwap(other); } // implements Message ----------------------------------------------  Request* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final { return CreateMaybeMessage\u0026lt;Request\u0026gt;(arena); } using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom; void CopyFrom(const Request\u0026amp; from); using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom; void MergeFrom( const Request\u0026amp; from) { Request::MergeImpl(*this, from); } private: static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message\u0026amp; to_msg, const ::PROTOBUF_NAMESPACE_ID::Message\u0026amp; from_msg); public: PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final; bool IsInitialized() const final; size_t ByteSizeLong() const final; const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final; uint8_t* _InternalSerialize( uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final; int GetCachedSize() const final { return _impl_._cached_size_.Get(); } private: void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned); void SharedDtor(); void SetCachedSize(int size) const final; void InternalSwap(Request* other); private: friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata; static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() { return \u0026#34;main.Request\u0026#34;; } protected: explicit Request(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned = false); public: static const ClassData _class_data_; const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final; ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final; // nested types ----------------------------------------------------  // accessors -------------------------------------------------------  enum : int { kTeNameFieldNumber = 1, }; // string te_name = 1;  void clear_te_name(); const std::string\u0026amp; te_name() const; template \u0026lt;typename ArgT0 = const std::string\u0026amp;, typename... ArgT\u0026gt; void set_te_name(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args); std::string* mutable_te_name(); PROTOBUF_NODISCARD std::string* release_te_name(); void set_allocated_te_name(std::string* te_name); private: const std::string\u0026amp; _internal_te_name() const; inline PROTOBUF_ALWAYS_INLINE void _internal_set_te_name(const std::string\u0026amp; value); std::string* _internal_mutable_te_name(); public: // @@protoc_insertion_point(class_scope:main.Request)  private: class _Internal; template \u0026lt;typename T\u0026gt; friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper; typedef void InternalArenaConstructable_; typedef void DestructorSkippable_; struct Impl_ { ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr te_name_; mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_; }; union { Impl_ _impl_; }; friend struct ::TableStruct_service_2eproto; }; // -------------------------------------------------------------------  class Response final : public ::PROTOBUF_NAMESPACE_ID::Message /* @@protoc_insertion_point(class_definition:main.Response) */ { public: inline Response() : Response(nullptr) {} ~Response() override; explicit PROTOBUF_CONSTEXPR Response(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized); Response(const Response\u0026amp; from); Response(Response\u0026amp;\u0026amp; from) noexcept : Response() { *this = ::std::move(from); } inline Response\u0026amp; operator=(const Response\u0026amp; from) { CopyFrom(from); return *this; } inline Response\u0026amp; operator=(Response\u0026amp;\u0026amp; from) noexcept { if (this == \u0026amp;from) return *this; if (GetOwningArena() == from.GetOwningArena() #ifdef PROTOBUF_FORCE_COPY_IN_MOVE  \u0026amp;\u0026amp; GetOwningArena() != nullptr #endif // !PROTOBUF_FORCE_COPY_IN_MOVE  ) { InternalSwap(\u0026amp;from); } else { CopyFrom(from); } return *this; } static const ::PROTOBUF_NAMESPACE_ID::Descriptor* descriptor() { return GetDescriptor(); } static const ::PROTOBUF_NAMESPACE_ID::Descriptor* GetDescriptor() { return default_instance().GetMetadata().descriptor; } static const ::PROTOBUF_NAMESPACE_ID::Reflection* GetReflection() { return default_instance().GetMetadata().reflection; } static const Response\u0026amp; default_instance() { return *internal_default_instance(); } static inline const Response* internal_default_instance() { return reinterpret_cast\u0026lt;const Response*\u0026gt;( \u0026amp;_Response_default_instance_); } static constexpr int kIndexInFileMessages = 1; friend void swap(Response\u0026amp; a, Response\u0026amp; b) { a.Swap(\u0026amp;b); } inline void Swap(Response* other) { if (other == this) return; #ifdef PROTOBUF_FORCE_COPY_IN_SWAP  if (GetOwningArena() != nullptr \u0026amp;\u0026amp; GetOwningArena() == other-\u0026gt;GetOwningArena()) { #else // PROTOBUF_FORCE_COPY_IN_SWAP  if (GetOwningArena() == other-\u0026gt;GetOwningArena()) { #endif // !PROTOBUF_FORCE_COPY_IN_SWAP  InternalSwap(other); } else { ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other); } } void UnsafeArenaSwap(Response* other) { if (other == this) return; GOOGLE_DCHECK(GetOwningArena() == other-\u0026gt;GetOwningArena()); InternalSwap(other); } // implements Message ----------------------------------------------  Response* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final { return CreateMaybeMessage\u0026lt;Response\u0026gt;(arena); } using ::PROTOBUF_NAMESPACE_ID::Message::CopyFrom; void CopyFrom(const Response\u0026amp; from); using ::PROTOBUF_NAMESPACE_ID::Message::MergeFrom; void MergeFrom( const Response\u0026amp; from) { Response::MergeImpl(*this, from); } private: static void MergeImpl(::PROTOBUF_NAMESPACE_ID::Message\u0026amp; to_msg, const ::PROTOBUF_NAMESPACE_ID::Message\u0026amp; from_msg); public: PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final; bool IsInitialized() const final; size_t ByteSizeLong() const final; const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final; uint8_t* _InternalSerialize( uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final; int GetCachedSize() const final { return _impl_._cached_size_.Get(); } private: void SharedCtor(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned); void SharedDtor(); void SetCachedSize(int size) const final; void InternalSwap(Response* other); private: friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata; static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() { return \u0026#34;main.Response\u0026#34;; } protected: explicit Response(::PROTOBUF_NAMESPACE_ID::Arena* arena, bool is_message_owned = false); public: static const ClassData _class_data_; const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*GetClassData() const final; ::PROTOBUF_NAMESPACE_ID::Metadata GetMetadata() const final; // nested types ----------------------------------------------------  // accessors -------------------------------------------------------  enum : int { kMessageFieldNumber = 1, }; // string message = 1;  void clear_message(); const std::string\u0026amp; message() const; template \u0026lt;typename ArgT0 = const std::string\u0026amp;, typename... ArgT\u0026gt; void set_message(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args); std::string* mutable_message(); PROTOBUF_NODISCARD std::string* release_message(); void set_allocated_message(std::string* message); private: const std::string\u0026amp; _internal_message() const; inline PROTOBUF_ALWAYS_INLINE void _internal_set_message(const std::string\u0026amp; value); std::string* _internal_mutable_message(); public: // @@protoc_insertion_point(class_scope:main.Response)  private: class _Internal; template \u0026lt;typename T\u0026gt; friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper; typedef void InternalArenaConstructable_; typedef void DestructorSkippable_; struct Impl_ { ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr message_; mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_; }; union { Impl_ _impl_; }; friend struct ::TableStruct_service_2eproto; }; // ===================================================================  // ===================================================================  #ifdef __GNUC__  #pragma GCC diagnostic push  #pragma GCC diagnostic ignored \u0026#34;-Wstrict-aliasing\u0026#34;  #endif // __GNUC__  // Request  // string te_name = 1;  inline void Request::clear_te_name() { _impl_.te_name_.ClearToEmpty(); } inline const std::string\u0026amp; Request::te_name() const { // @@protoc_insertion_point(field_get:main.Request.te_name)  return _internal_te_name(); } template \u0026lt;typename ArgT0, typename... ArgT\u0026gt; inline PROTOBUF_ALWAYS_INLINE void Request::set_te_name(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args) { _impl_.te_name_.Set(static_cast\u0026lt;ArgT0 \u0026amp;\u0026amp;\u0026gt;(arg0), args..., GetArenaForAllocation()); // @@protoc_insertion_point(field_set:main.Request.te_name)  } inline std::string* Request::mutable_te_name() { std::string* _s = _internal_mutable_te_name(); // @@protoc_insertion_point(field_mutable:main.Request.te_name)  return _s; } inline const std::string\u0026amp; Request::_internal_te_name() const { return _impl_.te_name_.Get(); } inline void Request::_internal_set_te_name(const std::string\u0026amp; value) { _impl_.te_name_.Set(value, GetArenaForAllocation()); } inline std::string* Request::_internal_mutable_te_name() { return _impl_.te_name_.Mutable(GetArenaForAllocation()); } inline std::string* Request::release_te_name() { // @@protoc_insertion_point(field_release:main.Request.te_name)  return _impl_.te_name_.Release(); } inline void Request::set_allocated_te_name(std::string* te_name) { if (te_name != nullptr) { } else { } _impl_.te_name_.SetAllocated(te_name, GetArenaForAllocation()); #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING  if (_impl_.te_name_.IsDefault()) { _impl_.te_name_.Set(\u0026#34;\u0026#34;, GetArenaForAllocation()); } #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING  // @@protoc_insertion_point(field_set_allocated:main.Request.te_name)  } // -------------------------------------------------------------------  // Response  // string message = 1;  inline void Response::clear_message() { _impl_.message_.ClearToEmpty(); } inline const std::string\u0026amp; Response::message() const { // @@protoc_insertion_point(field_get:main.Response.message)  return _internal_message(); } template \u0026lt;typename ArgT0, typename... ArgT\u0026gt; inline PROTOBUF_ALWAYS_INLINE void Response::set_message(ArgT0\u0026amp;\u0026amp; arg0, ArgT... args) { _impl_.message_.Set(static_cast\u0026lt;ArgT0 \u0026amp;\u0026amp;\u0026gt;(arg0), args..., GetArenaForAllocation()); // @@protoc_insertion_point(field_set:main.Response.message)  } inline std::string* Response::mutable_message() { std::string* _s = _internal_mutable_message(); // @@protoc_insertion_point(field_mutable:main.Response.message)  return _s; } inline const std::string\u0026amp; Response::_internal_message() const { return _impl_.message_.Get(); } inline void Response::_internal_set_message(const std::string\u0026amp; value) { _impl_.message_.Set(value, GetArenaForAllocation()); } inline std::string* Response::_internal_mutable_message() { return _impl_.message_.Mutable(GetArenaForAllocation()); } inline std::string* Response::release_message() { // @@protoc_insertion_point(field_release:main.Response.message)  return _impl_.message_.Release(); } inline void Response::set_allocated_message(std::string* message) { if (message != nullptr) { } else { } _impl_.message_.SetAllocated(message, GetArenaForAllocation()); #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING  if (_impl_.message_.IsDefault()) { _impl_.message_.Set(\u0026#34;\u0026#34;, GetArenaForAllocation()); } #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING  // @@protoc_insertion_point(field_set_allocated:main.Response.message)  } #ifdef __GNUC__  #pragma GCC diagnostic pop  #endif // __GNUC__  // -------------------------------------------------------------------  // @@protoc_insertion_point(namespace_scope)  } // namespace main  // @@protoc_insertion_point(global_scope)  #include \u0026lt;google/protobuf/port_undef.inc\u0026gt; #endif // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_service_2eproto    生成python 文件内容\n# -*- coding: utf-8 -*- # Generated by the protocol buffer compiler. DO NOT EDIT! # source: service.proto \u0026#34;\u0026#34;\u0026#34;Generated protocol buffer code.\u0026#34;\u0026#34;\u0026#34; from google.protobuf.internal import builder as _builder from google.protobuf import descriptor as _descriptor from google.protobuf import descriptor_pool as _descriptor_pool from google.protobuf import symbol_database as _symbol_database # @@protoc_insertion_point(imports) _sym_db = _symbol_database.Default() DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b\u0026#39;\\n\\rservice.proto\\x12\\x04main\\\u0026#34;\\x1a\\n\\x07Request\\x12\\x0f\\n\\x07te_name\\x18\\x01\\x01(\\t\\\u0026#34;\\x1b\\n\\x08Response\\x12\\x0f\\n\\x07message\\x18\\x01\\x01(\\t2\u0026lt;\\n\\x0bTestService\\x12-\\n\\nTestServer\\x12\\r.main.Request\\x1a\\x0e.main.Response\\\u0026#34;\\x00\\x62\\x06proto3\u0026#39;) _builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, globals()) _builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, \u0026#39;service_pb2\u0026#39;, globals()) if _descriptor._USE_C_DESCRIPTORS == False: DESCRIPTOR._options = None _REQUEST._serialized_start=23 _REQUEST._serialized_end=49 _RESPONSE._serialized_start=51 _RESPONSE._serialized_end=78 _TESTSERVICE._serialized_start=80 _TESTSERVICE._serialized_end=140 # @@protoc_insertion_point(module_scope)       ","date":"2022-08-05T22:00:38+08:00","image":"https://zcj-git520.github.io/p/proto3-%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0/1_hud944d25af46653be6ac685099ccea094_87560_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/proto3-%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0/","title":"proto3 语法学习"},{"content":"go 语言原生的rpc的实践  go 原生的rpc是使用的net/rpc库，使用encoding/gob进行编解码，支持tcp和http数据传输方式 提供了net/rpc/jsonrpc库实现RPC方法，jsonrpc采用JSON进行数据编解码，因而支持跨语言调用， 目前jsonrpc库是基于tcp协议实现的，暂不支持http传输方式  服务器端 必须符合4个基本条件  结构体字段首字母要大写，可以别人调用 函数名必须首字母大写 函数第一参数是接收参数，第二个参数是返回给客户端的参数，必须是指针类型 函数还必须有一个返回值error  服务器代码如下： 通过加密来实践rpc\npackage main import ( \u0026#34;crypto/hmac\u0026#34; \u0026#34;crypto/md5\u0026#34; \u0026#34;crypto/sha512\u0026#34; \u0026#34;encoding/base64\u0026#34; \u0026#34;encoding/hex\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;golang.org/x/crypto/bcrypt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/rpc\u0026#34; ) // 实例 字符串加密 // 采用哈希/md5/base64/sha512/hmac const HMACKEY = \u0026#34;ZCJ\u0026#34; type DeEncryptionPram struct { CodeStr string // 待加密/解密的字符串 \tCodeType string // 加解码的类型 } type Encryption struct { } // 哈希加密 func hasEncryption(codeStr string)string{ bytes, err := bcrypt.GenerateFromPassword([]byte(codeStr), bcrypt.DefaultCost) if err != nil { log.Println(\u0026#34;has 加密失败\u0026#34;) return \u0026#34;\u0026#34; } return string(bytes) } // MD5加密 func md5Encryption(codeStr string) string { data := md5.Sum([]byte(codeStr)) hexStr := fmt.Sprintf(\u0026#34;%x\u0026#34;, data) return hexStr } // base64加密 func base64Encryption(codeStr string) string { return base64.StdEncoding.EncodeToString([]byte(codeStr)) } // base64 解密 func base64Decryption(codeStr string)(string, error){ by, err := base64.StdEncoding.DecodeString(codeStr) if err != nil { return \u0026#34;\u0026#34;, err } return string(by), nil } // sha512加密 func sha512Encryption(codeStr string)string { w := sha512.New() io.WriteString(w, codeStr) bw := w.Sum(nil) return hex.EncodeToString(bw) } // 使用hmac 进行加密 func hmacEncryption(codeStr string)string { hw := hmac.New(md5.New, []byte(HMACKEY)) hw.Write([]byte(codeStr)) return hex.EncodeToString(hw.Sum([]byte(\u0026#34;\u0026#34;))) } func (e *Encryption)OptEncryption(pram *DeEncryptionPram, returnData *string) error { if pram.CodeStr == \u0026#34;\u0026#34;{ returnData = nil return fmt.Errorf(\u0026#34;加密字符串为空\u0026#34;) } switch pram.CodeType { case \u0026#34;HAS\u0026#34;: *returnData = hasEncryption(pram.CodeStr) case \u0026#34;MD5\u0026#34;: *returnData = md5Encryption(pram.CodeStr) case \u0026#34;BASE64\u0026#34;: *returnData = base64Encryption(pram.CodeStr) case \u0026#34;SHA512\u0026#34;: *returnData = sha512Encryption(pram.CodeStr) case \u0026#34;HMAC\u0026#34;: *returnData = hmacEncryption(pram.CodeStr) default: *returnData = hasEncryption(pram.CodeStr) } log.Printf(\u0026#34;加密类型为%v, 加密数据为：%v, 加密结果为：%v\u0026#34;, pram.CodeType, pram.CodeStr, *returnData) return nil } func (e *Encryption)OptDecryption(pram *DeEncryptionPram, returnData *string) error { if pram.CodeStr == \u0026#34;\u0026#34;{ returnData = nil return fmt.Errorf(\u0026#34;解密字符串为空\u0026#34;) } if pram.CodeType == \u0026#34;BASE64\u0026#34;{ str, err := base64Decryption(pram.CodeStr) if err != nil { *returnData = \u0026#34;\u0026#34; return err } *returnData = str log.Printf(\u0026#34;解密类型为%v, 解密数据为：%v, 解密结果为：%v\u0026#34;, pram.CodeType, pram.CodeStr, *returnData) return nil } *returnData = \u0026#34;\u0026#34; return fmt.Errorf(\u0026#34;解密类型只支持：base64\u0026#34;) } func main() { enc := new(Encryption) // 注册服务 \terr := rpc.Register(enc) if err != nil { log.Fatal(\u0026#34;服务注册失败\u0026#34;) } // 使用http \trpc.HandleHTTP() // 监听服务 \tlog.Println(\u0026#34;监听服务...........\u0026#34;) err = http.ListenAndServe(\u0026#34;:8000\u0026#34;, nil) if err != nil { log.Panicln(err) } } 客户端代码如下： package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/rpc\u0026#34; ) // 客户端开始请求  type DeEncryptionPram struct { CodeStr string // 待加密/解密的字符串 \tCodeType string // 加解码的类型 } func main() { // 连接http \tconn, err := rpc.DialHTTP(\u0026#34;tcp\u0026#34;, \u0026#34;:8000\u0026#34;) if err != nil { log.Panic(err) } pram := \u0026amp;DeEncryptionPram{ CodeStr: \u0026#34;zcj2565554485\u0026#34;, CodeType: \u0026#34;HAS\u0026#34;, } var HASData string err = conn.Call(\u0026#34;Encryption.OptEncryption\u0026#34;, pram, \u0026amp;HASData) if err != nil { log.Println(err) } fmt.Println(\u0026#34;Encryption data is :\u0026#34;, HASData) pram = \u0026amp;DeEncryptionPram{ CodeStr: \u0026#34;zcj2565554485\u0026#34;, CodeType: \u0026#34;MD5\u0026#34;, } var MD5Data string err = conn.Call(\u0026#34;Encryption.OptEncryption\u0026#34;, pram, \u0026amp;MD5Data) if err != nil { log.Println(err) } fmt.Println(\u0026#34;Encryption data is :\u0026#34;, MD5Data) pram = \u0026amp;DeEncryptionPram{ CodeStr: \u0026#34;zcj2565554485\u0026#34;, CodeType: \u0026#34;SHA512\u0026#34;, } var SHA512Data string err = conn.Call(\u0026#34;Encryption.OptEncryption\u0026#34;, pram, \u0026amp;SHA512Data) if err != nil { log.Println(err) } fmt.Println(\u0026#34;Encryption data is :\u0026#34;, SHA512Data) pram = \u0026amp;DeEncryptionPram{ CodeStr: \u0026#34;zcj2565554485\u0026#34;, CodeType: \u0026#34;HMAC\u0026#34;, } var HMACData string err = conn.Call(\u0026#34;Encryption.OptEncryption\u0026#34;, pram, \u0026amp;HMACData) if err != nil { log.Println(err) } fmt.Println(\u0026#34;Encryption data is :\u0026#34;, HMACData) pram = \u0026amp;DeEncryptionPram{ CodeStr: \u0026#34;zcj2565554485\u0026#34;, CodeType: \u0026#34;BASE64\u0026#34;, } var returnData string err = conn.Call(\u0026#34;Encryption.OptEncryption\u0026#34;, pram, \u0026amp;returnData) if err != nil { log.Println(err) } fmt.Println(\u0026#34;Encryption data is :\u0026#34;, returnData) pram = \u0026amp;DeEncryptionPram{ CodeStr: returnData, CodeType: \u0026#34;BASE64\u0026#34;, } returnData = \u0026#34;\u0026#34; err = conn.Call(\u0026#34;Encryption.OptDecryption\u0026#34;, pram, \u0026amp;returnData) if err != nil { log.Println(err) } fmt.Println(\u0026#34;Decryption data is :\u0026#34;, returnData) pram = \u0026amp;DeEncryptionPram{ CodeStr: returnData, CodeType: \u0026#34;HMAC\u0026#34;, } returnData = \u0026#34;\u0026#34; err = conn.Call(\u0026#34;Encryption.OptDecryption\u0026#34;, pram, \u0026amp;returnData) if err != nil { log.Println(err) } fmt.Println(\u0026#34;Decryption data is :\u0026#34;, returnData) } 测试结果 E:\\GO_Rroject\\rpc_zcj\\go_native_rpc\u0026gt;go run client.go Encryption data is : $2a$10$IaSoHv0OpVBZNk3zfx1Ct.dKLZJwU5of6qoKf2bABA7aKEQvObYLm Encryption data is : 2cb48591141c092db41a3edaf2bbbfdb Encryption data is : 0d7e532c800ee449a5eab309d1916e1f6ff4ffa0738d7e9aa06adae93154842f22896575c50e711f10d1 869b7945377c46ac7211d4aa919a0bed41ef2d806327 Encryption data is : fcba1e90c88b18eb08e59467f36bd202 Encryption data is : emNqMjU2NTU1NDQ4NQ== Decryption data is : zcj2565554485 2022/08/13 21:58:23 解密类型只支持：base64 Decryption data is : \r\n","date":"2022-08-01T22:00:38+08:00","image":"https://zcj-git520.github.io/p/prc-go-%E8%AF%AD%E8%A8%80%E5%AE%9E%E8%B7%B5%E4%B8%80/2_hu9db44f85261860f0cd6b40f5490959f6_304073_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/prc-go-%E8%AF%AD%E8%A8%80%E5%AE%9E%E8%B7%B5%E4%B8%80/","title":"PRC go 语言实践一"},{"content":"设置自己的编辑器 简单介绍  基于vim 设计自己的编辑器 使用vim插件 以下是编辑器的.vimrc  配置如下 set nocompatible \u0026quot; be iMproved, required filetype off \u0026quot; required \u0026quot; set the runtime path to include Vundle and initialize set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() \u0026quot; alternatively, pass a path where Vundle should install plugins \u0026quot;call vundle#begin('~/some/path/here') \u0026quot; let Vundle manage Vundle, required Plugin 'VundleVim/Vundle.vim' Plugin 'dense-analysis/ale' Plugin 'preservim/nerdtree' Plugin 'preservim/nerdcommenter' Plugin 'ludovicchabant/vim-gutentags' Plugin 'Valloric/YouCompleteMe' Plugin 'Shougo/neocomplete.vim' Plugin 'vim-scripts/taglist.vim' \u0026quot; Plugin 'rstacruz/sparkup', {'rtp': 'vim/'} call vundle#end() \u0026quot; required filetype plugin indent on \u0026quot; required set sw=4 set ts=4 set et set smarttab set smartindent set lbr set fo+=mB set sm set selection=inclusive set wildmenu set mousemodel=popup \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot;ale \u0026quot;始终开启标志列 let g:ale_sign_column_always = 1 let g:ale_set_highlights = 0 \u0026quot;自定义error和warning图标 let g:ale_sign_error = '✗' let g:ale_sign_warning = '⚡' \u0026quot;在vim自带的状态栏中整合ale let g:ale_statusline_format = ['✗ %d', '⚡ %d', '✔ OK'] \u0026quot;显示Linter名称,出错或警告等相关信息 let g:ale_echo_msg_error_str = 'E' let g:ale_echo_msg_warning_str = 'W' let g:ale_echo_msg_format = '[%linter%] %s [%severity%]' \u0026quot;普通模式下，sp前往上一个错误或警告，sn前往下一个错误或警告 nmap sp (ale_previous_wrap) nmap sn (ale_next_wrap) \u0026quot;s触发/关闭语法检查 nmap s :ALEToggle \u0026quot;a查看错误或警告的详细信息 nmap a :ALEDetail let g:ale_linters = { \\ 'c++': ['clang'], \\ 'c': ['clang'], \\ 'python': ['pylint'], \\ 'golang':['golangci-lint'], \\} \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot;将该配置写进.vimrc文件中\u0026quot; nnoremap \u0026lt;C-n\u0026gt; :NERDTreeToggle\u0026lt;CR\u0026gt; \u0026quot;打开NERDTree,在node中选中当前文件\u0026quot; nnoremap \u0026lt;C-f\u0026gt; :NERDTreeFind\u0026lt;CR\u0026gt; \u0026quot;vim打开时，自动打开NERDTree,并且将光标放在文件窗口\u0026quot; \u0026quot;autocmd VimEnter * NERDTree | wincmd p \u0026quot;当NERDTree是唯一的窗口时退出vim\u0026quot; autocmd BufEnter * if tabpagenr('$') == 1 \u0026amp;\u0026amp; winnr('$') == 1 \u0026amp;\u0026amp; exists('b:NERDTree') \u0026amp;\u0026amp; b:NERDTree.isTabTree() | quit | endif \u0026quot;在每一个新的new tab打开存在的NERDTree\u0026quot; autocmd BufWinEnter * silent NERDTreeMirror \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot; Add spaces after comment delimiters by default let g:NERDSpaceDelims = 1 \u0026quot; Use compact syntax for prettified multi-line comments let g:NERDCompactSexyComs = 1 \u0026quot; Align line-wise comment delimiters flush left instead of following code indentation let g:NERDDefaultAlign = 'left' \u0026quot; Set a language to use its alternate delimiters by default let g:NERDAltDelims_java = 1 \u0026quot; Add your own custom formats or override the defaults let g:NERDCommentEmptyLines = 1 \u0026quot; Enable trimming of trailing whitespace when uncommenting let g:NERDTrimTrailingWhitespace = 1 \u0026quot; Enable NERDCommenterToggle to check all selected lines is commented or not let g:NERDToggleCheckAllLines = 1 \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot; gutentags搜索工程目录的标志，碰到这些文件/目录名就停止向上一级目录递归 \u0026quot; let g:gutentags_project_root = ['.root', '.svn', '.git', '.project'] \u0026quot; 所生成的数据文件的名称 \u0026quot; let g:gutentags_ctags_tagfile = '.tags' \u0026quot; 将自动生成的 tags 文件全部放入 ~/.cache/tags 目录中，避免污染工程目录 \u0026quot; let s:vim_tags = expand('~/.cache/tags') let g:gutentags_cache_dir = s:vim_tags \u0026quot; 检测 ~/.cache/tags 不存在就新建 \u0026quot; if !isdirectory(s:vim_tags) silent! call mkdir(s:vim_tags, 'p') endif \u0026quot; 配置 ctags 的参数 \u0026quot; let g:gutentags_ctags_extra_args = ['--fields=+niazS', '--extra=+q'] let g:gutentags_ctags_extra_args += ['--c++-kinds=+pxI'] let g:gutentags_ctags_extra_args += ['--c-kinds=+px'] \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot; Use neocomplete. let g:neocomplete#enable_at_startup = 1 \u0026quot; Use smartcase. let g:neocomplete#enable_smart_case = 1 \u0026quot; Set minimum syntax keyword length. let g:neocomplete#sources#syntax#min_keyword_length = 3 let g:neocomplete#lock_buffer_name_pattern = '\\*ku\\*' \u0026quot; Define dictionary. let g:neocomplete#sources#dictionary#dictionaries = { \\ 'default' : '', \\ 'vimshell' : $HOME.'/.vimshell_hist', \\ 'scheme' : $HOME.'/.gosh_completions' \\ } \u0026quot; Define keyword. if !exists('g:neocomplete#keyword_patterns') let g:neocomplete#keyword_patterns = {} endif let g:neocomplete#keyword_patterns['default'] = '\\h\\w*' \u0026quot; Plugin key-mappings. inoremap \u0026lt;expr\u0026gt;\u0026lt;C-g\u0026gt; neocomplete#undo_completion() inoremap \u0026lt;expr\u0026gt;\u0026lt;C-l\u0026gt; neocomplete#complete_common_string() \u0026quot; Recommended key-mappings. \u0026quot; \u0026lt;CR\u0026gt;: close popup and save indent. inoremap \u0026lt;silent\u0026gt; \u0026lt;CR\u0026gt; \u0026lt;C-r\u0026gt;=\u0026lt;SID\u0026gt;my_cr_function()\u0026lt;CR\u0026gt; function! s:my_cr_function() return neocomplete#close_popup() . \u0026quot;\\\u0026lt;CR\u0026gt;\u0026quot; \u0026quot; For no inserting \u0026lt;CR\u0026gt; key. \u0026quot;return pumvisible() ? neocomplete#close_popup() : \u0026quot;\\\u0026lt;CR\u0026gt;\u0026quot; endfunction \u0026quot; \u0026lt;TAB\u0026gt;: completion. inoremap \u0026lt;expr\u0026gt;\u0026lt;TAB\u0026gt; pumvisible() ? \u0026quot;\\\u0026lt;C-n\u0026gt;\u0026quot; : \u0026quot;\\\u0026lt;TAB\u0026gt;\u0026quot; \u0026quot; \u0026lt;C-h\u0026gt;, \u0026lt;BS\u0026gt;: close popup and delete backword char. inoremap \u0026lt;expr\u0026gt;\u0026lt;C-h\u0026gt; neocomplete#smart_close_popup().\u0026quot;\\\u0026lt;C-h\u0026gt;\u0026quot; inoremap \u0026lt;expr\u0026gt;\u0026lt;BS\u0026gt; neocomplete#smart_close_popup().\u0026quot;\\\u0026lt;C-h\u0026gt;\u0026quot; inoremap \u0026lt;expr\u0026gt;\u0026lt;C-y\u0026gt; neocomplete#close_popup() inoremap \u0026lt;expr\u0026gt;\u0026lt;C-e\u0026gt; neocomplete#cancel_popup() \u0026quot; Enable omni completion. autocmd FileType css setlocal omnifunc=csscomplete#CompleteCSS autocmd FileType html,markdown setlocal omnifunc=htmlcomplete#CompleteTags autocmd FileType javascript setlocal omnifunc=javascriptcomplete#CompleteJS autocmd FileType python setlocal omnifunc=pythoncomplete#Complete autocmd FileType xml setlocal omnifunc=xmlcomplete#CompleteTags \u0026quot; Enable heavy omni completion. if !exists('g:neocomplete#sources#omni#input_patterns') let g:neocomplete#sources#omni#input_patterns = {} endif \u0026quot; For perlomni.vim setting. \u0026quot; https://github.com/c9s/perlomni.vim let g:neocomplete#sources#omni#input_patterns.perl = '\\h\\w*-\u0026gt;\\h\\w*\\|\\h\\w*::' \u0026quot; 显示相关 \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; syntax on set nobackup \u0026quot;取消自动备份，禁止生成临时文件 set noswapfile set nocompatible \u0026quot;关闭兼容模式 set incsearch \u0026quot;开启实时搜索功能 set ignorecase \u0026quot;搜索忽略大小写 set wildmenu \u0026quot;vim命令自动补全 set autoread \u0026quot;文件自动更新 set gcr=a:block-blinkon0 \u0026quot;禁止关闭闪烁 set laststatus=2 \u0026quot;总是显示状态栏 set ruler \u0026quot;显示光标位置 set nu \u0026quot;显示行号 \u0026quot; set relativenumber \u0026quot;显示相对行号 set cuc \u0026quot;浅色显示当前行 set cul \u0026quot;浅色显示当前行 set showcmd \u0026quot;输入的命令显示出来 set cmdheight=2 \u0026quot;命令行高度 set nofoldenable set foldmethod=manual \u0026quot;允许手动折叠 set cul \u0026quot;高亮光标所在行 set cuc set shortmess=atI \u0026quot; 启动的时候不显示那个援助乌干达儿童的提示 set go= \u0026quot; 不要图形按钮 \u0026quot;color desert \u0026quot; 设置背景主题 color ron \u0026quot; 设置背景主题 autocmd InsertEnter * se cul \u0026quot; 用浅色高亮当前行 set ruler \u0026quot; 显示标尺 set showcmd \u0026quot; 输入的命令显示出来，看的清楚些 set scrolloff=3 \u0026quot; 光标移动到buffer的顶部和底部时保持3行距离 set statusline=%F%m%r%h%w\\ [FORMAT=%{\u0026amp;ff}]\\ [TYPE=%Y]\\ [POS=%l,%v][%p%%]\\ %{strftime(\\\u0026quot;%d/%m/%y\\ -\\ %H:%M\\\u0026quot;)} \u0026quot;状态行显示的内容 set laststatus=2 \u0026quot; 启动显示状态行(1),总是显示状态行(2) set nocompatible \u0026quot;去掉讨厌的有关vi一致性模式，避免以前版本的一些bug和局限 \u0026quot; 显示中文帮助 if version \u0026gt;= 603 set helplang=cn set encoding=utf-8 endif \u0026quot; 自动缩进 set autoindent set cindent \u0026quot; Tab键的宽度 set tabstop=4 \u0026quot; 统一缩进为4 set softtabstop=4 set shiftwidth=4 \u0026quot; 使用空格代替制表符 set expandtab \u0026quot; 在行和段开始处使用制表符 set smarttab \u0026quot; 显示行号 set number \u0026quot; 历史记录数 set history=1000 \u0026quot;搜索逐字符高亮 set hlsearch set incsearch \u0026quot;语言设置 set langmenu=zh_CN.UTF-8 set helplang=cn \u0026quot; 总是显示状态行 set cmdheight=2 \u0026quot; 侦测文件类型 filetype on \u0026quot; 载入文件类型插件 filetype plugin on \u0026quot; 为特定文件类型载入相关缩进文件 filetype indent on \u0026quot; 保存全局变量 set viminfo+=! \u0026quot; 带有如下符号的单词不要被换行分割 set iskeyword+=_,$,@,%,#,- \u0026quot; 字符间插入的像素行数目 \u0026quot;markdown配置 au BufRead,BufNewFile *.{md,mdown,mkd,mkdn,markdown,mdwn} set filetype=mkd au BufRead,BufNewFile *.{go} set filetype=go au BufRead,BufNewFile *.{js} set filetype=javascript \u0026quot;rkdown to HTML nmap md :!~/.vim/markdown.pl % \u0026gt; %.html \u0026lt;CR\u0026gt;\u0026lt;CR\u0026gt; nmap fi :!firefox %.html \u0026amp; \u0026lt;CR\u0026gt;\u0026lt;CR\u0026gt; nmap \\ \\cc vmap \\ \\cc \u0026quot;将tab替换为空格 nmap tt :%s/\\t/ /g\u0026lt;CR\u0026gt; \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;新文件标题 \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot;新建.c,.h,.sh,.java文件，自动插入文件头 autocmd BufNewFile *.cpp,*.[ch],*.sh,*.rb,*.java,*.py exec \u0026quot;:call SetTitle()\u0026quot; \u0026quot;\u0026quot;定义函数SetTitle，自动插入文件头 func SetTitle() \u0026quot;如果文件类型为.sh文件 if \u0026amp;filetype == 'sh' call setline(1,\u0026quot;\\#!/bin/bash\u0026quot;) call append(line(\u0026quot;.\u0026quot;), \u0026quot;\u0026quot;) elseif \u0026amp;filetype == 'python' call setline(1,\u0026quot;#!/usr/bin/env python\u0026quot;) call append(line(\u0026quot;.\u0026quot;),\u0026quot;# coding=utf-8\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+1, \u0026quot;\u0026quot;) elseif \u0026amp;filetype == 'ruby' call setline(1,\u0026quot;#!/usr/bin/env ruby\u0026quot;) call append(line(\u0026quot;.\u0026quot;),\u0026quot;# encoding: utf-8\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+1, \u0026quot;\u0026quot;) \u0026quot; elseif \u0026amp;filetype == 'mkd' \u0026quot; call setline(1,\u0026quot;\u0026lt;head\u0026gt;\u0026lt;meta charset=\\\u0026quot;UTF-8\\\u0026quot;\u0026gt;\u0026lt;/head\u0026gt;\u0026quot;) else call setline(1, \u0026quot;/*************************************************************************\u0026quot;) call append(line(\u0026quot;.\u0026quot;), \u0026quot; \u0026gt; File Name: \u0026quot;.expand(\u0026quot;%\u0026quot;)) call append(line(\u0026quot;.\u0026quot;)+1, \u0026quot; \u0026gt; Author: username\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+2, \u0026quot; \u0026gt; Mail: 111111111@qq.com\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+3, \u0026quot; \u0026gt; Created Time: \u0026quot;.strftime(\u0026quot;%c\u0026quot;)) call append(line(\u0026quot;.\u0026quot;)+4, \u0026quot; ************************************************************************/\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+5, \u0026quot;\u0026quot;) endif if expand(\u0026quot;%:e\u0026quot;) == 'cpp' call append(line(\u0026quot;.\u0026quot;)+6, \u0026quot;#include \u0026lt;iostream\u0026gt;\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+7, \u0026quot;using std::cin;\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+8, \u0026quot;using std::cout;\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+9, \u0026quot;using std::endl;\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+10, \u0026quot;using namespace std;\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+11, \u0026quot;\u0026quot;) endif if \u0026amp;filetype == 'c' call append(line(\u0026quot;.\u0026quot;)+6, \u0026quot;#include \u0026lt;stdio.h\u0026gt;\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+7, \u0026quot;\u0026quot;) endif if expand(\u0026quot;%:e\u0026quot;) == 'h' call append(line(\u0026quot;.\u0026quot;)+6, \u0026quot;#ifndef _\u0026quot;.toupper(expand(\u0026quot;%:r\u0026quot;)).\u0026quot;_H\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+7, \u0026quot;#define _\u0026quot;.toupper(expand(\u0026quot;%:r\u0026quot;)).\u0026quot;_H\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+8, \u0026quot;#endif\u0026quot;) endif if \u0026amp;filetype == 'java' call append(line(\u0026quot;.\u0026quot;)+6,\u0026quot;public class \u0026quot;.expand(\u0026quot;%:r\u0026quot;)) call append(line(\u0026quot;.\u0026quot;)+7,\u0026quot;\u0026quot;) if \u0026amp;filetype == 'go' call append(line(\u0026quot;.\u0026quot;)+6,\u0026quot;package main\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+7,\u0026quot;\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+8,\u0026quot;func main() {\u0026quot;) call append(line(\u0026quot;.\u0026quot;)+9,\u0026quot;}\u0026quot;) endif \u0026quot;新建文件后，自动定位到文件末尾 endfunc autocmd BufNewFile * normal G command WQ wq command Wq wq \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot;键盘命令 \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; :nmap \u0026lt;silent\u0026gt; \u0026lt;F9\u0026gt; \u0026lt;ESC\u0026gt;:Tlist\u0026lt;RETURN\u0026gt; \u0026quot; shift tab pages map \u0026lt;S-Left\u0026gt; :tabp\u0026lt;CR\u0026gt; map \u0026lt;S-Right\u0026gt; :tabn\u0026lt;CR\u0026gt; map! \u0026lt;C-Z\u0026gt; \u0026lt;Esc\u0026gt;zzi map! \u0026lt;C-O\u0026gt; \u0026lt;C-Y\u0026gt;, map \u0026lt;C-A\u0026gt; ggVG$\u0026quot;+y map \u0026lt;Esc\u0026gt;\u0026lt;Esc\u0026gt; :w\u0026lt;CR\u0026gt; map \u0026lt;F12\u0026gt; gg=G map \u0026lt;C-w\u0026gt; \u0026lt;C-w\u0026gt;w imap \u0026lt;C-k\u0026gt; \u0026lt;C-y\u0026gt;, imap \u0026lt;C-t\u0026gt; \u0026lt;C-q\u0026gt;\u0026lt;TAB\u0026gt; imap \u0026lt;C-j\u0026gt; \u0026lt;ESC\u0026gt; \u0026quot; 选中状态下 Ctrl+c 复制 \u0026quot;map \u0026lt;C-v\u0026gt; \u0026quot;*pa imap \u0026lt;C-v\u0026gt; \u0026lt;Esc\u0026gt;\u0026quot;*pa imap \u0026lt;C-a\u0026gt; \u0026lt;Esc\u0026gt;^ imap \u0026lt;C-e\u0026gt; \u0026lt;Esc\u0026gt;$ vmap \u0026lt;C-c\u0026gt; \u0026quot;+y \u0026quot;set mouse=v \u0026quot;set clipboard=unnamed \u0026quot;去注释 nnoremap \u0026lt;F1\u0026gt; :g/^\\s*#/d\u0026lt;CR\u0026gt; \u0026quot;去空行 nnoremap \u0026lt;F2\u0026gt; :g/^\\s*$/d\u0026lt;CR\u0026gt; \u0026quot;比较文件 nnoremap \u0026lt;C-F2\u0026gt; :vert diffsplit \u0026quot;nnoremap \u0026lt;Leader\u0026gt;fu :CtrlPFunky\u0026lt;Cr\u0026gt; \u0026quot;nnoremap \u0026lt;C-n\u0026gt; :CtrlPFunky\u0026lt;Cr\u0026gt; \u0026quot;C，C++ 按F5编译运行 map \u0026lt;F5\u0026gt; :call CompileRunGcc()\u0026lt;CR\u0026gt; func! CompileRunGcc() exec \u0026quot;w\u0026quot; if \u0026amp;filetype == 'c' exec \u0026quot;!g++ % -o %\u0026lt;\u0026quot; exec \u0026quot;!time ./%\u0026lt;\u0026quot; elseif \u0026amp;filetype == 'cpp' exec \u0026quot;!g++ % -std=c++11 -o %\u0026lt;\u0026quot; exec \u0026quot;!time ./%\u0026lt;\u0026quot; elseif \u0026amp;filetype == 'java' exec \u0026quot;!javac %\u0026quot; exec \u0026quot;!time java %\u0026lt;\u0026quot; elseif \u0026amp;filetype == 'sh' :!time bash % elseif \u0026amp;filetype == 'python' exec \u0026quot;!time python2.7 %\u0026quot; elseif \u0026amp;filetype == 'html' exec \u0026quot;!firefox % \u0026amp;\u0026quot; elseif \u0026amp;filetype == 'go' \u0026quot; exec \u0026quot;!go build %\u0026lt;\u0026quot; exec \u0026quot;!time go run %\u0026quot; elseif \u0026amp;filetype == 'mkd' exec \u0026quot;!~/.vim/markdown.pl % \u0026gt; %.html \u0026amp;\u0026quot; exec \u0026quot;!firefox %.html \u0026amp;\u0026quot; endif endfunc \u0026quot;C,C++的调试 map \u0026lt;F8\u0026gt; :call Rungdb()\u0026lt;CR\u0026gt; func! Rungdb() exec \u0026quot;w\u0026quot; exec \u0026quot;!g++ % -std=c++11 -g -o %\u0026lt;\u0026quot; exec \u0026quot;!gdb ./%\u0026lt;\u0026quot; endfunc \u0026quot;代码格式优化化 map \u0026lt;F6\u0026gt; :call FormartSrc()\u0026lt;CR\u0026gt;\u0026lt;CR\u0026gt; \u0026quot;定义FormartSrc() func FormartSrc() exec \u0026quot;w\u0026quot; if \u0026amp;filetype == 'c' exec \u0026quot;!astyle --style=ansi -a --suffix=none %\u0026quot; elseif \u0026amp;filetype == 'cpp' || \u0026amp;filetype == 'hpp' exec \u0026quot;r !astyle --style=ansi --one-line=keep-statements -a --suffix=none %\u0026gt; /dev/null 2\u0026gt;\u0026amp;1\u0026quot; elseif \u0026amp;filetype == 'perl' exec \u0026quot;!astyle --style=gnu --suffix=none %\u0026quot; elseif \u0026amp;filetype == 'py'||\u0026amp;filetype == 'python' exec \u0026quot;r !autopep8 -i --aggressive %\u0026quot; elseif \u0026amp;filetype == 'java' exec \u0026quot;!astyle --style=java --suffix=none %\u0026quot; elseif \u0026amp;filetype == 'jsp' exec \u0026quot;!astyle --style=gnu --suffix=none %\u0026quot; elseif \u0026amp;filetype == 'xml' exec \u0026quot;!astyle --style=gnu --suffix=none %\u0026quot; else exec \u0026quot;normal gg=G\u0026quot; return endif exec \u0026quot;e! %\u0026quot; endfunc \u0026quot;结束定义FormartSrc \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot;\u0026quot;实用设置 \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; if has(\u0026quot;autocmd\u0026quot;) autocmd BufReadPost * \\ if line(\u0026quot;'\\\u0026quot;\u0026quot;) \u0026gt; 0 \u0026amp;\u0026amp; line(\u0026quot;'\\\u0026quot;\u0026quot;) \u0026lt;= line(\u0026quot;$\u0026quot;) | \\ exe \u0026quot;normal g`\\\u0026quot;\u0026quot; | \\ endif endif \u0026quot;当打开vim且没有文件时自动打开NERDTree autocmd vimenter * if !argc() | NERDTree | endif \u0026quot; 只剩 NERDTree时自动关闭 autocmd bufenter * if (winnr(\u0026quot;$\u0026quot;) == 1 \u0026amp;\u0026amp; exists(\u0026quot;b:NERDTreeType\u0026quot;) \u0026amp;\u0026amp; b:NERDTreeType == \u0026quot;primary\u0026quot;) | q | endif \u0026quot; 设置当文件被改动时自动载入 set autoread \u0026quot; quickfix模式 autocmd FileType c,cpp map \u0026lt;buffer\u0026gt; \u0026lt;leader\u0026gt;\u0026lt;space\u0026gt; :w\u0026lt;cr\u0026gt;:make\u0026lt;cr\u0026gt; \u0026quot;自动保存 set autowrite \u0026quot;set ruler \u0026quot; 打开状态栏标尺 \u0026quot;set cursorline \u0026quot; 突出显示当前行 set magic \u0026quot; 设置魔术 set guioptions-=T \u0026quot; 隐藏工具栏 set guioptions-=m \u0026quot; 隐藏菜单栏 \u0026quot; 不要使用vi的键盘模式，而是vim自己的 set nocompatible \u0026quot; 去掉输入错误的提示声音 set noeb \u0026quot; 在处理未保存或只读文件的时候，弹出确认 set confirm \u0026quot;禁止生成临时文件 set nobackup set noswapfile \u0026quot;搜索忽略大小写 set ignorecase set linespace=0 \u0026quot; 增强模式中的命令行自动完成操作 set wildmenu \u0026quot; 使回格键（backspace）正常处理indent, eol, start等 set backspace=2 \u0026quot; 允许backspace和光标键跨越行边界 set whichwrap+=\u0026lt;,\u0026gt;,h,l \u0026quot; 可以在buffer的任何地方使用鼠标（类似office中在工作区双击鼠标定位） \u0026quot;set mouse=a set selection=exclusive set selectmode=mouse,key \u0026quot; 通过使用: commands命令，告诉我们文件的哪一行被改变过 set report=0 \u0026quot; 在被分割的窗口间显示空白，便于阅读 set fillchars=vert:\\ ,stl:\\ ,stlnc:\\ \u0026quot; 高亮显示匹配的括号 set showmatch \u0026quot; 匹配括号高亮的时间（单位是十分之一秒） set matchtime=1 \u0026quot; 光标移动到buffer的顶部和底部时保持3行距离 set scrolloff=3 filetype plugin indent on \u0026quot;打开文件类型检测, 加了这句才可以用智能补全 set completeopt=longest,menu \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot; CTags的设定 \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; let Tlist_Sort_Type = \u0026quot;name\u0026quot; \u0026quot; 按照名称排序 let Tlist_Use_Right_Window = 1 \u0026quot; 在右侧显示窗口 let Tlist_Compart_Format = 1 \u0026quot; 压缩方式 let Tlist_Exist_OnlyWindow = 1 \u0026quot; 如果只有一个buffer，kill窗口也kill掉buffer \u0026quot;\u0026quot;let Tlist_File_Fold_Auto_Close = 0 \u0026quot; 不要关闭其他文件的tags \u0026quot;\u0026quot;let Tlist_Enable_Fold_Column = 0 \u0026quot; 不要显示折叠树 \u0026quot;let Tlist_Show_One_File=1 \u0026quot;不同时显示多个文件的tag，只显示当前文件的 \u0026quot;设置tags set tags=tags; \u0026quot;set autochdir \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot;默认打开Taglist let Tlist_Auto_Open=0 \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; \u0026quot; Tag list (ctags) \u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot; let Tlist_Ctags_Cmd = '/usr/local/bin/ctags' let Tlist_Show_One_File = 1 \u0026quot;不同时显示多个文件的tag，只显示当前文件的 let Tlist_File_Fold_Auto_Close = 1 let Tlist_Exit_OnlyWindow = 1 \u0026quot;如果taglist窗口是最后一个窗口，则退出vim let Tlist_Use_Right_Window = 1 \u0026quot;在右侧窗口中显示taglist窗口 \u0026quot; minibufexpl插件的一般设置 let g:miniBufExplMapWindowNavVim = 1 let g:miniBufExplMapWindowNavArrows = 1 let g:miniBufExplMapCTabSwitchBufs = 1 let g:miniBufExplModSelTarget = 1 nmap tl :Tlist\u0026lt;cr\u0026gt; set rtp+=~/.vim/bundle/vundle/ let g:indentLine_char = '┊' \u0026quot; \u0026quot;ctrlp设置 \u0026quot; set wildignore+=*/tmp/*,*.so,*.swp,*.zip,*.pyc,*.png,*.jpg,*.gif \u0026quot; MacOSX/Linux set wildignore+=*\\\\tmp\\\\*,*.swp,*.zip,*.exe,*.pyc,*.png,*.jpg,*.gif \u0026quot; Windows let g:ctrlp_custom_ignore = '\\v[\\/]\\.(git|hg|svn)$' let g:ctrlp_custom_ignore = '\\v\\.(exe|so|dll)$' let g:ctrlp_extensions = ['funky'] let NERDTreeIgnore=['\\.pyc'] \u0026quot;, \u0026quot;JavaScript\u0026quot;) } ","date":"2022-07-23T22:00:38+08:00","image":"https://zcj-git520.github.io/p/%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%B7%B1%E7%9A%84%E7%BC%96%E8%BE%91%E5%99%A8/1_hu3b1364509ee92ba594c04f8ddadc5a1f_100499_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/%E8%AE%BE%E7%BD%AE%E8%87%AA%E5%B7%B1%E7%9A%84%E7%BC%96%E8%BE%91%E5%99%A8/","title":"设置自己的编辑器"},{"content":"redis GO语言实践二 简单介绍  使用go 语言操作redis数据库 使用的库为：go get -u github.com/go-redis/redis 对redis数据库的map，集合和有序集合的操作  代码如下 /*操作hash Map数据类型*/ func (r *RedisInfo)OperaHashMap(){ //添加单个数据 \terr := r.RedisDb.HSet(\u0026#34;hKey\u0026#34;,\u0026#34;filed0\u0026#34;, \u0026#34;value0\u0026#34;).Err() if err != nil { fmt.Println(\u0026#34;添加单个数据失败\u0026#34;, err) return } // 批量添加数据 \thData := make(map[string]interface{}) hData[\u0026#34;filed1\u0026#34;] = \u0026#34;value1\u0026#34; hData[\u0026#34;filed2\u0026#34;] = \u0026#34;value2\u0026#34; hData[\u0026#34;filed3\u0026#34;] = \u0026#34;value3\u0026#34; hData[\u0026#34;filed4\u0026#34;] = 20 hData[\u0026#34;filed5\u0026#34;] = 12.5 err = r.RedisDb.HMSet(\u0026#34;hKey\u0026#34;, hData).Err() if err != nil { fmt.Println(\u0026#34;批量添加数据失败\u0026#34;,err) return } // 单个获取数据 \tvalue, err := r.RedisDb.HGet(\u0026#34;hKey\u0026#34;, \u0026#34;filed0\u0026#34;).Result() if err != nil { fmt.Println(\u0026#34;单个获取数失败\u0026#34;, err) return } fmt.Println(\u0026#34;value is \u0026#34;, value) // 整数数据的自增 \terr = r.RedisDb.HIncrBy(\u0026#34;hKey\u0026#34;, \u0026#34;filed4\u0026#34;, 50 ).Err() if err != nil { fmt.Println(\u0026#34;整数数据的自增失败\u0026#34;, err) return } // 浮点数数据的自增 \terr = r.RedisDb.HIncrByFloat(\u0026#34;hKey\u0026#34;, \u0026#34;filed5\u0026#34;, 52.64).Err() if err != nil { fmt.Println(\u0026#34;浮点数数据的自增失败\u0026#34;, err) return } // 获取所有字段名 \tkeys, _:= r.RedisDb.HKeys(\u0026#34;hKey\u0026#34;).Result() fmt.Println(\u0026#34;keys is \u0026#34;, keys) // 获取字段数量 \tkLen, _ := r.RedisDb.HLen(\u0026#34;hKey\u0026#34;).Result() fmt.Println(\u0026#34;kLen is \u0026#34;, kLen) // 批量获取数据 \tvalues, err := r.RedisDb.HMGet(\u0026#34;hKey\u0026#34;, \u0026#34;filed1\u0026#34;, \u0026#34;filed2\u0026#34;,\u0026#34;filed3\u0026#34;).Result() if err != nil { fmt.Println(\u0026#34;批量获取数据失败\u0026#34;, err) return } fmt.Println(\u0026#34;values is \u0026#34;, values) // 删除数据 \terr = r.RedisDb.HDel(\u0026#34;hKey\u0026#34;, \u0026#34;filed1\u0026#34;, \u0026#34;filed0\u0026#34;).Err() if err != nil { fmt.Println(\u0026#34;删除数据失败\u0026#34;,err) return } // 判断数据是否存在 \tok, _ := r.RedisDb.HExists(\u0026#34;hKey\u0026#34;, \u0026#34;filed1\u0026#34;).Result() if ok{ fmt.Println(\u0026#34;filed1 is 存在的\u0026#34;) }else{ fmt.Println(\u0026#34;filed1 is 不存在的\u0026#34;) } // 获取所有数据 \tallValues, err := r.RedisDb.HGetAll(\u0026#34;hKey\u0026#34;).Result() if err != nil { fmt.Println(\u0026#34;获取所有数据\u0026#34;, err) return } fmt.Println(\u0026#34;allValues is \u0026#34;, allValues) } /*操作set集合*/ func (r *RedisInfo) OperaSet() { // 添加数据 \terr := r.RedisDb.SAdd(\u0026#34;sKey\u0026#34;, \u0026#34;test1\u0026#34;,\u0026#34;value1\u0026#34;, 10, 25,3.215).Err() err = r.RedisDb.SAdd(\u0026#34;sKey1\u0026#34;, \u0026#34;value1\u0026#34;, 110, 25,3.215, \u0026#34;ff\u0026#34;,\u0026#34;zvj\u0026#34;,25).Err() if err != nil { fmt.Println(\u0026#34;添加数据失败\u0026#34;, err) return } // 获取数据个数 \tcLen, _ := r.RedisDb.SCard(\u0026#34;sKey\u0026#34;).Result() fmt.Println(\u0026#34;cLen is \u0026#34;, cLen) // 删除第一个数据 \tfData, _ := r.RedisDb.SPop(\u0026#34;sKey\u0026#34;).Result() fmt.Println(\u0026#34;第一个数据为：\u0026#34;, fData) // 删除某个元素，并返回集合数量 \tcLen, _ = r.RedisDb.SRem(\u0026#34;sKey\u0026#34;, \u0026#34;value1\u0026#34;).Result() fmt.Println(\u0026#34;删除后cLen is \u0026#34;, cLen) // 判断某个元素是否存在 \tok, _ := r.RedisDb.SIsMember(\u0026#34;sKey\u0026#34;, \u0026#34;value1\u0026#34;).Result() if ok{ fmt.Println(\u0026#34;value1 is 存在\u0026#34;) }else { fmt.Println(\u0026#34;value1 is 不存在\u0026#34;) } // 获取所有集合数据 \tsDataS, _ := r.RedisDb.SMembers(\u0026#34;sKey\u0026#34;).Result() fmt.Println(\u0026#34;sDataS is \u0026#34;, sDataS) // 求交集并保存在某个集合中 \tdataLen, _ := r.RedisDb.SInterStore(\u0026#34;sInterStore\u0026#34;, \u0026#34;sKey\u0026#34;, \u0026#34;sKey1\u0026#34;).Result() fmt.Println(\u0026#34;交集数据个数为：\u0026#34;, dataLen) // 求差集并保存在某个集合中 \tdataLen, _ = r.RedisDb.SDiffStore(\u0026#34;sDiffStore\u0026#34;, \u0026#34;sKey\u0026#34;, \u0026#34;sKey1\u0026#34;).Result() fmt.Println(\u0026#34;差集数据个数为：\u0026#34;, dataLen) // 求并集并保存在某个集合中 \tdataLen, _ = r.RedisDb.SUnionStore(\u0026#34;sUnionStore\u0026#34;, \u0026#34;sKey\u0026#34;, \u0026#34;sKey1\u0026#34;).Result() fmt.Println(\u0026#34;并集数据个数为：\u0026#34;, dataLen) } /*操作有序集合*/ func (r *RedisInfo) OperaSortSet() { // 添加数据 \tlanguages := [] redis.Z{ {Score: 90.0, Member: \u0026#34;Golang\u0026#34;}, {Score: 98.0, Member: \u0026#34;Java\u0026#34;}, {Score: 95.0, Member: \u0026#34;Python\u0026#34;}, {Score: 97.0, Member: \u0026#34;JavaScript\u0026#34;}, {Score: 92.0, Member: \u0026#34;C/C++\u0026#34;}, } num, err := r.RedisDb.ZAdd(\u0026#34;zKey\u0026#34;, languages...).Result() if err != nil { fmt.Println(\u0026#34;添加数据\u0026#34;, err) return } fmt.Println(\u0026#34;add 数据给个数为\u0026#34;, num) // 增加分时 \terr = r.RedisDb.ZIncrBy(\u0026#34;zKey\u0026#34;, 3, \u0026#34;Golang\u0026#34;).Err() if err != nil { fmt.Println(\u0026#34;增分数失败\u0026#34;, err) return } // 返回数据个数 \tzLen, _ := r.RedisDb.ZCard(\u0026#34;zKey\u0026#34;).Result() fmt.Println(\u0026#34;zLen is \u0026#34;, zLen) // 统计分数段的元素个数 \tzLen, _ = r.RedisDb.ZCount(\u0026#34;zKey\u0026#34;, \u0026#34;0\u0026#34;, \u0026#34;150\u0026#34;).Result() fmt.Println(\u0026#34;count zLen is \u0026#34;, zLen) // 排序 \tvalue, _ := r.RedisDb.ZRange(\u0026#34;zKey\u0026#34;, 0,-1).Result() fmt.Println(\u0026#34;value is \u0026#34;, value) // 删除某个元素 \tr.RedisDb.ZRem(\u0026#34;zKey\u0026#34;, \u0026#34;JavaScript\u0026#34;) } ","date":"2022-07-15T22:00:38+08:00","image":"https://zcj-git520.github.io/p/redis-go%E8%AF%AD%E8%A8%80%E5%AE%9E%E8%B7%B5%E4%BA%8C/1_hu38514b36fb33d89c48254822293248c6_47054_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/redis-go%E8%AF%AD%E8%A8%80%E5%AE%9E%E8%B7%B5%E4%BA%8C/","title":"redis GO语言实践二"},{"content":"redis GO语言实践一 简单介绍  使用go 语言操作redis数据库 使用的库为：go get -u github.com/go-redis/redis 对redis数据库的连接，对字符串和列表的操作  代码如下 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/go-redis/redis\u0026#34; \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) const ( ADDR = \u0026#34;192.168.1.128:6379\u0026#34; PASSWORD = \u0026#34;\u0026#34; DB = 0 ) type RedisInfo struct { Option *redis.Options RedisDb *redis.Client } // 连接redis数据库 func (r *RedisInfo)ConnRedis() error{ redisDb := redis.NewClient(r.Option) // 判断是否成功连接数据库 \t_, err := redisDb.Ping().Result() if err != nil { return err } r.RedisDb = redisDb return nil } /* 操作字符串类型 */ // 操作set/get func (r *RedisInfo)OperaStringSGet() { // 添加key/value 可设置过期时间 \terr := r.RedisDb.Set(\u0026#34;Key1\u0026#34;, \u0026#34;value1\u0026#34;, 4*time.Millisecond).Err() if err != nil { fmt.Println(\u0026#34;添加key失败\u0026#34;, err) return } time.Sleep(4*time.Millisecond) // 获取key的值 \tvalue, err := r.RedisDb.Get(\u0026#34;Key1\u0026#34;).Result() if err != nil { fmt.Println(\u0026#34;获取key的值失败\u0026#34;, err) return } if value == \u0026#34;\u0026#34;{ fmt.Println(\u0026#34;key 不存在\u0026#34;) // 如果不存在则就添加, 不设置过期时间 \tr.RedisDb.SetNX(\u0026#34;Key1\u0026#34;, \u0026#34;setnx value\u0026#34;, 0) }else { fmt.Printf(\u0026#34;获得value：%v \\n\u0026#34;, value) } } // 操作mset/mget func (r *RedisInfo)OperaStringMSGet() { // 批量添加key-value \terr := r.RedisDb.MSet(\u0026#34;key0\u0026#34;, \u0026#34;value0\u0026#34;, \u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;, \u0026#34;key3\u0026#34;, \u0026#34;value3\u0026#34;,\u0026#34;key4\u0026#34;, \u0026#34;value4\u0026#34;).Err() if err != nil { fmt.Printf(\u0026#34;批量添加key-value 失败 %v \\n\u0026#34;, err) return } // 批量获取value \tvalues, err := r.RedisDb.MGet(\u0026#34;key0\u0026#34;,\u0026#34;key1\u0026#34;,\u0026#34;key2\u0026#34;,\u0026#34;key3\u0026#34;, \u0026#34;key4\u0026#34;).Result() if err != nil { fmt.Printf(\u0026#34;批量获取value 失败：%v \\n\u0026#34;, err) return } fmt.Printf(\u0026#34;values is : %v\\n\u0026#34;, values) // 删除keys \terr = r.RedisDb.Del(\u0026#34;key0\u0026#34;).Err() if err != nil { fmt.Printf(\u0026#34;删除keys 失败 %v\\n\u0026#34;, err) return } // 获得指定的keys \tkeys, err := r.RedisDb.Keys(\u0026#34;k*\u0026#34;).Result() if err != nil { fmt.Printf(\u0026#34; 获得指定的keys 失败 %v\\n\u0026#34;, err) }else{ fmt.Printf(\u0026#34;keys is :%v\\n\u0026#34;, keys) } } // 操作自增自减 func (r *RedisInfo)OperaStringNcr(){ // 增加数据 \terr := r.RedisDb.Set(\u0026#34;score\u0026#34;, 120, 0).Err() if err != nil { fmt.Println(\u0026#34;增加数据失败\u0026#34;, err) return } //自增操作 \terr = r.RedisDb.Incr(\u0026#34;score\u0026#34;).Err() if err != nil { fmt.Println(\u0026#34;自增失败\u0026#34;, err) return } value, _ := r.RedisDb.Get(\u0026#34;score\u0026#34;).Result() fmt.Printf(\u0026#34;成绩为:%v\\n\u0026#34;, value) // 步长增加 \terr = r.RedisDb.IncrBy(\u0026#34;score\u0026#34;, 10).Err() if err != nil { fmt.Println(\u0026#34;步长增加失败\u0026#34;, err) return } value, _ = r.RedisDb.Get(\u0026#34;score\u0026#34;).Result() fmt.Printf(\u0026#34;成绩为:%v\\n\u0026#34;, value) // 自减 \terr = r.RedisDb.Decr(\u0026#34;score\u0026#34;).Err() if err != nil { fmt.Println(\u0026#34;自减失败\u0026#34;, err) return } value, _ = r.RedisDb.Get(\u0026#34;score\u0026#34;).Result() fmt.Printf(\u0026#34;成绩为:%v\\n\u0026#34;, value) // 步长减少 \terr = r.RedisDb.DecrBy(\u0026#34;score\u0026#34;, -20).Err() if err != nil { fmt.Println(\u0026#34;步长减少失败\u0026#34;, err) return } value, _ = r.RedisDb.Get(\u0026#34;score\u0026#34;).Result() fmt.Printf(\u0026#34;成绩为:%v\\n\u0026#34;, value) // 浮点数的自增/自减 \terr = r.RedisDb.IncrByFloat(\u0026#34;score\u0026#34;, -20.5).Err() if err != nil { fmt.Println(\u0026#34;浮点数的自增/自减失败\u0026#34;, err) return } value, _ = r.RedisDb.Get(\u0026#34;score\u0026#34;).Result() fmt.Printf(\u0026#34;成绩为:%v\\n\u0026#34;, value) } /* list类型的操作*/ // func (r *RedisInfo)OperaListLData() { // 左边Push任意增加key-value \terr := r.RedisDb.LPush(\u0026#34;Lkey1\u0026#34;, \u0026#34;Lvalue1\u0026#34;, \u0026#34;Lvalue2\u0026#34;, \u0026#34;Lvalue3\u0026#34;).Err() if err != nil { fmt.Println(\u0026#34;左边Push增加key失败：\u0026#34;, err) return } // 左边增加数据，当list不存在时，不能增加 \terr = r.RedisDb.LPushX(\u0026#34;LXkey\u0026#34;, \u0026#34;LXValue\u0026#34;).Err() if err != nil { fmt.Println(\u0026#34;左边Push增加key失败：\u0026#34;, err) return } // 获得list长度 \tLLen, err := r.RedisDb.LLen(\u0026#34;Lkey1\u0026#34;).Result() if err != nil { fmt.Println(\u0026#34;获得list长度失败：\u0026#34;, err) return } fmt.Println(\u0026#34;Lkey1 list len is :\u0026#34;, LLen) // 获取列表数据 \tLData, err := r.RedisDb.LRange(\u0026#34;Lkey1\u0026#34;, 0, -1).Result() if err != nil { fmt.Println(\u0026#34;获取列表数据失败\u0026#34;, err) return } fmt.Println(\u0026#34;列表数据为：\u0026#34;, LData) // 修改list中存在的value \terr = r.RedisDb.LSet(\u0026#34;Lkey1\u0026#34;, 1, \u0026#34;updateValue\u0026#34;).Err() if err != nil { fmt.Println(\u0026#34;修改值失败\u0026#34;, err) return } // 移除并返回list左边第一个数据 \tPData, err := r.RedisDb.LPop(\u0026#34;Lkey1\u0026#34;).Result() if err != nil { fmt.Println(\u0026#34;移除数据失败\u0026#34;, err) return } fmt.Println(\u0026#34;PData is :\u0026#34;, PData) // 移除list中重复的value,count为1时，移除一个 \tcount, err := r.RedisDb.LRem(\u0026#34;Lkey1\u0026#34;, 2,\u0026#34;Lvalue1\u0026#34;).Result() if err != nil { fmt.Println(\u0026#34;移除多个重读的value值失败\u0026#34;, err) return } fmt.Println(\u0026#34;count is\u0026#34;, count) // 列表索引获得数据 \tdata, err := r.RedisDb.LIndex(\u0026#34;Lkey1\u0026#34;, 1).Result() if err != nil { fmt.Println(\u0026#34;获得数据失败\u0026#34;, err) return } fmt.Println(\u0026#34;data is \u0026#34;, data) // 将某个数据插入到某个值前(before)插入到某个值之后(after) \terr = r.RedisDb.LInsert(\u0026#34;Lkey1\u0026#34;, \u0026#34;before\u0026#34;, \u0026#34;updateValue\u0026#34;, \u0026#34;insetData\u0026#34;).Err() //err := r.RedisDb.LInsertBefore(\u0026#34;Lkey1\u0026#34;, \u0026#34;updateValue\u0026#34;, \u0026#34;insetData\u0026#34;).Err() \tif err != nil { fmt.Println(\u0026#34;插入数据失败\u0026#34;, err) return } // 截取名称为key的list \tok, err := r.RedisDb.LTrim(\u0026#34;Lkey1\u0026#34;, 1,3).Result() if err != nil { fmt.Println(\u0026#34;获取新的list失败\u0026#34;) return } fmt.Println( ok) LData, err = r.RedisDb.LRange(\u0026#34;Lkey1\u0026#34;, 0, -1).Result() if err != nil { fmt.Println(\u0026#34;获取列表数据失败\u0026#34;, err) return } fmt.Println(\u0026#34;列表数据为：\u0026#34;, LData) } func main() { opt := \u0026amp;redis.Options{ Network: \u0026#34;tcp\u0026#34;, // 网络类型 tcp 或者 unix. \tAddr: ADDR, OnConnect: nil, // 新建一个redis连接的时候，会回调这个函数 \tPassword: PASSWORD, // redis数据库连接的密码 \tDB: DB, // redis数据库，序号从0开始，默认是0，可以不用设置 \tMaxRetries: 5, // redis操作失败最大重试次数，默认不重试。 \t/* MinRetryBackoff: 0, // 最小重试时间间隔 默认是 8ms ; -1 表示关闭 MaxRetryBackoff: 0, // 最小重试时间间隔 默认是 512ms ; -1 表示关闭 DialTimeout: 0, // redis连接超时时间. 默认为5秒 ReadTimeout: 0, // socket读取超时时间 默认时间为3秒 WriteTimeout: 0, // socket写超时时间 PoolSize: 0, // redis连接池的最大连接数.默认连接池大小等于 cpu个数 * 10 MinIdleConns: 0, //redis连接池最小空闲连接数. MaxConnAge: 0, // redis连接最大的存活时间，默认不会关闭过时的连接. PoolTimeout: 0, // 当你从redis连接池获取一个连接之后，连接池最多等待这个拿出去的连接多长时间。 默认是等待 ReadTimeout + 1 秒. IdleTimeout: 0, // redis连接池多久会关闭一个空闲连接. 默认是 5 分钟. -1 则表示关闭这个配置项 IdleCheckFrequency: 0, // 多长时间检测一下，空闲连接 默认是 1 分钟. -1 表示关闭空闲连接检测 TLSConfig: nil, // 要使用的TLS配置。设置TLS时将进行协商 */ } redisClient := \u0026amp;RedisInfo{ Option: opt, RedisDb: nil, } err := redisClient.ConnRedis() if err != nil { log.Fatal(\u0026#34;redis 数据库连接失败！！！\u0026#34;, err) } fmt.Println(\u0026#34;数据库连接成功\u0026#34;) redisClient.OperaStringSGet() redisClient.OperaStringMSGet() redisClient.OperaStringNcr() redisClient.OperaListLData() } ","date":"2022-07-08T22:00:38+08:00","image":"https://zcj-git520.github.io/p/redis-go%E8%AF%AD%E8%A8%80%E5%AE%9E%E8%B7%B5%E4%B8%80/1_hu92e993ca1384cf9d7fc0be4e9454fb8f_41826_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/redis-go%E8%AF%AD%E8%A8%80%E5%AE%9E%E8%B7%B5%E4%B8%80/","title":"redis GO语言实践一"},{"content":"redis 常用命令的实践 结构化与非结构化   关系型数据库\n 结构化 关联性 sql查询 满足事务的ACID  ![](C:\\Users\\90953\\AppData\\Roaming\n  非关系型数据\n 非结构化 无关联性 非sql base(基础性的事务)    \r\nredis 通用命令 通用指令是部分数据类型的，都可以使用的指令，常见的有：\n KEYS:查看符合模板的所有key del：删除指定的key exists:判读key是否存在 expire:给一个可以设置有效期（单位时间为s），有效期到时会自动删除key ttl:查看key的有效期  \r\nstring 类型常用命令 string类型是redis中最简单的存储类型，其value是字符串，字符串可以分为3类：\n  string:普通字符串\n  int：整数类型，可以自增或自减\n  float:浮点型，可以自增或自减\n无论是哪一种格式，底层都是字节数组形式存储，只不过是编码不同，字符串类型的最大空间不超过512M\n\r\n  常用的命令有：   set:添加或者修改也存在的的一个string类型的键值对\n  get:根据key获取string类型的value\n  mset:批量添加多个stingl类型的键值对\n  mget:根据多个key获取多个string类型的value\n  incr:让一个int的key自增1\n  incrby:让一个整型的key自增并指定步长\n  incrbyfloat:让一个浮点数的数值自增并指定步长\n  setnx:添加一个string类型的键值对，当key存在时，不执行\n  setex:添加一个string类型的键值对，并且设置有效期\n\r\n  key的结构 redis的key允许有多个单词形成层级结构，有多个单词之间用“：”隔开;\n格式如下：项目名：业务名：类型：id;\n 例如：user相关的key:sysd:user:1 例如：产品相相关的key:sysd:product:1  \r\n\r\nHASH类型 hash类型是叫散列，其value是一个无序的字典，hash的结构可以将对象的每个单独的字段独立存储，可以对每个字段做CRUD;\n常用的命令如下：   hset key fileld value :添加或者修改hash类型key的fileld的值\n  hget key fileld: 获取一个hash类型的fileld的值\n  hmset: 批量添加多个hash类型的key的field的值\n  hmget：批量获取多个hash类型的keyde fileld的值\n  hgetall:获取一个hash类型的key中的所有的fileld和value\n  hkeys:获取一个hash类型的key中的所有的filed\n  hvale:获取一个hash类型中的key的所有value\n  hincrby:让一个hash类型key的字段值自增并指定步长\n  hseinx:添加一个hash类型的key的fileld值，若存在则步添加\n\r\n  ​\t\r\nLIST类型 redis中的list可以看作是一个双向链表的结构，支持正向与反向的检索，有以下特征：\n 有序 元素可以重复 插入与删除快 查询速度一般  常用的命令  lpush key value…… ：向左插入一个或多个元素 lpop key ：移除左边的第一个元素，没有就返回nil rpush key value……：向右插入一个或者多个元素 Rrpop key:移除并返回右侧的第一个元素，没有就返回nil lrang key star end:返回一段角标范围内所有元素 blpop和brpop:与lpop和rpop类似，只不过在没有元素时等待的时间，而不是直接返回nil  \r\n\r\nset类型 redis中的set结构可以看作是一个value为nil的hashmap。具备一下特征：\n 无序 元素不可重复 查找快 支持交集/并集/差集等功能  常用的命令   sadd key number ……：向set中添加一个或者多个元素\n  srem key number ……：移除set中指定的元素\n  scard key:返回set中的元素个数\n  sismembre key member:判断一个元素是否存在与一个set中\n  smembers:获取set中所有的元素\n  sinter key1 key2……：求集合之间的交集\n  sdiff key1 key2……：集合之间的差集\n  sunion key1 key2……：集合之间的并集\n\r\n  ​\t\r\nSortedSet类型 redis的sortedset是一个有序的集合，每一个元素都带有一个score的属性，可以基于score属性对元素进行排序，其底层是一个由一个跳跃表和hash表实现，其具备一下特性：\n 可排序 元素不可重复 查询速度快  常用命令   zadd key score member: 添加一个或者多个元素到有序集合中，如果存在则更新其score\n  zrem key member:删除有序集合中的一个指定元素\n  zscore key member:获取指定元素的的score值\n  zrank key member:获取有序集合元素的排名\n  zcard key:获取有序集合中的元素个数\n  zcount key min max:统计score值在给定范围内中的所有元素和个数\n  zincrby key increment member:让有序集合中的指定元素自增，步长为指定的increment值\n  zrange key min max:按照score排序后，获取指定排名范围的元素\n  zrangebyscore key min max:按照score排序后，获取指定的score范围的元素\n  zdiff/zinter/zuninon:求差集/交集/并集\n注明：排名默认为升序，rev为降序\n\r\n  ​\t\r\n","date":"2022-07-01T22:00:38+08:00","image":"https://zcj-git520.github.io/p/redis-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%9A%84%E5%AE%9E%E8%B7%B5/image-20220703184326525_hu8f470d54622ce88b90e96a39d1a48252_105753_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/redis-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E7%9A%84%E5%AE%9E%E8%B7%B5/","title":"redis 常用命令的实践"},{"content":"diskText  直接跳过文件系统，对磁盘数据进行读写，判断磁盘测试数据读写校验数据是否丢失  磁盘信息 type DiskSizeInfo struct { DiskPath string // 磁盘名 \tSrcMap map[string]string // 测试数据集(文件夹/校验数据) \tSize int // 磁盘分组大小 \tSeekSize int\t// 磁盘数据偏移 \tBlockSize int // 读写磁盘数据的大小 } 使用两种方式跳过文件系统直接对磁盘进行读写  直接读写磁盘  // 磁盘的写入 func (d *DiskSizeInfo)DiskWriteByFile(src string) error // 读取磁盘 func (d *DiskSizeInfo)DiskReadByFile() ([]byte, error) ​\t2.通过dd命令行对磁盘进行读者\n// 通过dd命令写于磁盘 func (d *DiskSizeInfo)WriteDisk(staPos int, iFile string) error // 通过dd命令读取磁盘数据 func (d *DiskSizeInfo)ReadDisk(staPos int, oFile string) error 对磁盘已有数据进行校验 func (d *DiskSizeInfo)CheckReadDisk(src string, i int) 磁盘校验数据的类型的返回 func (d *DiskSizeInfo)DiskDatatype( i int) 循环通过数据集进行校验 func (d *DiskSizeInfo)Run() error 初始化校验集数据文件 func (d *DiskSizeInfo)initFile()error 磁盘的挂起或者卸载（针对与带文件系统）和磁盘清除 func (d *DiskSizeInfo)MountDisk(src string) error func (d *DiskSizeInfo)ClearDisk(src string) error 初始化校验集数据文件 func (d *DiskSizeInfo)initFile() 其他功能 文件通过md5校验比较 func FileCompare(src, dst string) (bool, error) 生成文件校验和函数 func fileCheckSum(fileName string) (string, error) //PathExists 判断一个文件或文件夹是否存在 //输入文件路径，根据返回的bool值来判断文件或文件夹是否存在 func PathExists(path string) (bool,error) 校验文件中是否存在校验值 func CheckFileData(data []byte, check string) bool 源码  我的github:https://github.com/zcj-git520/diskTest  ","date":"2022-06-20T22:00:38+08:00","image":"https://zcj-git520.github.io/p/disk-test/1_hu4b9f21e0357fa4a3de89be2058c4c1e0_86402_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/disk-test/","title":"Disk Test"},{"content":"mdadm mdadm是linux下的一款标准的RAID的管理工具\n基本语法 mdadm [mode] [option] 目前支持 RAID0(striping), RAID1(mirroring), RAID4, RAID5, RAID6, RAID10, MULTIPATH和FAULTY\n模式  Assemble：加入一个以前定义的阵列 Build：创建一个没有超级块的阵列 Create：创建一个新的阵列，每个设备具有超级块； -l,\u0026ndash;level: RAID级别 -n,\u0026ndash;raid-devices: 活动设备个数 -a {yes|no}: 是否自动为其创建设备文件 -c,\u0026ndash;chunk: CHUNK大小, 默认为64K，重要的参数,决定了一次向阵列中每个磁盘写入数据的大小 -x,\u0026ndash;spare-devices: 备用盘个数 Manage： 管理阵列(如添加和删除) Misc：允许单独对阵列中的某个设备进行操作(如停止阵列) Follow or Monitor:监控RAID的状态 Grow：改变RAID的容量或阵列中的设备数目 ；-n,\u0026ndash;raid-devices=: 活动设备个数-x,\u0026ndash;spare-devices=：备用盘个数-c,\u0026ndash;chunk=: CHUNK大小, 默认为64K，重要的参数,决定了一次向阵列中每个磁盘写入数据的大小-z,\u0026ndash;size=：阵列中从每个磁盘获取的空间总数-l,\u0026ndash;level=: RAID级别-p,\u0026ndash;layout=：设定raid5 和raid10的奇偶校验规则；并且控制故障的故障模式\u0026ndash;parity: 类似于\u0026ndash;layout\u0026ndash;assume-clean:目前仅用于 \u0026ndash;build 选项-R \u0026ndash;run: 强制激活RAID，使用这个选项，设备上有旧的元数据信息的提示会被忽略-N \u0026ndash;name=: 设定阵列的名称–-rounding：在linear array中的rounding factor，等于条带大小。  可用的[options]  -A，\u0026ndash;assemble：加入一个以前定义的阵列 -B,\u0026ndash;build:Build a legacy array without superblocks . -C，\u0026ndash;create：创建一个新的阵列 -Q\u0026ndash;query：查看一个device，判断它为一个md device或是一个md阵列的一部分 -D，\u0026ndash;detail：打印一个或多个md device的详细信息 -E，\u0026ndash;examine：打印device上的md superblock 的内容 -F，\u0026ndash;follow，\u0026ndash;monitor：选择Monitor模式 -G，\u0026ndash;grow：改变在用阵列的大小或形态 -h，\u0026ndash;help：帮助信息，用在以上选项后，则显示该选项信息\u0026ndash;help-options -V,\u0026ndash;version -V，\u0026ndash;verbose：显示细节 -b,\u0026ndash;brief：较少的细节。用于\u0026ndash;detail和\u0026ndash;examine选项 -f,\u0026ndash;force -c，\u0026ndash;config=：指定配置文件，缺省为/etc/mdadm/mdadm. conf -s，\u0026ndash;scan：扫描配置文件或/proc/mdstat以搜寻丢失的信息。配置文件/etc/mdadm/mdadm. conf create或build使用的选项： -c,\u0026ndash;chunk=:Specify chunk size of kibibytes.缺省为64. \u0026ndash;rounding=:Specify rounding factor for linear array(==chunk size) -I,\u0026ndash;level=:设定raid level. \u0026ndash;create可用：linear，raid 0，0，stripe，raid 1，1，mirror，raid 4，4，raid 5，5，raid 6，6，multipath, mp. \u0026ndash;build可用：linear，raid 0，0，stripe. -p，\u0026ndash;parity=：设定raid 5的奇偶校验规则：eft- asymmetric ，left-symmetric，right- asymmetric , right-symmetric, la, ra, ls, rs.缺省为left-symmetric\u0026ndash;layout=：类似于\u0026ndash;parity -n，\u0026ndash;raid-devices=：指定阵列中可用device数目，这个数目只能由\u0026ndash;grow修改-x，\u0026ndash;spare-devices=：指定初始阵列的富余device数目 -z，\u0026ndash;size=：组建RAID1/4/5/6后从每个device获取的空间总数\u0026ndash;assume-clean:目前仅用于\u0026ndash;build选项 -R，-run：阵列中的某一部分出现在其他阵列或文件系统中时，m dadm会确认该阵列。此选项将不作确认。 -f, \u0026ndash;force:通常mdadm不允许只用一个device创建阵列，而且创建raid5时会使用一个device作为missingdrive。此选项正相反 -a, \u0026ndash;auto{=no,yes,md,mdp,part,p}{NN}  测试 创建RAID5阵列   执行命令: mdadm \u0026ndash;create /dev/md0 \u0026ndash;level=5 \u0026ndash;chunk=64 \u0026ndash;raid-devices=4 \u0026ndash;spare-devices=1 /dev/sd[b-f]\n  使用cat /proc/mdstat查看RAID5阵列状态\n  结果：\nPersonalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] md0 : active raid5 sde[5] sdf[4](S) sdd[2] sdc[1] sdb[0] 328704 blocks super 1.2 level 5, 64k chunk, algorithm 2 [4/4] [UUUU] unused devices: \u0026lt;none\u0026gt; 显示设备盘为sdf为热备盘， 使用fdisk –l查看磁盘阵列, 显示磁盘大小为：Disk /dev/md0: 320 MB   停止RAID5阵列   执行命令: sudo mdadm -Ss 或者 mdadm \u0026ndash;stop /dev/md0\n  使用cat /proc/mdstat查看RAID5阵列状态\n  结果\nPersonalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] unused devices: \u0026lt;none\u0026gt; // 磁盘已经停止 mdadm: stopped /dev/md0   启动RAID5阵列   执行命令: sudo mdadm -As\n  使用cat /proc/mdstat查看RAID5阵列状态\n  结果\nmdadm: /dev/md/0 has been started with 4 drives and 1 spare. Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] md0 : active raid5 sdb[0] sdf[4](S) sde[5] sdd[2] sdc[1] 328704 blocks super 1.2 level 5, 64k chunk, algorithm 2 [4/4] [UUUU] unused devices: \u0026lt;none\u0026gt;   查看md状态   执行命令：mdadm -D /dev/md0\n  结果：\n/dev/md0: Version : 1.2 Creation Time : Wed Jun 8 14:28:56 2022 Raid Level : raid5 Array Size : 328704 (321.00 MiB 336.59 MB) Used Dev Size : 109568 (107.00 MiB 112.20 MB) Raid Devices : 4 Total Devices : 5 Persistence : Superblock is persistent Update Time : Wed Jun 8 14:28:57 2022 State : clean Active Devices : 4 Working Devices : 5 Failed Devices : 0 Spare Devices : 1 Layout : left-symmetric Chunk Size : 64K Consistency Policy : resync Name : zcjubuntu-virtual-machine:0 (local to host zcjubuntu-virtual-machine) UUID : 03cfb72d:971a754f:8236aa23:21b23fd3 Events : 18 Number Major Minor RaidDevice State 0 8 16 0 active sync /dev/sdb 1 8 32 1 active sync /dev/sdc 2 8 48 2 active sync /dev/sdd 5 8 64 3 active sync /dev/sde 4 8 80 - spare /dev/sdf   模拟损坏   执行命令：mdadm /dev/md0 -f /dev/sdf\n  使用cat /proc/mdstat查看RAID5阵列状态\n  结果\nPersonalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] md0 : active raid5 sde[5] sdf[4](F) sdd[2] sdc[1] sdb[0] 328704 blocks super 1.2 level 5, 64k chunk, algorithm 2 [4/4] [UUUU] unused devices: \u0026lt;none\u0026gt; /dev/md0: Version : 1.2 Creation Time : Wed Jun 8 14:28:56 2022 Raid Level : raid5 Array Size : 328704 (321.00 MiB 336.59 MB) Used Dev Size : 109568 (107.00 MiB 112.20 MB) Raid Devices : 4 Total Devices : 5 Persistence : Superblock is persistent Update Time : Wed Jun 8 14:44:51 2022 State : clean Active Devices : 4 Working Devices : 4 Failed Devices : 1 Spare Devices : 0 Layout : left-symmetric Chunk Size : 64K Consistency Policy : resync Name : zcjubuntu-virtual-machine:0 (local to host zcjubuntu-virtual-machine) UUID : 03cfb72d:971a754f:8236aa23:21b23fd3 Events : 19 Number Major Minor RaidDevice State 0 8 16 0 active sync /dev/sdb 1 8 32 1 active sync /dev/sdc 2 8 48 2 active sync /dev/sdd 5 8 64 3 active sync /dev/sde 4 8 80 - faulty /dev/sdf   移除损坏的磁盘   执行命令：mdadm /dev/md0 -r /dev/sdf\n  使用cat /proc/mdstat查看RAID5阵列状态\n  结果\nPersonalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10] md0 : active raid5 sde[5] sdd[2] sdc[1] sdb[0] 328704 blocks super 1.2 level 5, 64k chunk, algorithm 2 [4/4] [UUUU] unused devices: \u0026lt;none\u0026gt; /dev/md0: Version : 1.2 Creation Time : Wed Jun 8 14:28:56 2022 Raid Level : raid5 Array Size : 328704 (321.00 MiB 336.59 MB) Used Dev Size : 109568 (107.00 MiB 112.20 MB) Raid Devices : 4 Total Devices : 4 Persistence : Superblock is persistent Update Time : Wed Jun 8 14:49:13 2022 State : clean Active Devices : 4 Working Devices : 4 Failed Devices : 0 Spare Devices : 0 Layout : left-symmetric Chunk Size : 64K Consistency Policy : resync Name : zcjubuntu-virtual-machine:0 (local to host zcjubuntu-virtual-machine) UUID : 03cfb72d:971a754f:8236aa23:21b23fd3 Events : 20 Number Major Minor RaidDevice State 0 8 16 0 active sync /dev/sdb 1 8 32 1 active sync /dev/sdc 2 8 48 2 active sync /dev/sdd 5 8 64 3 active sync /dev/sde   添加新的硬盘到已有阵列   执行命令：mdadm /dev/md0 -a /dev/sdf\n  使用cat /proc/mdstat查看RAID5阵列状态\n  结果\nmd0 : active raid5 sdf[4](S) sde[5] sdd[2] sdc[1] sdb[0] 328704 blocks super 1.2 level 5, 64k chunk, algorithm 2 [4/4] [UUUU] unused devices: \u0026lt;none\u0026gt; /dev/md0: Version : 1.2 Creation Time : Wed Jun 8 14:28:56 2022 Raid Level : raid5 Array Size : 328704 (321.00 MiB 336.59 MB) Used Dev Size : 109568 (107.00 MiB 112.20 MB) Raid Devices : 4 Total Devices : 5 Persistence : Superblock is persistent Update Time : Wed Jun 8 14:53:45 2022 State : clean Active Devices : 4 Working Devices : 5 Failed Devices : 0 Spare Devices : 1 Layout : left-symmetric Chunk Size : 64K Consistency Policy : resync Name : zcjubuntu-virtual-machine:0 (local to host zcjubuntu-virtual-machine) UUID : 03cfb72d:971a754f:8236aa23:21b23fd3 Events : 21 Number Major Minor RaidDevice State 0 8 16 0 active sync /dev/sdb 1 8 32 1 active sync /dev/sdc 2 8 48 2 active sync /dev/sdd 5 8 64 3 active sync /dev/sde 4 8 80 - spare /dev/sdf   ","date":"2022-06-12T22:00:38+08:00","image":"https://zcj-git520.github.io/p/linux-mdadm%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/1_hu859ea59f552859095fb986ed5a22b665_11306_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/linux-mdadm%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0/","title":"Linux-mdadm工具学习"},{"content":"概述 Linux内核在多块设备的基础上，注册了一块特殊的设备，称为为MD设备。这个MD设备形成一个逻辑层，支持不同的RAID技术\n\r\nMD模块是一个虚拟块设备，它属于块i/o子系统中的块设备驱动层，架构于物理块设备层；其有两层：RAID共性层和RAID个性层\n RAID共性层：它提取出各种级别的RAID的公共特性，依照块设备的实现模板向上层注册，同时向RAID个性层提供公共函数，以及接口注册函数 RAID个性层：是各种级别RAID的个性体现，它向RAID公共层注册个性接口，利用RAID公共层提供的公共函数，基于低层实现个性化功能  RAID模块对象   核心MD设备结构mddev及其成员磁盘设备结构mdk_rdev_t是系统中的两个关键结构。核心MD设备结构mddev_t是内核中RAID设备保存自身信息的结构体，它包括了完整的RAID设备的信息。成员磁盘设备结构mdk_rdev_t反映了组成MD设备的底层块设备的信息；\n  MD设备处理可以有不同的特性，它指向一个MD个性结构体，有个性ND设备的操作表和操作的最终数据\n  MD设备通过块设备号和块设备描述符（block_device）关联起来，低层成员磁盘也指向和它相对应的块设备描述符正是以块设备描述符为“纽带”，使得MD可以构建在其他的物理或虚拟磁盘设备之上，成为一个“栈式”块设备；\n\r\n  MD模块初始化   MD模块加载时，它的初始化函数md_init将被执行;\n  __register_blkdev函数:是维护主设备号和块设备名之间的关联,所有块设备模块初始化时，都应该调用这个函数\nstatic void md_geninit(void) { pr_debug(\u0026quot;md: sizeof(mdp_super_t) = %d\\n\u0026quot;, (int)sizeof(mdp_super_t)); proc_create(\u0026quot;mdstat\u0026quot;, S_IRUGO, NULL, \u0026amp;mdstat_proc_ops); } static int __init md_init(void) { int ret = -ENOMEM; md_wq = alloc_workqueue(\u0026quot;md\u0026quot;, WQ_MEM_RECLAIM, 0); if (!md_wq) goto err_wq; md_misc_wq = alloc_workqueue(\u0026quot;md_misc\u0026quot;, 0, 0); if (!md_misc_wq) goto err_misc_wq; md_rdev_misc_wq = alloc_workqueue(\u0026quot;md_rdev_misc\u0026quot;, 0, 0); if (!md_rdev_misc_wq) goto err_rdev_misc_wq; ret = __register_blkdev(MD_MAJOR, \u0026quot;md\u0026quot;, md_probe); if (ret \u0026lt; 0) goto err_md; ret = __register_blkdev(0, \u0026quot;mdp\u0026quot;, md_probe); if (ret \u0026lt; 0) goto err_mdp; mdp_major = ret; register_reboot_notifier(\u0026amp;md_notifier); raid_table_header = register_sysctl_table(raid_root_table); md_geninit(); return 0; err_mdp: unregister_blkdev(MD_MAJOR, \u0026quot;md\u0026quot;); err_md: destroy_workqueue(md_rdev_misc_wq); err_rdev_misc_wq: destroy_workqueue(md_misc_wq); err_misc_wq: destroy_workqueue(md_wq); err_wq: return ret; }   MD设备创建   md_probe()函数负责创建MD对象,直接调用md_alloc函数；\nstatic void md_probe(dev_t dev) { if (MAJOR(dev) == MD_MAJOR \u0026amp;\u0026amp; MINOR(dev) \u0026gt;= 512) return; if (create_on_open) md_alloc(dev, NULL); }   md_open():是系统调用open的实现代码继续执行，调用块设备操作表的open回调函数的实例化\n  用户态发送ioctl创建MD 使用管理工具创建MD是通过ioctl来实现的。在打开MD设备文件（如/dev/md0）情况下，文件操作表被设置为def_blk_fops，其unlocked_ioctl回调函数的实现为block_ioctl，而后者经调用blkdev_ioctl，再调用__blkdev_driver_ioctl，最后调用的是通用磁盘的块设备操作表中的ioctl回调函数\n函数md_iocal()可对设备驱动、磁盘、设备进行查询、控制和配置:\n 针对于RAID驱动程序，而非特定的阵列；例如获取RAID驱动程序版本号以及打印所有RAID阵列信息等 针对于特定阵列，主要命令如下：如SET_ARRAY_INFO设置MD设备信息；ADD_NEW_DISK在MD设备中添加一个磁盘设备；RUN_ARRAY运行MD设备等 SET_ARRAY_INFO：在md_ioctl，处理SET_ARRAY_INFO控制码的代码首先从用户空间复制参数，然后根据MD设备是否已经存在分别调用update_array_info和md_set_array_info函数； ADD_NEW_DISK:在md_ioctl，处理ADD_NEW_DISK控制码的代码首先从用户空间复制参数，然后调md_add_new_disk函数; RUN_ARRAY:处理RUN_ARRAY控制码的代码直接调用do_md_run函数;  MD设备请求执行 MD模块中提供了一个通用的接口函数md_make_request作为各种级别RAID设备的读／写请求的入口;\n加载MD模块时，调用blk_queue_make_request函数将所有对主设备号为MD_MAJOR的读／写请求都转发到这个函数。但这个函数并不执行真正处理，只是通过映射找到块设备次设备号对应MD设备结构，进而获得其个性化结构指针，调用个性化结构的make_request，即通过和该RAID级别对应的请求处理函数来处理这个请求;\n","date":"2022-05-30T22:00:38+08:00","image":"https://zcj-git520.github.io/p/linux-multi-disk-md%E6%A8%A1%E5%9D%97/image-20220613151649807_huc45ff52f0cf6b2c13cf0b9e2262e1b7b_66945_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/linux-multi-disk-md%E6%A8%A1%E5%9D%97/","title":"Linux-Multi-Disk (MD)模块"},{"content":"RAID5模块 RAID5模块的对象，模块的执行过程及其同步和恢复过程\nRAID5模块对象 对于RAID5，MD设备描述符（mddev）的private域指向RAID5私有配置结构r5conf。后者包含一个成员磁盘 数组，每一项都指向对应的成员磁盘描述符（mdk_rdev_t），而这些成员磁盘描述符被链入MD设备描述符的成员磁盘链表，并且有指针指向MD设备；\n\r\nRAID5支持冗余，在条带中采用了校验和技术。对RAID5设备的正常读／写和同步／恢复／扩展等操作都是以条带为基本单位处理的，条带管理结构为“条带头”（stripe_head）。每个RAID5设备分配有固定数目的条带头，随着系统运行，这些条带头可能被挂载到RAID5设备的不同链表，被条带使用中的条带头结构还会链入RAID5的哈希表以便于查找\n每个RAID5设备被分配一定数目的条带用于处理提交给它的请求，最大条带数目由max_nr_stripes域给出。这些条带根据其状态被链入到不同的链表。RAID5设备有以下五个不同的链表\n inactive_list为空闲的条带列表：在RAID5开始运行之初，所有的条带都在inactive_list中。在有请求到达时，为它分配并关联一个条带。条带处理完成，又被释放回到这个链表； handle_list为需要处理的条带列表：要处理的条带都会被添加到handle_list链表，RAID5守护线程就是根据这个链表进行处理的。条带被处理时，会被从链表中删除，暂时处于“游离”状态。一个条带需要多轮处理，每一轮处理完成之后，都被重新加入某个链表，最终又会被重新加入handle_list链表，开始新一轮处理。 bitmap_list为因等待位图更新而延迟的条带链表：如果在对RAID5设备进行写操作时突然掉电，就可能造成某些条带的不同步，有可能数据已经被写入成员磁盘，而校验和还没有被写入，又或者校验和已经被写入，而某些数据还没有被写入成员磁盘。当RAID5再次被重组以后，就需要进行同步处478理，而这需要我们知道哪些条带需要被同步，否则只能进行全面的同步，这样做显然开销非常大。位图就是为此目的而引入的。如果RAID5支持位图，每一个块会对应一个位图位，在进行写操作的时候，会先将对应的位图位置成1，这时写请求也被放入bitmap_list链表，只有在该位图位被成功冲刷到磁盘之后，才能处理这个写请求。当进行同步操作的时候，根据位图位，只同步那些被置为1的条带。采用位图策略最大的优点是减少了无谓的同步操作，提高了同步操作效率。 delayed_list为被延迟处理的条带链表：在有写请求到达条带的某个成员磁盘时，并不是立即将请求放handle_list准备处理，而是先放入delayed_list链表延迟一段时间，延迟的目的是为了等待“可能有”更多针对这个条带的其他成员磁盘的写请求到来，这样做可以从整体上减少“预读”（无论是重构写还是读改写）的次数。只有当条带被“激活读”后，才开始将delayed_list链表中的条带转移到其他链表进行处理。 hold_list为准备好预读的条带链表：当前的Linux内核版本为了防止delayed_list一股脑儿将所有的条带转移到handle_list，在其中引入hold_list链表，延迟的条带先被保存到hold_list链表以进一步延迟，根据特定的算法，hold_list被绕过，也有可能被转移到handle_list而得到处理。事实证明，这样做可以改进写性能  \r\n请求执行过程 RAID5作为一个独立的模块，在初始化时调用raid5_init，在卸载时调用raid5_exit。而raid5_init则是通过调用register_md_personality注册RAID5个性化，包括模块名和一些个性化方法信息。在raid5_exit中则调用unregister_md_personality注销RAID5个性化；\n 接收上层提交请求：上层提交给MD设备的请求，会被传递给raid5_make_request函数； md_write_start函数，它和后面的md_write_end互为对应，都是MD模块提供的公共函数，供RAID5等支持冗余的个性模块调用; chunk_aligned_read函数处理对齐读。所谓对齐读（AlignedRead），是指要读的数据在一个Chunk边界内，因此只需要从某个成员磁盘读取即可，不涉及整个条带的配合;函数根据请求是否在一个Chunk边界内，以及目标成员磁盘是否处在同步状态等，判断是否可以按对齐读处理 raid5_compute_sector:函数输入一个相对RAID5设备的“大的”扇区编号，输出数据磁盘和校验磁盘的编号，以及其上的扇区编号，即条带编号，根据扇区编号计算数据磁盘和校验磁盘的编号及在其上的扇区编号 raids_compute_sector函数有五个参数：第一个为指向r5conf描述符的指针；第二个为目标扇区编号（相对于RAID5设备）；第三个为1表示根据变更前的参数进行计算，为0表示根据变更后的参数进行计算；第四个为输出参数，通过它返回数据单元在条带中的编号；第五个为指向对应stripe_head描述符的指针，这时计算好的P校验单元编号、Q校验单元编号、ddf_layout标志将被保存在它的对应域，或为NULL。函数返回对应扇区在成员磁盘上的扇区编号，即条带编号  RAID5校验盘和数据盘编号与算法 假设数据单元标号为chunk_number，RAID磁盘数为raid_disks，数据盘数为data_disks，所在条带编号为stripe=chunk_number/data_disks。然后计算在条带内的数据磁盘和校验磁盘编号\nRAID5的算法如下：\n  向左不对称算法：校验盘编号为data_disks-stripe%raid_disks。数据盘编号为chunk_number%data_disks，如果该值大于或等于校验盘编号，则还需要加1；\n  向右不对称算法：校验盘编号为stripe%raid_disks。数据盘编号为chunk_number%data_disks，如果该值大于或等于校验盘编号，则还需要加1；\n  向左对称算法：校验盘编号为data_disks-stripe%raid_disks，而数据盘编号为（校验盘编号＋1＋chunk_number%data_disks）%raid_disks；\n  向右对称算法：校验盘编号为stripe%raid_disks，而数据盘编号为（校验盘编号＋1＋chunk_number%data_disks）%raid_disks。\n  最后，目标扇区在数据盘和校验盘上的扇区编号为stripe*sectors_per_chunk＋ chunk_offset。\n\r\n  管理RAID5条带资源 条带头是在RAID5开始运行的时候开辟的缓冲区，这是一个有限的资源，除了在数据处理过程中需要调度以外，还需要一套完整的机制去使得这些有限的资源能够满足数据请求处理所需\n raid5_get_active_stripe：函数有五个参数：第一个为指向RAID5私有数据描述符的指针；第二个为条带编号；第三个为1表示根据变更前的参数进行计算，为0表示根据变更后的参数进行计算；第四个为1表示不要阻塞，为0表示阻塞，直到获得一个活动条带；第五个为noquiesce。函数返回指向条带头描述符的指针，或者在失败时返回NULL __find_stripe：在哈希表中找看指定扇区的条带是否已经存在。如果不存在，函数会返回NULL get_free_stripe从inactive_list链表尝试获得一个条带； 当条带使用完毕后，也就是没有条带的时候，会先将inactive_blocked域置1，然后调用wait_event_lock_irq开始等待； wait_event_lock_irq：四个参数：第一个为等待队列；第二个为条件；第三个为锁；第四个为命令。它的解释为：如果条件不满足，就将当前线程加入到等待队列，当时在放弃执行之前，还会执行一个命令，这通常就是督促其他部分去赶紧处理，使得等待的条件尽早满足；等待条件是：1.RAID5的inactive_list链表不为空；2.RAID5的活动条带数域小于其最大条带数目的3/4，或者RAID5的inactive_blocked为0  RAID5守护线程处理 每个RAID4/5/6设备可以同时存在两个MD线程：一个名字为md#_raid5，称为RAID5守护线程，它执行的处理函数为raid5d；另一个名字为resync或reshape，笼统地称为RAID5同步线程，它执行的处理函数为md_do_sync\nRAID5守护线程，它负责条带各个轮次的处理，从接受上层请求时开始，处理过程中不断推进条带状态的变化，直至最终完成\n","date":"2022-05-15T22:00:38+08:00","image":"https://zcj-git520.github.io/p/linux-raid5%E5%AD%A6%E4%B9%A0/1_hu7e02b142b51acc83a4bc67a855e709b3_49591_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/linux-raid5%E5%AD%A6%E4%B9%A0/","title":"Linux-raid5学习"},{"content":"概述 文件系统是存储和组织文件，以便可以访问和查找的一种机制；不同的文件系统有不同的存储和组织方式；基于磁盘的有一下几种存储方式：\n 连续存储：把数据作为连续的数据块存储到磁盘上；这一方案简单、容易实现，记录文件用到的磁盘块仅需记住第一块的地址，并且性能较好，一次操作就可读出整个文件。但是，它有一个致命的缺陷。在创建文件时，必须知道文件的最大长度，否则无法确定需要为它保留多少磁盘空间。因此，连续存储主要适合于文件数据一次性写入的系统（例如romfs） 连接表存储：将每个文件用磁盘块顺序连接起来；虽然用于链接磁盘块的指针可以使用磁盘块本身的空间，但这将使得每个磁盘块实际存储的数据字节数不再是2的幂，给上层应用程序带来不便。文件系统从磁盘块中取出一些指针，作为索引存放在文件分配表FAT。只需要记录文件的起始磁盘块编号，顺着文件分配表中索引指针组织成的链表，就可以找到文件的所有磁盘块。 inode存储：每个文件都有一个称为node的表；通过它获取所有磁盘的编号；小文件的所有磁盘块编号都直接存放在inode内。稍大的一些文件，inode记录了一个称为一次间接块的磁盘块编号，这个磁盘块存放着文件的其他磁 盘块编号。如果文件再扩大，可以在inode中记录二次间接块编号，二次间接块存放着多个一次间接块的编号，而每个一次间接块又存放着文件的其他磁盘块编号。如果这也不够的话，还可以使用三次间接块。本章要讨论的Minix文件系统，就使用的这种分配方案  Linux将文件系统分为两层：\n  上层为虚拟文件系统开关层，简称为虚拟文件系统：它是具体文件系统和上层应用之间的接口层，将各种不同文件系统的操作和管理纳入一个统一的框架，使得用户不需要关心各种不同文件系统的实现细节。VFS由超级块、inode、dentry、vfsmount等信息组成\n  下层为具体文件系统实现，如Minix、EXT2/3/4、sysfs等。具体文件系统实现代码组织成模块形式，向Linux VFS注册回调函数，处理和具体文件系统密切相关的细节操作\n\r\n  文件系统对象 Linux文件系统对象之间的关系可以概括为文件系统类型、超级块、inode、dentry和vfsmount之间的关系；\nLinux有一颗全局文件系统树，反映了Linux VFS对象之间的关系；\n\r\n每个文件系统装载实例有四个必备元素：vfsmount、超级块、根inode和根dentry。\n装载文件系统 文件系统要被使用就应该被装载。体现一个文件系统装载实例要素是：vfsmount、super_block、根dentry和根inode；\n\r\n在内核角度，装载过程中，文件系统类型中的get_sb将被调用，它将生成一个新的文件系统装载对象vfsmount，并和该文件系统类型的一个超级块实例关联起来；\n","date":"2022-05-12T22:00:38+08:00","image":"https://zcj-git520.github.io/p/linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E9%98%85/1_hudd81952809099175edb54de5cef86875_45536_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%AE%80%E9%98%85/","title":"Linux-文件系统(简阅)"},{"content":"raid是什么 raid是廉价冗余磁盘阵列，简称磁盘阵列。\nraid:是一种把多块独立的物理磁盘按不同的技术组合起来的形成的一个磁盘组，在逻辑上看起来是一块大的磁盘，可以提供比较单个的物理磁盘更大的存储容量或更高的存储性能，同时有能提供不同级别数据的冗余备份的一种技术\nraid的级别 把多个物理磁盘通过不同的技术方式组成的磁盘阵列，不同的技术称为raid级别。\n级别一般有：raid0,raid1,raid0+1(raid10),raid2,raid3,raid4,raid5,raid6,raid7,raid53\n生产环境常用的级别为：raid0,raid1,raid10,raid5\nraid级别的比较    raid级别 优点 缺点 实际使用场景     raid0 读写速度快 没有冗余 mysql slave,集群的节点rs   raid1 100%冗余，镜像 读写性能一般，成本高 单独的，数据重要，且宕机的业务，监控，系统盘   raid5 具备一定的性能和冗余，可坏一块盘，读写性能不错 写入性能不高 用于一般的业务   raid10 读写速度快，100%冗余 成本高 性能和冗余的业务要求高的业务    raid技术分类 软raid技术 在linux中，通过自带软件就能实现软raid功能，它的配置高，管理方便，可以是实现将将几个物理盘合成一个更大的虚拟设备，从而到达性能的改进合数据的冗余的目的\n硬raid技术 基于硬件的raid解决方案比基于软件的raid技术在使用的性能合服务器上更好，具体表现在检测和修复多位错误的能力，错误的磁盘自动检测和阵列重建等方面，从安全性上考虑，基于硬件的raid的解决方案更加的安全\nraid0原理及特点 \r\n特点：  读写性能高 没有冗余 可用空间N*min（s1,S2\u0026hellip;） 最少磁盘数为，2，2+  raid1特点 \r\n特点  读性能提升，写性能降低 可用空间为：min（s1,S2\u0026hellip;） 可冗余 最少磁盘数为：2，2+  raid5特点 \r\n特点：  读性能有提升，写性能有所欠缺 可用空间为：（n-1）*min(s1,s2,\u0026hellip;) 有冗余，有一块磁盘 最少磁盘数：3，3+  raid10特点 \r\n特点：  读写性能有提升 可用空间：N*min（s1,s2\u0026hellip;）/2 有冗余，每组最多坏一块 最少磁盘数为：4，4+  RAID5的基本架构 RAID5的读写操作采用的是stripe的基本结构，即以stripe为读写的基本单位，假设一个3+1的RAID5，即3个数据盘+1个校验盘，那么一个stripe就包含3个数据块和一个校验块；\n\r\n如图所示，这是一个3+1的RAID5，图中的每一个方块表示一个stripe的一个基本单元，又称为chunk；相同颜色的方块组成一个stripe，即每个stripe由3个数据chunk(A,B,C)+1个校验chunk(P)组成。关于校验块的生成方法以及数据恢复原理如下：\n  校验块P的生成方法为P=A⊕B⊕C 。(⊕表示异或运算)\n  加入1号盘坏了，此时有读请求读B0块的数据，那么可以通过B0=A0⊕C0⊕P0 的方法 来进行恢复\n  ","date":"2022-04-30T22:00:38+08:00","image":"https://zcj-git520.github.io/p/linux-raid%E5%AD%A6%E4%B9%A0/1_huf00169aa6abc51faa601f0bf72d243b8_76358_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/linux-raid%E5%AD%A6%E4%B9%A0/","title":"Linux-raid学习"},{"content":"存储设备 磁盘柜 磁盘柜一般分为磁盘阵列（disk array）和磁盘族（jbod）两种；\nRAID（Redundant Array of Independent Disks），即“独立磁盘冗余阵列”或者简称 为“磁盘阵列”，基本思想就是把多个独立的磁盘组合起来，成为一个磁盘阵列组，以 获得一个或多个方面的好处：增加容量（Capacity）、提升性能（Performance）、增强 容错性（Redundancy）和降低成本（Cost）。 JBOD（Just a Bundle Of Disks）译成中文可以是“简单磁盘捆绑”或者“磁盘簇”。在 Linux中，它相当于Linear RAID模式，但这不是标准的RAID级别，JBOD在逻辑上把几 个物理磁盘一个接一个串联到一起，从而提供一个大的逻辑磁盘。\nNAS存储设备 NAS是一种将存储设备和应用服务器分开的机制，它使用CIFS和NFS向客服端提供文件级服务。\n\r图(1)\r\niSCSI存储设备 isCSI存储设备既以硬件方式或者软件方式实现IsCSI协议目标端的存储设备。\niSCSI，即Internet SCSI或SCSI over TCP/IP，是IETF制定的一项基于IP的存储网络标 准，用于连接数据存储设备。透过在IP网络上传输SCSI命令，iSCSI可以摆脱SCSI总线 的距离限制。iSCSI被用于在局域网（LAN）、广域网（WAN）或者Internet上传输数 据，实现位置无关的数据存储及检索。iSCSI是一个广为流行的存储区域网络协议，允 许企业将存储归并到数据中心，同时向应用服务器提供无区别于本地磁盘的幻想。和 传统的Fibre Channel不同，iSCSI不需要专用的线缆，可以在现有的网络基础设施上长 距离传输。\n\r图(2)\r\nNAS/iSCSI集成存储设备 NAS/iSCSI集成存储设备结合了NAS存储设备和iSCSI存储 设备的优势，同时支持iSCSI磁盘和本地磁盘，对外支持CIFS协议和iSCSI协议，即支 持块数据和文件数据，理论上可以整合无限的存储容量，构建RAID和LVM，灵活配置 成纯文件服务器、纯iSCSI目标器，或者将存储空间分别用于文件服务和块服务。\n\r图(3)\r\nLinux 驱动模型 Linux内核基于kobject内核对象机制将系统中的总线、设备和驱动设备分别用bus_type、device和device_driver等对象描述将其组织成一个层次结构的系统，统一管理各种内别的设备以其接口，同时借助sysdfs文件系统将其内核所见的设备展给用户空间，提供一个完全层次结构的用户视图。\n\r图(4)\r\nLinux驱动模型的核心内容综合如下：\n 以内核对象为基础 用sysfs文件系统导出到用户空间 将Linux子系统表达为总线类型/驱动/设备/类/接口的关系，分别用bus_type、device、device_driver、class和class_interface结构表示  引用计数 引用计数的主要功能为：\n 防止内存泄漏：确保已分配的对象最终会被释放； 防止访问已释放的内存：确保不会使用已经被释放的对象  Linux内核提供了相关函数进行操作：\n void kref_init (struct kref *kref);初始化对象，将对象引用次数设置为1，而不是0；这是因为生成该对象的代码也需要最初的引用，以防止其他部分在调用kref_put时释放该对象 void kref_get (struct kref *kref); 递增对象的引用计数。在这之前，确保引用次数不为0，否则答应一条警告信息。这可以防止常见的错误：不先调用kref_init，而直接调用kref_get。 int kref_put (struct kref *kref, void (*release) (struct kref *kref));递减对象的引用计数。如果该计数减为0，则表明是该对象的最后一个引用，因此传入的release函数被调用，以回收这个对象用到的内存。  内核对象及集合 Linux驱动模型的基础是内核对象。它将总线类型、设备、驱动等都看作是内核对 象。表示内核对象的结构是kobject，相当于Linux驱动模型的“基类”\n在Linux内核中的双循环链表实现方式下： ● 链表结构作为一个成员嵌入到宿主数据结构内； ● 可以将链表结构放在宿主结构内的任何地方； ● 可以为链表结构取任何名字； ● 宿主结构可以有多个链表结构。\n\r图(5)\r\nsysfs文件系统 sysfs核心负责为内核中的内部表示和用户空间的外部呈现之间建立对应关系，也称为sysfs映射：\n 内核对象被映射为用户空间的目录 对象属性被映射为用户空间的常规文件 对象关系被映射为用户空间的符号链接  sysfs核心确实将内核对象、对象属性以及对象关系也组织成树的结构。sysfs内部树中有四种类型的节点：目录节点、链接节点、属性节点和二进制属性节点，分别和内核对象、对象关系、对象属性相对应。\n\r图(6)\r\n驱动模型对象 Linux驱动模型适用于linux各种子系统，它描述了总线类型、设备、驱动以及类和接口之间的关系。每一个子系统都有属于自己的唯一的总线类型。它上面链接了注册了这一总线类型的多个设备。另外它还注册了到这个总线类型的多个驱动链接在一起。\n总线类型：Linux驱动模型中的总线类型结构使用bus_type和bus_type_private两个结构体来表 示\n设备：Linux驱动模型中的设备，我们有时简称为驱动模型设备，使用device和device_private两个结构体来表示\n驱动：同总线类型和设备一样，在Linux驱动模型中表示一个驱动也需要两个结构体：device_driver和driver_private。这两个结构体同时存在，并且一一对应。\nPCI子系统 PCI是外围设备互联的简称，是一种通用总线的接口标准。PCI总线是一种常见的主机I/O总线，用于链接高速的外部设备。\nPCI总线体系是结构是一种层次式的体系结构。\n\r图(7)\r\n● PCI设备：遵循PCI规范，工作在PCI局部总线环境下的设备。典型的PCI设备 是封装在集成线路板（IC Package）中，或者集成到PCI扩展卡上的完整的外围元件适 配器。通常见到的有网络、显示或者SCSI适配器。PCI局部总线规范指出，每个PCI设 备可以包含最多8个PCI功能，每个功能是一个逻辑设备。 ● PCI桥设备：由于电子负载限制，每条PCI总线上可以挂载的设备数目是有限 的，因此使用了一种特殊的设备，即PCI-PCI桥设备。PCI-PCI桥为两条独立的PCI总线 提供连接。PCI-PCI桥设备也是一种广义上的PCI设备。在本文中，PCI-PCI桥设备简称 PCI桥。 ● 主桥设备：PCI桥设备和PCI设备最终通过Host-PCI桥设备连接到CPU，使整个 系统看起来像一颗倒置的树状结构，树的顶端是CPU和内存。由Host-PCI桥设备引出的 PCI总线也称为PCI根总线。在本文中，Host-PCI桥设备简称为主桥。\nPCI子系统对象 在PIC子系统中有PCI总线和PCI设备，基于这两个核心的x抽象，linux PCI子系统定义了两个关键的数据结构：pci_bus和pci_dev,以此来描述PCI总线和PCI设备\n\r图(8)\r\npci_bus：PCI总线：pci_bus是描述PCI总线的结构。无论是根PCI总线，还是非根PCI总线，都对应一个pci_bus描述符\npci_dev：PCI设备：由于每条PCI总线上可以挂载的物理设备数目是有限的，因此作为扩展，每个物理设备可以包含多个功能，即逻辑设备。从物理硬件的角度，PCI设备实际上指的是包含从一个到八个“功能”的某个PCI硬件，它被集成到系统主板上，或者安装在插槽中，这是PCI物理硬件的概念\nSCSI子系统 Linux SCSI子系统是一种分层的架构，共三层。\n  低层：最低一层代表是适用于SCSI的物理接口的实际驱动器。\n  中间层，也称公共层或统一层，在这一层包含SCSI堆栈的高层和底层的公共服务函数。\n  高层：高层代表着各种SCSI设备类型的驱动。\n\r图(9)\r\n  SCSI子系统对象 Scsi_Host、scsi_target和scsi_device分别描述的是Linux SCSI模型中的主机适配器、目标节点和逻辑单元。\n\r图(10)\r\n","date":"2022-04-15T22:00:38+08:00","image":"https://zcj-git520.github.io/p/linux%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1_hub95fcc2a246a65208e8832126d70bee7_36058_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/linux%E5%AD%98%E5%82%A8%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"Linux存储技术学习笔记"},{"content":"基本概念 块设备（block device） 是一种有一定结构的随机存取的设备，对于这种设备的读写是按块进行的，他使用的缓冲区来存放暂时的数据，达到一定条件后。从缓存一次性写入设备或者从设备一次性读到缓冲区\n字符设备（character device） 是一种顺序的数据设备，对于这种设备的读写是按字符进行的，连续的字符组成数据流，是没有缓冲区，是只用实时的读写设备；\n块设备与字符设备之间的区别  读写数据的单元不同：块设备是以块为读写单元，而字符设备是以字符为读写单元 块设备是可以随机访问，而字符设备只能顺序访问  扇区（sectors） 是块设备硬件对数据处理的基本单位，通常1扇区=512byte\n块（blocks） 是Linux种制定对内核或文件系统等数据处理的基本单位，通常1块=1个或多个扇区\n段（segments） 是由若干个相邻的块组成。是linux内存管理机制中一个内存页或者内存页中的一部分\n页、段、块、扇区之间的关系如图 \r图(1)\r\n块设备的层次 \r图(2)\r\n  Linux是支持多种不同存储介质，在内核中间都要适配有块设备驱动程序来读写块设备。\n  往上是io调度层，将文件系统的读写请求进行编排，合并用以提高磁盘的读写效率。\n  通用块层，对应与bio结构。是将io请求的抽象，描述对应的io操作涉及到多个页\n块设备的应用在linux中是一个完整的子系统 在linux中，驱动对块设备的中输入或者输出（io）操作都会向块设备发出请求，在驱动中使用request结构体描述。\n对于一些磁盘设备请求的速度很慢，内核提供一种队列的机制，将这些io请求添加到队列中（即：请求队列），在驱动中使用request_queue结构体进行描述。在向块设备提交这些请求前内核会先执行请求合并和排序的预操作，以提高访问的效率，然后在由内核中的io调度程序子系统来负责提交io请求，调度程序将磁盘分配给系统中所有挂起的块io请求，其工作是管理块设备的请求队列。\n在由通用层（generic block layer）负责维持一个io请求在上层文件系统与底层物理磁盘之间的关系，在通用层中，通常用一个bio结构体来对应一个io请求。\nlinux提供一个gendisk数据结构体，用来表示一个独立的磁盘设备或者是分区，用来对底层物理磁盘的访问。在gendisk中有一个类似于字符设备中的file_operations的硬件操作结构指针，是block_device_operations结构体。\n当多个请求在提交块设备时。执行的效率依赖于请求的顺序。如果请求的速度是同一方向，执行效率最大。内核在调用块设备驱动程序请求之前，先收集io请求并将请求进行排序，然后将连续扇区操作的请求进行合并以提高执行效率。\n块设备的缓冲区和缓冲区头 缓冲区对应一个磁盘块，当磁盘块被调入内存时，就存储在缓冲区；块包含一个或多个扇区，且不大于一个页，所以一个页可以容纳一个或者多个块，并存储一些控制信息。控制信息一般是使用结构体buff-head来表示，结构体如下：\n  struct buffer_head{ unsigned long b_state; /* 标志位 */ struct buffer_head *b_this_page; /* 页面中的缓冲区 */ struct page *b_page; /* 当前页面 */ sector_t b_blocknr; /* 起始块号 */ size_t size; /* 映像的大小 */ char *b_data; /* 数据指针 */ struct block_device *b_bdev; /* 关联的块设备 */ atomic_t b_count; /* 使用计数 */ ... }; 请求结构request 结构request代表了挂起的io请求，每一个请求用同一个结构request实例进行描述，存放在请求队列链表中，由电梯算法进行排序，每一个请求包含1个或多个结构体bio实例，其结构体如下：\nstruct request { //用于挂在请求队列链表的节点，使用函数blkdev_dequeue_request访问它，而不能直接访 问 struct list_head queuelist; struct list_head donelist; /*用于挂在已完成请求链表的节点*/ struct request_queue *q; /*指向请求队列*/ unsigned int cmd_flags; /*命令标识*/ enum rq_cmd_type_bits cmd_type; /*命令类型*/ /*各种各样的扇区计数*/ /*为提交i/o维护bio横断面的状态信息，hard_*成员是块层内部使用的，驱动程序不应该改变 它们*/ sector_t sector; /*将提交的下一个扇区*/ sector_t hard_sector; /* 将完成的下一个扇区*/ unsigned long nr_sectors; /* 整个请求还需要传送的扇区数*/ unsigned long hard_nr_sectors; /* 将完成的扇区数*/ /*在当前bio中还需要传送的扇区数 */ unsigned int current_nr_sectors; /*在当前段中将完成的扇区数*/ unsigned int hard_cur_sectors; struct bio *bio; /*请求中第一个未完成操作的bio*、 struct bio *biotail; /*请求链表中末尾的bio*、 struct hlist_node hash; /*融合 hash */ /* rb_node仅用在I/O调度器中，当请求被移到分发队列中时， 请求将被删除。因此，让completion_data与rb_node分享空间*/ union { struct rb_node rb_node; /* 排序/查找*/ void *completion_data; }; bio结构体 通常1个bio对应1个io请求，io调度算法可将连续的bio合并成1个请求。所以一个请求可以包含多个bio。\nbio为通用层的主要数据结构，即描述了磁盘的位置，又描述了内存的位置，是上层内核vfs与下层驱动的连接纽带，其结构体如下：\nstruct bio { sector_t bi_sector;//该bio结构所要传输的第一个（512字节）扇区：磁盘的位置 struct bio *bi_next; //请求链表 struct block_device *bi_bdev;//相关的块设备 unsigned long bi_flags//状态和命令标志 unsigned long bi_rw; //读写 unsigned short bi_vcnt;//bio_vesc偏移的个数 unsigned short bi_idx; //bi_io_vec的当前索引 unsigned short bi_phys_segments;//结合后的片段数目 unsigned short bi_hw_segments;//重映射后的片段数目 unsigned int bi_size; //I/O计数 unsigned int bi_hw_front_size;//第一个可合并的段大小; unsigned int bi_hw_back_size;//最后一个可合并的段大小 unsigned int bi_max_vecs; //bio_vecs数目上限 struct bio_vec *bi_io_vec; //bio_vec链表：内存的位置 bio_end_io_t *bi_end_io;//I/O完成方法 atomic_t bi_cnt; //使用计数 void *bi_private; //拥有者的私有方法 bio_destructor_t *bi_destructor; //销毁方法 }; 内存数据段结构bio_vec 结构bio_vec代表了内存中的一个数据段，数据段用页、偏移和长度描 述。I/O需要执行的内存位置用段表示，结构bio指向了一个段的数组。 结构bio_vec列出如下（在include/linux/bio.h中）： struct bio_vec { struct page *bv_page; /*数据段所在的页*/ unsigned short bv_len; /*数据段的长度*/ unsigned short bv_offset; /*数据段页内偏移*/ }; 块设备结构体 block_device 内核用结构体block_device实例代表一个块设备对象，块设备的结构体为block_device如下\nstruct block_device { dev_t bd_dev; /* not a kdev_t - it\u0026#39;s a search key */ struct inode * bd_inode; /* 分区节点 */ struct super_block * bd_super; int bd_openers; struct mutex bd_mutex;/* open/close mutex 打开与关闭的互斥量*/ struct semaphore bd_mount_sem; /*挂载操作信号量*/ struct list_head bd_inodes; void * bd_holder; int bd_holders; #ifdef CONFIG_SYSFS  struct list_head bd_holder_list; #endif  struct block_device * bd_contains; unsigned bd_block_size; /*分区块大小*/ struct hd_struct * bd_part; unsigned bd_part_count; /*打开次数*/ int bd_invalidated; struct gendisk * bd_disk; /*设备为硬盘时，指向通用硬盘结构*/ struct list_head bd_list; struct backing_dev_info *bd_inode_backing_dev_info; unsigned long bd_private; /* The counter of freeze processes */ int bd_fsfreeze_count; /* Mutex for freeze */ struct mutex bd_fsfreeze_mutex; }; 通用硬盘结构 gendisk 结构gendisk代表了一个通用硬盘（genreic hard disk）对象，它存储了一个硬盘的信息，包括请求队列，分区链表和块设备操作函数集等。块设备驱动程序分配结构gendisk实例，装载分区表，分配请求队列并填充结构的其他域。其结构体如下：\nstruct gendisk { int major; /* 驱动程序的主设备号 */ int first_minor; /*第一个次设备号*/ int minors; /*次设备号的最大数量，没有分区的设备，此值为1 */ char disk_name[32]; /* 主设备号驱动程序的名字*/ struct hd_struct **part; /* 分区列表，由次设备号排序 */ struct block_device_operations *fops; /*块设备操作函数集*/ struct request_queue *queue; /*请求队列*/ struct blk_scsi_cmd_filter cmd_filter; void *private_data; /*私有数据*/ sector_t capacity; /* 函数set_capacity设置的容量，以扇区为单位*/ int flags; /*设置驱动器状态的标志，如：可移动介质为 GENHD_FL_REMOVABLE*/ struct device dev; /*从设备驱动模型基类结构device继承*/ struct kobject *holder_dir; struct kobject *slave_dir; struct timer_rand_state *random; int policy; atomic_t sync_io; /* RAID */ unsigned long stamp; int in_flight; #ifdef CONFIG_SMP  struct disk_stats *dkstats; #else /*硬盘统计信息，如：读或写的扇区数、融合的扇区数、在请求队列的时间等*/ struct disk_stats dkstats; #endif  struct work_struct async_notify; #ifdef CONFIG_BLK_DEV_INTEGRITY  struct blk_integrity *integrity; /*用于数据完整性扩展*/ #endif }; 块设备各个结构体间的关系 \r图(3)\r\n","date":"2022-04-02T22:00:38+08:00","image":"https://zcj-git520.github.io/p/linux%E5%86%85%E6%A0%B8%E4%B8%AD%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/1_huf160ae63de05609269a7d8cc29249a6e_88106_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/linux%E5%86%85%E6%A0%B8%E4%B8%AD%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8/","title":"Linux内核中设备驱动"},{"content":"性能  高并发和快响应的性能指标是指：吞吐和延时 性能的本质：系统资源已经到达瓶颈时，处理请求不够快，不足以处理更多的请求。 性能分析：找到系统或者应用的瓶颈，尽最大的可能避免或者缓解这样的瓶颈。 常用的性能分析工具： \r  cup上下文切换  cup上下文切换：将上一个任务cup的上下文保存系统的内核中休眠，然后将新任务的cup上下文进行加载，然后执行这个新任务。 cup的上下文切换可分为：线程上下文切换、进程上下文切换和中断上下文切换。在内核中中断的等级与进程和线程的等级高，所以保证了中断上下文 切换与进程和线程上下文切换不同时发生。 通过vmstat可以查看系统总体的上下文切换情况 \r  进程上下切换   linux进程按照等级权限将进程的运行空间分为内核空间和用户态空间。其中用户态向内核态转换需要进行系统调用。执行一次系统调用 需要进行两次cpu的上下文切换分别为：\n   CPU寄存器中用户态的指令位置先保存起来，CPU寄存器更新为内核态指令的位置，跳转到内核态运行内核任务；\n系统调用结束后，CPU寄存器恢复原来保存的用户态数据，再切换到用户空间继续运行。\n   进程是由内核管理和调度的，进程上下文切换只能发生在内核态。因此相比系统调用来说，在保存当前进程的内核状态和CPU寄存器之前，需要先把该进程的虚拟内存，栈保存下来。再加载新进程的内核态后，还要刷新进程的虚拟内存和用户栈。\n  进程只有在调度到CPU上运行时才需要切换上下文，有以下几种场景：CPU时间片轮流分配，系统资源不足导致进程挂起，进程通过sleep函数主动挂起，高优先级进程抢占时间片，硬件中断时CPU上的进程被挂起转而执行内核中的中断服务。\n  线程上下文切换  在同一进程中的线程进行上下文切换，切换时，只需要切换线程的私有数据、寄存器等，消耗资源少。 在不同进程的中的线程进行上下文切换，切换与进程的上下文切换一致。  中断上下文切换  中断上下文切换只包括内核态中断服务程序执行所需要的状态（CPU寄存器，内核堆栈，硬件中断参数等）（CPU寄存器，内核堆栈，硬件中断参数等）  参考文献： 极限好文！Linux 性能优化全景指南\n","date":"2022-03-15T22:00:38+08:00","image":"https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%BA%8C/3_hu66cf5664c43f449fa744670ec4319b24_173122_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%BA%8C/","title":"linux 性能优化(二)"},{"content":"Linux常用的性能查看命令 CPU CPU的性能指标  cup的使用率分为：    用户CPU使用率，主要包括用户态和低优先级用户态，反应的是应用程序的cpu的使用情况 系统CPU使用率，cpu在内核态运行的时间百分比,不包含中断。反应的是内核的使用情况 等待IO的CPU使用率，反应的是系统与硬件IO的交互的情况 软/硬中断CPU的使用率，反应的中断的发生的情况 steal CPU / guest CPU, 表示虚拟机占用的CPU百分比.    在理想情况下，平均负载等于逻辑CPU个数(几核的CPU),表示每个CUP都被充分使用。大于这个逻辑CPU个数表示负载较大 CUP缓存率指的是CPU缓存的复用情况。命中率越高表示性能越好，其中L1/L2常用在单核,L3则用在多核中  CPU的优化  用户态的优化，即应用程序的的优化，尽可能的减少cpu的上下文的切换 内核态的优化，即内核的优化，可以CPU绑定，调整有优先级，中断的负载均衡等  性能工具  根据不同的性能指标来找合适的工具\n\r 根据指标查找 \r  CPU性能查看  使用ps查看正在运行的进程 \r \r 使用top查看各cup的使用情况、对应内存以及个进程占cpu和使用内存的情况 \r vmstat命令：查看CPU负载 \r  内存使用情况查看  除了使用top可以查看内存使用情况外，还可以使用free命令进行查看 \r  磁盘I/O性能查看  可以使用df 或者 df -h 查看磁盘占用用情况 \r iostat -d 进行查看 \r  查看网络情况  使用ifconfig查看或者修改网络 \r netstat命令：-i 查看网络接口信息，-r 检测系统路由表信息 \r  动态监控性能  使用watch命令：动态监控，默认2秒钟执行一次，执行结果更新在屏幕上 \r \r  ","date":"2022-03-05T22:00:38+08:00","image":"https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%80/3_hu66cf5664c43f449fa744670ec4319b24_173122_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/linux-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B8%80/","title":"linux 性能优化(一)"},{"content":"数据切分  当数据库中的数据或者单表数据过大时，会影响对数据库查询等操作的效率。此时可以减轻数据库的负担 可以将数据库进行拆分，即分库分表。来提高数据库的效率。 数据库有两种拆分方式：水平切分和垂直切分  垂直切分 垂直分库  垂直分库：根据业务解耦，以表为单位，将相同业务的表存储在同一数据库中。将大数据库拆分为不同的小数据库。 小数据库的结构和存储的数据不一样。小数据库的并集为大数据库。 \r 使用场景高并发时，将数据分类到不同数据库中，提升数据库的查询效率  垂直分表  垂直分表：是以字段为单位，将表中的不常用的字段和字段名较长的字段拆分到扩展表中，其余放入到主表中。也可以经热数据放入主表，冷 数据放入拓展表。主表和拓展表的数据结构和存储的数据是不一样。将表中的进行冷热数据的拆分，减少了对磁盘io的操作，提升数据库的效率 \r 使用场景：表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈  优缺点  优点：业务解耦合，方便对不同业务进行管理，提升数据库的效率 缺点：部分表不能join,表中的热数据太多  水平切分 水平分库和分表  都是以字段为单位，通过哈希和随机等策略，将数据分到不同的子库或者子表中。 所有的子库和子表的数据结构一样和数据不一致，即所有子库的数据等于数据库中的数据。形成分布式的效果。 \r 使用场景：数据量行数巨大，存在单库读写、存储性能瓶颈，数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。  优缺点  优点：提升系统稳定性和负载能力 缺点：事务一致性难以保证  数据库的瓶颈  数据库的瓶颈可分为：io瓶颈和cpu瓶颈  io瓶颈  磁盘读写io瓶颈：当热数据过多时，数据库内存(buffer Pool)保存不下时，会产生大量的io。此时就需要进行分库和垂直分表。 网络io瓶颈：请求的数据太多，网络带宽不够，此时就需要分库。  CPU瓶颈  sql中使用了大量的cpu运算的操作。此时需要优化sql,如增加索引 单表数据量大时，且进行全表扫描，查询效率低时，需要水平分表分库。   参考文献： 数据库分库分表思路\n","date":"2022-03-01T22:00:38+08:00","image":"https://zcj-git520.github.io/p/mysql%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/3_hu5261706da37be2572fd4622db307b63b_273707_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/mysql%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98-%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/","title":"mysql性能调优-分库分表"},{"content":"事务  事务就是一组原子性的SQL语句.  buffer Pool  当启动mysql会开启默认为128M的内存空间来保存从磁盘获取的页的数据到这块内存空间。 \r InnoDB通过free链表来管理buffer Pool中的空闲页，通过控制块来指向空白页.即从磁盘中的获取的页数据通过 控制块放入到buffer Pool中对应的空闲页中。 通过flush链表来管理buffer Poll中的脏页(通过事务修改过的页)。通过链表中控制块指向脏页。 通过lru链表来对Buffer Pool中的页进行淘汰。通过头插法将最新的页插入到链表中的控制块。当buffer Pool中的页满后，删除链表最后的控制块。 也存在当全表扫描时，也造成数据的覆盖，性能下降。因此链表被划分为热数据区域(5/8)和冷数据区域(3/8)。当两次访问页的时间大于1秒时，把页放入到热数据的控制块 ，否则就放入冷数据页，避免了全表扫描造成热数据被覆盖。生成redo log后，mysql通过后台进程经将脏页持久化到磁盘。当MySQL挂了之后， 会通过redo log恢复数据。 \r \r  事务具有的ACID的特性  原子性:事务中所有的操作那么全部提交成功，要么全部失败回滚 一致性：数据库总是从一个一致性状态转换到另一个一致性的状态 隔离性：一个事务在所做修改在提交前对其他事务是不可见的 持久性：一旦事务提交，说有的修改都会永久保存在数据库中  事务的隔离级别  读未提交：事务中的修改即使未提交也是对其他事务可见，这级别的事务隔离有脏读、重复读、幻读的问题。 读也提交：事务提交后所做的修改才会被另一个事务所看见，可能产生一个事务中两次查询的结果不同。 可重复读： 只有当前事务提交才能看见另一个事务的修改结果。解决了一个事务中两次查询的结果不同的问题。 可串行化：只有一个事务提交之后才会执行另一个事务。 \r  死锁  死锁：两个或多个事务在同一资源上相互占用并请求锁定对方占用的资源，从而导致恶性循环的现象。MySQL的部分存储引擎能够检测到死锁的循环依赖并产生相应的错误。InnoDB引擎解决死锁的方案是将持有最少排它锁的事务进行回滚  MVCC原理  mvcc 多版本并发控制：指在读取数据时通过一种类似快照的方式将数据保存下来，这样读锁和写锁不冲突。是 innodb 实现事务并发与回滚的重要功能。  版本链  每次更新后，都会将旧值放到一条 undo log 中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被roll_ptr 属性连接成一个链表，我们把这个链表称之为版本链，版本链的头节点就是当前记录最新的值   trx_id：每次一个事务对某条聚簇索引记录进行改动时，都会把该事务的事务id赋值给trx_id隐藏列。 roll_pointer：每次对某条聚簇索引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。\n ReadView  InnoDB提出了一个ReadView的概念，这个ReadView 中有个 id 列表 trx_ids 来存储系统中当前活跃着的读写事务，也就是 begin 了还未 commit 或 rollback 的事务  参考文献： MySQL运行原理与基础架构\n","date":"2022-02-25T22:00:38+08:00","image":"https://zcj-git520.github.io/p/mysql%E4%BA%8B%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/1_hub1d649ce0ea89887083315ebed128a77_18394_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/mysql%E4%BA%8B%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/","title":"mysql事务实现基本原理"},{"content":"索引  索引是帮助数据库获取有序数据的数据结构，实现快速检索  数据库索引的数据结构 哈希表(hash)  通过哈希函数，实现key-value的存储，同时可以使用开放地址法和拉链法解决哈希冲突，对查询单个值的 时间复杂度为O(1)，例如查找id=1：select * from user where id=1 ,但对范围查询十分的不友好,例如查找范围id\u0026gt;100的值：select * from user where id \u0026gt;100;  二叉树  二叉树的数据结构左小右大，可以通过中序遍历直接获取所有升序的数据，二叉树的查询的时间复杂度为 O(lgn),缺点是二叉树容易退化链表，增加数据的查找的时间。在最坏的情况下的时间复杂度为O(n)  平衡二叉树(AVL)和红黑树  通过左旋和右旋以及节点颜色的改变等方式调整树避免退化为链表，使二叉树保持平衡转态，保证树的查找性能 即时间复杂度在O(lgn)。但是二叉树不适合用做数据的底层数据结构原因如下：   1.数据库的查询的瓶颈在于对磁盘io的操作，当存储大量数据的情况下，要保证树的平衡的时候，树的高度 是在不断的增加，在对每一个节点的操作时，就是对磁盘io的操作，即对磁盘io的操作过于的频繁，增加了对数据库 查询等时间。 2 每个节点的分配的内存是16kb的数据量，对于二叉树的节点保持的数据是下于16KB,当数据过低时，也会造成内存的浪费\n B树  B树是一种平衡多分树，节点最多含有N颗子树(指针)，N-1个关键字(数据存储空间) (N\u0026gt;=2);除了根节点和叶子节点外，其它每个节点至少有M=N/2个子节点，M向上取整，即分裂的时候从中间分开，分成M棵子树； 若根节点不是叶子结点，则至少有两颗子树。B树解决了二叉树的高度问题，即减少了对磁盘io的操作，减少了数据库的时间,查询的时间复杂度为 h*O(lgn),h为树的高度。但是也存在一下问题   1.不太适合范围的查询，存在索引的失效 2.稳定性较弱，节点存储的数据较大，占用的内存空间较大\n B+树  B+树和B树类似,B+树的非叶子节点不会存储数据，只存储索引值(指针地址)，所有的数据都是存储在叶子节点，其目的是为了增加系统的稳定性。 应为节点存储的索引，叶子节点存储数据，叶子节点用了链表连接起来，这个链表本身就是有序的，在数据范围查找时，更具备效率 ，保证了存储空间的使用。高度不高，减少了对磁盘的io的操作，保证了查询的效率。  存储引擎 InnoDB引擎 引擎特点 1.将数据存储在表空间中，表空间由一系列的数据文件组成，由InnoDB管理；\n2.支持每个表的数据和索引存放在单独文件中(innodb_file_per_table)；\n3.支持事务，采用MVCC来控制并发，并实现标准的4个事务隔离级别，支持外键；\n4.索引基于聚簇索引建立，对于主键查询有较高性能；\n5.数据文件的平台无关性，支持数据在不同的架构平台移植；\n6.能够通过一些工具支持真正的热备。如XtraBackup等；\n7.内部进行自身优化如采取可预测性预读，能够自动在内存中创建hash索引等。\n引擎实现  InnoDB是采用的是B+树作为索引的结构，其存储文件分别是.frm表的定义文件和.idb的数据文件。InnoDB是支持行锁和表锁的。InnoDB 支持事务，且支持四种隔离级别（读未提交、读已提交、可重复读、串行化），默认的为可重复读 表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 \r  MyISAM引擎 引擎特点 1.MySQL5.1中默认，不支持事务和行级锁；\n2.提供大量特性如全文索引、空间函数、压缩、延迟更新等；\n3.数据库故障后，安全恢复性差；\n4.对于只读数据可以忍受故障恢复，MyISAM依然非常适用；\n5.日志服务器的场景也比较适用，只需插入和数据读取操作；\n6.不支持单表一个文件，会将所有的数据和索引内容分别存在两个文件中；\n7.MyISAM对整张表加锁而不是对行，所以不适用写操作比较多的场景；\n8.支持索引缓存不支持数据缓存。\n引擎实现 MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。其存储的文件有三个分别是：.frm表的定义文件、.MYD为数据文件和.MYL索引文件。 Myisam 只支持表锁，且不支持事务。Myisam 由于有单独的索引文件，在读取数据方面的性能很高\n 参考文献： MySQL运行原理与基础架构\n","date":"2022-02-20T22:00:38+08:00","image":"https://zcj-git520.github.io/p/mysql%E5%BA%95%E5%B1%82%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/1_huc45b7cee299d4b0bd96f8dd390c7ebfb_163533_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/mysql%E5%BA%95%E5%B1%82%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/","title":"mysql底层基本原理"},{"content":"平衡二叉树 数据结构定义 // 定义树的节点\rtype AVLTreeNode struct {\rinfo int // 定义存储的内容\rheight int // 树的高度\rright *AVLTreeNode // 右节点\rleft *AVLTreeNode // 左节点\r}\r// 定义树\rtype AVLTree struct {\rroot *AVLTreeNode // 定义根节点\r}\r// 创建节点\rfunc creatNode(data int) *AVLTreeNode{\rreturn \u0026amp;AVLTreeNode{\rinfo: data,\rheight: -1,\rright: nil,\rleft: nil,\r}\r}\r数据操作  增删改查  数据的插入 \r// 数据的插入\rfunc getHeight(node *AVLTreeNode) int {\rif node == nil{\rreturn -1\r}\rreturn node.height\r}\r// 左子树调整\rfunc (a *AVLTree)leftTreeAdjust(node *AVLTreeNode, data int) *AVLTreeNode {\r// 判断是否需要调整树\rif getHeight(node.left) - getHeight(node.right) \u0026gt; 1{\r// 插入的节点在左边上，进右旋\rif data \u0026lt; node.left.info{\rreturn a.lR(node)\r}else{\r// 进行左右旋\rreturn a.rLR(node)\r}\r}\rreturn node\r}\r// 右子树调整\rfunc (a *AVLTree)rightTreeAdjust(node *AVLTreeNode, data int) *AVLTreeNode {\r// 判断是否需要调整树\rif getHeight(node.right) - getHeight(node.left) \u0026gt; 1{\r// 插入的节点在右边上，进左旋\rif data \u0026gt;= node.right.info{\rreturn a.rR(node)\r}else{\r// 进行右左旋\rreturn a.lRR(node)\r}\r}\rreturn node\r}\rfunc (a *AVLTree)insertNode(node **AVLTreeNode, data int) {\rif *node == nil{\r*node = creatNode(data)\r(*node).height = maxValue(getHeight((*node).left), getHeight((*node).right)) + 1\rreturn\r}\r// 插入左子树\rif data \u0026lt; (*node).info{\ra.insertNode(\u0026amp;(*node).left, data)\r// 调整树\r*node = a.leftTreeAdjust(*node, data)\r}else{\r// 插入右子树\ra.insertNode(\u0026amp;(*node).right, data)\r// 调整树\r*node = a.rightTreeAdjust(*node, data)\r}\r// 调整节点的高度\r(*node).height = maxValue(getHeight((*node).left), getHeight((*node).right)) + 1\r}\rfunc (a *AVLTree)InsertData(data int ) {\r// 如果树为空\rif a.root == nil{\ra.root = creatNode(data)\ra.root.height = 0\rreturn\r}\ra.insertNode(\u0026amp;a.root, data)\r}\r数据的删除 // 清空树\rfunc (a *AVLTree)Clear(){\ra.root = nil\r}\r// 删除节点\rfunc (a *AVLTree)deleteNode(node **AVLTreeNode, data int) {\rif *node == nil{\rfmt.Printf(\u0026quot;no find data is %d \\n\u0026quot;, data)\rreturn\r}\rif (*node).info == data{\r// 如果右节点为nil\rif (*node).right == nil{\r*node = (*node).left\r}else if (*node).left == nil{\r*node = (*node).right\r}else{\r// 找出左子树的最大值\rtemp := (*node).left\rprev := *node // 左子树最大值的最前驱节点\rfor ; temp.right != nil; temp = temp.right{\rprev = temp\r}\r// 左子树的最大值复制给node\r(*node).info = temp.info\rif prev == *node{ // 如果左子树的最大值为node的node的子节点\rprev.left = temp.left // 先驱节点的左节点指向左子树最大节点的左节点\r}else{\rprev.right = temp.left // 先驱节点的右节点指向左子树最大节点的右节点\r}\ra.leftTreeAdjust(*node, data)\r}\rif *node != nil{\r// 调整节点的高度\r(*node).height = maxValue(getHeight((*node).left), getHeight((*node).right)) + 1\r}\rreturn\r}else if (*node).info \u0026gt; data{\ra.deleteNode(\u0026amp;(*node).left, data)\ra.leftTreeAdjust(*node, data)\r}else {\ra.deleteNode(\u0026amp;(*node).right, data)\ra.rightTreeAdjust(*node,data)\r}\r(*node).height = maxValue(getHeight((*node).left), getHeight((*node).right)) + 1\r}\rfunc (a *AVLTree)Remove(data int) {\rif a.root == nil{\rreturn\r}\ra.deleteNode(\u0026amp;a.root, data)\r}\r// 得到最大值\rfunc maxValue(value, value1 int) int {\rif value \u0026gt;= value1{\rreturn value\r}\rreturn value1\r}\r数据的查询  前序遍历、中序遍历、后续遍历、值查询  // 树的遍历\r// 前序遍历\rfunc (a *AVLTree)nLR(node *AVLTreeNode){\r// 如果节点为空就返回\rif node == nil{\rreturn\r}\rfmt.Printf(\u0026quot;%d-\u0026gt;\u0026quot;, node.info)\r// 遍历左子树\ra.nLR(node.left)\r// 遍历右子树\ra.nLR(node.right)\r}\r// 中序遍历\rfunc (a *AVLTree)lNR(node *AVLTreeNode){\r// 如果节点为空就返回\rif node == nil{\rreturn\r}\ra.lNR(node.left)\rfmt.Printf(\u0026quot;%d-\u0026gt;\u0026quot;, node.info)\ra.lNR(node.right)\r}\r// 后序遍历\rfunc (a *AVLTree)lRN(node *AVLTreeNode){\rif node == nil{\rreturn\r}\ra.lRN(node.left)\ra.lRN(node.right)\rfmt.Printf(\u0026quot;%d-\u0026gt;\u0026quot;, node.info)\r}\r// 前序显示\rfunc (a *AVLTree)ShowNLR(){\rif a.root == nil{\rfmt.Println(\u0026quot;zhe tree is empty\u0026quot;)\rreturn\r}\rfmt.Print(\u0026quot;NLR:\u0026quot;)\rnode := a.root\ra.nLR(node)\rfmt.Println()\r}\r// 中序显示\rfunc (a *AVLTree)ShowLNR(){\rif a.root == nil{\rfmt.Println(\u0026quot;zhe tree is empty\u0026quot;)\rreturn\r}\rfmt.Print(\u0026quot;LNR:\u0026quot;)\rnode := a.root\ra.lNR(node)\rfmt.Println()\r}\r// 后序显示\rfunc (a *AVLTree)ShowLRN(){\rif a.root == nil{\rfmt.Println(\u0026quot;zhe tree is empty\u0026quot;)\rreturn\r}\rfmt.Print(\u0026quot;LRN:\u0026quot;)\rnode := a.root\ra.lRN(node)\rfmt.Println()\r}\r树的旋转  单左旋 单右旋 左右旋 右左旋  // 单右旋\rfunc (a *AVLTree)lR(node *AVLTreeNode) *AVLTreeNode {\r// 临时node 指向节点的左节点\rtemp := (*node).left\r// node的左节点指向temp 的右节点\r(*node).left = temp.right\r// temp 的右节点指向node（node 为temp的右节点的）\rtemp.right = node\r// 调整高度\r(*node).height = maxValue(getHeight((*node).left), getHeight((*node).right)) + 1\rtemp.height = maxValue(getHeight(temp.left), getHeight(temp.right)) + 1\rreturn temp\r}\r// 单左旋\rfunc (a *AVLTree)rR(node *AVLTreeNode) *AVLTreeNode {\r// 临时node 指向节点的右节点\rtemp := (*node).right\r// node的右节点指向temp的左节点\r(*node).right = temp.left\r// temp的左节点指向node\rtemp.left = node\r// 调整树的高度\r(*node).height = maxValue(getHeight((*node).left), getHeight((*node).right)) + 1\rtemp.height = maxValue(getHeight(temp.left), getHeight(temp.right)) + 1\rreturn temp\r}\r// 左右旋(先左旋在右旋)\rfunc (a *AVLTree)rLR(node *AVLTreeNode) *AVLTreeNode {\rnode.left = a.rR(node.left)\rreturn a.lR(node)\r}\r// 右左旋(先右旋再左旋)\rfunc (a *AVLTree)lRR(node *AVLTreeNode) *AVLTreeNode {\rnode.right = a.lR(node.right)\rreturn a.rR(node)\r}\r测试 \rfunc TestAVRTree_InsertData(t *testing.T) {\ravl := CreatAVLTree()\ravl.InsertData(2)\ravl.InsertData(12)\ravl.InsertData(24)\ravl.InsertData(1)\ravl.InsertData(65)\ravl.InsertData(72)\ravl.InsertData(32)\ravl.InsertData(21)\ravl.ShowNLR()\ravl.ShowLNR()\ravl.ShowLRN()\r}\rfunc TestAVLTree_Remove(t *testing.T) {\ravl := CreatAVLTree()\ravl.InsertData(1)\ravl.InsertData(2)\ravl.InsertData(3)\ravl.InsertData(4)\ravl.InsertData(5)\ravl.InsertData(6)\ravl.InsertData(7)\ravl.InsertData(8)\ravl.ShowNLR()\ravl.ShowLNR()\ravl.ShowLRN()\rfmt.Println(\u0026quot;**********************\u0026quot;)\ravl.Remove(4)\ravl.ShowNLR()\ravl.ShowLNR()\ravl.ShowLRN()\r}\rfunc TestAVLTree_IsValue(t *testing.T) {\ravl := CreatAVLTree()\ravl.InsertData(1)\ravl.InsertData(2)\ravl.InsertData(3)\ravl.InsertData(4)\ravl.InsertData(5)\ravl.InsertData(6)\ravl.InsertData(7)\ravl.InsertData(8)\ravl.ShowNLR()\ravl.ShowLNR()\ravl.ShowLRN()\rdata := 4\ris := avl.IsValue(data)\rif is{\rfmt.Printf(\u0026quot;%d :is exits\\n\u0026quot;, data)\r}else{\rfmt.Printf(\u0026quot;%d :is not exits\\n\u0026quot;, data)\r}\r}\r源码  我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForGo/tree/master/tree/AVL_tree  ","date":"2022-02-15T21:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-avl-tree-go%E5%AE%9E%E7%8E%B0/1_hu627ccad35150ba5c25206c4fe774bc3e_21463_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-avl-tree-go%E5%AE%9E%E7%8E%B0/","title":"数据结构-AVL tree go实现"},{"content":"平衡二叉树 数据结构定义 \r// 定义树的节点\rtemplate\u0026lt;class T\u0026gt;\rclass AvrTreeNode\r{\rpublic:\rAvrTreeNode(){};\rAvrTreeNode(T data)\r{\rthis-\u0026gt;data = data;\rleft = 0;\rright = 0;\rhight = -1;\r}\r~AvrTreeNode(){};\rT data; // 存储的数据\rAvrTreeNode *left; // 左子树\rAvrTreeNode *right; // 右子树\rint hight; // 高度 };\r// 定义树\rtemplate\u0026lt;class T\u0026gt;\rclass AvrTree\r{\rprivate:\rAvrTreeNode\u0026lt;T\u0026gt; *root; // 定义根节点\r// 插入节点\rvoid inseartNode(AvrTreeNode\u0026lt;T\u0026gt;*\u0026amp; node, const T data);\rvoid deleteNodeAll(AvrTreeNode\u0026lt;T\u0026gt; *node); // 删除所有节点\r// 显示节点\rvoid DLR(AvrTreeNode\u0026lt;T\u0026gt; *node);\rvoid LDR(AvrTreeNode\u0026lt;T\u0026gt; *node);\rvoid LRD(AvrTreeNode\u0026lt;T\u0026gt; *node);\r// 删除*\u0026amp;代表指针引用\rbool deleteNode(AvrTreeNode\u0026lt;T\u0026gt;*\u0026amp; node, const T data);\r// void deleteNodeByMerge(AvrTreeNode\u0026lt;T\u0026gt;*\u0026amp; node); // 合并删除\r// void deleteNodeByCopy(AvrTreeNode\u0026lt;T\u0026gt;*\u0026amp; node); // 复制删除\r// 单右旋\rvoid LL(AvrTreeNode\u0026lt;T\u0026gt; *\u0026amp;node);\r// 单左旋\rvoid RR(AvrTreeNode\u0026lt;T\u0026gt; *\u0026amp;node);\r// 左右旋\rvoid RLR(AvrTreeNode\u0026lt;T\u0026gt; *\u0026amp;node);\r// 右左旋\rvoid LRR(AvrTreeNode\u0026lt;T\u0026gt; *\u0026amp;node);\r// 求高度的最大值\rint maxHight(int h1, int h2)\r{\rreturn h1\u0026gt;h2 ? h1:h2;\r}\r// 得到树的高度\rint getTreeHight(AvrTreeNode\u0026lt;T\u0026gt; *node)\r{\rif(!node)\r{\rreturn -1;\r}\rreturn node-\u0026gt;hight;\r}\rpublic:\rAvrTree(/* args */)\r{\rroot = 0;\r}\r~AvrTree();\r// 清空树\rvoid clear();\r// 是否为空树\rbool isEmpty()\r{\rreturn root == 0;\r}\r// 插入数据\rvoid inseartData(const T data);\r// 深度优先遍历树\r// 前序遍历(DLR 根-\u0026gt;左-\u0026gt;右)\rvoid showNodeByDLR();\r// 中序遍历(LDR 左-\u0026gt;根-\u0026gt;右)\rvoid showNodeByLDR();\r// 后序遍历(LRD 左-\u0026gt;右-\u0026gt;根)\rvoid showNodeByLRD();\r// 删除节点的数据\rbool remove(const T data);\r// LVR查找树\rbool LVRSearchData(const T data);\r};\r数据操作  增删改查  数据的插入 \r// 数据的插入\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::inseartNode(AvrTreeNode\u0026lt;T\u0026gt; *\u0026amp; node, const T data)\r{\r// 如果节点为空\rif(node == 0)\r{\rnode = new AvrTreeNode\u0026lt;T\u0026gt;(data);\rreturn;\r}\r// 插入在左子树\rif(data \u0026lt; node-\u0026gt;data)\r{\rinseartNode(node-\u0026gt;left, data);\r// 树不平衡时\rif(getTreeHight(node-\u0026gt;left) - getTreeHight(node-\u0026gt;right) \u0026gt; 1)\r{\r// 当值比左节点的值小时，则进行单右旋\rif(data \u0026lt; node-\u0026gt;left-\u0026gt;data)\r{\rLL(node);\r}\r// 否则进行左右旋\relse\r{\rRLR(node);\r}\r} }\r// 插入在右子树\relse\r{\rinseartNode(node-\u0026gt;right, data);\r// 树不平衡时\rif(getTreeHight(node-\u0026gt;right) - getTreeHight(node-\u0026gt;left) \u0026gt; 1)\r{\r// 当值比右节点的值大时，则进行单左旋\rif(data \u0026gt;= node-\u0026gt;right-\u0026gt;data)\r{\rRR(node);\r}\r// 否则进行右左旋\relse\r{\rLRR(node);\r}\r}\r}\r// 重新计算节点的高度，节点的深度+1\rnode-\u0026gt;hight = maxHight(getTreeHight(node-\u0026gt;left), getTreeHight(node-\u0026gt;right)) + 1;\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::inseartData(const T data)\r{\r// 如果为空树\rif(isEmpty())\r{\rroot = new AvrTreeNode\u0026lt;T\u0026gt;(data);\rroot-\u0026gt;hight = 0;\rreturn;\r}\rinseartNode(root, data);\r}\r数据的删除 \r// 数据的删除\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::deleteNodeAll(AvrTreeNode\u0026lt;T\u0026gt; *node)\r{\rif(node == 0)\r{\rreturn;\r}\r// 删除左节点\rdeleteNodeAll(node-\u0026gt;left);\r// 删除右节点\rdeleteNodeAll(node-\u0026gt;right);\r// 释放节点\rdelete node;\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::clear()\r{\r// 如果为空树，直接返回\rif(root == 0)\r{\rreturn;\r}\rdeleteNodeAll(root);\r}\rtemplate\u0026lt;class T\u0026gt;\rbool AvrTree\u0026lt;T\u0026gt; ::deleteNode(AvrTreeNode\u0026lt;T\u0026gt; *\u0026amp; node, const T data)\r{\r// 如果节点为空，直接返回，表示未找到数据\rif(!node)\r{\rcout \u0026lt;\u0026lt; \u0026quot;no find:\u0026quot; \u0026lt;\u0026lt; data \u0026lt;\u0026lt; endl;\rreturn false;\r}\r// 找到数据节点\rif(data == node-\u0026gt;data)\r{\rAvrTreeNode\u0026lt;T\u0026gt; *temp = node;\r// 只有右节点\rif(!node-\u0026gt;left)\r{\rnode = node-\u0026gt;right;\r}\r// 只有左节点\relse if(!node-\u0026gt;right)\r{\rnode = node-\u0026gt;left;\r}\relse\r{\r// 采用合并的方式进行删除节点\rtemp = node-\u0026gt;left;\r// 找到左子树的做大值\rwhile (temp-\u0026gt;right)\r{\rtemp = temp-\u0026gt;right;\r}\rtemp-\u0026gt;right = node-\u0026gt;right;\rtemp = node;\rnode = node-\u0026gt;left;\r// 是否对树进行调整\rif(getTreeHight(node-\u0026gt;left)-getTreeHight(node-\u0026gt;right) \u0026gt; 1)\r{\r// 值比最大值大或者等于，就采用单左旋\rif(data \u0026gt;= node-\u0026gt;right-\u0026gt;data)\r{\rRR(node);\r}\r//采用先右旋在左旋\relse\r{\rLRR(node);\r}\r}\r}\r// 删除节点，返回\rdelete temp;\rif(node)\r{\rnode-\u0026gt;hight = maxHight(getTreeHight(node-\u0026gt;right), getTreeHight(node-\u0026gt;right)) + 1;\r}\rreturn true;\r}\r// 在左子树查找\relse if(data \u0026lt; node-\u0026gt;data)\r{\rdeleteNode(node-\u0026gt;left, data);\r// 是否对树进行调整\rif(getTreeHight(node-\u0026gt;left)-getTreeHight(node-\u0026gt;right) \u0026gt; 1)\r{\r// 如果值比左子树小，就采用单右旋，\rif(data \u0026lt; node-\u0026gt;left-\u0026gt;data)\r{\rLL(node);\r}\r// 采用先左旋在右旋\relse\r{\rRLR(node);\r}\r}\r}\r// 在右子树查找\relse\r{\rdeleteNode(node-\u0026gt;right, data);\r// 是否要对树进行调整\rif(getTreeHight(node-\u0026gt;right) - getTreeHight(node-\u0026gt;left) \u0026gt; 1)\r{\r// 值比最大值大或者等于，就采用单左旋\rif(data \u0026gt;= node-\u0026gt;right-\u0026gt;data)\r{\rRR(node);\r}\r// 采用先右旋在左旋\relse\r{\rLRR(node);\r}\r}\r}\r// 对节点的深度进行调整\rnode-\u0026gt;hight = maxHight(getTreeHight(node-\u0026gt;right), getTreeHight(node-\u0026gt;right)) + 1;\r}\rtemplate\u0026lt;class T\u0026gt;\rbool AvrTree\u0026lt;T\u0026gt; ::remove(const T data)\r{\r// 如果为空树\rif(isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;this tree is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn false;\r}\rreturn deleteNode(root, data);\r}\r数据的查询  前序遍历、中序遍历、后续遍历、值查询  // 数据的查询\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::DLR(AvrTreeNode\u0026lt;T\u0026gt; *node)\r{\rif(!node)\r{ return;\r}\r// 前序遍历(DLR)(根-\u0026gt;左-\u0026gt;右)\rcout \u0026lt;\u0026lt; node-\u0026gt;data \u0026lt;\u0026lt; \u0026quot;-\u0026gt;\u0026quot;;\rDLR(node-\u0026gt;left);\rDLR(node-\u0026gt;right);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::LDR(AvrTreeNode\u0026lt;T\u0026gt; *node)\r{\rif(!node)\r{\rreturn;\r}\r// 中序遍历(LDR)(左-\u0026gt;根-\u0026gt;右)\rLDR(node-\u0026gt;left);\rcout \u0026lt;\u0026lt; node-\u0026gt;data \u0026lt;\u0026lt; \u0026quot;-\u0026gt;\u0026quot;;\rLDR(node-\u0026gt;right);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::LRD(AvrTreeNode\u0026lt;T\u0026gt; *node)\r{\rif(!node)\r{\rreturn;\r}\r// 后序遍历(LRD)(左-\u0026gt;右-\u0026gt;根)\rLRD(node-\u0026gt;left);\rLRD(node-\u0026gt;right);\rcout \u0026lt;\u0026lt; node-\u0026gt;data \u0026lt;\u0026lt; \u0026quot;-\u0026gt;\u0026quot;;\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::showNodeByDLR()\r{\rif(isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;this tree is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn;\r}\r// 遍历树\rAvrTreeNode\u0026lt;T\u0026gt; *node = root;\rcout \u0026lt;\u0026lt; \u0026quot;DLR: \u0026quot;;\rDLR(node); cout \u0026lt;\u0026lt; endl;\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::showNodeByLDR()\r{\rif(isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;this tree is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn;\r}\r// 遍历树\rAvrTreeNode\u0026lt;T\u0026gt; *node = root;\rcout \u0026lt;\u0026lt; \u0026quot;LDR: \u0026quot;;\rLDR(node); cout \u0026lt;\u0026lt; endl; }\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::showNodeByLRD()\r{\rif(isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;this tree is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn;\r}\r// 遍历树\rAvrTreeNode\u0026lt;T\u0026gt; *node = root;\rcout \u0026lt;\u0026lt; \u0026quot;LRD: \u0026quot;;\rLRD(node); cout \u0026lt;\u0026lt; endl; }\rtemplate\u0026lt;class T\u0026gt;\rbool AvrTree\u0026lt;T\u0026gt; ::LVRSearchData(const T data)\r{\r// 如果树为空就直接返回\rif(isEmpty())\r{\rreturn false;\r}\rAvrTreeNode\u0026lt;T\u0026gt; *node = root;\rwhile (node)\r{\rif(data == node-\u0026gt;data)\r{\rreturn true;\r}\relse if(data \u0026lt; node-\u0026gt;data)\r{\rnode = node-\u0026gt;left;\r}\relse\r{\rnode = node-\u0026gt;right;\r}\r}\rreturn false;\r}\r树的旋转  单左旋 单右旋 左右旋 右左旋  // 节点的旋转\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::LL(AvrTreeNode\u0026lt;T\u0026gt; *\u0026amp; node)\r{\r// 临时节点为节点的左节点\rAvrTreeNode\u0026lt;T\u0026gt; *temp = node-\u0026gt;left;\r// 节点的左节点指向临时节点的右节点\rnode-\u0026gt;left = temp-\u0026gt;right;\r// 临时节点的右节点指向节点(将临时节点的设置为根)\rtemp-\u0026gt;right = node;\r// 重新获得树的高度\rtemp-\u0026gt;hight = maxHight(getTreeHight(temp-\u0026gt;left), getTreeHight(temp-\u0026gt;right)) + 1;\rnode-\u0026gt;hight = maxHight(getTreeHight(node-\u0026gt;left), getTreeHight(node-\u0026gt;right)) + 1;\r// 经node 重新指向temp, 即将temp设置为根节点，防止树的断\rnode = temp; }\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::RR(AvrTreeNode\u0026lt;T\u0026gt; *\u0026amp; node)\r{\r// 临时节点为节点的右节点\rAvrTreeNode\u0026lt;T\u0026gt; *temp = node-\u0026gt;right;\r// 节点的右节点指向临时节点的节点\rnode-\u0026gt;right = temp-\u0026gt;left;\r// 临时节点的左节点指向节点\rtemp-\u0026gt;left = node;\r// 重新计算树的高度\rtemp-\u0026gt;hight = maxHight(getTreeHight(temp-\u0026gt;left), getTreeHight(temp-\u0026gt;right)) + 1;\rnode-\u0026gt;hight = maxHight(getTreeHight(node-\u0026gt;left), getTreeHight(node-\u0026gt;right)) + 1;\r// 经node 重新指向temp, 即将temp设置为根节点，防止树的断\rnode = temp;\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::RLR(AvrTreeNode\u0026lt;T\u0026gt; *\u0026amp; node)\r{\r// 先进行左旋\rRR(node-\u0026gt;left);\r// 在进行右旋\rLL(node);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid AvrTree\u0026lt;T\u0026gt; ::LRR(AvrTreeNode\u0026lt;T\u0026gt; *\u0026amp; node)\r{\r// 先进行右旋\rLL(node-\u0026gt;right);\r// 在进行左旋\rRR(node);\r}\r测试 \rint main(int argc, char const *argv[])\r{\rAvrTree\u0026lt;int\u0026gt; avr;\ravr.inseartData(12);\ravr.inseartData(42);\ravr.inseartData(93);\ravr.inseartData(4);\ravr.inseartData(15);\ravr.inseartData(66);\ravr.inseartData(97);\ravr.showNodeByDLR();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\ravr.showNodeByLDR();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\ravr.showNodeByLRD();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\rbool ok = avr.remove(42);\rcout \u0026lt;\u0026lt; \u0026quot;remove is:\u0026quot; \u0026lt;\u0026lt; ok \u0026lt;\u0026lt; endl;\ravr.showNodeByDLR();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\ravr.showNodeByLDR();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\ravr.showNodeByLRD();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\rbool is = avr.remove(12);\rcout \u0026lt;\u0026lt; \u0026quot;remove is:\u0026quot; \u0026lt;\u0026lt; is \u0026lt;\u0026lt; endl;\ravr.showNodeByDLR();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\ravr.showNodeByLDR();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\ravr.showNodeByLRD();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\rbool is1 = avr.remove(661);\rcout \u0026lt;\u0026lt; \u0026quot;remove1 is:\u0026quot; \u0026lt;\u0026lt; is1 \u0026lt;\u0026lt; endl;\ravr.showNodeByDLR();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\ravr.showNodeByLDR();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\ravr.showNodeByLRD();\rcout \u0026lt;\u0026lt; \u0026quot;***********************************\u0026quot; \u0026lt;\u0026lt; endl;\rbool ok_ = avr.LVRSearchData(66);\rcout \u0026lt;\u0026lt; \u0026quot;SearchData is:\u0026quot; \u0026lt;\u0026lt; ok_ \u0026lt;\u0026lt; endl;\rsystem(\u0026quot;pause\u0026quot;);\rreturn 0;\r}\r源码  我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForC/tree/master/tree/avr_tree  ","date":"2022-01-10T21:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-avl-tree-c-%E5%AE%9E%E7%8E%B0/1_hu627ccad35150ba5c25206c4fe774bc3e_21463_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-avl-tree-c-%E5%AE%9E%E7%8E%B0/","title":"数据结构-AVL tree c++实现"},{"content":"二叉查找树 数据结构定义 \r// 定义树的节点\rtype binarySearchTreeNode struct {\rinfo int // 定义存储的内容\rleft *binarySearchTreeNode // 左节点\rright *binarySearchTreeNode // 右节点\r}\r// 定义树\rtype BinarySearchTree struct {\rroot *binarySearchTreeNode // 定义根节点\rnumNodes int // 节点树\r}\r// 创建节点\rfunc creatNode(data int) *binarySearchTreeNode{\rreturn \u0026amp;binarySearchTreeNode{\rinfo: data,\rleft: nil,\rright: nil,\r}\r}\r// 节点的数量\rfunc (b *BinarySearchTree)GetNodeNum()int{\rreturn b.numNodes\r}\r数据操作  增删改查  数据的插入 \r// 节点的插入\rfunc (b *BinarySearchTree) InsertNode(data int) {\rnewNode := creatNode(data)\r// 如果为空树\rif b.root == nil{\rb.root = newNode\rb.numNodes++\rreturn\r}\rnode := b.root\rfor {\r// 当值小于节点的值时，就往左子树插入\rif data \u0026lt; node.info{\r// 左节点为空，直接插入,跳出循环\rif node.left == nil{\rnode.left = newNode\rbreak\r}else{\r// 否则继续往左子树插\rnode = node.left\r}\r}else{\r// 当值大于等于节点的值时，就往右子树插入\r// 右节点为空，直接插入,跳出循环\rif node.right == nil{\rnode.right = newNode\rbreak\r}else {\r// 否则继续往右子树插\rnode = node.right\r}\r}\r}\r// 节点树+1\rb.numNodes++\r}\r数据的删除  复制删除法：   将被删除节点的左子树的最大值或者右子树的最小值复制给被删除的节点的数值， 然后删除左子树的最大值的节点或者右子树的最小值的节点\n 2.合并删除法：\n 从删除的节点的两棵子树合并未一棵树，然后将这颗树连接到删除节点的父节点 具体操作：左子树的最大值左作为有子树的父节点，左子树的根节点作为这棵树的根节点 或右子树的最小值作为左子树的父节点，右子树的根节点作为这棵树的根节点\n \r// 清空树\rfunc (b *BinarySearchTree) Clear(){\rb.root = nil\rb.numNodes = 0\r}\r//合并删除法：\r//从删除的节点的两棵子树合并未一棵树，然后将这颗树连接到删除节点的父节点\r//具体操作：左子树的最大值左作为有子树的父节点，左子树的根节点作为这棵树的根节点\r//或右子树的最小值作为左子树的父节点，右子树的根节点作为这棵树的根节点\r//\rfunc (b *BinarySearchTree)deleteByMerge(node **binarySearchTreeNode) {\r// 如果右节点为nil\rif (*node).right == nil{\r*node = (*node).left\r}else if (*node).left == nil{\r*node = (*node).right\r}else{\r// 找出左子树的最大值\rtemp := (*node).left\rfor ; temp.right != nil; temp = temp.right{}\r// 左子树的最大值的右节点指向右子树\rtemp.right = (*node).right\r// node的头指针指向这个树既指向左子树的头节点\r*node = (*node).left\r}\r}\r// 移除节点，通过合并的方法\rfunc (b *BinarySearchTree)RemoveByMerge(data int) bool{\r// 如果为空树\rif b.root == nil{\rreturn false\r}\r// 找到值的节点\rnode := b.root\rprev := b.root\rfor {\rif node == nil{\rreturn false\r}\rif node.info == data{\rbreak\r}\rprev = node\rif data \u0026lt; node.info{\rnode = node.left\r}else {\rnode = node.right\r}\r}\rif node == b.root{\rb.deleteByMerge(\u0026amp;b.root)\r}else if node == prev.left{\rb.deleteByMerge(\u0026amp;prev.left)\r}else{\rb.deleteByMerge(\u0026amp;prev.right)\r}\r// 节点树-1\rb.numNodes--\rreturn true\r}\r/*\r复制删除法：\r将被删除节点的左子树的最大值或者右子树的最小值复制给被删除的节点的数值，\r然后删除左子树的最大值的节点或者右子树的最小值的节点\r*/\rfunc (b *BinarySearchTree)deleteByCopy(node **binarySearchTreeNode) {\r// 如果右节点为nil\rif (*node).right == nil{\r*node = (*node).left\r}else if (*node).left == nil{\r*node = (*node).right\r}else{\r// 找出左子树的最大值\rtemp := (*node).left\rprev := *node // 左子树最大值的最前驱节点\rfor ; temp.right != nil; temp = temp.right{\rprev = temp\r}\r// 左子树的最大值复制给node\r(*node).info = temp.info\rif prev == *node{ // 如果左子树的最大值为node的node的子节点\rprev.left = temp.left // 先驱节点的左节点指向左子树最大节点的左节点\r}else{\rprev.right = temp.left // 先驱节点的右节点指向左子树最大节点的右节点\r}\r}\r}\r// 移除节点，通过复制的方法\rfunc (b *BinarySearchTree)RemoveByCopy(data int) bool{\r// 如果为空树\rif b.root == nil{\rreturn false\r}\r// 找到值的节点\rnode := b.root\rprev := b.root\rfor {\rif node == nil{\rreturn false\r}\rif node.info == data{\rbreak\r}\rprev = node\rif data \u0026lt; node.info{\rnode = node.left\r}else {\rnode = node.right\r}\r}\r//b.deleteByCopy(\u0026amp;node)\rif node == b.root{\rb.deleteByCopy(\u0026amp;b.root)\r}else if node == prev.left{\rb.deleteByCopy(\u0026amp;prev.left)\r}else{\rb.deleteByCopy(\u0026amp;prev.right)\r}\r// 节点树-1\rb.numNodes--\rreturn true\r}\r数据的查询  前序遍历、中序遍历、后续遍历、值查询  // 前序遍历\rfunc (b *BinarySearchTree) nLR(node *binarySearchTreeNode){\rif node == nil{\rreturn\r}\rfmt.Printf(\u0026quot;%d-\u0026gt;\u0026quot;, node.info)\rb.nLR(node.left)\rb.nLR(node.right)\r}\r// 中序遍历\rfunc (b *BinarySearchTree)lNR(node *binarySearchTreeNode){\rif node == nil{\rreturn\r}\rb.lNR(node.left)\rfmt.Printf(\u0026quot;%d-\u0026gt;\u0026quot;, node.info)\rb.lNR(node.right)\r}\r// 后序遍历\rfunc (b *BinarySearchTree)lRN(node *binarySearchTreeNode){\rif node == nil{\rreturn\r}\rb.lRN(node.left)\rb.lRN(node.right)\rfmt.Printf(\u0026quot;%d-\u0026gt;\u0026quot;, node.info)\r}\r// 前序显示\rfunc (b *BinarySearchTree)ShowNLR(){\rif b.root == nil{\rfmt.Println(\u0026quot;zhe tree is empty\u0026quot;)\rreturn\r}\rfmt.Print(\u0026quot;NLR:\u0026quot;)\rnode := b.root\rb.nLR(node)\rfmt.Println()\r}\r// 中序显示\rfunc (b *BinarySearchTree)ShowLNR(){\rif b.root == nil{\rfmt.Println(\u0026quot;zhe tree is empty\u0026quot;)\rreturn\r}\rfmt.Print(\u0026quot;LNR:\u0026quot;)\rnode := b.root\rb.lNR(node)\rfmt.Println()\r}\r// 后序显示\rfunc (b *BinarySearchTree)ShowLRN(){\rif b.root == nil{\rfmt.Println(\u0026quot;zhe tree is empty\u0026quot;)\rreturn\r}\rfmt.Print(\u0026quot;LRN:\u0026quot;)\rnode := b.root\rb.lRN(node)\rfmt.Println()\r}\r// 查找值是否存在\rfunc (b *BinarySearchTree)IsValue(data int) bool {\rif b.root == nil{\rreturn false\r}\rnode := b.root\rfor {\rif node == nil{\rreturn false\r}\rif node.info == data {\rreturn true\r}\rif data \u0026lt; node.info{\rnode = node.left\r}else {\rnode = node.right\r}\r}\r}\r树的创建 func NewBinarySearchTree() *BinarySearchTree {\rreturn \u0026amp;BinarySearchTree{\rroot: nil,\rnumNodes: 0,\r}\r}\r源码  我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForGo/tree/master/tree/binary_search_tree  ","date":"2022-01-05T21:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-binary-search-tree-go%E5%AE%9E%E7%8E%B0/1_hu163e0849e6d75821587eb02814146518_65785_120x120_fill_box_smart1.gif","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-binary-search-tree-go%E5%AE%9E%E7%8E%B0/","title":"数据结构-Binary search tree go实现"},{"content":"二叉查找树 数据结构定义 \r// 节点的定义\rtemplate\u0026lt;class T\u0026gt;\rclass BinarySearchTreeNode\r{\rpublic:\rBinarySearchTreeNode()\r{\rleft = 0;\rright = 0;\r}\rBinarySearchTreeNode(T data)\r{\rthis-\u0026gt;data = data;\rleft = 0;\rright = 0;\r}\r~BinarySearchTreeNode(){};\rT data; // 保存的节点的数据\rBinarySearchTreeNode *left; // 指向左节点\rBinarySearchTreeNode *right; // 指向右节点\r};\r// 树的定义\rtemplate\u0026lt;class T\u0026gt;\rclass BinarySearchTree\r{\rprivate:\rBinarySearchTreeNode\u0026lt;T\u0026gt; *root; // 定义头节点\rint treeNodeNum; // 树的节点数\rvoid deleteNodeAll(BinarySearchTreeNode\u0026lt;T\u0026gt; *node); // 删除所有节点\r// 显示节点\rvoid DLR(BinarySearchTreeNode\u0026lt;T\u0026gt; *node);\rvoid LDR(BinarySearchTreeNode\u0026lt;T\u0026gt; *node);\rvoid LRD(BinarySearchTreeNode\u0026lt;T\u0026gt; *node);\r// 删除*\u0026amp;代表指针引用\rvoid deleteNodeByMerge(BinarySearchTreeNode\u0026lt;T\u0026gt;*\u0026amp; node); // 合并删除\rvoid deleteNodeByCopy(BinarySearchTreeNode\u0026lt;T\u0026gt;*\u0026amp; node); // 复制删除\rpublic:\rBinarySearchTree()\r{\rroot = 0;\rtreeNodeNum = 0;\r};\r~BinarySearchTree();\r// 清空树\rvoid clear();\r// 节点的个数\rint Nodes()\r{\rreturn treeNodeNum;\r}\r// 是否为空树\rbool isEmpty()\r{\rreturn root == 0;\r}\r// 插入数据\rvoid inseartNode(const T data);\r// 深度优先遍历树\r// 前序遍历(DLR 根-\u0026gt;左-\u0026gt;右)\rvoid showNodeByDLR();\r// 中序遍历(LDR 左-\u0026gt;根-\u0026gt;右)\rvoid showNodeByLDR();\r// 后序遍历(LRD 左-\u0026gt;右-\u0026gt;根)\rvoid showNodeByLRD();\r// 删除节点的数据\r// 合并删除\rbool removeNodeMerge(const T data);\r// 复制删除\rbool removeNodeCopy(const T data);\r// 查找数据\rbool SearchData(const T data);\r};\r数据操作  增删改查  数据的插入 template\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::inseartNode(const T data)\r{\rBinarySearchTreeNode\u0026lt;T\u0026gt; *new_node = new BinarySearchTreeNode\u0026lt;T\u0026gt;(data);\r// 如果为空树\rif(isEmpty())\r{\rroot = new_node; // 新建节点设置为root 节点\rtreeNodeNum ++; // 树的节点数+1\rreturn;\r}\rBinarySearchTreeNode\u0026lt;T\u0026gt; *node = root;\r// 遍历树， 找到插入的节点的位置\rwhile (node != 0)\r{\r// 当节点的值大于插入的值时，就插入到左子数\rif(node-\u0026gt;data \u0026gt; data)\r{\r// 左节点为nill, 将新节点赋值给节点的左节点\rif(node-\u0026gt;left == NULL)\r{\rnode-\u0026gt;left = new_node;\rbreak; // 推出循环\r}\relse\r{\rnode = node-\u0026gt;left;\rcontinue; // 继续查找下一个节点\r}\r}\relse\r{\r// 如果右节点为nill, 右节点-\u0026gt;新节点\rif(node-\u0026gt;right == NULL)\r{\rnode-\u0026gt;right = new_node;\rbreak;\r}\relse\r{\rnode = node-\u0026gt;right;\rcontinue;\r}\r} }\rtreeNodeNum ++; // 数的节点数+1\r}\r数据的删除 // 采用递归的方式删除节点\rtemplate\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::deleteNodeAll(BinarySearchTreeNode\u0026lt;T\u0026gt; *node)\r{\r// 如果的空树就结束递归\rif(node == 0)\r{\rreturn;\r}\rdeleteNodeAll(node-\u0026gt;left);\rdeleteNodeAll(node-\u0026gt;right);\rcout \u0026lt;\u0026lt; node-\u0026gt;data \u0026lt;\u0026lt; endl;\rdelete node; // 释放资源\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::clear()\r{\rdeleteNodeAll(root); // 清空所有节点\rtreeNodeNum = 0; // 树的节点数为0\r}\r/*\r合并删除法：\r从删除的节点的两棵子树合并未一棵树，然后将这颗树连接到删除节点的父节点\r具体操作：左子树的最大值左作为有子树的父节点，左子树的根节点作为这棵树的根节点 或右子树的最小值作为左子树的父节点，右子树的根节点作为这棵树的根节点\r*/\rtemplate\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::deleteNodeByMerge(BinarySearchTreeNode\u0026lt;T\u0026gt;*\u0026amp; node)\r{\r// 左子树作为root作为树的root\r/*\rBinarySearchTreeNode\u0026lt;T\u0026gt; *temp = node;\rif(node != 0)\r{\r// 如果节点的左节点为空\rif(!node-\u0026gt;left)\r{\rnode = node-\u0026gt;right; //直接指向node的右节点\r}\r// 如果右子节点为空\relse if(!node-\u0026gt;right)\r{\rnode = node-\u0026gt;left; // 直接指向node的左节点\r}\relse{\rtemp = node-\u0026gt;left; // temp 为node的左节点\r// 找出左节点中的最大值\rwhile (temp-\u0026gt;right)\r{\rtemp = temp-\u0026gt;right;\r}\rtemp-\u0026gt;right = node-\u0026gt;right; // 左子树的最大值指向右节点\rtemp = node; node = node-\u0026gt;left; // 左子树作为两颗树的头节点\r}\rdelete temp;\r} */\r// 右子树的root作为树的root\rBinarySearchTreeNode\u0026lt;T\u0026gt; *temp = node;\rif(node)\r{\rif(!node-\u0026gt;left)\r{\rnode = node-\u0026gt;right;\r}\relse if(!node-\u0026gt;right)\r{\rnode = node-\u0026gt;left;\r}\relse\r{\rtemp = node-\u0026gt;right;\rwhile (temp-\u0026gt;left)\r{\rtemp = temp -\u0026gt;left;\r}\rtemp -\u0026gt;left = node-\u0026gt;left;\rtemp = node;\rnode = node-\u0026gt;right;\r}\rdelete temp;\r}\r}\r/*\r复制删除法：\r将被删除节点的左子树的最大值或者右子树的最小值复制给被删除的节点的数值，\r然后删除左子树的最大值的节点或者右子树的最小值的节点\r*/\rtemplate\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::deleteNodeByCopy(BinarySearchTreeNode\u0026lt;T\u0026gt;*\u0026amp; node)\r{\r// 复制右子树的最小值\r/*\rBinarySearchTreeNode\u0026lt;T\u0026gt; *prev = 0; // 复制节点(右子树最小值被删节点)的前驱节点\rBinarySearchTreeNode\u0026lt;T\u0026gt; *temp = node;\rif(node)\r{\rif(!node-\u0026gt;left)\r{\rnode = node-\u0026gt;right;\r}\relse if(!node-\u0026gt;right)\r{\rnode = node-\u0026gt;left;\r}\relse\r{\rtemp = node-\u0026gt;right;\r// 找到右子树的最小值\rwhile (temp-\u0026gt;left)\r{\rprev = temp;\rtemp = temp-\u0026gt;left;\r}\rnode-\u0026gt;data = temp-\u0026gt;data; // 将右子树的最小值复制给被删节点\r// 当右子树的首节点没有左节点时\rif(prev == node)\r{\rnode-\u0026gt;right = temp-\u0026gt;right; // 直接指向被删节点的右节点\r}\relse\r{\rprev-\u0026gt;left = temp-\u0026gt;right; // 先驱节点的左节点指向删除节点的右节点\r}\r}\rdelete temp;\r}*/\r// 复制左子树的最大值\rBinarySearchTreeNode\u0026lt;T\u0026gt; *prev = 0; // 复制节点(右子树最小值被删节点)的前驱节点\rBinarySearchTreeNode\u0026lt;T\u0026gt; *temp = node;\rif(node)\r{\rif(!node-\u0026gt;left)\r{\rnode = node-\u0026gt;right;\r}\relse if(!node-\u0026gt;right)\r{\rnode = node-\u0026gt;left;\r}\relse\r{\rtemp = node-\u0026gt;left;\r// 找到左子树的最大值\rwhile (temp-\u0026gt;right)\r{\rprev = temp;\rtemp = temp-\u0026gt;right;\r}\rnode-\u0026gt;data = temp-\u0026gt;data; // 将左子树的最大值复制给被删节点\r// 当左子树的首节点没有右节点时\rif(prev == node)\r{\rnode-\u0026gt;left = temp-\u0026gt;left; // 直接指向被删节点的左节点\r}\relse\r{\rprev-\u0026gt;right = temp-\u0026gt;left; // 先驱节点的右节点指向删除节点的左节点\r}\r}\rdelete temp;\r}\r}\r// 合并删除\rtemplate\u0026lt;class T\u0026gt;\rbool BinarySearchTree\u0026lt;T\u0026gt; ::removeNodeMerge(const T data)\r{\rif(isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;the tree is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn false;\r}\rBinarySearchTreeNode\u0026lt;T\u0026gt; *prev_node = 0; // 头节点\rBinarySearchTreeNode\u0026lt;T\u0026gt; *node = root;\r// 找到值的节点\rwhile (node)\r{\r// 如果node的值等于data\rif(node-\u0026gt;data == data)\r{\rbreak;\r}\rprev_node = node; // node的头节点\r// node 的值大于deta 就往左子树找\rif(node-\u0026gt;data \u0026gt; data)\r{\rnode = node-\u0026gt;left;\r}\r// node 的值小于 data 就往右子树找\relse{\rnode = node-\u0026gt;right;\r}\r}\r// 找到值的节点了\rif(node != 0 \u0026amp;\u0026amp; node-\u0026gt;data == data)\r{\r// 如果是头节点\rif(node == root)\r{\r// deleteNodeByMerge(root);\rdeleteNodeByCopy(root);\r}\r// 其他节点的左节点==data\relse if(prev_node-\u0026gt;left == node)\r{\r// deleteNodeByMerge(prev_node-\u0026gt;left);\rdeleteNodeByCopy(prev_node-\u0026gt;left);\r}\relse\r{\r// deleteNodeByMerge(prev_node-\u0026gt;right);\rdeleteNodeByCopy(prev_node-\u0026gt;right);\r}\rtreeNodeNum--; //节点数减一\rreturn true;\r}\relse\r{\rcout \u0026lt;\u0026lt; data \u0026lt;\u0026lt; \u0026quot;no exits tree\u0026quot; \u0026lt;\u0026lt; endl;\r}\rreturn false;\r}\r// 复制删除\rtemplate\u0026lt;class T\u0026gt;\rbool BinarySearchTree\u0026lt;T\u0026gt; ::removeNodeCopy(const T data)\r{\rif(isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;the tree is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn false;\r}\rBinarySearchTreeNode\u0026lt;T\u0026gt; *node = root;\rBinarySearchTreeNode\u0026lt;T\u0026gt; *prev = 0;\r// 找到数据的节点\rwhile (node)\r{\r// 找到值就跳出循环\rif(node-\u0026gt;data == data)\r{\rbreak;\r}\r// 未找到，父节点给prev\rprev = node;\r// data \u0026gt; value -\u0026gt; 右子树查找\rif(data \u0026gt; node-\u0026gt;data)\r{\rnode = node-\u0026gt;right;\r}\r// 左子树查找\relse\r{\rnode = node-\u0026gt;left;\r}\r}\r// 找到节点\rif(node \u0026amp;\u0026amp; node-\u0026gt;data == data)\r{\r// 节点为根节点\rif(node == root)\r{\rdeleteNodeByCopy(root);\r}\r// 右节点\relse if(prev-\u0026gt;right == node)\r{\rdeleteNodeByCopy(prev-\u0026gt;right);\r}\r// 左节点\relse\r{\rdeleteNodeByCopy(prev-\u0026gt;left);\r}\r// 节点数-1\rtreeNodeNum--;\rreturn true;\r}\r// 未找到\relse\r{\rcout \u0026lt;\u0026lt; data \u0026lt;\u0026lt; \u0026quot;no exits in zhe tree\u0026quot; \u0026lt;\u0026lt; endl;\r}\rreturn false;\r}\r数据的查询  前序遍历、中序遍历、后续遍历、值查询  template\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::DLR(BinarySearchTreeNode\u0026lt;T\u0026gt; *node)\r{\rif(!node)\r{ return;\r}\r// 前序遍历(DLR)(根-\u0026gt;左-\u0026gt;右)\rcout \u0026lt;\u0026lt; node-\u0026gt;data \u0026lt;\u0026lt; \u0026quot;-\u0026gt;\u0026quot;;\rDLR(node-\u0026gt;left);\rDLR(node-\u0026gt;right);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::LDR(BinarySearchTreeNode\u0026lt;T\u0026gt; *node)\r{\rif(!node)\r{\rreturn;\r}\r// 中序遍历(LDR)(左-\u0026gt;根-\u0026gt;右)\rLDR(node-\u0026gt;left);\rcout \u0026lt;\u0026lt; node-\u0026gt;data \u0026lt;\u0026lt; \u0026quot;-\u0026gt;\u0026quot;;\rLDR(node-\u0026gt;right);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::LRD(BinarySearchTreeNode\u0026lt;T\u0026gt; *node)\r{\rif(!node)\r{\rreturn;\r}\r// 后序遍历(LRD)(左-\u0026gt;右-\u0026gt;根)\rLRD(node-\u0026gt;left);\rLRD(node-\u0026gt;right);\rcout \u0026lt;\u0026lt; node-\u0026gt;data \u0026lt;\u0026lt; \u0026quot;-\u0026gt;\u0026quot;;\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::showNodeByDLR()\r{\rif(isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;this tree is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn;\r}\r// 遍历树\rBinarySearchTreeNode\u0026lt;T\u0026gt; *node = root;\rcout \u0026lt;\u0026lt; \u0026quot;DLR: \u0026quot;;\rDLR(node); cout \u0026lt;\u0026lt; endl;\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::showNodeByLDR()\r{\rif(isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;this tree is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn;\r}\r// 遍历树\rBinarySearchTreeNode\u0026lt;T\u0026gt; *node = root;\rcout \u0026lt;\u0026lt; \u0026quot;LDR: \u0026quot;;\rLDR(node); cout \u0026lt;\u0026lt; endl; }\rtemplate\u0026lt;class T\u0026gt;\rvoid BinarySearchTree\u0026lt;T\u0026gt; ::showNodeByLRD()\r{\rif(isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;this tree is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn;\r}\r// 遍历树\rBinarySearchTreeNode\u0026lt;T\u0026gt; *node = root;\rcout \u0026lt;\u0026lt; \u0026quot;LRD: \u0026quot;;\rLRD(node); cout \u0026lt;\u0026lt; endl; }\rtemplate\u0026lt;class T\u0026gt;\rbool BinarySearchTree\u0026lt;T\u0026gt; ::SearchData(const T data)\r{\rif(isEmpty())\r{\rreturn false;\r}\rBinarySearchTreeNode\u0026lt;T\u0026gt; *node = root;\rwhile (node)\r{\rif(node-\u0026gt;data == data)\r{\rreturn true;\r}\relse if(data \u0026gt; node-\u0026gt;data)\r{\rnode = node-\u0026gt;right;\r}\relse\r{\rnode = node-\u0026gt;left;\r}\r}\rreturn false\r;\r}\r测试 \rint main(int argc, char const *argv[])\r{\rBinarySearchTree\u0026lt;int\u0026gt; tree;\rtree.inseartNode(5);\rtree.inseartNode(3);\rtree.inseartNode(2);\rtree.inseartNode(4);\rtree.inseartNode(6);\rtree.inseartNode(5);\rtree.inseartNode(7);\r// 前序遍历\rtree.showNodeByDLR();\r// 中序遍历\rtree.showNodeByLDR();\r// 后序遍历\rtree.showNodeByLRD();\rcout \u0026lt;\u0026lt; \u0026quot;*******************************\u0026quot; \u0026lt;\u0026lt; endl;\rcout \u0026lt;\u0026lt; tree.removeNodeMerge(5) \u0026lt;\u0026lt; endl;\r// 前序遍历\rtree.showNodeByDLR();\r// 中序遍历\rtree.showNodeByLDR();\r// 后序遍历5\rtree.showNodeByLRD();\rcout \u0026lt;\u0026lt; \u0026quot;nodes is:\u0026quot; \u0026lt;\u0026lt; tree.Nodes() \u0026lt;\u0026lt; endl;\rcout \u0026lt;\u0026lt; \u0026quot;*******************************\u0026quot; \u0026lt;\u0026lt; endl;\rcout \u0026lt;\u0026lt; tree.removeNodeCopy(7) \u0026lt;\u0026lt; endl;\r// 前序遍历\rtree.showNodeByDLR();\r// 中序遍历\rtree.showNodeByLDR();\r// 后序遍历\rtree.showNodeByLRD();\rcout \u0026lt;\u0026lt; \u0026quot;nodes is:\u0026quot; \u0026lt;\u0026lt; tree.Nodes() \u0026lt;\u0026lt; endl;\rcout \u0026lt;\u0026lt; \u0026quot;*******************************\u0026quot; \u0026lt;\u0026lt; endl;\rcout \u0026lt;\u0026lt; tree.SearchData(21) \u0026lt;\u0026lt; endl;\rsystem(\u0026quot;pause\u0026quot;);\rreturn 0;\r}\r源码  我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForC/tree/master/tree/binary_tree  ","date":"2022-01-01T21:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-binary-search-tree-c-%E5%AE%9E%E7%8E%B0/1_hu163e0849e6d75821587eb02814146518_65785_120x120_fill_box_smart1.gif","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-binary-search-tree-c-%E5%AE%9E%E7%8E%B0/","title":"数据结构-Binary search tree c++实现"},{"content":"栈 基于单向链表实现\n数据结构定义 type stackData struct {\rlist *Singly_linked_list.LinkedList\r}\r// 获得栈的长度\rfunc (s *stackData)Len() int{\rreturn s.list.Len()\r}\r数据操作 // 将数据插入栈顶\rfunc (s *stackData)Push(data interface{}) {\rs.list.AddToHead(data)\r}\r// 将数据从栈顶取出，并删除数据\rfunc (s *stackData)Pop()interface{}{\rdata := s.list.QuireIndex(0)\r// 栈不为空, 删除栈顶数据\rif data != nil{\rs.list.DeleteToHead()\r}\rreturn data\r}\r// 将数据取出，不删除数据\rfunc (s *stackData)GetTopValue()interface{}{\rreturn s.list.QuireIndex(0)\r}\r// 展示栈\rfunc (s *stackData)ShowStack() {\rs.list.QuireAll()\r}\r创建栈 func NewStackData()*stackData{\rreturn \u0026amp;stackData{list:Singly_linked_list.NewLinkedList()}\r}\r队列  基于双向链表实现  数据结构定义 type queueData struct {\rlist *double_linked_list.DoubleList\r}\r// 获得队列的大小\rfunc (q *queueData)Len() int{\rreturn q.list.Len()\r}\r数据的操作 // 将数据队尾\rfunc (q *queueData)EnQueue(data interface{}) {\rq.list.AddToTail(data)\r}\r// 将数据从队首取出，并删除数据\rfunc (q *queueData)DeQueue()interface{}{\rdata := q.list.QuireIndex(0)\r// 栈不为空, 删除栈顶数据\rif data != nil{\rq.list.DeleteToHead()\r}\rreturn data\r}\r// 将数据取出，不删除数据\rfunc (q *queueData)GetTopQueueValue()interface{}{\rreturn q.list.QuireIndex(0)\r}\r// 展示队列\rfunc (q *queueData)ShowQueue() {\rq.list.QuireAll()\r}\r创建队列 func NewQueueData()*queueData{\rreturn \u0026amp;queueData{list:double_linked_list.NewDoubleLinkedList()}\r}\r源码  我的github:https:https://github.com/zcj-git520/DataStructuresAlgorithmsForGo/tree/master/stack_queue/queue 我的github:https:https://github.com/zcj-git520/DataStructuresAlgorithmsForGo/tree/master/stack_queue/stack  ","date":"2021-12-31T22:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E5%9F%BA%E4%BA%8E%E5%8D%95%E9%A1%B9%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97%E5%9F%BA%E4%BA%8E%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8go%E5%AE%9E%E7%8E%B0/1_hucc057a99640c389677e7decbd4886594_40524_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E5%9F%BA%E4%BA%8E%E5%8D%95%E9%A1%B9%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97%E5%9F%BA%E4%BA%8E%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8go%E5%AE%9E%E7%8E%B0/","title":"数据结构-栈(基于单项链表)\u0026\u0026队列(基于双向链表)go实现"},{"content":"栈 基于单向链表实现\n数据结构定义 \rtemplate\u0026lt;class T\u0026gt;\rclass Stack\r{\rprivate:\rSinglyList\u0026lt;T\u0026gt; list; // 存储数据的链表\rpublic:\rStack(/* args */){};\r~Stack();\r// 获得栈的长度\rint len()\r{\rreturn list.getlen();\r}\r// 清空栈\rvoid clear();\r// 判断栈是否为空s\rbool isEmpty();\r// 将数据放入栈顶\rvoid push(T data);\r// 获取栈顶数据，并删除数据\rbool pop(T *info);\r// 获取栈顶数据但不删除数据\rbool getTopValue(T *info);\r// 显示所有栈的数据\rvoid showStack();\r};\r数据操作 \rtemplate\u0026lt;class T\u0026gt;\rvoid Stack\u0026lt;T\u0026gt; ::clear()\r{\rlist.clear();\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid Stack\u0026lt;T\u0026gt; ::push(T data)\r{\rlist.inseartToHead(data);\r}\rtemplate\u0026lt;class T\u0026gt;\rbool Stack\u0026lt;T\u0026gt; ::pop(T *info)\r{\r// 判断栈顶是否有值\rif(getTopValue(info))\r{\rlist.deleteToHead(); // 删除栈顶值\rreturn true;\r}\rreturn false;\r}\rtemplate\u0026lt;class T\u0026gt;\rbool Stack\u0026lt;T\u0026gt; ::getTopValue(T *info)\r{\r// 判断栈顶是否有值\rif(list.queryIndex(0, info))\r{\rreturn true;\r}\rreturn false;\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid Stack\u0026lt;T\u0026gt; ::showStack()\r{\rlist.queryAll();\r}\r测试 int main()\r{\rStack\u0026lt;int\u0026gt; s;\rs.push(0);\rs.push(1);\rs.push(2);\rs.push(3);\rs.push(4);\rs.showStack();\rcout \u0026lt;\u0026lt; \u0026quot;********************************\u0026quot; \u0026lt;\u0026lt; endl;\rint info = -1;\rif(s.getTopValue(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rif(s.getTopValue(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rif(s.getTopValue(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rcout \u0026lt;\u0026lt; \u0026quot;********************************\u0026quot; \u0026lt;\u0026lt; endl;\rs.showStack();\rcout \u0026lt;\u0026lt; \u0026quot;********************************\u0026quot; \u0026lt;\u0026lt; endl;\rif(s.pop(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rif(s.pop(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rif(s.pop(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rif(s.pop(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rcout \u0026lt;\u0026lt; \u0026quot;********************************\u0026quot; \u0026lt;\u0026lt; endl;\rs.showStack();\rcout \u0026lt;\u0026lt; \u0026quot;********************************\u0026quot; \u0026lt;\u0026lt; endl;\rsystem(\u0026quot;pause\u0026quot;);\rreturn 0;\r}\r队列  基于双向链表实现  数据结构定义 \rtemplate\u0026lt;class T\u0026gt;\rclass Queue\r{\rprivate:\rTwoWayList\u0026lt;T\u0026gt; list; // 定义的双向链表\rpublic:\rQueue(/* args */){};\r~Queue();\r// 获得队列的长度\rint len()\r{\rreturn list.getlen();\r}\r// 清空队列\rvoid clear();\r// 判断栈是否为空s\rbool isEmpty();\r// 将数据存入队列尾中\rvoid enQueue(T data);\r// 获取获得队列数据，并删除数据\rbool deQueue(T *info);\r// 获取获得队列数据，但不删除数据\rbool getQueueValue(T *info);\r// 显示所有队列的数据\rvoid showQueue();\r};\r数据的操作 \rtemplate\u0026lt;class T\u0026gt;\rvoid Queue\u0026lt;T\u0026gt; ::clear()\r{\rlist.clear();\r}\rtemplate\u0026lt;class T\u0026gt;\rbool Queue\u0026lt;T\u0026gt; ::isEmpty()\r{\rreturn list.isEmpty();\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid Queue\u0026lt;T\u0026gt; ::enQueue(T data)\r{\rlist.inseartTotail(data);\r}\rtemplate\u0026lt;class T\u0026gt;\rbool Queue\u0026lt;T\u0026gt; ::getQueueValue(T *info)\r{\rif(list.queryIndex(0, info))\r{\rreturn true;\r}\rreturn false;\r}\rtemplate\u0026lt;class T\u0026gt;\rbool Queue\u0026lt;T\u0026gt; ::deQueue(T *info)\r{\rif(list.queryIndex(0, info))\r{\rlist.deleteToHead();\rreturn true;\r}\rreturn false;\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid Queue\u0026lt;T\u0026gt; ::showQueue()\r{\rlist.queryAll();\r}\r测试 int main()\r{\rQueue\u0026lt;int\u0026gt; q;\rq.enQueue(0);\rq.enQueue(1);\rq.enQueue(2);\rq.enQueue(3);\rq.enQueue(4);\rq.enQueue(5);\rq.showQueue();\rcout \u0026lt;\u0026lt; \u0026quot;**************************************\u0026quot;\u0026lt;\u0026lt; endl;\rint info = -1;\rif(q.getQueueValue(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;queue top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rif(q.getQueueValue(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;queue top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rif(q.getQueueValue(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;queue top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rq.showQueue();\rcout \u0026lt;\u0026lt; \u0026quot;**************************************\u0026quot;\u0026lt;\u0026lt; endl;\rif(q.deQueue(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;queue top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rq.showQueue();\rcout \u0026lt;\u0026lt; \u0026quot;**************************************\u0026quot;\u0026lt;\u0026lt; endl;\rif(q.deQueue(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;queue top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rq.showQueue();\rcout \u0026lt;\u0026lt; \u0026quot;**************************************\u0026quot;\u0026lt;\u0026lt; endl;\rif(q.deQueue(\u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;queue top value is: \u0026quot; \u0026lt;\u0026lt;info \u0026lt;\u0026lt; endl;\r}\rq.showQueue();\rcout \u0026lt;\u0026lt; \u0026quot;**************************************\u0026quot;\u0026lt;\u0026lt; endl;\rq.clear();\rq.showQueue();\rsystem(\u0026quot;pause\u0026quot;);\rreturn 0;\r}\r源码  我的github:https:https://github.com/zcj-git520/DataStructuresAlgorithmsForC/tree/master/stack_queue/queue 我的github:https:https://github.com/zcj-git520/DataStructuresAlgorithmsForGo/tree/master/stack_queue/stackhttps://github.com/zcj-git520/DataStructuresAlgorithmsForC/tree/master/stack_queue/stack  ","date":"2021-12-31T21:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E5%9F%BA%E4%BA%8E%E5%8D%95%E9%A1%B9%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97%E5%9F%BA%E4%BA%8E%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8c-%E5%AE%9E%E7%8E%B0/1_hucc057a99640c389677e7decbd4886594_40524_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%88%E5%9F%BA%E4%BA%8E%E5%8D%95%E9%A1%B9%E9%93%BE%E8%A1%A8%E9%98%9F%E5%88%97%E5%9F%BA%E4%BA%8E%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8c-%E5%AE%9E%E7%8E%B0/","title":"数据结构-栈(基于单项链表)\u0026\u0026队列(基于双向链表)c++实现"},{"content":"双向链表 数据结构的定义 // 双向链表的节点定义\rtype doubleLinkedNode struct {\rinfo interface{} // 存储的数据\rprev *doubleLinkedNode // 指向先驱节点\rnext *doubleLinkedNode // 指向后驱几点\r}\r// 双向链表定义\rtype DoubleList struct {\rHead *doubleLinkedNode // 头节点\rTail *doubleLinkedNode // 尾节点\rlen int // 链表长度\r}\r创建节点 func createNode(data interface{}) *doubleLinkedNode {\rreturn \u0026amp;doubleLinkedNode{\rinfo: data,\rprev: nil,\rnext: nil,\r}\r}\r链表的长度 // 链表的长度\rfunc(d *DoubleList)Len() int{\rreturn d.len\r}\r数据的插入 单个节点的插入 // 链表的尾插法\rfunc (d *DoubleList)AddToTail(info interface{}) *DoubleList {\rnewNode := createNode(info) // 创建新节点\r// 链表为空, 头尾节点都指向该节点\rif d.Head == nil{\rd.Head = newNode\rd.Tail = newNode\r}else{\rd.Tail.next = newNode\rnewNode.prev = d.Tail\rd.Tail = d.Tail.next\r}\r// 链表长度+1\rd.len++\rreturn d\r}\r// 链表的头插法\rfunc (d *DoubleList)AddToHead(info interface{}) *DoubleList {\rnewNode := createNode(info) // 创建节点\r// 链表为空\rif d.Head == nil{\rd.Head = newNode\rd.Tail = newNode\r}else{\rnewNode.next = d.Head // 新节点的后驱指向头节点\rd.Head.prev = newNode // 头节点的前驱指向新节点\rd.Head = newNode // 将新节点设置尾头节点\r}\r// 链表长度+1\rd.len++\rreturn d\r}\r// 链表的index\r// 通过index=\u0026gt;插入链表新的节点\r// index为正数 为从左-\u0026gt;右 // 0表示第一个节点\r// index为负数 为从右-\u0026gt;左 // -1表示第一个节点\rfunc (d *DoubleList)AddToIndex(index int, info interface{}) *DoubleList {\r// 当链表为空时，采用了尾插入法插入数据\rif d.Head == nil{\rreturn d.AddToTail(info)\r}\r// 当index大于链表的值时，默认将数据插入到链表的后面\rif int(math.Abs(float64(index))) \u0026gt; d.len-1{\rreturn d.AddToTail(info)\r}\r// 插入链表的头部\rif index == 0{\rreturn d.AddToHead(info)\r}\r// 插入到链表的末尾\rif index == -1{\rreturn d.AddToTail(info)\r}\r// 当index 为负数时，从右到左插入\rif index \u0026lt; 0{\rindex += d.len +1\r}\r__index := 1 // 内部的index值\r// 从第二个值开始插入\rfor node := d.Head; node != d.Tail; node = node.next{\rif index == __index{\rnewNode := createNode(info)\rnode.next.prev = newNode // 节点的后驱节点的先驱指向新节点\rnewNode.prev = node // 新节点的前驱指向节点\rnewNode.next = node.next // 新节点的后驱指向节点的后驱\rnode.next = newNode // 节点的后驱指向新节点\r// 链表的节点数加1\rd.len ++\rreturn d\r}\r__index ++\r}\rreturn d\r}\r链表的合并 // 将新的链表插入头部\rfunc (d *DoubleList)AddListToHead(list *DoubleList)*DoubleList{\r// 两个链表都为空时\rif d.Head == nil \u0026amp;\u0026amp; list.Head == nil{\rreturn d\r}\r// 合并表为空\rif d.Head != nil \u0026amp;\u0026amp; list.Head == nil{\rreturn d\r}\r// 主表为空\rif d.Head == nil \u0026amp;\u0026amp; list.Head != nil{\rreturn list\r}\r// 合并表的尾指针指向主表的头\rlist.Tail.next = d.Head\rd.Head.prev = list.Tail\rlist.Tail = d.Tail\r// 表节点数合并\rlist.len += d.len\rreturn list\r}\r// 将新的链表插入到尾部\rfunc (d *DoubleList)AddListToTail(list *DoubleList)*DoubleList{\r// 两个链表都为空时\rif d.Head == nil \u0026amp;\u0026amp; list.Head == nil{\rreturn d\r}\r// 合并表为空\rif d.Head != nil \u0026amp;\u0026amp; list.Head == nil{\rreturn d\r}\r// 主表为空\rif d.Head == nil \u0026amp;\u0026amp; list.Head != nil{\rreturn list\r}\r// 将新表插入到主表之后\rd.Tail.next = list.Head\rlist.Head.prev = d.Tail\rd.Tail = list.Tail\rd.len += list.len\rreturn d\r}\r// 经新的表插入到index\rfunc (d *DoubleList)AddListToIndex(index int, list *DoubleList) *DoubleList {\r// 两个链表都为空时\rif d.Head == nil \u0026amp;\u0026amp; list.Head == nil{\rreturn d\r}\r// 合并表为空\rif d.Head != nil \u0026amp;\u0026amp; list.Head == nil{\rreturn d\r}\r// 主表为空\rif d.Head == nil \u0026amp;\u0026amp; list.Head != nil{\rreturn list\r}\rif int(math.Abs(float64(index))) \u0026gt; d.len{\rfmt.Println(\u0026quot;错误的index\u0026quot;)\rreturn d\r}\rif index == 0{\rreturn d.AddListToHead(list)\r}\rif index == -1{\rreturn d.AddListToTail(list)\r}\rif index \u0026lt; 0{\rindex += d.len\r}\r__index := 1\rfor node := d.Head; node != d.Tail; node = node.next{\rif index == __index{\rnode.next.prev = list.Tail\rlist.Tail.next = node.next\rnode.next = list.Head\rlist.Head.prev = node\rd.len += list.len // 链表的数值相加\rreturn d\r}\r__index ++\r}\rreturn d\r}\r数据的删除 // 链表头删除法\rfunc (d *DoubleList)DeleteToHead()*DoubleList{\r// 链表为空\rif d.Head == nil{\rreturn d\r}\r// 链表中只有一个数\rif d.Head == d.Tail{\rd.Head = nil\rd.Tail = nil\rd.len = 0\rreturn d\r}\rd.Head = d.Head.next\rd.Head.prev = nil\r// node数减一\rd.len --\rreturn d\r}\r// 链表尾删除法\rfunc (d *DoubleList)DeleteToTail()*DoubleList{\r// 链表为空\rif d.Tail == nil{\rreturn d\r}\r// 链表中只有一个数\rif d.Head == d.Tail{\rd.Head = nil\rd.Tail = nil\rd.len = 0\rreturn d\r}\rd.Tail = d.Tail.prev\rd.Tail.next = nil\r// node数减一\rd.len --\rreturn d\r}\r// 通过值=\u0026gt;删除链表的节点(第一个)\rfunc (d *DoubleList)DeleteToAValue(value interface{})*DoubleList{\r// 链表为空\rif d.Head == nil{\rfmt.Println(\u0026quot;链表为空\u0026quot;)\rreturn d\r}\r// value == head.info\r// 就采用头删法\rif value == d.Head.info{\rreturn d.DeleteToHead()\r}\rif value == d.Tail.info{\rreturn d.DeleteToTail()\r}\r// 中间采用轮询查找value, 从第二个开始轮询到倒数第二个结束\rfor node := d.Head.next; node != d.Tail; node = node.next{\rif node.info == value{\r// 删除node\rnode.next.prev = node.prev\rnode.prev.next = node.next\rd.len --\rreturn d\r}\r}\rfmt.Println(\u0026quot;链表中：值不存在\u0026quot;)\rreturn d\r}\r// 通过值=\u0026gt;删除链表的节点(所有)\rfunc (d *DoubleList)DeleteToValue(value interface{})*DoubleList{\r// 链表为空\rif d.Head == nil{\rfmt.Println(\u0026quot;链表为空\u0026quot;)\rreturn d\r}\rnode := d.Head // 当前的node\rfor {\r// 当下一个节点是尾节点时，就判断首位和末尾是为需要删除的node\rif node == d.Tail {\rif d.Head.info == value{\rd.DeleteToHead()\r}\rif d.Tail.info == value{\rd.DeleteToTail()\r}\rreturn d\r}\rif node.info == value{\r// 删除node， 非头节点\rif node.prev != nil{\rnode.next.prev = node.prev\rnode.prev.next = node.next\rd.len --\r}else{\r// 头节点\rd.DeleteToHead()\r}\r}\rnode = node.next\r}\r}\r// 通过index=\u0026gt;删除链表的节点\r// index为正数 为从左-\u0026gt;右 // 0表示第一个节点\r// index为负数 为从右-\u0026gt;左 // -1表示第一个节点\rfunc (d *DoubleList)DeleteToIndex(index int)*DoubleList{\r// 链表为空\rif d.Head == nil{\rfmt.Println(\u0026quot;链表为空\u0026quot;)\rreturn d\r}\r// index 超过链表数\rif int(math.Abs(float64(index))) \u0026gt; d.len-1{\rfmt.Println(\u0026quot;错误的index\u0026quot;)\rreturn d\r}\r// 删除第一个node\rif index == 0{\rreturn d.DeleteToHead()\r}\rif index \u0026lt; 0{\rindex += d.len\r}\rif index == d.len -1{\rreturn d.DeleteToTail()\r}\r_index := 1\rnode := d.Head.next\rfor {\rif index == _index{\rnode.next.prev = node.prev\rnode.prev.next = node.next\rd.len --\rreturn d\r}\rnode = node.next\r_index ++\r}\r}\r数据的查询 // 遍历链表\rfunc (d *DoubleList) QuireAll() {\rif d.Head == nil{\rfmt.Println(\u0026quot;链表数据为空\u0026quot;)\rreturn\r}\rnode := d.Head\rfor {\rif node == nil{\rreturn\r}\rfmt.Println(node.info)\rif node == d.Tail{\rreturn\r}\rnode = node.next\r}\r}\r// 判断valve是否存在\rfunc (d *DoubleList)QuireValue(value interface{}) bool{\r// 表为空\rif d.Head == nil{\rreturn false\r}\r// 表中只存在一个值\rif d.Head == d.Tail{\rif d.Head.info == value{\rreturn true\r}\rreturn false\r}\r// 遍历查值\rfor node := d.Head; node != d.Tail.next; node = node.next{\rif node.info == value{\rreturn true\r}\r}\rreturn false\r}\r// 根据索引返回值\rfunc (d *DoubleList)QuireIndex(index int) interface{} {\r// 链表为空\rif d.Head == nil{\rreturn nil\r}\rif int(math.Abs(float64(index))) \u0026gt; d.len -1 {\rfmt.Println(\u0026quot;索引值错误\u0026quot;)\rreturn nil\r}\rif index == 0{\rreturn d.Head.info\r}\rif index == d.len -1 || index == -1{\rreturn d.Tail.info\r}\rif index \u0026lt; 0{\rindex += d.len\r}\r__index := 1\rfor node := d.Head.next; node != d.Tail; node = node.next{\rif __index == index{\rreturn node.info\r}\r__index ++\r}\r//fmt.Println(\u0026quot;未能找到！！！！\u0026quot;)\rreturn nil\r}\r结构的入口 func NewDoubleLinkedList()*DoubleList{\r// 创建的链表头尾节点都为空\rreturn \u0026amp;DoubleList{\rHead: nil,\rTail: nil,\rlen: 0,\r}\r}\r循环双向链表 数据结构的定义 // 节点的定义\rtype circleDoubleNode struct {\rinfo interface{} // 数据结构的定义\rprev *circleDoubleNode // 前驱指针\rnext *circleDoubleNode // 后驱指针\r}\r// 双向循环链表的定义\rtype circleDoubleList struct {\rcurrentNode *circleDoubleNode // 指向链表的指针\rlen int // 链表的长度\r}\r创建节点 func createNode(data interface{}) *circleDoubleNode{\rreturn \u0026amp;circleDoubleNode{\rinfo: data,\rprev: nil,\rnext: nil,\r}\r}\r// 得到链表的长度\rfunc (c *circleDoubleList)GetLen()int{\rreturn c.len\r}\r节点的插入 func (c *circleDoubleList)InsertNode(data interface{}) {\rnewNode := createNode(data)\r// 如果链表为空\rif c.currentNode == nil{\rc.currentNode = newNode // 新创建的节点为当前节点\r// 节点的前驱与后驱都指向自己\rc.currentNode.next = c.currentNode\rc.currentNode.prev = c.currentNode\r}else{\r// 节点的插入\rc.currentNode.next.prev = newNode\rnewNode.prev = c.currentNode\rnewNode.next = c.currentNode.next\rc.currentNode.next = newNode\rc.currentNode = newNode\r}\r// 链表长度 +1\rc.len ++\r}\r当前节点的删除 func (c *circleDoubleList)DeleteNode() bool{\r// 链表为空\rif c.currentNode == nil{\rreturn false\r}\r// 当链表值存在一个元素时\rif c.len == 1{\rc.currentNode = nil\rc.len --\rreturn true\r}\r// 当链表只存在两个元素时\rif c.len == 2{\rc.currentNode = c.currentNode.next\rc.len --\rreturn true\r}\r// 当前节点的后驱节点的前驱指针指向当前节点的的前驱节点\rc.currentNode.next.prev = c.currentNode.prev\r// 当前节点的前驱节点的后驱指针指向当前节点的后驱节点\rc.currentNode.prev.next = c.currentNode.next\r// 设置当前节点的后驱节点为当前节点\rc.currentNode = c.currentNode.next\rc.len --\rreturn true\r}\r遍历说有节点 func (c *circleDoubleList)QuireAll(){\rif c.currentNode == nil{\rfmt.Println(\u0026quot;circle double linked list is empty\u0026quot;)\rreturn\r}\r//__index := 1\r//for node := c.currentNode.next; node != c.currentNode; node = node.next{\r//\tfmt.Printf(\u0026quot;index is %d, node value is %v\u0026quot;, __index, node.info)\r//\t__index ++\r//}\rfmt.Printf(\u0026quot;circle double linked list len is %d \\n\u0026quot;, c.len)\rnode := c.currentNode.next\rfor i := 1; i \u0026lt; c.len; i++{\rfmt.Printf(\u0026quot;index is %d, node value is %v \\n\u0026quot;, i, node.info)\rnode = node.next\r}\rfmt.Printf(\u0026quot;index is %d, node value is %v \\n\u0026quot;, c.len, c.currentNode.info)\r}\r// 判断值是否存在\rfunc (c *circleDoubleList)QuireValue(data interface{}) bool{\rif c.currentNode == nil{\rreturn false\r}\rnode := c.currentNode\rfor i := 1; i \u0026lt;= c.len; i++{\rif node.info == data{\rreturn true\r}\rnode = node.next\r}\rreturn false\r}\r链表实例化 func NewCircleDoubleList()*circleDoubleList{\rreturn \u0026amp;circleDoubleList{\rcurrentNode: nil,\rlen: 0,\r}\r}\r源码  我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForGo/tree/master/Linked_list/double_linked_list 我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForGo/tree/master/Linked_list/circle_double_linked_list  ","date":"2021-12-30T22:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E5%BE%AA%E7%8E%AF%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/1_huc216cf6486350636a2e6728955e7fc78_62516_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E5%BE%AA%E7%8E%AF%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/","title":"数据结构-双向链表\u0026\u0026循环双向链表go语言实现"},{"content":"双向链表 数据结构的定义 template\u0026lt;class T\u0026gt;\rclass TwoWayLinkedNode\r{\rpublic:\rTwoWayLinkedNode(/* args */){}; TwoWayLinkedNode(T data)\r{\rthis-\u0026gt;data = data;\rthis-\u0026gt;prev = 0;\rthis-\u0026gt;next = 0;\r}\r~TwoWayLinkedNode(){};\rT data; // 数据\rTwoWayLinkedNode *next; // 指向后继节点\rTwoWayLinkedNode *prev; // 指向前驱\r};\rtemplate\u0026lt;class T\u0026gt;\rclass TwoWayList\r{\rprivate:\r/* data */\rTwoWayLinkedNode\u0026lt;T\u0026gt; *head; // 头节点\rTwoWayLinkedNode\u0026lt;T\u0026gt; *tail; // 尾节点\rint len; // 链表长度\rpublic:\rTwoWayList()\r{\rhead = 0;\rtail = 0;\rlen = 0;\r};\r~TwoWayList();\r// 链表的长度+1\rvoid setlen(int len)\r{\rthis-\u0026gt;len += len;\r}; // 返回链表的长度\rint getlen()\r{\rreturn len;\r};\r// 清空链表\rvoid clear();\r// 链表是否为空\rbool isEmpty()\r{\rreturn head == 0;\r}\r// 插入到链表的头部\rvoid inseartToHead(T data); // 插入到链表的尾部\rvoid inseartTotail(T data); // 插入到链表的index\rvoid inseartToindex(int index, T data); // 删除链表的头部元素\rvoid deleteToHead();\r// 删除链表的尾部元素\rvoid deleteToTail();\r// 删除链表的index元素\rvoid deleteToIndex(int index);\r// 查询链表的所有值\rvoid queryAll();\r// 返回index的值\rbool queryIndex(int index, T *data);\r// 判断value是否存在\rbool queryValue(T data);\r};\r数据的操作 \rtemplate\u0026lt;class T\u0026gt;\rvoid TwoWayList\u0026lt;T\u0026gt; ::inseartToHead(T data)\r{\rTwoWayLinkedNode\u0026lt;T\u0026gt; *new_Node = new TwoWayLinkedNode\u0026lt;T\u0026gt;(data); // 链表为空\rif (isEmpty())\r{\rhead = tail = new_Node;\r}\relse\r{\rnew_Node-\u0026gt;next = head; // 新节点的后驱指向头节点\rhead-\u0026gt;prev = new_Node; // 头节点的前驱指向新节点\rhead = new_Node; // 将新节点设置新的头节点\r}\rsetlen(addOne);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid TwoWayList\u0026lt;T\u0026gt; ::inseartTotail(T data)\r{\rTwoWayLinkedNode\u0026lt;T\u0026gt; *new_Node = new TwoWayLinkedNode\u0026lt;T\u0026gt;(data);\rif(isEmpty())\r{\rhead = tail = new_Node;\r}\relse\r{\rtail-\u0026gt;next = new_Node; // 尾节点的next指向新节点\rnew_Node-\u0026gt;prev = tail; // 新节点的前驱指向尾节点\rtail = new_Node; // 将新节点设置为新的尾节点\r}\rsetlen(addOne);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid TwoWayList\u0026lt;T\u0026gt; ::inseartToindex(int index, T data)\r{\rint len = getlen();\rif(index == 0)\r{\rinseartToHead(data);\rreturn;\r}\r// 链表为空，当index 小于0 或者大于等于链表数，采用尾插法\rif (isEmpty() || index \u0026lt; 0 || index \u0026gt;= len)\r{\rinseartTotail(data);\rreturn;\r}\rTwoWayLinkedNode\u0026lt;T\u0026gt; *node = head;\rint __index = 1;\rwhile (__index != index)\r{\rnode = node-\u0026gt;next;\r__index ++;\r}\rTwoWayLinkedNode\u0026lt;T\u0026gt; *new_node = new TwoWayLinkedNode\u0026lt;T\u0026gt;(data);\rnode-\u0026gt;next-\u0026gt;prev = new_node; // node节点的后继节点的先驱要指向新节点\rnew_node-\u0026gt;prev = node; // 新节点的先驱要指向node\rnew_node-\u0026gt;next = node-\u0026gt;next; // 新节点的后继要指向node的后继\rnode-\u0026gt;next = new_node; // node的后继要指向新节点\rsetlen(addOne);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid TwoWayList\u0026lt;T\u0026gt; ::clear()\r{\rwhile (!isEmpty())\r{\rTwoWayLinkedNode\u0026lt;T\u0026gt; *node = head-\u0026gt;next;\rdelete head;\rhead = node;\r}\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid TwoWayList\u0026lt;T\u0026gt; ::deleteToHead()\r{\r// 链表为空就返回\rif(isEmpty())\r{\rreturn;\r}\r// 链表只存在一个节点\rif(head == tail)\r{\rdelete head;\rhead = tail = 0;\r}\relse{\rhead = head-\u0026gt;next; // 将下一节点设置头节点\rdelete head-\u0026gt;prev; // 释放新的头节点的前驱节点\rhead-\u0026gt;prev = 0; // 头节点的先驱设置nil\r}\rsetlen(ReductOne);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid TwoWayList\u0026lt;T\u0026gt; ::deleteToTail()\r{\r// 链表为空就返回\rif(isEmpty())\r{\rreturn;\r}\r// 链表只存在一个节点\rif(head == tail)\r{\rdelete head;\rhead = tail = 0;\r}\relse{\rtail = tail-\u0026gt;prev; // 尾节点的先驱节点重新设置为新的尾节点\rdelete tail-\u0026gt;next; // 释放新的尾节点的后驱\rtail-\u0026gt;next = 0; // 新的尾节点的后驱指向尾nil\r}\rsetlen(ReductOne);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid TwoWayList\u0026lt;T\u0026gt; ::deleteToIndex(int index)\r{\rlen = getlen();\r// 链表为空,就返回\rif(isEmpty())\r{\rreturn;\r}\r// index \u0026gt;= len || index \u0026lt; 0 采用删除末尾值\rif (index \u0026gt;= len || index \u0026lt; 0)\r{\rdeleteToTail();\rreturn;\r}\rif(index == 0)\r{\rdeleteToHead();\rreturn;\r}\rif (index == len - 1)\r{\rdeleteToTail();\rreturn;\r}\rint __index = 1;\rTwoWayLinkedNode\u0026lt;T\u0026gt; *node = head-\u0026gt;next;\rwhile (__index != index)\r{\rnode = node-\u0026gt;next;\r__index ++;\r}\rnode-\u0026gt;prev-\u0026gt;next = node-\u0026gt;next; // node节点的先驱节点的后驱指向node的后驱\rnode-\u0026gt;next-\u0026gt;prev = node-\u0026gt;prev; // node节点的后驱节点的先驱指向node的先驱\rdelete node; // 释放node\rsetlen(ReductOne);\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid TwoWayList\u0026lt;T\u0026gt; ::queryAll()\r{\rif (isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;The list length is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn;\r}\rcout \u0026lt;\u0026lt; \u0026quot;The length of the two way list is zero:\u0026quot; \u0026lt;\u0026lt; getlen() \u0026lt;\u0026lt; endl;\rint __index = 1;\rTwoWayLinkedNode\u0026lt;T\u0026gt; *node = head;\rwhile (node != tail-\u0026gt;next)\r{\rcout \u0026lt;\u0026lt; \u0026quot;node num is:\u0026quot; \u0026lt;\u0026lt; __index \u0026lt;\u0026lt; \u0026quot; data:\u0026quot; \u0026lt;\u0026lt; node-\u0026gt;data \u0026lt;\u0026lt; endl;\rnode = node-\u0026gt;next;\r__index++; }\r}\rtemplate\u0026lt;class T\u0026gt;\rbool TwoWayList\u0026lt;T\u0026gt; ::queryIndex(int index, T *data)\r{\rlen = getlen();\r// 链表为空,index \u0026gt;= len || index \u0026lt; 0 就返回\rif(isEmpty() || index \u0026gt;= len || index \u0026lt; 0)\r{\rreturn false;\r}\rint __index = 0;\rfor(TwoWayLinkedNode\u0026lt;T\u0026gt; *node = head; node != tail-\u0026gt;next; node = node-\u0026gt;next)\r{\rif (__index == index)\r{\r*data = node-\u0026gt;data;\rreturn true;\r}\r__index++;\r}\rreturn false;\r}\rtemplate\u0026lt;class T\u0026gt;\rbool TwoWayList\u0026lt;T\u0026gt; ::queryValue(T data)\r{\rif(isEmpty())\r{\rreturn false;\r}\rfor(TwoWayLinkedNode\u0026lt;T\u0026gt; *node = head; node != tail-\u0026gt;next; node = node-\u0026gt;next)\r{\rif (node-\u0026gt;data == data)\r{\rreturn true;\r}\r}\rreturn false;\r}\r测试 int main()\r{\rTwoWayList\u0026lt;int\u0026gt; newList;\rnewList.inseartToHead(3);\rnewList.inseartToHead(2);\rnewList.inseartToHead(1);\rnewList.inseartToHead(-11);\rnewList.inseartTotail(4);\rnewList.inseartTotail(5);\rnewList.inseartTotail(6);\rnewList.inseartTotail(7);\rnewList.inseartTotail(8);\rnewList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;****************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rnewList.inseartToindex(2, 11);\rnewList.inseartToindex(0, 2);\rnewList.inseartToindex(1, 3);\rnewList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;****************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rnewList.deleteToHead();\rnewList.deleteToHead();\rnewList.deleteToHead();\rnewList.queryAll();\r// newList.clear();\rcout \u0026lt;\u0026lt; \u0026quot;****************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rnewList.deleteToTail();\rnewList.deleteToTail();\rnewList.deleteToTail();\rnewList.deleteToTail();\rnewList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;****************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rnewList.deleteToIndex(4);\rnewList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;****************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rint index = 1;\rint info;\rif(newList.queryIndex(index, \u0026amp;info))\r{\rcout \u0026lt;\u0026lt; \u0026quot;exits index: \u0026quot; \u0026lt;\u0026lt; index \u0026lt;\u0026lt; \u0026quot; =\u0026gt; value is \u0026quot; \u0026lt;\u0026lt; info\u0026lt;\u0026lt; endl;\r}\relse\r{\rcout \u0026lt;\u0026lt;\u0026quot; no exits index:\u0026quot; \u0026lt;\u0026lt; index \u0026lt;\u0026lt; endl;\r}\rcout \u0026lt;\u0026lt; \u0026quot;****************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rnewList.queryAll();\rcout \u0026lt;\u0026lt; newList.queryValue(1)\u0026lt;\u0026lt; endl;\rsystem(\u0026quot;pause\u0026quot;);\rreturn 0;\r}\r循环双向链表 数据结构的定义 // 循环双向链表节点\rtemplate\u0026lt;class T\u0026gt;\rclass CircularDoubleLinkedNode\r{\rpublic:\rCircularDoubleLinkedNode()\r{\rprev = next = 0;\r}\rCircularDoubleLinkedNode(T data)\r{\rinfo = data;\rprev = next = 0;\r}\r~CircularDoubleLinkedNode(){};\rT info; // 数据\rCircularDoubleLinkedNode *prev; // 先驱节点\rCircularDoubleLinkedNode *next; // 后继节点\r};\rtemplate\u0026lt;class T\u0026gt;\rclass CircularDoubleList\r{\rprivate:\rCircularDoubleLinkedNode\u0026lt;T\u0026gt; *current_node; // 指向当前节点\rint len; // 链表的长度\rpublic:\rCircularDoubleList()\r{\rcurrent_node = 0;\rlen = 0;\r}\r~CircularDoubleList();\rvoid addLen()\r{\rlen++;\r}\rvoid reduceLen()\r{\rlen--;\r}\rint getLen()\r{\rreturn len;\r}\rbool isEmpty()\r{\rreturn current_node == 0;\r}\rvoid inseartNode(T data);\rbool deleteNode();\rvoid queryAll();\r// 判断value是否存在\rbool queryValue(T data);\r};\r数据的操作 \rtemplate\u0026lt;class T\u0026gt;\rvoid CircularDoubleList\u0026lt;T\u0026gt; ::inseartNode(T data)\r{\rCircularDoubleLinkedNode\u0026lt;T\u0026gt; *new_node = new CircularDoubleLinkedNode\u0026lt;T\u0026gt;(data);\r// 如果链表为空\rif(isEmpty())\r{\r// 当前节点为新的节点\rcurrent_node = new_node;\rcurrent_node-\u0026gt;next = current_node; // 后驱指向自己\rcurrent_node-\u0026gt;prev = current_node; // 前驱也指向自己\r}\relse\r{\r/*与双向链表中的插入到链表中是一样的*/\rcurrent_node-\u0026gt;next-\u0026gt;prev = new_node;\rnew_node-\u0026gt;prev = current_node;\rnew_node-\u0026gt;next = current_node-\u0026gt;next;\rcurrent_node-\u0026gt;next = new_node;\rcurrent_node = new_node;\r}\raddLen();\r}\rtemplate\u0026lt;class T\u0026gt;\rbool CircularDoubleList\u0026lt;T\u0026gt; ::deleteNode()\r{\r// 链表为空\rif(isEmpty())\r{\rreturn false;\r}\rint len = getLen();\r// 链表中只有一个元素\rif(len == 1)\r{\rdelete current_node;\rcurrent_node = 0;\rreduceLen();\rreturn true;\r}\r// 链表中只有两个元素\rif (len == 2)\r{\rCircularDoubleLinkedNode\u0026lt;T\u0026gt; *node = current_node;\rcurrent_node = current_node-\u0026gt;next;\rcurrent_node-\u0026gt;next = current_node;\rcurrent_node-\u0026gt;prev = current_node;\rdelete node;\rreduceLen();\rreturn true;\r}\r// 链表元素达到3个及3个以上\rCircularDoubleLinkedNode\u0026lt;T\u0026gt; *node = current_node;\rcurrent_node-\u0026gt;prev-\u0026gt;next = current_node-\u0026gt;next;\rcurrent_node-\u0026gt;next-\u0026gt;prev = current_node-\u0026gt;prev;\rcurrent_node = current_node-\u0026gt;next;\rdelete node;\rreduceLen();\rreturn true;\r}\rtemplate\u0026lt;class T\u0026gt;\rvoid CircularDoubleList\u0026lt;T\u0026gt; ::queryAll()\r{\rif(isEmpty())\r{\rcout \u0026lt;\u0026lt; \u0026quot;circular double list is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn;\r}\rcout \u0026lt;\u0026lt; \u0026quot;circular double list len is:\u0026quot; \u0026lt;\u0026lt; getLen() \u0026lt;\u0026lt; endl;\rint __index = 1;\rfor (CircularDoubleLinkedNode\u0026lt;T\u0026gt; *node = current_node-\u0026gt;next; node != current_node; node = node-\u0026gt;next)\r{\rcout \u0026lt;\u0026lt; \u0026quot;index:\u0026quot; \u0026lt;\u0026lt; __index \u0026lt;\u0026lt; \u0026quot; data is: \u0026quot; \u0026lt;\u0026lt; node-\u0026gt;info \u0026lt;\u0026lt; endl;\r__index++;\r}\rcout \u0026lt;\u0026lt; \u0026quot;index:\u0026quot; \u0026lt;\u0026lt; __index \u0026lt;\u0026lt; \u0026quot; data is: \u0026quot; \u0026lt;\u0026lt; current_node-\u0026gt;info \u0026lt;\u0026lt; endl;\r}\rtemplate\u0026lt;class T\u0026gt;\rbool CircularDoubleList\u0026lt;T\u0026gt; ::queryValue(T data)\r{\r// 判断链表为空\rif(isEmpty())\r{\rreturn false;\r}\r// 当前节点的值== data\rif(current_node-\u0026gt;info == data)\r{\rreturn true;\r}\r// 循环遍历当节点的value== data then retuen ture\rfor(CircularDoubleLinkedNode\u0026lt;T\u0026gt; *node = current_node-\u0026gt;next; node != current_node; node = node-\u0026gt;next)\r{\rif(node-\u0026gt;info == data)\r{\rreturn true;\r}\r}\rreturn false;\r}\r测试 int main()\r{\rCircularDoubleList\u0026lt;int\u0026gt; cirList;\rcirList.inseartNode(0);\rcirList.inseartNode(1);\rcirList.inseartNode(2);\rcirList.inseartNode(3);\rcirList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;*****************************************************\u0026quot; \u0026lt;\u0026lt; endl;\rcirList.deleteNode();\rcirList.deleteNode();\r// cirList.deleteNode();\r// cirList.deleteNode();\rcirList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;******************************************************\u0026quot; \u0026lt;\u0026lt;endl;\rint data = 11;\rif(cirList.queryValue(data))\r{\rcout \u0026lt;\u0026lt; data \u0026lt;\u0026lt; \u0026quot; is exists\u0026quot; \u0026lt;\u0026lt; endl;\r}\relse\r{\rcout \u0026lt;\u0026lt; data \u0026lt;\u0026lt; \u0026quot; is not exists\u0026quot; \u0026lt;\u0026lt; endl;\r}\rsystem(\u0026quot;pause\u0026quot;);\rreturn 0;\r}\r源码  我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForC/tree/master/linked_list/two_way_linked_list 我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForC/tree/master/linked_list/circular_double_linked_list  ","date":"2021-12-30T21:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E5%BE%AA%E7%8E%AF%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8-c-%E5%AE%9E%E7%8E%B0/1_huc216cf6486350636a2e6728955e7fc78_62516_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8%E5%BE%AA%E7%8E%AF%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8-c-%E5%AE%9E%E7%8E%B0/","title":"数据结构-双向链表\u0026\u0026循环双向链表 c++实现"},{"content":"单向链表 数据结构的定义 数据节点的类的定义 class SinglyLinkedNode\r{\rpublic:\rSinglyLinkedNode(){\rnext = 0;\r};\r// 创建新的node\rSinglyLinkedNode(int data)\r{\rthis-\u0026gt;data = data;\rnext = 0;\r};\r~SinglyLinkedNode(){};\rint data; // 链表的数据\rSinglyLinkedNode *next; // 指向下一个节点\r};\r链表的数据结构(类的定义) class SinglyList\r{\rprivate:\r/* data */\rSinglyLinkedNode *head; // 头节点\rSinglyLinkedNode *tail; // 尾节点\rint len; // 链表长度\rpublic:\rSinglyList(){\rhead = 0;\rtail = 0;\rlen = 0;\r};\r~SinglyList();\r// 链表的长度+1\rvoid setlen(int len)\r{\rthis-\u0026gt;len += len;\r}; // 返回链表的长度\rint getlen()\r{\rreturn len;\r};\r// 链表是否为空\rbool ismpty()\r{\rreturn head == 0;\r}\r// 插入到链表的头部\rvoid inseartToHead(int data); // 插入到链表的尾部\rvoid inseartTotail(int data); // 插入到链表的index\rvoid inseartToindex(int index, int data); // 删除链表的头部元素\rvoid deleteToHead();\r// 删除链表的尾部元素\rvoid deleteToTail();\r// 删除链表的index元素\rvoid deleteToIndex(int index);\r// 查询链表的所有值\rvoid queryAll();\r// 返回index的值\rint queryIndex(int index);\r// 判断value是否存在\rbool queryValue(int data);\r};\r数据的插入 插入到链表的尾部 void SinglyList::inseartTotail(int data)\r{\r// 定义node\rSinglyLinkedNode *new_node;\rnew_node = new SinglyLinkedNode(data);\r// 链表为空\rif (ismpty())\r{\rhead = tail = new_node; // 头尾节点都指向新创节点\rsetlen(addOne); // 节点数+1\rreturn;\r}\rtail-\u0026gt;next = new_node;\rtail = tail-\u0026gt;next;\rsetlen(addOne);\r}\r插入到链表的头部 void SinglyList::inseartToHead(int data)\r{\rSinglyLinkedNode *node;\rnode = new SinglyLinkedNode(data);\rif (ismpty()){\rhead = tail = node;\rsetlen(addOne);\rreturn ;\r}\rnode-\u0026gt;next = head;\rhead = node;\rsetlen(addOne);\r}\r插入到链表的index void SinglyList::inseartToindex(int index, int data)\r{\rint len;\rlen = getlen()-1;\r// 如果链表为空, 或者插入到末尾,或者index \u0026lt;0 采用尾插法添加到链表中\rif (ismpty() || index ==len || index \u0026lt; 0)\r{\rinseartTotail(data);\rreturn;\r}\rif(index == 0){\rinseartToHead(data);\rreturn;\r}\rSinglyLinkedNode *node;\rnode = new SinglyLinkedNode(data);\rint __index = 1;\rfor (node = head; node != tail; node = node-\u0026gt;next)\r{\rif (__index == index)\r{\rSinglyLinkedNode *new_node;\rnew_node = new SinglyLinkedNode(data);\rnew_node -\u0026gt;next = node-\u0026gt;next;\rnode-\u0026gt;next = new_node;\rsetlen(addOne);\rreturn;\r}\r__index ++;\r}\r}\r数据的删除 删除链表的头部元素 void SinglyList::deleteToHead()\r{\r// 链表为空\rif(ismpty())\r{\rreturn;\r}\rSinglyLinkedNode *tmp = head;\r// 链表只存在一个值\rif(head == tail)\r{\rhead = tail = 0;\r}\relse\r{\rhead = head-\u0026gt;next;\r}\rdelete tmp; // 释放资源\rsetlen(ReductOne);\r}\r删除链表的尾部元素 void SinglyList::deleteToTail()\r{\r// 链表为空\rif(ismpty())\r{\rreturn;\r}\r// 链表只存在一个值\rif(head == tail)\r{\rdelete head;\rsetlen(ReductOne);\rhead = tail = 0;\rreturn;\r}\rSinglyLinkedNode *tmp = head;\rwhile (tmp-\u0026gt;next != tail)\r{\rtmp = tmp-\u0026gt;next;\r}\rdelete tail;\rtail = tmp;\rtail-\u0026gt;next = 0;\rsetlen(ReductOne);\r}\r删除链表的index元素 void SinglyList::deleteToIndex(int index)\r{\r// 链表为空\rif(ismpty())\r{\rreturn;\r}\r// 链表只存在一个值\rif(head == tail)\r{\rdelete head;\rsetlen(ReductOne);\rhead = tail = 0;\rreturn;\r}\rint len = getlen();\rif (index \u0026gt;= len-1 || index \u0026lt; 0)\r{\rdeleteToTail();\rreturn;\r}\rif (index == 0)\r{\rdeleteToHead();\rreturn;\r}\rSinglyLinkedNode *node = head;\rSinglyLinkedNode *tmp = head-\u0026gt;next;\rint __index = 1;\rwhile (__index != index)\r{\rnode = node-\u0026gt;next;\rtmp = tmp-\u0026gt;next;\r__index ++;\r}\rnode-\u0026gt;next = tmp-\u0026gt;next;\rdelete tmp;\rsetlen(ReductOne);\r}\r数据的查询 查询链表的所有值 void SinglyList::queryAll()\r{\rif (ismpty()){\rcout \u0026lt;\u0026lt; \u0026quot;The list length is empty\u0026quot; \u0026lt;\u0026lt; endl;\rreturn;\r}\rint i = 1;\rcout \u0026lt;\u0026lt; \u0026quot;The length of the list is zero:\u0026quot; \u0026lt;\u0026lt; getlen() \u0026lt;\u0026lt; endl;\rSinglyLinkedNode *node;\rfor(node = head; node != tail-\u0026gt;next; node = node-\u0026gt;next){\rcout \u0026lt;\u0026lt; \u0026quot;node num is:\u0026quot; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026quot; data:\u0026quot; \u0026lt;\u0026lt; node-\u0026gt;data \u0026lt;\u0026lt; endl;\ri++;\r}\r}\r返回index的值 int SinglyList::queryIndex(int index)\r{\rint len = getlen();\r// 链表为空, 索引不存在\rif(ismpty() || index \u0026gt; len -1 || index \u0026lt; 0)\r{\rreturn -1;\r}\rif (index == 0)\r{\rreturn head -\u0026gt;data;\r}\rif (index == len -1)\r{\rreturn tail -\u0026gt;data;\r}\rint __index = 1;\rfor (SinglyLinkedNode *node = head-\u0026gt;next; node != tail; node = node-\u0026gt;next)\r{\rif (index == __index)\r{\rreturn node-\u0026gt;data;\r}\r__index ++; }\rreturn -1;\r}\r判断value是否存在 bool SinglyList::queryValue(int value)\r{\r// 链表为空\rif(ismpty())\r{\rreturn false;\r}\r// 链表只存在一个值\rif(head == tail)\r{\rif (head-\u0026gt;data == value){\rreturn true;\r}\rreturn false;\r}\rfor(SinglyLinkedNode *node = head; node != tail-\u0026gt;next; node = node-\u0026gt;next)\r{\rif(node-\u0026gt;data == value)\r{\rreturn true;\r}\r}\rreturn false;\r}\r测试 int main()\r{\rSinglyList newList;\rnewList.inseartTotail(1);\rnewList.inseartTotail(2);\rnewList.inseartTotail(3);\rnewList.inseartToHead(0);\rnewList.inseartToHead(-11);\rnewList.inseartToHead(-12);\rnewList.inseartToHead(-13);\rnewList.inseartToindex(6,5);\rnewList.inseartToindex(-7,51);\rnewList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rnewList.deleteToHead();\rnewList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rnewList.deleteToTail();\rnewList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rnewList.deleteToTail();\rnewList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rnewList.deleteToIndex(3);\rnewList.queryAll();\rcout \u0026lt;\u0026lt; \u0026quot;************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rcout \u0026lt;\u0026lt; newList.queryIndex(5) \u0026lt;\u0026lt; endl;\rcout \u0026lt;\u0026lt; \u0026quot;************************************************\u0026quot;\u0026lt;\u0026lt; endl;\rcout \u0026lt;\u0026lt; newList.queryValue(21) \u0026lt;\u0026lt; endl;\rsystem(\u0026quot;pause\u0026quot;);\rreturn 0;\r}\r源码  我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForC/tree/master/linked_list/singly_linked_list  ","date":"2021-12-27T22:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8c-%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/1_huda65db0749ea5cfbe7a2aa726c042ca1_14970_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8c-%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/","title":"数据结构-单向链表c++语言实现"},{"content":"单向链表 数据结构的定义 单项链表节点的定义\rtype singlyLinkedNode struct {\rinfo interface{} // 存储任意数据\rnext *singlyLinkedNode // 指向下一节点\r}\rtype linkedList struct {\rlen int // 链表长度\rHead *singlyLinkedNode // 头节点\rTail *singlyLinkedNode // 尾节点\r}\r创建节点 func createNode(info interface{}) *singlyLinkedNode {\rnode := \u0026amp;singlyLinkedNode{\rinfo: info,\rnext: nil,\r}\rreturn node\r}\r链表的长度 func(l *linkedList)Len() int{\rreturn l.len\r}\r数据的插入 单个节点的插入 // 链表的尾插法\rfunc (l *linkedList)AddToTail(info interface{}) *linkedList {\rnewNode := createNode(info) // 创建新节点\r// 链表为空, 头尾节点都指向该节点\rif l.Tail == nil{\rl.Head = newNode\rl.Tail = newNode\r}\rl.Tail.next = newNode\rl.Tail = l.Tail.next\r// 链表长度+1\rl.len++\rreturn l\r}\r// 链表的头插法\rfunc (l *linkedList)AddToHead(info interface{}) *linkedList {\rnewNode := createNode(info) // 创建节点\r// 链表为空\rif l.Head == nil{\rl.Head = newNode\rl.Tail = newNode\r}\rnewNode.next = l.Head\rl.Head = newNode\r// 链表长度+1\rl.len++\rreturn l\r}\r// 链表的index\r// 通过index=\u0026gt;插入链表新的节点\r// index为正数 为从左-\u0026gt;右 // 0表示第一个节点\r// index为负数 为从右-\u0026gt;左 // -1表示第一个节点\rfunc (l *linkedList)AddToIndex(index int, info interface{}) *linkedList {\r// 当链表为空时，采用了尾插入法插入数据\rif l.Head == nil{\rreturn l.AddToTail(info)\r}\r// 当index大于链表的值时，默认将数据插入到链表的后面\rif int(math.Abs(float64(index))) \u0026gt; l.len-1{\rreturn l.AddToTail(info)\r}\r// 插入链表的头部\rif index == 0{\rreturn l.AddToHead(info)\r}\r// 插入到链表的末尾\rif index == -1{\rreturn l.AddToTail(info)\r}\r// 当index 为负数时，从右到左插入\rif index \u0026lt; 0{\rindex += l.len\r}\r__index := 1 // 内部的index值\r// 从第二个值开始插入\rfor node := l.Head.next; node != l.Tail; node = node.next{\rif index == __index{\rnewNode := createNode(info)\rnewNode.next = node.next // 指向node的后继节点\rnode.next = newNode // node 指向这个新的节点\r// 链表的节点数加1\rl.len ++\rreturn l\r}\r__index ++\r}\rreturn l\r}\r链表的合并 // 将新的链表插入头部\rfunc (l *linkedList)AddListToHead(list *linkedList)*linkedList{\r// 两个链表都为空时\rif l.Head == nil \u0026amp;\u0026amp; list.Head == nil{\rreturn l\r}\r// 合并表为空\rif l.Head != nil \u0026amp;\u0026amp; list.Head == nil{\rreturn l\r}\r// 主表为空\rif l.Head == nil \u0026amp;\u0026amp; list.Head != nil{\rreturn list\r}\r// 合并表的尾指针指向主表的头\rlist.Tail.next = l.Head\rlist.Tail = l.Tail\r// 表节点数合并\rlist.len += l.len\rreturn list\r}\r// 将新的链表插入到尾部\rfunc (l *linkedList)AddListToTail(list *linkedList)*linkedList{\r// 两个链表都为空时\rif l.Head == nil \u0026amp;\u0026amp; list.Head == nil{\rreturn l\r}\r// 合并表为空\rif l.Head != nil \u0026amp;\u0026amp; list.Head == nil{\rreturn l\r}\r// 主表为空\rif l.Head == nil \u0026amp;\u0026amp; list.Head != nil{\rreturn list\r}\r// 将新表插入到主表之后\rl.Tail.next = list.Head\rl.Tail = list.Tail\rl.len += list.len\rreturn l\r}\r// 经新的表插入到index\rfunc (l *linkedList)AddListToIndex(index int, list *linkedList) *linkedList {\r// 两个链表都为空时\rif l.Head == nil \u0026amp;\u0026amp; list.Head == nil{\rreturn l\r}\r// 合并表为空\rif l.Head != nil \u0026amp;\u0026amp; list.Head == nil{\rreturn l\r}\r// 主表为空\rif l.Head == nil \u0026amp;\u0026amp; list.Head != nil{\rreturn list\r}\rif int(math.Abs(float64(index))) \u0026gt; l.len{\rfmt.Println(\u0026quot;错误的index\u0026quot;)\rreturn l\r}\rif index == 0{\rreturn l.AddListToHead(list)\r}\rif int(math.Abs(float64(index))) == l.len -1 || index == -1{\rreturn l.AddListToTail(list)\r}\rif index \u0026lt; 0{\rindex += l.len\r}\r__index := 1\rfor node := l.Head.next; node != l.Tail; node = node.next{\rif index == __index{\rlist.Tail.next = node.next\rnode.next = list.Head\rl.len += list.len // 链表的数值相加\rreturn l\r}\r__index ++\r}\rreturn l\r}\r数据的删除 // 链表头删除法\rfunc (l *linkedList)DeleteToHead()*linkedList{\r// 链表为空\rif l.Head == nil{\rreturn l\r}\r// 链表中只有一个数\rif l.Head == l.Tail{\rl.Head = nil\rl.Tail = nil\rl.len = 0\rreturn l\r}\rl.Head = l.Head.next\r// node数减一\rl.len --\rreturn l\r}\r// 链表尾删除法\rfunc (l *linkedList)DeleteToTail()*linkedList{\r// 链表为空\rif l.Tail == nil{\rreturn l\r}\r// 链表中只有一个数\rif l.Head == l.Tail{\rl.Head = nil\rl.Tail = nil\rl.len = 0\rreturn l\r}\r// 找出尾节点的上一节点\rvar node *singlyLinkedNode\rfor node = l.Head; node.next != l.Tail; node = node.next{}\rnode.next = nil\rl.Tail = node\r// node数减一\rl.len --\rreturn l\r}\r// 通过值=\u0026gt;删除链表的节点(第一个)\rfunc (l *linkedList)DeleteToAValue(value interface{})*linkedList{\r// 链表为空\rif l.Head == nil{\rfmt.Println(\u0026quot;链表为空\u0026quot;)\rreturn l\r}\r// value == head.info\r// 就采用头删法\rif value == l.Head.info{\rreturn l.DeleteToHead()\r}\r// 中间采用轮询查找value, 从第二个开始轮询到倒数第二个结束\rnode := l.Head\rfor temp := l.Head.next; temp != nil; temp = node.next{\rif temp.info == value{\r// 删除node\rnode.next = temp.next\rl.len --\rreturn l\r}\rnode = node.next\r}\rfmt.Println(\u0026quot;链表中：值不存在\u0026quot;)\rreturn l\r}\r// 通过值=\u0026gt;删除链表的节点(所有)\rfunc (l *linkedList)DeleteToValue(value interface{})*linkedList{\r// 链表为空\rif l.Head == nil{\rfmt.Println(\u0026quot;链表为空\u0026quot;)\rreturn l\r}\rnode := l.Head // 当前的node\rtemp := l.Head.next // 下一个node\rfor {\r// 当下一个节点是尾节点时，就判断首位和末尾是为需要删除的node\rif temp == l.Tail {\rif l.Head.info == value{\rl.DeleteToHead()\r}\rif l.Tail.info == value{\rl.DeleteToTail()\r}\rreturn l\r}\rif temp.info == value{\r// 删除node\rnode.next = temp.next\rtemp = temp.next\r// node数减一\rl.len --\rcontinue\r}\rnode = node.next\rtemp = temp.next\r}\r}\r// 通过index=\u0026gt;删除链表的节点\r// index为正数 为从左-\u0026gt;右 // 0表示第一个节点\r// index为负数 为从右-\u0026gt;左 // -1表示第一个节点\rfunc (l *linkedList)DeleteToIndex(index int)*linkedList{\r// 链表为空\rif l.Head == nil{\rfmt.Println(\u0026quot;链表为空\u0026quot;)\rreturn l\r}\r// index 超过链表数\rif int(math.Abs(float64(index))) \u0026gt; l.len-1{\rfmt.Println(\u0026quot;错误的index\u0026quot;)\rreturn l\r}\r// 删除第一个node\rif index == 0{\rreturn l.DeleteToHead()\r}\rif index \u0026lt; 0{\rindex += l.len\r}\r_index := 1\rnode := l.Head\rtemp := node.next\rfor {\rif index == _index{\rif temp != nil{\rnode.next = temp.next\r}\rl.len --\rreturn l\r}\rnode = node.next\rtemp = temp.next\r_index ++\r}\r}\r数据的查询 // 遍历链表\rfunc (l *linkedList) QuireAll() {\rif l.Head == nil{\rfmt.Println(\u0026quot;链表数据为空\u0026quot;)\rreturn\r}\rnode := l.Head\rfor {\rif node == nil{\rreturn\r}\rfmt.Println(node.info)\rif node == l.Tail{\rreturn\r}\rnode = node.next\r}\r}\r// 判断valve是否存在\rfunc (l *linkedList)QuireValue(value interface{}) bool{\r// 表为空\rif l.Head == nil{\rreturn false\r}\r// 表中只存在一个值\rif l.Head == l.Tail{\rif l.Head.info == value{\rreturn true\r}\rreturn false\r}\r// 遍历查值\rfor node := l.Head; node != l.Tail.next; node = node.next{\rif node.info == value{\rreturn true\r}\r}\rreturn false\r}\r// 根据索引返回值\rfunc (l *linkedList)QuireIndex(index int) interface{} {\r// 链表为空\rif l.Head == nil{\rreturn nil\r}\rif int(math.Abs(float64(index))) \u0026gt; l.len -1 {\rfmt.Println(\u0026quot;索引值错误\u0026quot;)\rreturn nil\r}\rif index == 0{\rreturn l.Head.info\r}\rif index == l.len -1 || index == -1{\rreturn l.Tail.info\r}\rif index \u0026lt; 0{\rindex += l.len\r}\r__index := 1\rfor node := l.Head.next; node != l.Tail; node = node.next{\rif __index == index{\rreturn node.info\r}\r__index ++\r}\r//fmt.Println(\u0026quot;未能找到！！！！\u0026quot;)\rreturn nil\r}\r结构的入口 func NewLinkerList()*linkedList{\r// 创建的链表头尾节点都为空\rreturn \u0026amp;linkedList{\rHead: nil,\rTail: nil,\rlen: 0,\r}\r}\r源码  我的github:https://github.com/zcj-git520/DataStructuresAlgorithmsForGo/tree/master/Linked_list/Singly_linked_list  ","date":"2021-12-25T22:00:08+08:00","image":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/1_huda65db0749ea5cfbe7a2aa726c042ca1_14970_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%8D%95%E5%90%91%E9%93%BE%E8%A1%A8go%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0/","title":"数据结构-单向链表go语言实现"},{"content":"host_try  host_try：主要是目的是在单个或者多个host的下，连接超时或者连接失败下的重试机制 host_try: 提供三种退避策略：1. 尝试等待时间指数增长 2. 以相同时间进行尝试 3.随机时间进行尝试 三种尝试策略可一起使用 host_try: 提供三种重试方式：1. 轮询host进行重连, 重连次数达到后,在将换下一host, 直到重新连接成功或所有的host都重连完成结束 2.每一个host进行重连, 在将换下一host, 所有的host失败了,在进行下一次重连。直到重新连接成功或重连次数达到后结束 3. 重试直到成功 host_try 只是提供重试连接的接口，具体请求的方法需要自己写  host_try的工作原理  存在多个host的请求提供相同的服务如(ntp)，存在连接超时的情况，需要不断的尝试连接， 只要一个host连接请求成功就返回  host_try的配置结构 type tryConfig struct {\rattemptNum uint // 尝试的重连的次数\rnowAttempt uint // 现在第几次重连\rhosts []string // 连接的host组\rsuccessHost string // 连接成功的host\rerrorHost map[string]string // 连接失败的host和错误原因\rattemptType string // 重连方式\rattemptStatus bool // 最终重连的状态\rdelay time.Duration // 延时时间\rmaxDelay time.Duration // 最大延时时间\rmaxJitter time.Duration // 最大随机数时间\rdelayType []uint // 退避策略类型\rcontest context.Context\r}\r提供三种退避策略 第一种策略  延时时间* 因子**重连次数(因子默认为2) func (t *tryConfig)backOffDelay(n uint) time.Duration  第二种策略  以相同的时间进行延时  func (t *tryConfig)fixedDelay() time.Duration  第三种策略  随机延迟时间  func (t *tryConfig)randomDelay() time.Duration  重试方式 方式1  轮询host进行重连, 重连次数达到后,在将换下一host, 直到重新连接成功或所有的host都重连完成结束 func (t *tryConfig) directConnection (retryableFunc RetryableFunc)  方式2  每一个host进行重连, 在将换下一host, 所有的host失败了,在进行下一次重连。直到重新连接成功或重连次数达到后结束  func (t *tryConfig) staggeredConnection (retryableFunc RetryableFunc)  方式3  重试直到成功 func (t *tryConfig) untilConnection (retryableFunc RetryableFunc)  使用 host := []string{\u0026quot;172.16.21.1\u0026quot;,\u0026quot;ntp.ntsc1.ac.cn\u0026quot;,\u0026quot;cn.ntp1.org.cn\u0026quot;,\u0026quot;cn.pool.ntp1.org\u0026quot;,\u0026quot;time.pool.aliyun1.com\u0026quot;, \u0026quot;172.16.2.1\u0026quot;}\rdemo := New(host, AttemptType(\u0026quot;directConnection\u0026quot;))\rdemo.DoTry(SetNtpTime)\r 重连的入口，当轮询时间为0时，使用方式3，默认为：方式2  // 尝试的重连的次数默认为：5次\r// 重连方式默认为：方式2\r// 延时时间默认为：10*time.Minute\r// 最大延时时间默认为：100*time.Minute\r// 最大随机数时间默认为：100*time.Minute\r// 退避策略类型默认为：策略1\rfunc New(hots []string, opts ...Option) *tryConfig\rfunc (t *tryConfig) DoTry(retryableFunc RetryableFunc)\r源码  我的github:https://github.com/zcj-git520/host_try  ","date":"2021-12-20T22:00:08+08:00","image":"https://zcj-git520.github.io/p/%E8%B6%85%E6%97%B6%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6-host_try/1_huc278944164dd3ada59be56854851c305_117502_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/%E8%B6%85%E6%97%B6%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6-host_try/","title":"超时重试机制-host_try"},{"content":"timerTask 定时任务：可以定时执行单个或者对个任务：\n 定时定时任务 停止定时任务 重置定时时间，并执行定时任务 定时开启定时任务 定时结束定时任务  timerTask结构 type timerConfig struct {\rtiming time.Duration // 定时时间\rstartTiming time.Duration // 定时开启定时任务时间\rstopTiming time.Duration // 定时停止定时任务时间\rrunning bool // 定时器运行的状态,运作中为true/没有运行为false\rtasks []func() // 定时任务\rstopChan chan struct{} // 停止定时器日任务\rrunningMu sync.Mutex\rWaiter sync.WaitGroup\r}\r定时任务的开始和结束 函数原型：NewTimerTask(d time.Duration, tasks []func(), opts ... Option) *timerConfig\r参数为：统一的定时任务时间,定时任务集, 可选参数【定时开启定时任务时间(SetTimerStart(d time.Duration)), 定时停止定时任务时间(SetTimerStop(d time.Duration))】\rStart()开始定时任务, Stop()结束定时任务 使用\nt1 := 1 * time.Second\rtasks := []func(){printTest1, printTest2, printTest3, printTest4, printTest5}\rtimer := NewTimerTask(t1, tasks)\rtimer.Waiter.Add(2)\rtimer.start()\rgo func() {\rselect {\rcase \u0026lt;-time.After(5*time.Second):\rtimer.stop()\rtimer.Waiter.Done()\rreturn\r}\r}()\rtimer.Waiter.Wait()\r重置定时时间任务 函数原型：Reset(d time.Duration) // 重置定时的时间\r使用：\n\tt1 := 1 * time.Second\rtasks := []func(){printTest1, printTest2, printTest3, printTest4, printTest5}\rtimer := NewTimerTask(t1, tasks)\rtimer.Waiter.Add(3)\rtimer.start()\rgo func() {\rselect {\rcase \u0026lt;-time.After(10*time.Second):\rtimer.stop()\rtimer.Waiter.Done()\rreturn\r}\r}()\rgo func() {\rselect {\rcase \u0026lt;-time.After(5*time.Second):\rtimer.Reset(2*time.Second)\rtimer.Waiter.Done()\rreturn\r}\r}()\rtimer.Waiter.Wait()\r定时开始定时任务 函数原型：TimerStart() ,需要在初始化时,设定定时开始定时任务的时间\r使用：\n\tt1 := 1 * time.Second\rts := time.Now()\rtasks := []func(){printTest1, printTest2, printTest3, printTest4, printTest5}\rtimer := NewTimerTask(t1, tasks, SetTimerStart(3*time.Second))\rtimer.TimerStart()\rt.Logf(\u0026quot;定时时间为：%v\u0026quot;, time.Now().Sub(ts))\rtimer.Waiter.Add(2)\rtimer.start()\rgo func() {\rselect {\rcase \u0026lt;-time.After(5*time.Second):\rtimer.stop()\rtimer.Waiter.Done()\rreturn\r}\r}()\rtimer.Waiter.Wait()\r定时结束定时任务 函数原型：TimerStop(),设定定时结束定时任务的时间\r 使用：  t1 := 1 * time.Second\rtasks := []func(){printTest1, printTest2, printTest3, printTest4, printTest5}\rtimer := NewTimerTask(t1, tasks, SetTimerStop(3*time.Second))\rtimer.Waiter.Add(1)\rtimer.start()\rtime.Sleep(1*time.Second)\rts := time.Now()\rtimer.TimerStop()\rt.Logf(\u0026quot;定时时间为：%v\u0026quot;, time.Now().Sub(ts))\rtimer.Waiter.Wait()\r源码  我的github:https://github.com/zcj-git520/timerTask  ","date":"2021-12-15T22:00:08+08:00","image":"https://zcj-git520.github.io/p/timertask-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%8C%85/1_hu8e77554b4f75574526b9eba572e1dcc7_37690_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/timertask-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%8C%85/","title":"timerTask 定时任务包"},{"content":"常见的IO类型 同步阻塞IO  用户线程通过调用系统命令发起io操作，由用户态复制到内核态空间，内核态一直在等待， 直到获取到数据时，将接收到的数据拷贝到用户态空间，用户线程在获取数据。整个过程用户线程 处于阻塞的状态，直到有数据为止。  同步非阻塞IO  在同步阻塞io的基础上，用户线程发起io操作后，就立刻返回。由于是非阻塞的方式，就存在返回时 没有数据，就需要不断的轮询发起io请求，直到接收到数据为止。  IO多路复用  io多路复用是一种同步的io模型。实现在内核态中一个线程监视多个io(文件句柄)，一旦某个io就绪后， 就通知用户线程进行相关的操作。没有io就绪时就阻塞用户线程，将交出cpu。多路是指网络连接，复用是指 用一个线程。  信号驱动IO  用户线程发起一个io操作后，会向内核注册一个信号处理函数，然后返回，当内核中有数据时，就会发送一个 信号给用户线程，用户态的线程在调用io请求，获取到数据。  异步IO  用户线程发起io操作后就返回。由内核态的线程处理，当内核线程获取到数据后，主动将数据拷贝到用户态， 并告知用户线程io操作也完成。 \r  io多路复用的三种实现方式 select  select是采用数组的存储的结构存储io(fd文件句柄)，默认的最大的fd为32位系统1024，64位系统是2048(可设置),用户线程将fd集合拷贝到 内核态并开始监控，当有fd就绪或者过了设置超时时间，就将fd集合中所有未就绪的fd清空(将bitmap置为0)，将就id集合返回到用户态， 用户态的线程通过轮询返回的fd集合找到就绪的fd,进行相关的io操作获取数据。再一次监控时，需要将之前清空的fd 添加到fd集合中进行新一轮的监控。  #include \u0026lt;sys/select.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #define FD_SETSIZE 1024 #define NFDBITS (8 * sizeof(unsigned long)) #define __FDSET_LONGS (FD_SETSIZE/NFDBITS) // 数据结构 (bitmap) typedef struct { unsigned long fds_bits[__FDSET_LONGS]; } fd_set; // API int select( int max_fd, // 最大的文件文件描述符fd fd_set *readset, // 读文件描述符集合 fd_set *writeset, // 写文件描述符集合 fd_set *exceptset, // 异常的文件描述符集合 struct timeval *timeout // 超时时间 ) // 返回值就绪描述符的数目 FD_ZERO(int fd, fd_set* fds) // 清空集合 FD_SET(int fd, fd_set* fds) // 将给定的描述符加入集合 FD_ISSET(int fd, fd_set* fds) // 判断指定描述符是否在集合中 FD_CLR(int fd, fd_set* fds) // 将给定的描述符从文件中删除 //select使用示例 int main() { /* * 这里进行一些初始化的设置， * 包括socket建立，地址的设置等, */ fd_set read_fs, write_fs; struct timeval timeout; int max = 0; // 用于记录最大的fd，在轮询中时刻更新即可 // 初始化比特位 FD_ZERO(\u0026amp;read_fs); FD_ZERO(\u0026amp;write_fs); int nfds = 0; // 记录就绪的事件，可以减少遍历的次数 while (1) { // 阻塞获取 // 每次需要把fd从用户态拷贝到内核态 nfds = select(max + 1, \u0026amp;read_fd, \u0026amp;write_fd, NULL, \u0026amp;timeout); // 每次需要遍历所有fd，判断有无读写事件发生 for (int i = 0; i \u0026lt;= max \u0026amp;\u0026amp; nfds; ++i) { if (i == listenfd) { --nfds; // 这里处理accept事件 FD_SET(i, \u0026amp;read_fd);//将客户端socket加入到集合中 } if (FD_ISSET(i, \u0026amp;read_fd)) { --nfds; // 这里处理read事件 } if (FD_ISSET(i, \u0026amp;write_fd)) { --nfds; // 这里处理write事件 } } } \r\nselect存在的问题  监控的文件描述符集合是有上线的，即存储的fd有最大值，默认的最大的fd为32位系统1024，64位系统2048(可设置) 每一次都是需要将文件描述符集合从用户态拷贝到内核态，且内核态是通过轮询的方式判断fd是否就绪，当文件描述符增多时 会造成整体的性能的下降。 文件描述符集合返回时，会将没有就绪的fd删除(将bitmap置为0)，当继续监控时，会将删除的fd添加到集合中 返回到用户态的集合，并未明确就绪的文件描述符，仍然需要轮询判断  poll  poll 是采用链表来存储fd,没有了最大连接数的限制。用户未每一个fd定义一个事件结构体，然后将事件结构体的链表拷贝到内核中， 内核线程进行轮询遍历进行判断fd是否就绪。当有fd就绪就将就绪事件放入revents中，然后返回，用户态遍历事件链表对事件结构体的revents 进行判断就绪的fd，进行相关的io操作获取数据。  #include \u0026lt;poll.h\u0026gt; // 数据结构 struct pollfd { int fd; // 需要监视的文件描述符 short events; // 需要内核监视的事件（读写） short revents; // 实际发生的事件 }; // // API int poll(struct pollfd fds[], nfds_t nfds, int timeout); // fd的集合， 个数，超时时间 // // 先宏定义长度 #define MAX_POLLFD_LEN 4096 int main() { /* * 在这里进行一些初始化的操作， * 比如初始化数据和socket等。 */ int nfds = 0; pollfd fds[MAX_POLLFD_LEN]; memset(fds, 0, sizeof(fds)); fds[0].fd = listenfd; fds[0].events = POLLRDNORM; int max = 0; // 队列的实际长度，是一个随时更新的，也可以自定义其他的 int timeout = 0; int current_size = max; while (1) { // 阻塞获取 // 每次需要把fd从用户态拷贝到内核态 nfds = poll(fds, max+1, timeout); if (fds[0].revents \u0026amp; POLLRDNORM) { // 这里处理accept事件 connfd = accept(listenfd); //将新的描述符添加到读描述符集合中 } // 每次需要遍历所有fd，判断有无读写事件发生 for (int i = 1; i \u0026lt; max; ++i) { if (fds[i].revents \u0026amp; POLLRDNORM) { sockfd = fds[i].fd if ((n = read(sockfd, buf, MAXLINE)) \u0026lt;= 0) { // 这里处理read事件 if (n == 0) { close(sockfd); fds[i].fd = -1; } } else { // 这里处理write事件 } if (--nfds \u0026lt;= 0) { break; } } } } poll存在的问题  poll解决了select的最大连接数的问题，但是还是存在：每次调用poll都需要将fd文件描述符集合拷贝到内核态 对fd是线性扫描，即还是采用了轮询遍历的方法,内核态中监控是否有就绪的fd,用户态中判断就绪的fd  epoll  epoll是采用红黑树存储fd,采用rdlist存储就绪的fd, 通过epoll_creat()方法来创建eventPoll结构体(红黑树+relist)。 通过epoll_ctl()方法将fd存入到红黑树中，若有就绪的fd,就调用ep_poll_callback()回调函数将就绪的fd添加到relist中。 调用event_wait()检查是否有就绪的fd,即检测relist是否为空。若不为空，将将就绪的fd的数量返回。用户态遍历relist+返回的就绪的fd 的数量即可获得数据。   #include \u0026lt;sys/epoll.h\u0026gt; // 数据结构 // 每一个epoll对象都有一个独立的eventpoll结构体 // 用于存放通过epoll_ctl方法向epoll对象中添加进来的事件 // epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可 struct eventpoll { /*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*/ struct rb_root rbr; /*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*/ struct list_head rdlist; }; // 对于每一个事件，都会建立一个epitem结构体 struct epitem{ struct rb_node rbn;//红黑树节点 struct list_head rdllink;//双向链表节点 struct epoll_filefd ffd; //事件句柄信息 struct eventpoll *ep; //指向其所属的eventpoll对象 struct epoll_event event; //期待发生的事件类型 } // API int epoll_create(int size); // 内核中间加一个 ep 对象，把所有需要监听的 socket 都放到 ep 对象中 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); // epoll_ctl 负责把 socket 增加、删除到内核红黑树 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);// epoll_wait 负责检测可读队列，没有可读 socket 则阻塞进程 //epoll使用示例 int main(int argc, char* argv[]) { /* * 在这里进行一些初始化的操作， * 比如初始化数据和socket等。 */ // 内核中创建ep对象 epfd=epoll_create(256); // 需要监听的socket放到ep中 epoll_ctl(epfd,EPOLL_CTL_ADD,listenfd,\u0026amp;ev); while(1) { // 阻塞获取 nfds = epoll_wait(epfd,events,20,0); for(i=0;i\u0026lt;nfds;++i) { if(events[i].data.fd==listenfd) { // 这里处理accept事件 connfd = accept(listenfd); // 接收新连接写到内核对象中 epoll_ctl(epfd,EPOLL_CTL_ADD,connfd,\u0026amp;ev); } else if (events[i].events\u0026amp;EPOLLIN) { // 这里处理read事件 read(sockfd, BUF, MAXLINE); //读完后准备写 epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,\u0026amp;ev); } else if(events[i].events\u0026amp;EPOLLOUT) { // 这里处理write事件 write(sockfd, BUF, n); //写完后准备读 epoll_ctl(epfd,EPOLL_CTL_MOD,sockfd,\u0026amp;ev); } } } return 0; }  \r  epoll 优点  采用了红黑树进行存储fd, 没有fd的最大连接数限制 采用了事件回调的方式，即有就绪的fd时，就会将fd通过回调函数添加到relist表中，并不是采用轮询+遍历的方式 利用mmap()文件映射内存加速与内核态空间的信息传递(用户态与内核态共享内存)，减少了fd集合从用户态拷贝 (用户空间和内核空间的只拷贝一次)到内核态的开销  epoll的触发  水平触发LT:只有要就绪的fd,epoll_wait()就会返回，并提醒用户态进行相关的操作。即只有缓冲区有变化就会触发 边缘触发ET:当文件描述符关联的缓冲区有空转为非空时，或者是缓冲区由满到不满就会触发。即只有缓冲区有空转为非空或者是由满转为非满的 情况才会触发。  三者总结 \r\n参考文献 彻底理解 IO 多路复用实现机制\n","date":"2021-12-12T12:00:38+08:00","image":"https://zcj-git520.github.io/p/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/3_hu407313779efa40a3c2449c5134b0af99_194287_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","title":"io多路复用"},{"content":"redis的网络协议  redis是基于tcp/ip协议，即客户端与服务器保持双工连接，通过序列化的协议(resp协议)进行数据的交互，在Redis中，协议数据分为不同的类型， 每种类型的数据均以CRLF（\\r\\n）结束，通过数据的首字符区分类型 \r redis服务器是一个事件驱动系统主要分为：文件事件(io事件)和时间事件 文件驱动：socket的读取事件(io事件)是由；连接(三次握手)、请求、响应(数据返回)、断开连接(四次挥手)组成，redis是采用单线程 和epoll(io多路复用)的机制处理相关的文件事件。 时间事件：可分为定时事件(程序在指定时间后执行相关的操作)和周期事件(程序每隔一段时间运行相关的操作)  redis客户端与服务器交互模式 串行的请求/交互模式  客户端与服务器建立长连接，通过心跳检测(ping-pong)ack应答，即客户端发送请求，服务器在进行响应。 在单连接下。大部分时间都是处于网络等待上(客户端在发送请求命令，并监听socket返回，通常以阻塞模式等待服务器端的响应)，这种模式下 的性能较低 \r  管道技术(pipeline)双工的请求/响应模式  将一批命令进行打包，然后发送给服务器，服务器获取数据后按顺序打包返回，即批量请求，批量响应。以次来减少网络等待的延时，提高性能 \r  原子化的批量请求/响应(事务)模式  客户端将请求的命令发送发到服务器，服务器经这些请求暂存在服务器的请求队列中，这过程也称为：请求入队列。服务器在从请求队列中 拿去所有的请求执行，然后再将数据返回给客户端，这过程称为执行阶段。 服务器在执行过程中不会在接收其他客户端发送的请求。所有的操作都是原子操作，即请求都执行或都不执行。 事务的步骤为：开始事务-\u0026gt;请求入队列-\u0026gt;执行请求 \r  发布/订阅(pub/sub)模式  发布者(pub)发送消息，订阅者(sub)接收消息，发布者和订阅者通过(通道)channel关联，所有的channel都是由一个map维护，map的key是 channel的名字，value是所有的订阅者的指针链表。客户端可以订阅任意的数量的频道，也可以进行发布。 发布者和订阅者都是客户端，服务器只是进行数据的中转。即发布者着向服务端发起请求，服务端将请求的数据推送给订阅者。 \r  redis的持久化机制  redis的持久化机制主要是有：RDB(快照)和AOF(日志)两种持久化的方式。持久的化的作用在于：故障恢复和数据恢复  RDB(快照)持久化机制  快照是redis默认的持久化方案，在指定时间间隔内生成数据集的时间点，即在指定的时间段内将内存的数据写入磁盘，在磁盘 上生成一个rdb的备份文件。在redis重启时加载rdb文件进行数据的恢复。 快照的持久化提供自动备份：需要修改配置文件redis.conf。也提供save和bysave(后台子进程)进行主动备份  RDB(快照)的工作流程：  主进程会单独创建子进程，将主进程的数据库的数据复制到子进程。 子进程将数据写入到临时文件中进行持久化，在经临时文件替换之前的rdb文件,子进程退出，释放内存中的数据 主进程不进行持久化，即不进行任何的io操作，确保redis的极高的性能  RDB(快照)的优缺点 优点  单一的紧凑文件保存了莫一段时间的数据集，比较适合做数据的备份尤其的冷备份 在对数据完整性不敏感下，适合大规模的数据的恢复，因直接从磁盘获取数据，恢复数据快 由子进程进行持久化，主进程不进行持久化，即不进行任何的io操作，确保redis的极高的性能  缺点  不能保障数据的完整性，若redis出现宕机，就不会出现最近的数据未持久化，导致数据的丢失。 当持久化的数据量较大时，会导致持久化的子进程就会很耗时，即使主线程在不参与持久化也可能导致服务器在毫秒级内不能响应 客户端的请求，若数据巨大时且cpu的性能不佳时，会出现秒级不能响应客户端的请求。  AOF(日志)持久化  通过将每个写操作记录到日志中且以追加文件不修改文件的模式，重启时更具根据日志文件从头到未执行一遍即恢复数据。，因AOF采用的是经操作记录以追加模式下写入日志文件中，会导致AOF文件越来越大。AOF引入了重写机制。 AOF引入了重写机制：当文件AOF是上次重写大小的一倍且文件大于64MB时就创建一个子进程遍历服务器的键值对，转换成一系列 Redis 的操作 指令，序列化到一个新的AOF日志文件中，再替换旧的AOF日志文件。可以修改配置文件设定持久化策略。  AOF 提供了三种持久化策略：  no: 无 fsync，由系统保证数据刷新到磁盘，速度最快，但很不安全（通常不使用）； always: 每次 fsync，每一个修改内存的 Redis 指令都会执行一次 fsync，速度很慢（通常不使用）； everysec: 每秒进行一次 fsync，有可能丢失一秒的 fsync 的数据。通常选择 everysec 策略，兼顾安全性和效率。  AOF(日志)的优缺点 优点  可以采用everysec的持久化策略，能确保数据的完整性  缺点  AOF的日志文件通常是比rdb文件大 在数据的恢复时，需要遍历日志文件，将日志文件的数据操作命令在执行一遍，导致数据恢复相对于快照(rdb)较慢，尤其在大数据下。  redis 缓存中的状况于解决方案 缓存雪崩  数据未加载到内存或者同一时间发生大规模的key失效，从而导致所有的请求都直接在查数据库。导致数据库和cpu负载过高，甚至宕机  解决方案  加锁计数，限制并发的数量，避免出现并发出现大量的请求访问到数据库，降低服务器的吞吐量 设置热点key永不失效，均匀过期，避免出现大面积的key同时失效 设置缓存服务器的主备  缓存穿透  指客户端请求的数据在缓存和数据库中均没有，导致客户端在每次请求都需要去数据库查询。若在并发时，也会导致数据库和cpu的负载过高， 导致数据库的宕机  解决方案  若查询数据库不存在，直接在缓存中保存一个默认的值，并设置较短的过期时间，下次请求直接从缓存中返回。 使用布隆过滤器，阻挡无效的请求。  缓存并发  在并发情况下，一个缓存失效，在高并发下访问数据库，缓存更新，也会导致数据的压力变大。  解决方案  对缓存加锁，若key不存在，就加锁，当查询数据库的数据写入缓存在解锁  缓存预热  在系统运行前，将数据加载到缓存中  解决方案  数据量不大，直接加载 数据量大时，设置定时的脚本进行缓存的刷新 数据量巨大时，优先保障热点数据提前加载到缓存中  缓存降级  指缓存失效或者缓存服务器宕机时，不去访问数据库，直接返回默认值或访问内存数据  分布锁  使用setnx加锁，并设置超时时间，过了超时时间就解锁，并删除锁  参考文献 Redis 客户端服务端交互1 客户端/服务端协议\n","date":"2021-12-08T22:00:38+08:00","image":"https://zcj-git520.github.io/p/redis%E8%BF%9B%E9%98%B6/5_hu55d28ed2616667077617555b48a30f7c_17120_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/redis%E8%BF%9B%E9%98%B6/","title":"redis进阶"},{"content":"redis  redis 是一个开源（BSD许可）的，数据结构为key-value的存储系统。它可以用作分布式数据库、缓存 和消息队列（消息中间件）。数据保存在内存中，存取速度快，并发能力强。 redis 支持多种数据结构，如字符串、map(哈希)、列表、集合、有序集合等数据类型。数据都是原子操作， 数据都缓存在内存中，会定期将数据更新到磁盘或者修改操作写入追加记录。再次基础上实现了主从（master-slave）  redis 数据结构 字符串(string)类型  字符串类型是redis最基础的数据结构，可以存储简单的字符串也可存储复杂的xml、json、二进制数据（如图像、音频） value内部以保存整数的int和保存字符的sds组成的数据存储结构。sds内部结构为：  struct sdshdr { int len; // 记录着buf中也使用的字符串数量 int free; // 记录着buf中未使用的字符串数量 char buh[]; // 字符串数组，用于保存字符串 } \r\n字符串类型特性  分配冗余空间：采用预先分配冗余空间的方式来减少内存的频繁分配 自动扩容： 当字符串所占空间小于1MB时，redis会按照字符串（len + addLen）*2倍数存储空间增加， 当字符串的存储空间超过所占空间的1MB时，每次自会增加1MB的存储空间扩容，最大扩容为512MB的存储空间 二进制的安全性，兼容c语言函数库中字符串以\\0结束。  字符串常用的场景  缓存功能： 基于redis作为缓存再配合其他的数据库最为存储层，利用redis的数据存储在内存和支持高并发的特点，可以大大加快 系统的读写速度以及降低后端数据库的压力。（单值缓存、对象缓存、分布式锁等） 计数器： 使用redis作为系统的实时计数器，可以加快计数和查询功能。 共享用户的session：利用redis将用户的session集中管理，这种模式确保redis的高可用。每次用户的session的更新和获取快速完成  列表(list)  list类型的value对象内部采用的quicklist(快速列表)或者ziplist(压缩列表)承载。当list的元素和单个元素较小时采用ziplist实现来减少内存的 占用否则采用quicklist结构进行存储。 ziplist所有内容都存放在来连续的内存中。zipbytes表示ziplist的总长度， zltail表示指向最末的元素，zllen表示元素个数， entryX表示元素自身内容， zlend是ziplist的定界符 ziplist的内部结构为：  typedef struct ziplist{ /*ziplist分配的内存大小*/ uint32_t bytes; /*达到尾部的偏移量*/ uint32_t tail_offset; /*存储元素实体个数*/ uint16_t length; /*存储内容实体元素*/ unsigned char* content[]; /*尾部标识*/ unsigned char end; }ziplist; /*元素实体所有信息, 仅仅是描述使用, 内存中并非如此存储*/ typedef struct zlentry { /*前一个元素长度需要空间和前一个元素长度*/ unsigned int prevrawlensize, prevrawlen; /*元素长度需要空间和元素长度*/ unsigned int lensize, len; /*头部长度即prevrawlensize + lensize*/ unsigned int headersize; /*元素内容编码*/ unsigned char encoding; /*元素实际内容*/ unsigned char *p; }zlentry; \r\n quicklist是底层是ziplist的双向链表,结构为：  struct quicklistNode { quicklistNode *prev; quicklistNode *next; ziplist *zl; // 指向压缩列表 int32 size; // ziplist字节总数 int16 count; // ziplist中元素数量 int2 encoding; // 存储形式，表示原生字节数组还是LZF压缩存储 ... } quicklistNode； // 快速列表 struct quicklist { quicklistNode *head; quicklistNode *next; long count; // 元素总数 int nodes; // ziplist节点个数 int compressDepth; // LZF算法压缩深度 } quicklist; \r\n redis的list支持存储2的32次方个元素，可以通过下标获取指定元素和莫个范围的元素集  列表常用场景  消息队列：redis的链表式结构，可以轻松实现阻塞队列，可以使用左进右出的命令完成队列的设计 文章列表或者数据分页展示的应用  map类型(hash 散列)  map主要由hashtable和ziplist两种承载方式承载。当存储数据较小时，采用ziplist实现  hashtable组成  dict: 当dictht需要扩容/缩容时，用于管理桶的迁移，结构图下  typedef struct dict{ // 类型特定函数 dictType *type; // 私有数据 void *private; // 哈希表 dictht ht[2]; // rehash 索引，当当前的字典不在 rehash 时，值为-1 int trehashidx; } dictht: 维护哈希表的说有桶连,结构如下：  typedef struct dictht{ //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 //总是等于 size-1 unsigned long sizemask; //该哈希表已有节点的数量 unsigned long used; }dictht dictEntry:管理一个k-v对，同时保留着一个桶中相邻元素的指针，一次维护哈希桶内部相连，结构如下  typedef struct dictEntry{ void *key; union{ void *val; uint64_tu64; int64_ts64; }v; //下一个 struct dictEntry *next; }dictEntry \r\nziplist  map中对应的ziplist的entry的个数一定是2的整数倍。即奇数存放着key,偶数存放着value  map类型的特性  map内部的key和value不能在嵌套map,只能是string，int或着是float 负载因子 = 哈希表中已有的元素/哈希桶数 扩容：通过负载因子判断是否需要增加桶数。即当负载因子小于1时，一定不扩容， 当负载因子大于1，且在没有在执行BGSAVE进行或当负载因子大于5时，一顶会进行扩容， 扩容时，新桶的数目是现有桶数目的两倍。 缩容：当负载因子小于0.1时，就进行缩容。 扩/缩容都是通过新建哈希表的方式实现，扩容时新建现有桶的2倍的新表，缩容时是新建原表的一半新建哈希表。 将原表的桶逐步迁移到目标表(新建的哈希表)  map常用场景  利用键值对的特性，用来存储关系性数据库中表的记录 存储用户信息，优化用户信息的来源，提高系统的性能  集合(set)类型  set是由inset或者hashtable来存储，hashtable的value永远为nil,只有int类型是使用inset进行存储 inset:其核心是一个字符数组  set类型的特性  允许重复元素，没有顺序，没有下表，支持集合内的增删改查，并支持多个集合的交、并、差集等操作  set常用场景  根据set的特性，适合于聚合分类，如标签、好友共同喜好等场景 利用set中元素的唯一性，适合于数据的唯一性，如统计网站的独立ip  有序集合(sorted-set)  sorter-set是的内部结构是以压缩列表(ziplist)或者跳跃表(skiplist)+hashtable构成 sorted-set类似于map的键值对(key-value)且有序，value是一个浮点数称之为score，是排序的根据 跳跃表(skiplist)其核心点主要是包括一个dict对象和一个skiplist对象,结构如下：  typedef struct zset{ //跳跃表 zskiplist *zsl; //字典 dict *dice; } zset /* ZSETs use a specialized version of Skiplists */ /* * 跳跃表节点 */ typedef struct zskiplistNode { // 成员对象 robj *obj; // 分值 double score; // 后退指针 struct zskiplistNode *backward; // 层 struct zskiplistLevel { // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned int span; } level[]; } zskiplistNode; /* * 跳跃表 */ typedef struct zskiplist { // 表头节点和表尾节点 struct zskiplistNode *header, *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level; } zskiplist; \r\n有序集合(sorted-set)特性  sorted-set是集合的基础上，增加了给每一个元素设置分数(score),利用该分数进行排序，集合元素是唯一的，分数是不唯一的。  有序集合(sorted-set)常用创景  利用它的特性，可以适合于排序的场景，如排行榜等 根据集合的每个元素都设置了一个score分数的特性，做带权的队列，如：普通的信息的权重为1，重要的信息的权重为2， 应用线程可以根据权重调用。  参考文献： Redis底层数据结构详解\n","date":"2021-12-05T22:00:38+08:00","image":"https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/2_hu2e0e0d83f63ca97b7bb5a7ad9fe95b5f_87192_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%88%86%E6%9E%90/","title":"初识redis(数据结构分析)"},{"content":"jwt  jwt 它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息，是最流行的跨域认证的解决方案  传统跨域认证  客服端向服务器发送用用户名和密码，服务器验证通过后，把当前对话的session里保存 相关数据，并写在客户端的cookie, 向客户端返回一个session id。客户端再次通过cookie, 经session id 传回服务器，服务器通过session id得知访问客户端的身份。 存在的问题：扩展性不佳，服务器集群或者跨域的服务导向架构，就需要共享session共享数据 解决方案：1. 将session 数据保存在数据库中或者其他的持久层，服务器访问持久层的session数据 2. 服务器不保存session数据，所有的数据保存在客户端，每次请求都发回服务器  jwt的原理  服务器认证以后，生成一个json对象，返回给客户端之后，客户端与服务器靠这个json对象认证，会会 加上签名来防止客户端修该json 对象  jwt的数据结构  jwt的数据结构为：Header(头部)、payload(负载)、signature(签名)\n\r  Header(头部)  Header部分是一个json对象，描述jwt的元素据。声明类型，这里是jwt声明加密的算法 通常直接使用 HMAC SHA256，结构如下：  { 'typ': 'JWT', 'alg': 'HS256' } payload(负载)  payload 也是一个json对象，用来存放实际需要的传递的数据，iss：发行人，exp：到期时间，sub：主题，aud：用户， nbf：在此之前不可用，iat：发布时间，jti：JWT ID用于标识该JWT  { \u0026quot;sub\u0026quot;: \u0026quot;1234567890\u0026quot;, \u0026quot;name\u0026quot;: \u0026quot;John Doe\u0026quot;, \u0026quot;admin\u0026quot;: true } signature(签名)  是对前两部分进行签名，防止篡改。在服务器上指明一个密钥，在根据header中指定的算法， 按照格式产生签名，header (base64后的)、payload (base64后的)、secret。其格式如下：  // javascript var encodedString = base64UrlEncode(header) + '.' + base64UrlEncode(payload); var signature = HMACSHA256(encodedString, 'secret'); // TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ jwt的特点  jwt默认不加密，但是可以对原生的Token加密或者使用https加密传输 jwt在不加密的情况下，不能加秘密数据写入jwt jwt不仅可以使用与认证，也能用于信息的交换 jwt不能在使用过程中清除莫一个token和更改该token的权限，一旦签发一直到到期都是有效的，应该jwt 的有效期  认证  认证就是根据声明者所持有的识别信息，确认声明者的身份  授权  一般是指获取用户的委派的权限  鉴权  指对一个声明者所声明的身份的权限的真实性进行鉴别和确认的过程  权限控制  是指可执行和操作的组合配置的权限列表，然后根据执行者的权限，若其操作在权限范围内，则允许执行，否则禁止  参考文献： 什么是 JWT \u0026ndash; JSON WEB TOKEN\n","date":"2021-11-30T22:00:38+08:00","image":"https://zcj-git520.github.io/p/%E5%88%9D%E6%8E%A2jwtjson-web-token/1_hu679d1d76db059750024901bffb37cf39_65265_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/%E5%88%9D%E6%8E%A2jwtjson-web-token/","title":"初探jwt(json web Token)"},{"content":"Nginx  nginx 是轻量级高并发web服务器，是基于Rest架构风格。通过http协议提供各种网络服务\n其高并发是基于事件驱动架构，io多路复用的epoll,使得可以轻松支持百万计的icp连接。\n轻量级主要体现在：采用插件化开发，cup亲和，将cpu与nginx工作进程绑定，减少cpu切换带来的消耗  代理  代理是客户端与服务器之间的一层服务器，将客户端的请求转发给服务器，然后服务器的响应转发给客户端  正向代理  客户端向代理服务器转发请求和指定目标服务器，代理服务器向目标服务器发送请求，并将结果返回给客户端。 对客户端是透明的，即客户端知道访问的是目标服务器，对目标服务器来说是非透明的，并不知道访问服务器是 客户端还是代理服务器  反向代理  客户端向代理服务器发送请求，代理服务器将请求转发给内部的网络服务器(目标服务器)，在将结果返回给客户端。对于客户端 是非透明的，即客户端不清楚是访问是那一台目标服务器。对于目标服务器是透明的，即目标服务器知道访问的是 代理服务器 nginx反向代理的配置如下：  server { listen 80; server_name www.123.com; location / { proxy_pass http://127.0.0.1:8080; index index.html index.htm index.jsp; } } 我们监听80端口，访问域名为www.123.com，不加端口号时默认为80端口，故访问该域名时会跳转到127.0.0.1:8080路径上\n负载均衡  当请求过大时，将请求分发给各个服务器。负载均衡的分配策略为：weight(权重)轮询，fair(智能调整调度) nginx轮询配置(所有请求都按照时间顺序分配到不同的服务上)  upstream dalaoyang-server { server localhost:10001; server localhost:10002; }  nginx权重配置(权重轮询：代理服务器接收到请求，按照设定的权重，请求分配到不同的后端服务器，如果发现后端服务器宕机时， 代理服务器会将其剔除出队列)  upstream dalaoyang-server { server localhost:10001 weight=1; server localhost:10002 weight=2; }  nginx iphash 配置(每个请求都根据访问ip的hash结果分配)  upstream dalaoyang-server { ip_hash; server localhost:10001 weight=1; server localhost:10002 weight=2; }  最少连接(将请求分配到连接数最少的服务上)  upstream dalaoyang-server { least_conn; server localhost:10001 weight=1; server localhost:10002 weight=2; }  far 智能调整调度算法：动态根据后端服务器的请求处理到响应时间进行均衡分配。即响应时间短，处理效率高的服务器 分配到请求的概率高。响应时间长，效率低的服务器分配到请求的概率低。 far 配置文件如下：  upstream dalaoyang-server { server localhost:10001 weight=1; server localhost:10002 weight=2; fair; } 流量控制  限流实际就是限制流入请求的数量：有计数器固定窗口算法、令牌桶算法、漏桶算法和限制并发连接数限制\n令牌桶算法:存在一个大小固定的令牌桶，会以恒定的速率源源不断产生令牌。如果令牌消耗速率小于生产令牌的速度， 令牌就会一直产生直至装满整个令牌桶。如果请求获取令牌失败则请求会被禁止访问\n\r 漏桶算法:突发流量会进入到一个漏桶，漏桶会按照我们定义的速率依次处理请求，如果水流过大也就是突发流量过大就会直接溢出， 则多余的请求会被拒绝。所以漏桶算法能控制数据的传输速率。算法的核心是：缓存请求、匀速处理、多余的请求直接丢弃。\n\r  统一鉴权  客户端请求时，将Token放入在请求头head中。服务器解析Token,对访问者都进行鉴权，最后进入权力访问  主流的网关  Hong：是基于nginx+lua开源的网关 Traefik是http反向代理和负载均衡器，支持动态配置和较好的伸缩性 kubernetes是基于Envog Proxy构建的原生k8s网关  参考文献： Nginx（三）nginx 反向代理 \n","date":"2021-11-24T22:00:38+08:00","image":"https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86nginx/1_hu3f3721f37acfbb79e3bc6e8d69d34816_28729_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/%E5%88%9D%E8%AF%86nginx/","title":"初识Nginx"},{"content":"HTTP  HTTP是(Hyper Text Transfer Protocol)超文本传输协议, 基于tcp的应用层传输协议（请求-响应）协议 影响HTTP网络请求的主要因素带宽和延迟  延迟的种类:  浏览器阻塞(超过浏览器连接数限制的后续请求都会被阻塞) DNS查询 (将域名解析造成的延迟，可以通过缓存DNS进行解决) 建立链接 (因HTTP是基于TCP的应用层协议，在建立连接时需要进行)  HTTP1.0 http1.0存在的问题：  短连接：规定客户端与服务器只保持短暂连接，客户端每次请求都需要建立连接，服务器完成请求后 断开连接，服务器不跟踪客户端，不保存客户端的请求记录。 没有host头域：每台服务器都绑定一个唯一的IP地址，请求消息中的URL并没有传递主机名（hostname） 不允许短点续传  HTTP1.1 根据http1.0暴露的问题，http1.1增加优化方案  缓存处理：http1.1增加更多的缓存控制策略 带宽优化及网络连接的使用：http1.1中请求头引入了range头域和支持断点续传的功能 Host头处理：http1.1的请求消息和相应消息虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机(Multi-homed Web Servers),并且它们共享一个IP地址,HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request） 长连接： 支持长连接和流水线处理，默认开始是长连接：keep-alive  http1.1 也带来新的问题：HTTP 队头阻塞(head of line blocking)  因http1.1支持了长连接和使用了管道机制，客户端与服务器建立一次连接，客户端不用等待服务器响应就能发送下一个请求，支持了并行发送多个请求， 但服务器必须按照请求的顺序来相应请求，也就是通过串行响应请求，这就造成了HTTP的队头阻塞。  解决Http 队头阻塞方法  并发连接：一个域名允许分配多个长连接，增加处理请求任务 域名分片：将一个域名分解为多个域名，在进行并发连接  HTTP2.0  HTTP2.0主要是基于SPDY协议。实现了低延时高吞吐量  SPDY协议  是基于TCP协议的应用层协议，其目标是通过头部压缩、多路复用、优先级等作用缩短网页放入加载时间和 优化http的性能，其核心是尽量减少TCP连接数  HTTP 2.0的特性 头部压缩 头部存在大量的信息，而且每次在发送都会降低http的性能，在用HPACK算法对头部进行压缩： 1.在客户端和服务器维持一个头部表来跟踪和存储客户端发来的键值对 2.客户端在请求的时候便只需要发送在表里的索引位置即可 3.HPACK 不仅仅通过索引键值对来降低数据量，同时还会将字符串进行霍夫曼编码来压缩字符串大小 \r\n多路复用  基于二进制分帧，在共享的Tcp连接的基础上同时发送请求和响应。http的消息被分解成独立的帧层，交错发出 通过流标识符和首部将他们重新组装起来，避免了队头阻塞和提高了传输的性能 \r  二进制分帧  经http报文格式转换成二进制格式，全部的io串。将原来的header的报文分成二进制帧沉在的头部字段， body被拆分成二进制帧存放在请求体数据段。服务器接收的不是http报文，而是二进制帧。 帧(frame)包含部分：类型Type, 长度Length, 标记Flags, 流标识Stream和frame payload有效载荷。 消息(message)：一个完整的请求或者响应，比如请求、响应等，由一个或多个 Frame 组成。 流是连接中的一个虚拟信道，可以承载双向消息传输。每个流有唯一整数标识符。为了防止两端流ID冲突，客户端发起的流具有奇数ID，服务器端发起的流具有偶数ID。 流标识是描述二进制frame的格式，使得每个frame能够基于http2发送，与流标识联系的是一个流，每个流是一个逻辑联系，一个独立的双向的frame存在于客户端和服务器端之间的http2连接中。一个http2连接上可包含多个并发打开的流，这个并发流的数量能够由客户端设置。  \r\n二进制分帧的特性  并发性：同时可发多个帧 自增性：流的id不可重用，按顺序递增，到阈值后置零 双向性：客户端与服务端都可到流，互不干扰，都可收发 可设优先级：设置帧的优先级，服务器优先处理  服务器推送  服务器不在是完全被动的接收和响应请求，也能创建新的资源(流)发送给客户端。 服务器可以对一个客户端请求发送多个响应，服务器向客户端推送资源无需客户端明确地请求。 并且，服务端推送能把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。 当服务端需要主动推送某个资源时，便会发送一个 Frame Type 为 PUSH_PROMISE 的 Frame，里面带了 PUSH 需要新建的 Stream ID。 意思是告诉客户端：接下来我要用这个 ID 向你发送东西，客户端准备好接着。客户端解析 Frame 时，发现它是一个 PUSH_PROMISE 类型， 便会准备接收服务端要推送的流。  \r\n请求优先级  通过设置帧的优先级，优化帧的传输顺序 把http消息分为很多独立帧之后，就可以通过优化这些帧的交错和传输顺序进一步优化性能。每个流都可以带有一个31比特的优先值：0 表示最高优先级；2的31次方-1 表示最低优先级。 服务器可以根据流的优先级，控制资源分配（CPU、内存、带宽），而在响应数据准备好之后，优先将最高优先级的帧发送给客户端。高优先级的流都应该优先发送，但又不会绝对的。绝对地准守，可能又会引入首队阻塞的问题：高优先级的请求慢导致阻塞其他资源交付。 4.分配处理资源和客户端与服务器间的带宽，不同优先级的混合也是必须的。客户端会指定哪个流是最重要的，有一些依赖参数，这样一个流可以依赖另外一个流。优先级别可以在运行时动态改变，当用户滚动页面时，可以告诉浏览器哪个图像是最重要的，你也可以在一组流中进行优先筛选，能够突然抓住重点流。  优先级等级：  优先级最高：主要的html 优先级高：CSS文件 优先级中：js文件 优先级低：图片  参考文献： ","date":"2021-11-18T22:00:38+08:00","image":"https://zcj-git520.github.io/p/http%E5%8D%8F%E8%AE%AE%E5%BA%95%E5%B1%82%E5%88%86%E6%9E%90/1_hu7de10a5ba4c09963d2757d75c9451326_29719_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/http%E5%8D%8F%E8%AE%AE%E5%BA%95%E5%B1%82%E5%88%86%E6%9E%90/","title":"http协议底层分析"},{"content":"RPC  RPC(Remote Procedure Call Protocol)——远程过程调用协议，它是一种通过网络从远程计算机程序上请求服务， 而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP/IP或UDP，为通信程序之间携带信息数据。 RPC将原来的本地调用转变为调用远端的服务器上的方法，给系统的处理能力和吞吐量带来了近似于无限制提升的可能。 在OSI网络通信模型中，RPC跨域了传输层和应用层。RPC使得开发包括网络分布式多程序在内的应用程序更加容易 RPC采用客户机/服务器(client-server)模式,也是一种请求/响应(request-response)模式，可以通过TCP/UDP以及HTTP 协议进行传输  RPC 架构  CAll ID 映射：客户端通过ID传输给服务器，服务器通过ID调用相应的函数返回 序列化与烦序列化：客户端与服务器通过序列化与反序列化进行传参 一个完整的RPC架构里面包含了四个核心的组件，分别是Client，Client Stub，Server以及Server Stub，这个Stub可以理解为存根。   客户端(Client)，服务的调用方。 客户端存根(Client Stub)，存放服务端的地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程发送给服务方。 服务端(Server)，真正的服务提供者。 服务端存根(Server Stub)，接收客户端发送过来的消息，将消息解包，并调用本地的方法。  RPC调用过程  客户端（client）以本地调用方式（即以接口的方式）调用服务； 客户端存根（client stub）接收到调用后，负责将方法、参数等组装成能够进行网络传输的消息体（将消息体对象序列化为二进制）； 客户端通过sockets将消息发送到服务端； 服务端存根( server stub）收到消息后进行解码（将消息对象反序列化）； 服务端存根( server stub）根据解码结果调用本地的服务； 本地服务执行并将结果返回给服务端存根( server stub）； 服务端存根( server stub）将返回结果打包成消息（将结果消息对象序列化）； 服务端（server）通过sockets将消息发送到客户端； 客户端存根（client stub）接收到结果消息，并进行解码（将结果消息发序列化）； 客户端（client）得到最终结果。\nRPC的目标是要把2、3、4、7、8、9这些步骤都封装起来。   注意：无论是何种类型的数据，最终都需要转换成二进制流在网络上进行传输，数据的发送方需要将对象转换为二进制流，而数据的接收方则需要把二进制流再恢复为对象。 \r  gPRC  gRPC 是一种现代开源高性能远程过程调用 (RPC) 框架，可以在任何环境中运行。它可以通过对负载平衡、跟踪、健康检查和身份验证的可插拔支持，有效地连接数据中心内和数据中心之间的服务。它还适用于分布式计算的最后一英里，将设备、移动应用程序和浏览器连接到后端服务。 gRPC 是基于HTTP2.0(多路复用,消除了线头阻塞)标准协议色设计的基于ProtoBuf序列化的高性能框架。 《gRPC 官方文档中文版》  Protocol Buffers  Protocol Buffers 是一种轻便高效的结构化数据存储格式，可以用于结构化数据序列化，很适合做数据存储或 RPC 数据交换格式。它可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式 序列化：将数据结构或对象转换成能被传输或者存储（如二进制格式）的过程。 反序列化：将在序列化过程中所生成的(格式)转换成数据结构或者对象的过程。  参考文献： RPC原理解析\n","date":"2021-11-15T22:00:38+08:00","image":"https://zcj-git520.github.io/p/prc/1_hu92b5144e2fe44c426742bd76f38787bf_37611_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/prc/","title":"PRC"},{"content":"Restful API  rest是Representational state Transfer 的缩写（表述性转态传递） api是应用程序接口 Restful API是一种软件结构风格，设计风格，让软件更加清晰、简洁、易维护。是一种流行的软件API 设计风格  Rest的指导风格  客户端-服务器：通过将用户接口问题与数据存储问题分开，简化服务器组件来提高跨平台放入用户接口的 可移植性性并提高可伸缩性 无转态：从客户端到服务器的每个请求都必须包含理解请求所需的所有信息，并且不能利用服务器上任何存储的上下文。因此，会话状态完全保留在客户端上。 可缓存：缓存约束要求将对请求的响应中的数据隐式或显式标记为可缓存或不可缓存。如果响应是可缓存的，则客户端缓存有权重用该响应数据以用于以后的等效请求。 统一接口：通过将通用性的软件工程原理应用于组件接口，简化了整个系统架构，提高了交互的可见性。为了获得统一的接口，需要多个架构约束来指导组件的行为。REST由四个接口约束定义：资源识别; 通过陈述来处理资源; 自我描述性的信息; 并且，超媒体作为应用程序状态的引擎 分层系统：分层系统风格允许通过约束组件行为来使体系结构由分层层组成，这样每个组件都不能“看到”超出与它们交互的直接层。 按需编码（可选）： REST允许通过以小程序或脚本的形式下载和执行代码来扩展客户端功能。这通过减少预先实现所需的功能数量来简化客户端  RestFul 架构  资源：网络的实体或者是具体的信息，使用URI(统一资源定位符)，URI是每一个资源的地址或者独一无二的是识别符 表现层： 对资源的外在表现，如：json、xml、txt、二进制等 转态转化：互联网是一种无转态的协议，所有的状态都是保存在服务器上，客户端通过 HTTP的操作方式(GET,POST,PUT,DELETE)等改变服务器的“状态变化” \r  RESTful API接口规范 接口风格  路径和变量均采用小驼峰式，例如deviceId 使用HTTP动词作为action操作URL资源，动词一律大写。  GET：读取\\查询（Read） POST：新建（Create） PUT：更新（Update） PATCH：更新（Update），通常是部分更新 DELETE：删除（Delete） HEAD：获取资源的元数据。 OPTIONS：获取信息，关于资源的哪些属性是客户端可以改变的。 5种请求动作中，GET、PUT、PATCH、DELETE均是幂等的；只有POST是非幂等的。幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。是非幂等是判断接口使用POST还是PUT的决定条件。幂等的理解见本文附录。   参数：  PATH（路径）：  版本号放入PATH，且在最前  尽量使用名词，不使用动词，把每个URL看成一个资源，名称都用复数 微服务名称不放入PATH中     Query参数：主要用在GET查询中，简单的PUT动作，也用Query参数 Headers参数：公共参数通过header传递，content-type、authorization认证必填，其他统一按调用链规范、速率限制规范填写。content-type应该固定为application/json。 Body：  统一使用json格式，所有返回都是json格式  POST所有参数通过JSON传递 GET请求不允许有body， 所有参数通过拼接在URL之后传递，所有的请求参数都要进行遵循RFC 3986的URL Encode。 DELETE删除单个资源时，资源标识通过path传递，批量删除时，通过在body中传递JSON。       返回结果  状态码：HTTP状态码标准用法，见后状态码规范 Body返回，只提供json返回格式 GET：返回资源对象，完整对象或通过Query参数可过滤 POST：返回新生成的资源对象，可能是ID或完整的资源对象 PUT：返回完整的资源对象 DELETE：返回一个空文档   过滤信息：查询及查询结果使用  pageNo：分页查询标识第几页 pageSize：分页查询标识每页多少条数据 begin：录像/截图开始时间，Unix时间戳，单位秒 end：录像/截图结束时间，Unix时间戳，单位秒 orderby：排序规则，desc或asc q：搜索关键字（uri encode之后的） totalCount：总记录数，分页查询，返回json携带 totalPages：总页数，分页查询，返回json携带，等于page时，表示当前是最后一页   微服务内部使用http协议，对外使用https协议  详细设计要求  输入参数要精简有效  不能把内部对象作为接口参数，通过DTO进行转换； required的字段尽可能少   CRUD的U(POST)要通过业务分析（领域建模）具体化操作，不要提供灵活但是支持不全面的接口 查询尽可能提供丰富的查询条件，可以返回尽可能详细的信息 同类资源尽可能统一接口 避免多级 URL，比如获取某个作者的某一类文章： GET /authors/12/categories/2 这种 URL 不利于扩展，语义也不明确，往往要想一会，才能明白含义。 更好的做法是，除了第一级，其他级别都用查询字符串表达。 GET /authors/12?categories=2 如何设计批量处理 把URL设计为PATCH /authors/batch，也就是具体的id传入batch表示批量，参数通过body传递，例如如下：  { {\u0026quot;method\u0026quot;:\u0026quot;DELETE\u0026quot;,\u0026quot;id\u0026quot;:\u0026quot;12\u0026quot;,\u0026quot;value\u0026quot;:\u0026quot;\u0026quot;} {\u0026quot;method\u0026quot;:\u0026quot;PUT\u0026quot;,\u0026quot;id\u0026quot;:\u0026quot;23\u0026quot;,\u0026quot;value\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;michael\u0026quot;,\u0026quot;group\u0026quot;:\u0026quot;fisrt\u0026quot;,...}} } 在method中传递HTTP动词，主要是PUT\\DELETE，GET通过查询条件本身就支持批量，POST是创建，几乎不需批量创建，而PUT\\DELETE都是对某个id操作，同时修改或删除多个id就是批量操作；在id中明确具体的id，value则传递与操作单个id一致的数据。批量操作的返回body与传入body保持一致，只是value可能是error数据也可能是PUT的结果数据。通过这种设计，在实现时，batch操作可以复用单个id操作的处理过程。\n状态码规范 正确 接口正常访问情况下，服务器返回2××的HTTP状态码。 200 OK ：表示已在响应中发出、资源更改成功（GET、PUT） 201 Created：表示新资源被创建（POST） 204 No Content ：资源被删除（DELETE）\n错误 当用户访问接口出错时，服务器会返回给一个合适的4××或者5××的HTTP状态码；以及一个application/json格式的消息体，消息体中包含错误码code和错误说明message，json格式如下：\n{ \u0026quot;code\u0026quot;:\u0026quot;内部错误代码可以是数字或Exeption字符串，例如20003, OAuthException\u0026quot; \u0026quot;message\u0026quot;:\u0026quot;格式化的错误信息，英文，此message是对code的更细的错误描述，可以把一些状态变量格式化嵌入。\u0026quot; } 补充说明：以上错误返回全英文，若Web提示，由web客户端建立code的多语言字符串表，把错误码转化为对于的多语言字符串，展示多语言提示。\n 发生错误时，绝对不要返回 200 状态码 4××错误( 400=\u0026lt;status code\u0026lt;500 )为客户端的请求错误，需要根据具体的code做相应的提示和逻辑处理，message仅供开发时参考，不建议作为用户提示。 5××错误( 500=\u0026lt;status code )为服务器或程序出错，客户端只需要提示“服务异常，请稍后重试”即可，该类错误不在每个接口中列出。  400 Bad Request ：服务器不理解客户端的请求，未做任何处理。\n401 Unauthorized ：用户未提供身份验证凭据，或者没有通过身份验证。\n403 Forbidden ：用户通过了身份验证，但是不具有访问资源所需的权限。\n404 Not Found ：所请求的资源不存在，或不可用。\n405 Method Not Allowed ：用户已经通过身份验证，但是所用的 HTTP 方法不在他的权限之内。\n410 Gone ：所请求的资源已从这个地址转移，不再可用。\n415 Unsupported Media Type ：客户端要求的返回格式不支持。比如，API 只能返回 JSON 格式，但是客户端要求返回 XML 格式。\n422 Unprocessable Entity ：客户端上传的附件无法处理，导致请求失败。\n429 Too Many Requests ：客户端的请求次数超过限额。\n500 Internal Server Error ：客户端请求有效，服务器处理时发生了意外。\n503 Service Unavailable ：服务器无法处理请求，一般用于网站或设备维护状态。\n附录：幂等性 幂等性：幂等性是分布式环境下常见的问题；幂等性指的是多次操作，结果是一致的。（多次操作数据库数据是一致的。）\n GET方法用于获取资源，不应有副作用，所以是幂等的。 DELETE方法用于删除资源，有副作用，但它应该满足幂等性。 POST所对应的URI并非创建的资源本身，而是资源的接收者。比如： POST http://www.forum.com/articles 的语义是在 http://www.forum.com/articles 下创建一篇帖子，HTTP响应中应包含帖子的创建状态以及帖子的URI。两次相同的POST请求会在服务器端创建两份资源，它们具有不同的URI；所以，POST方法不具备幂等性。 PUT所对应的URI是要创建或更新的资源本身。比如： PUT http://www.forum/articles/4231 的语义是创建或更新ID为4231的帖子。对同一URI进行多次PUT的副作用和一次PUT是相同的；因此，PUT方法具有幂等性。 如何把非幂等的POST操作设计为幂等的，可以参加下面的帖子的示例： https://www.cnblogs.com/weidagang2046/archive/2011/06/04/idempotence.html  ","date":"2021-11-10T22:00:08+08:00","image":"https://zcj-git520.github.io/p/restfulapi/1_hu5d30570469f48ece7400dce081384b39_15097_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/restfulapi/","title":"RestfulAPI"},{"content":"概念知识 Docker镜像 Docker镜像是由文件和元数据组成的。\n 文件：语言环境、库、执行文件  由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。   元数据：环境变量、端口映射、卷等 镜像信息：  RESPOSITORY：仓库名 TAG：标签 IMAGE ID：镜像ID CREATED：创建时间 SIZE：所占用的空间   虚悬镜像(dangling image)  RESPOSITROY及TAG都为 使用docker image prune 可以删除    容器 容器是从镜像中创建，继承了他们的文件系统，并使用他们的元数据来确定其启动配置。\n 启动时，运行一个进程，不过可派生其他进程。 文件的变更通过写时复制存储在容器中，基础镜像不会受影响。  数据卷 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：\n 数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。 数据卷 是被设计用来持久化数据的，它的生命周期独立于容器，Docker 不会在容器被删除后自动删除 数据卷  Docker网络 当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。\n同时，Docker 随机分配一个本地未占用的私有网段（在 RFC1918 中定义）中的一个地址给 docker0 接口。比如典型的 172.17.42.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。\n当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。 \rimage\r\n其他知识  Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 systemd 去启动后台服务，容器内没有后台服务的概念。  使用镜像的命令工具    命令 功能     docker pull [Registry地址[:端口]/] 仓库名[:标签] Registry 地址拉取镜像   Docker run 仓库名:标签 [命令] 以容器形式运行一个Docker镜像   Docker run -it 仓库名:标签 [命令] -it表示进入交互终端   Docker run \u0026ndash;rm 仓库名:标签 [命令] \u0026ndash;rm退出后删除，否则docker ps -a看得到   docker image ls 列出已经下载下来的镜像   docker images 同上   docker image ls [仓库名][:标签] 列出指定仓库名或附带标签的镜像   docker image ls -q 仅列出表格的IMAGE ID列表   docker image ls -f label=com.example.version=0.1 -f 增加过滤器   docker image ls \u0026ndash;format \u0026ldquo;{{.ID}}: {{.Repository}}\u0026rdquo; 利用Go的模板语法列出信息   docker image ls \u0026ndash;digests 列出镜像，增加DIGEST摘要显示（确保唯一）   docker image rm [选项] \u0026lt;镜像1\u0026gt; [\u0026lt;镜像2\u0026gt; \u0026hellip;] 删除镜像，镜像可以是ID、仓库名:标签，摘要   docker image rm $(docker images -q redis) 删除所有redis名称的镜像   docker image rm $(docker images -q -f before=镜像) 删除某个镜像前面的镜像   docker run \u0026ndash;name webserver -d -p 80:80 nginx 指定容器名称为webserver，且配置端口   docker exec -it webserver bash 进入容器，打开bash控制台   docker commit [选项] \u0026lt;容器ID或容器名\u0026gt; [\u0026lt;仓库名\u0026gt;[:\u0026lt;标签\u0026gt;]] 保存镜像   Docker tag 给一个Docker镜像打标签   docker system df 便捷的查看镜像、容器、数据卷所占用的空间   docker image prune 删除虚悬镜像(dangling image)   docker build [选项] \u0026lt;上下文路径/URL/-\u0026gt; 构建镜像    $ docker commit \\ --author \u0026quot;Tao Wang \u0026lt;twang2218@gmail.com\u0026gt;\u0026quot; \\ --message \u0026quot;修改了默认网页\u0026quot; \\ webserver \\ nginx:v2 使用Dockerfile定制镜像    指令 功能     FROM \u0026lt;基础镜像\u0026gt; 基础镜像   FROM scratch 不以任何镜像为基础，Go语言开发的应用很多会使用这种方式   RUN shell格式命令 shell命令追加层   RUN [\u0026ldquo;可执行文件\u0026rdquo;, \u0026ldquo;参数1\u0026rdquo;, \u0026ldquo;参数2\u0026rdquo;] exec格式追加层   COPY ./package.json /app/ 其中.表示上下文目录   docker build -t nginx:v3 . 其中.就是传入的上下文目录，一般及时Dockerfile文件所在目录   COPY [\u0026ndash;chown=:] \u0026lt;源路径\u0026gt;\u0026hellip; \u0026lt;目标路径\u0026gt; 复制上下文目录中的文件/目录到镜像中   WORKDIR \u0026lt;绝对路径\u0026gt; 指定某个绝对路径作为后续的相对路径   ADD [\u0026ndash;chown=:] \u0026lt;源路径\u0026gt;\u0026hellip; \u0026lt;目标路径\u0026gt; 仅源自动解压缩时使用   CMD \u0026lt;shell命令\u0026gt; 容器主进程的启动命令，例如ubuntu镜像默认的CMD是/bin/bash   CMD [\u0026ldquo;可执行文件\u0026rdquo;, \u0026ldquo;参数1\u0026rdquo;, \u0026ldquo;参数2\u0026rdquo;\u0026hellip;] exec 格式容器主进程的启动命令，推荐使用   ENTRYPOINT [\u0026ldquo;可执行文件\u0026rdquo;, \u0026ldquo;参数1\u0026rdquo;, \u0026ldquo;参数2\u0026rdquo;\u0026hellip;] 入口点，镜像变成命令一样使用，或者运行前的准备工作   ENV  ENV 设置环境变量   ENV ==\u0026hellip; ENV 设置环境变量   ARG \u0026lt;参数名\u0026gt;[=\u0026lt;默认值\u0026gt;] docker build中用\u0026ndash;build-arg \u0026lt;参数名\u0026gt;=\u0026lt;值\u0026gt;来覆盖，生效范围为下一个指令   VOLUME [\u0026quot;\u0026lt;路径1\u0026gt;\u0026quot;, \u0026ldquo;\u0026lt;路径2\u0026gt;\u0026rdquo;\u0026hellip;] VOLUME 定义匿名卷，这样运行时，不会向容器存储层写入数据，运行命令-v可以覆盖位置   VOLUME \u0026lt;路径\u0026gt; VOLUME 定义匿名卷   EXPOSE \u0026lt;端口1\u0026gt; [\u0026lt;端口2\u0026gt;\u0026hellip;] 暴露端口，容器运行时提供服务的端口，这只是一个声明   WORKDIR \u0026lt;工作目录路径\u0026gt; 指定工作目录（或者称为当前目录），如该目录不存在，WORKDIR 会帮你建立目录   USER \u0026lt;用户名\u0026gt;[:\u0026lt;用户组\u0026gt;] 指定当前用户，这个用户必须是事先建立好的   HEALTHCHECK [选项] CMD \u0026lt;命令\u0026gt; 设置检查容器健康状况的命令   HEALTHCHECK NONE 如果基础镜像有健康检查指令，使用这行可以屏蔽掉其健康检查指令\\   ONBUILD \u0026lt;其它指令\u0026gt; 后面指令，以当前镜像为基础镜像构建下一级镜像时被执行。   LABEL ==\u0026hellip; 镜像以键值对的形式添加一些元数据（metadata）   SHELL [\u0026ldquo;executable\u0026rdquo;, \u0026ldquo;parameters\u0026rdquo;] 指定RUN ENTRYPOINT CMD 指令的 shell，Linux 中默认为 [\u0026quot;/bin/sh\u0026quot;, \u0026ldquo;-c\u0026rdquo;]    示例\nFROM FROM nginx RUN echo '\u0026lt;h1\u0026gt;Hello, Docker!\u0026lt;/h1\u0026gt;' \u0026gt; /usr/share/nginx/html/index.html docker build -t nginx:v3 . FROM debian:stretch RUN apt-get update RUN apt-get install -y gcc libc6-dev make wget RUN wget -O redis.tar.gz \u0026quot;http://download.redis.io/releases/redis-5.0.3.tar.gz\u0026quot; RUN mkdir -p /usr/src/redis RUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 RUN make -C /usr/src/redis RUN make -C /usr/src/redis install FROM debian:stretch RUN set -x; buildDeps='gcc libc6-dev make wget' \\ \u0026amp;\u0026amp; apt-get update \\ \u0026amp;\u0026amp; apt-get install -y $buildDeps \\ \u0026amp;\u0026amp; wget -O redis.tar.gz \u0026quot;http://download.redis.io/releases/redis-5.0.3.tar.gz\u0026quot; \\ \u0026amp;\u0026amp; mkdir -p /usr/src/redis \\ \u0026amp;\u0026amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\ \u0026amp;\u0026amp; make -C /usr/src/redis \\ \u0026amp;\u0026amp; make -C /usr/src/redis install \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* \\ \u0026amp;\u0026amp; rm redis.tar.gz \\ \u0026amp;\u0026amp; rm -r /usr/src/redis \\ \u0026amp;\u0026amp; apt-get purge -y --auto-remove $buildDeps COPY package.json /usr/src/app/ COPY hom* /mydir/ COPY hom?.txt /mydir/ COPY --chown=55:mygroup files* /mydir/ COPY --chown=bin files* /mydir/ COPY --chown=1 files* /mydir/ COPY --chown=10:11 files* /mydir/ ADD --chown=55:mygroup files* /mydir/ ADD --chown=bin files* /mydir/ ADD --chown=1 files* /mydir/ ADD --chown=10:11 files* /mydir/ FROM ubuntu:18.04 RUN apt-get update \\ \u0026amp;\u0026amp; apt-get install -y curl \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* ENTRYPOINT [ \u0026quot;curl\u0026quot;, \u0026quot;-s\u0026quot;, \u0026quot;http://myip.ipip.net\u0026quot; ] FROM ubuntu:18.04 RUN apt-get update \\ \u0026amp;\u0026amp; apt-get install -y curl \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* ENTRYPOINT [ \u0026quot;curl\u0026quot;, \u0026quot;-s\u0026quot;, \u0026quot;http://myip.ipip.net\u0026quot; ] ENV VERSION=1.0 DEBUG=on \\ NAME=\u0026quot;Happy Feet\u0026quot; # 后面的指令中，可以通过$VERSION、$NAME来引用。列指令可以支持环境变量展开： # ADD、COPY、ENV、EXPOSE、FROM、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBUILD、RUN。 ARG DOCKER_USERNAME=library FROM ${DOCKER_USERNAME}/alpine # 在FROM 之后使用变量，必须在每个阶段分别指定 ARG DOCKER_USERNAME=library RUN set -x ; echo ${DOCKER_USERNAME} FROM ${DOCKER_USERNAME}/alpine # 在FROM 之后使用变量，必须在每个阶段分别指定 ARG DOCKER_USERNAME=library RUN set -x ; echo ${DOCKER_USERNAME} RUN groupadd -r redis \u0026amp;\u0026amp; useradd -r -g redis redis USER redis RUN [ \u0026quot;redis-server\u0026quot; ] FROM nginx RUN apt-get update \u0026amp;\u0026amp; apt-get install -y curl \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* HEALTHCHECK --interval=5s --timeout=3s \\ CMD curl -fs http://localhost/ || exit 1 Dockerfile多阶段构建 在Docker 17.05之后，开始支持多阶段构建 (multistage builds)。解决了之前编写2个Dockerfile的方案，一个Dockerfile把项目及其依赖库编译测试打包，一个Dockerfile构建运行镜像包，把之前的构建结果拷贝到运行环境。\n我们可以使用 as 来为某一阶段命名，例如\n FROM golang:alpine as builder 一个为go程序，多阶段构建的例子：\nFROM golang:alpine as builder RUN apk --no-cache add git WORKDIR /go/src/github.com/go/helloworld/ RUN go get -d -v github.com/go-sql-driver/mysql COPY app.go . RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . FROM alpine:latest as prod RUN apk --no-cache add ca-certificates WORKDIR /root/ COPY --from=0 /go/src/github.com/go/helloworld/app . CMD [\u0026quot;./app\u0026quot;] 例如当我们只想构建 builder 阶段的镜像时，增加 \u0026ndash;target=builder 参数即可\n docker build --target builder -t username/imagename:tag . 构建时从其他镜像复制文件\n COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf 构建多种系统架构支持的 Docker 镜像 参见：https://yeasy.gitbook.io/docker_practice/image/manifest\nDocker 镜像的导入和导出 docker save 和 docker load    命令示例 说明     docker save alpine -o filename 把alphine镜像保存到filename文件   docker save alpine gzip \u0026gt; alpine-latest.tar.gz   docker load -i alpine-latest.tar.gz 把alpine-latest.tar.gz镜像压缩文件导入到Docker系统中    操作镜像    命令示例 说明     docker run ubuntu:18.04 /bin/echo \u0026lsquo;Hello world\u0026rsquo; 通过镜像，输出一个 “Hello World”，之后终止容器   docker run -t -i ubuntu:18.04 /bin/bash 启动一个 bash 终端，允许用户进行交互   docker container start 历史容器 将一个已经终止（exited）的容器启动运行   docker run -d ubuntu:18.04 /bin/sh -c \u0026ldquo;\u0026hellip;脚本\u0026rdquo; -d容器输出到容器中，会返回一个唯一的id   docker container ls 可以看到容器id，运行中的   docker container ls -a 查看所有容器，加了-a包括已经终止的容器   docker container logs [container ID or NAMES] 可以获取容器的输出信息   docker container stop [container ID or NAMES] 终止一个运行中的容器   docker exec -it 69d1 bash 进入container ID以69d1开头的容器，打开bash，退出时，容器继续运行   docker attach -it 69d1 bash 进入container ID以69d1开头的容器，打开bash，退出时，容器停止   docker export 7691a814370e \u0026gt; ubuntu.tar 导出容器快照到本地文件   cat ubuntu.tar docker import - test/ubuntu:v1.0   docker import http://example.com/exampleimage.tgz example/imagerepo 通过指定 URL 或者某个目录来导入   docker container rm trusting_newton 删除一个处于终止状态的NAMES为trusting_newton的容器   docker container prune 清理所有处于终止状态的容器    数据管理    命令示例 说明     docker volume create my-vol 创建一个名称为my-vol的数据卷，宿主机默认目录/var/lib/docker/volumes/my-vol/_data   docker volume ls 查看所有的 数据卷   docker volume inspect my-vol 在主机里查看指定 数据卷 的信息   docker run -v my-vol:/usr/share/nginx/html [其他省略] 运行时加载my-vol数据卷 到容器的 /usr/share/nginx/html 目录   docker run \u0026ndash;mount source=my-vol,target=/usr/share/nginx/html [其他省略] 同上，另一种写法   docker inspect web 查看web容器时，可以在Mouts中查看数据卷的具体信息   docker volume rm my-vol 删除数据卷   docker rm -v \u0026lt;容器ID或名称\u0026gt; 删除容器时，同时移除数据卷   docker volume prune 清理无主的数据卷   docker -v /src/webapp:/usr/share/nginx/html [其他省略] 挂载一个本地主机的目录到容器中去   docker \u0026ndash;mount type=bind,source=/src/webapp,target=/usr/share/nginx/html [其他省略] 同上，另一种严格写法   -v /src/webapp:/usr/share/nginx/html:ro [其他省略] ro表示只读，不加表示读写   \u0026ndash;mount type=bind,source=/src/webapp,target=/usr/share/nginx/html,readonly [其他省略] 表示只读   -v $HOME/.bash_history:/root/.bash_history [其他省略] 挂载一个本地主机文件作为数据卷   \u0026ndash;mount type=bind,source=$HOME/.bash_history,target=/root/.bash_history [其他省略] 同上    使用网络    命令 功能     docker run -p [其他省略] -p随机映射端口到内部容器开放的网络端口   docker container ls 列表中PORTS（如0.0.0.0:32768-\u0026gt;80/tcp）前一个表示宿主机端口   docker logs \u0026lt;容器ID\u0026gt; 上面已描述，查看容器内的打印   docker run -p ip:hostPort:containerPort [其他省略] 指定映射端口，-p可以多次使用   docker run -p ip::containerPort [其他省略] 指定映射端口   docker run -p hostPort:containerPort [其他省略] 指定映射端口   docker port \u0026lt;容器ID\u0026gt; \u0026lt;容器端口\u0026gt; 查看当前映射的端口配置，和绑定的地址   docker network create -d bridge my-net 创建Docker网络，-d指定类型，有bridge\\overlay，my-net是名称   mount 在容器中使用mount可查看挂载信息   docker run [其他省略] cat /etc/resolv.conf 启动时，查看DNS配置   docker run [其他省略] -h HOSTNAME 设定容器的主机名，写到容器内的/etc/hostname 和/etc/hosts，外包看不到   docker run [其他省略] \u0026ndash;dns=IP_ADDRESS 添加 DNS 服务器到容器的/etc/resolv.conf 中，等在宿主/etc/hosts 临时增加    Dockerfile最佳实践指南  不常变动的部分写在dockerfile上面，以便后续变更时可以利用缓存，减少build时间。 编写 .dockerignore 编译镜像时，docker 先要准备编译用的context，默认情况下会把 Dockerfile所在的所在文件夹下所有文件包含进去，如果不想把src目录包含进去来加快编译速度，可以添加.dockerignore，内容如下 src/ RUN rm xxx 删除前面层的文件不会减小镜像大小，因为包含文件的那层会一直存在，RUN set合并为一层 尽量不在dockerfile去修改文件权限，修改权限后的文件会生成一份新的文件导致镜像变大，修改权限最好本地直接改好或写在启动脚本中(不推荐)。 只复制需要的，如果可能，避免复制。在将文件复制到镜像中时，请确保对要复制的内容非常明确，避免 COPY . /home/admin/broker 这样的操作，使用COPY app/xxx.jar /home/admin/broker 添加文件夹到指定目录，最好填写绝对路径，如果想把kafka文件夹添加到home，要写成ADD kafka/ /home/kafka/ 大的rpm包，如果要安装到镜像中，可以做成yum 源，yum install xx之后yum clean all，如果ADD XX.rpm /xx，这样rpm会使镜像增大。 大的压缩包最好是做成可以下载的文件，下载解压后删除源文件 多个RUN或者ENV最好合并为一个，这样生成的文件都在同一层，便于优化大小 去掉不必要的组件，比如 yum install vim 不安装运行不必须得vim，可以减小镜像体积 每次RUN的后面阶段删除不必要的文件，比如 yum install xx 安装软件后要执行 yum clean all 清除缓存，减小镜像。 基础镜像要指定明确的版本 FROM openjdk:latest 建议使用 FROM openjdk:8-jre-alpine 基础镜像如果可能，尽量使用官方发布的版本，第三方的版本有被植入病毒的风险，而且没法保证及时补丁升级和更新 基础镜像尽量选择小体积的发行版本，比如基于alpine linux制作的镜像， 分阶段编译，docker 17.05 版本以后开始支持分阶段编译，可以使用编译镜像去编译，生成的目标文件导入到运行环境镜像中，这样编译出的镜像就可以不需要一些编译工具，编译依赖，去掉编译中产生的无用文件 WORKDIR 为 RUN CMD ENTRYPOINT指定一个默认的工作目录 启动脚本中最好使用 exec去运行程序 使用LABEL去添加一些附属信息，比如作者，联系方式，内部软件版本之类 使用HEALTHCHECK添加健康检查，判断拉起的容器业务是否正常  FROM golang:1.7.3 AS builder WORKDIR /go/src/github.com/alexellis/href-counter/ RUN go get -d -v golang.org/x/net/html COPY app.go . RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app . FROM alpine:latest RUN apk --no-cache add ca-certificates WORKDIR /root/ COPY --from=builder /go/src/github.com/alexellis/href-counter/app . CMD [\u0026quot;./app\u0026quot;] Docker 实战与练习 Docker 实战与练习\n","date":"2021-11-05T22:00:38+08:00","image":"https://zcj-git520.github.io/p/docker%E7%9F%A5%E8%AF%86%E6%80%BB%E8%A7%88/1_hub2f0788524e05f802191dca26df6a25d_10280_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/docker%E7%9F%A5%E8%AF%86%E6%80%BB%E8%A7%88/","title":"Docker知识总览"},{"content":"文章来源 鹅厂(腾讯)代码安全指南\n通用 加密算法 【必须】避免使用不安全的对称加密算法  DES和3DES已经不再适用于现代应用程序，应改为使用AES。  程序日志 【建议】对每个重要行为都记录日志  确保重要行为都记录日志，且可靠保存6个月以上。  1.2.2 【建议】禁止将未经验证的用户输入直接记录日志  当日志条目包含未经净化的用户输入时会引发记录注入漏洞。恶意用户会插入伪造的日志数据，从而让系统管理员以为是系统行为。  1.2.3 【建议】避免在日志中保存敏感信息  不能在日志保存密码（包括明文密码和密文密码）、密钥和其它敏感信息  系统口令 【必须】禁止使用空口令、弱口令、已泄露口令 【必须】口令强度要求  口令强度须同时满足：\n 密码长度大于14位 必须包含下列元素：大小写英文字母、数字、特殊字符 不得使用各系统、程序的默认初始密码 不能与最近6次使用过的密码重复 不得与其他外部系统使用相同的密码   【必须】口令存储安全  禁止明文存储口令 禁止使用弱密码学算法（如DES和3DES）加密存储口令 使用不可逆算法和随机salt对口令进行加密存储  【必须】禁止传递明文口令 【必须】禁止在不安全的信道中传输口令 配置\u0026amp;环境 Python版本选择 【建议】使用Python 3.6+的版本  新增的项目应使用 Python 3.6+   为什么要这么做？ 由于 Python 2 在 2020 年停止维护，相关组件的漏洞不能得到及时修复与维护\n 第三方包安全 【必须】禁止使用不安全的组件 配置信息 【必须】密钥存储安全  在使用对称密码算法时，需要保护好加密密钥。当算法涉及敏感、业务数据时，可通过非对称算法协商加密密钥。其他较为不敏感的数据加密，可以通过变换算法等方式保护密钥。  【必须】禁止硬编码敏感配置  禁止在源码中硬编码AK/SK、IP、数据库账密等配置信息 应使用配置系统或KMS密钥管理系统。  后台 输入验证 【必须】按类型进行数据校验   所有程序外部输入的参数值，应进行数据校验。校验内容包括但不限于：数据长度、数据范围、数据类型与格式。校验不通过，应拒绝。\n  推荐使用组件：Cerberus、jsonschema、Django-Validators\n  # Cerberus示例 v = Validator({\u0026#39;name\u0026#39;: {\u0026#39;type\u0026#39;: \u0026#39;string\u0026#39;}}) v.validate({\u0026#39;name\u0026#39;: \u0026#39;john doe\u0026#39;}) # jsonschema示例 schema = { \u0026#34;type\u0026#34; : \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34; : { \u0026#34;price\u0026#34; : {\u0026#34;type\u0026#34; : \u0026#34;number\u0026#34;}, \u0026#34;name\u0026#34; : {\u0026#34;type\u0026#34; : \u0026#34;string\u0026#34;}, }, } validate(instance={\u0026#34;name\u0026#34; : \u0026#34;Eggs\u0026#34;, \u0026#34;price\u0026#34; : 34.99}, schema=schema) SQL操作 【必须】使用参数化查询  使用参数化SQL语句，强制区分数据和命令，避免产生SQL注入漏洞。  # 错误示例 import mysql.connector mydb = mysql.connector.connect( ... ... ) cur = mydb.cursor() userid = get_id_from_user() # 使用%直接格式化字符串拼接SQL语句 cur.execute(\u0026#34;SELECT `id`, `password` FROM `auth_user` WHERE `id`=%s\u0026#34; % (userid,)) myresult = cur.fetchall() # 安全示例 import mysql.connector mydb = mysql.connector.connect( ... ... ) cur = mydb.cursor() userid = get_id_from_user() # 将元组以参数的形式传入 cur.execute(\u0026#34;SELECT `id`, `password` FROM `auth_user` WHERE `id`=%s\u0026#34; , (userid,)) myresult = cur.fetchall()  推荐使用ORM框架来操作数据库，如：使用SQLAlchemy。  # 安装sqlalchemy并初始化数据库连接 # pip install sqlalchemy from sqlalchemy import create_engine # 初始化数据库连接，修改为你的数据库用户名和密码 engine = create_engine(\u0026#39;mysql+mysqlconnector://user:password@host:port/DATABASE\u0026#39;) # 引用数据类型 from sqlalchemy import Column, String, Integer, Float from sqlalchemy.ext.declarative import declarative_base Base = declarative_base() # 定义 Player 对象: class Player(Base): # 表的名字: __tablename__ = \u0026#39;player\u0026#39; # 表的结构: player_id = Column(Integer, primary_key=True, autoincrement=True) team_id = Column(Integer) player_name = Column(String(255)) height = Column(Float(3, 2)) # 增删改查 from sqlalchemy.orm import sessionmaker # 创建 DBSession 类型: DBSession = sessionmaker(bind=engine) # 创建 session 对象: session = DBSession() # 增: new_player = Player(team_id=101, player_name=\u0026#34;Tom\u0026#34;, height=1.98) session.add(new_player) # 删: row = session.query(Player).filter(Player.player_name==\u0026#34;Tom\u0026#34;).first() session.delete(row) # 改: row = session.query(Player).filter(Player.player_name==\u0026#34;Tom\u0026#34;).first() row.height = 1.99 # 查: rows = session.query(Player).filter(Player.height \u0026gt;= 1.88).all() # 提交即保存到数据库: session.commit() # 关闭 session: session.close() 【必须】对参数进行过滤  将接受到的外部参数动态拼接到SQL语句时，必须对参数进行安全过滤。  def sql_filter(sql, max_length=20): dirty_stuff = [\u0026#34;\\\u0026#34;\u0026#34;, \u0026#34;\\\\\u0026#34;, \u0026#34;/\u0026#34;, \u0026#34;*\u0026#34;, \u0026#34;\u0026#39;\u0026#34;, \u0026#34;=\u0026#34;, \u0026#34;-\u0026#34;, \u0026#34;#\u0026#34;, \u0026#34;;\u0026#34;, \u0026#34;\u0026lt;\u0026#34;, \u0026#34;\u0026gt;\u0026#34;, \u0026#34;+\u0026#34;, \u0026#34;\u0026amp;\u0026#34;, \u0026#34;$\u0026#34;, \u0026#34;(\u0026#34;, \u0026#34;)\u0026#34;, \u0026#34;%\u0026#34;, \u0026#34;@\u0026#34;, \u0026#34;,\u0026#34;] for stuff in dirty_stuff: sql = sql.replace(stuff, \u0026#34;x\u0026#34;) return sql[:max_length] 执行命令 【建议】避免直接调用函数执行系统命令  相关功能的实现应避免直接调用系统命令（如os.system()、os.popen()、subprocess.call()等），优先使用其他同类操作进行代替，比如：通过文件系统API进行文件操作而非直接调用操作系统命令 如评估无法避免，执行命令应避免拼接外部数据，同时进行执行命令的白名单限制。  【必须】过滤传入命令执行函数的字符  程序调用各类函数执行系统命令时，如果涉及的命令由外部传入，过滤传入命令执行函数的字符。  import os import sys import shlex domain = sys.argv[1] # 替换可以用来注入命令的字符为空 badchars = \u0026#34;\\n\u0026amp;;|\u0026#39;\\\u0026#34;$()`-\u0026#34; for char in badchars: domain = domain.replace(char, \u0026#34; \u0026#34;) result = os.system(\u0026#34;nslookup \u0026#34; + shlex.quote(domain)) XML读写 【必须】禁用外部实体的方法  禁用外部实体的方法，来预防XXE攻击。  from lxml import etree xmlData = etree.parse(xmlSource,etree.XMLParser(resolve_entities=False)) 文件操作 【必须】文件类型限制  通过白名单对上传或者下载的文件类型、大小进行严格校验。仅允许业务所需文件类型上传，避免上传木马、WebShell等文件。  import os ALLOWED_EXTENSIONS = [\u0026#39;txt\u0026#39;,\u0026#39;jpg\u0026#39;,\u0026#39;png\u0026#39;] def allowed_file(filename): if (\u0026#39;.\u0026#39; in filename and \u0026#39;..\u0026#39; not in filename and os.path.splitext(filename)[1].lower() in ALLOWED_EXTENSIONS): return filename return None 【必须】禁止外部文件存储于可执行目录  禁止外部文件存储于WEB容器的可执行目录（appBase）。建议使用 tempfile 库处理临时文件和临时目录。  【必须】避免路径穿越  保存在本地文件系统时，必须对路径进行合法校验，避免目录穿越漏洞  import os upload_dir = \u0026#39;/tmp/upload/\u0026#39; # 预期的上传目录 file_name = \u0026#39;../../etc/hosts\u0026#39; # 用户传入的文件名 absolute_path = os.path.join(upload_dir, file_name) # /tmp/upload/../../etc/hosts normalized_path = os.path.normpath(absolute_path) # /etc/hosts if not normalized_path.startswith(upload_dir): # 检查最终路径是否在预期的上传目录中 raise IOError() 【建议】避免路径拼接  文件目录避免外部参数拼接。保存文件目录建议后台写死并对文件名进行校验（字符类型、长度）。  【建议】文件名hash化处理  建议文件保存时，将文件名替换为随机字符串。  import uuid def random_filename(filename): ext = os.path.splitext(filename)[1] new_filename = uuid.uuid4().hex + ext return new_filename 网络请求 【必须】限定访问网络资源地址范围 当程序需要从用户指定的URL地址获取网页文本内容、加载指定地址的图片、进行下载等操作时，需要对URL地址进行安全校验：\n  只允许HTTP或HTTPS协议\n  解析目标URL，获取其host\n  解析host，获取host指向的IP地址转换成long型\n  检查IP地址是否为内网IP\n  # 以RFC定义的专有网络为例，如有自定义私有网段亦应加入禁止访问列表。 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16 127.0.0.0/8  请求URL\n  如果有跳转，跳转后执行1，否则对URL发起请求\n  响应输出 【必须】设置正确的HTTP响应包类型 响应包的HTTP头“Content-Type”必须正确配置响应包的类型，禁止非HTML类型的响应包设置为“text/html”。\n【必须】设置安全的HTTP响应头   X-Content-Type-Options\n添加“X-Content-Type-Options”响应头并将其值设置为“nosniff ”\n  HttpOnly 控制用户登鉴权的Cookie字段 应当设置HttpOnly属性以防止被XSS漏洞/JavaScript操纵泄漏。\n  X-Frame-Options\n设置X-Frame-Options响应头，并根据需求合理设置其允许范围。该头用于指示浏览器禁止当前页面在frame、 iframe、embed等标签中展现。从而避免点击劫持问题。它有三个可选的值: DENY: 浏览器会拒绝当前页面加 载任何frame页面; SAMEORIGIN:则frame页面的地址只能为同源域名下的页面 ALLOW-FROM origin:可以定 义允许frame加载的页面地址。\n  【必须】对外输出页面包含第三方数据时须进行编码处理  当响应“Content-Type”为“text/html”类型时，需要对响应体进行编码处理  # 推荐使用mozilla维护的bleach库来进行过滤 import bleach bleach.clean(\u0026#39;an \u0026lt;script\u0026gt;evil()\u0026lt;/script\u0026gt; example\u0026#39;) # u\u0026#39;an \u0026amp;lt;script\u0026amp;gt;evil()\u0026amp;lt;/script\u0026amp;gt; example\u0026#39; 数据输出 【必须】敏感数据加密存储  敏感数据应使用SHA2、RSA等算法进行加密存储 敏感数据应使用独立的存储层，并在访问层开启访问控制 包含敏感信息的临时文件或缓存一旦不再需要应立刻删除  【必须】敏感信息必须由后台进行脱敏处理  敏感信息须再后台进行脱敏后返回，禁止接口返回敏感信息交由前端/客户端进行脱敏处理。  【必须】高敏感信息禁止存储、展示  口令、密保答案、生理标识等鉴权信息禁止展示 非金融类业务，信用卡cvv码及日志禁止存储  【必须】个人敏感信息脱敏展示 在满足业务需求的情况下，个人敏感信息需脱敏展示，如：\n 身份证只显示第一位和最后一位字符，如3****************1。 移动电话号码隐藏中间6位字符，如134******48。 工作地址/家庭地址最多显示到“区”一级。 银行卡号仅显示最后4位字符，如************8639  【必须】隐藏后台地址  若程序对外提供了登录后台地址，应使用随机字符串隐藏地址。  # 不要采取这种方式 admin_login_url = \u0026#34;xxxx/login\u0026#34; # 安全示例 admin_login_url = \u0026#34;xxxx/ranD0Str\u0026#34; 权限管理 【必须】默认鉴权  除非资源完全可对外开放，否则系统默认进行身份认证（使用白名单的方式放开不需要认证的接口或页面）。  ####【必须】授权遵循最小权限原则\n 程序默认用户应不具备任何操作权限。  【必须】避免越权访问  对于非公共操作，应当校验当前访问账号进行操作权限（常见于CMS）和数据权限校验。   验证当前用户的登录态； 从可信结构中获取经过校验的当前请求账号的身份信息（如：session），禁止从用户请求参数或Cookie中获取外部传入不可信用户身份直接进行查询； 校验当前用户是否具备该操作权限； 校验当前用户是否具备所操作数据的权限； 校验当前操作是否账户是否预期账户。  【建议】及时清理不需要的权限  程序应定期清理非必需用户的权限。  异常处理 【必须】不向对外错误提示  应合理使用try/except/finally 处理系统异常，避免出错信息输出到前端。 对外环境禁止开启debug模式，或将程序运行日志输出到前端。  【必须】禁止异常抛出敏感信息 Flask安全 【必须】生产环境关闭调试模式 【建议】遵循Flask安全规范  参考Flask文档中的安全注意事项 https://flask.palletsprojects.com/en/latest/security/  Django安全 【必须】生产环境关闭调试模式 ####【建议】保持Django自带的安全特性开启\n  保持Django自带的安全特性开启 https://docs.djangoproject.com/en/3.0/topics/security/\n  在默认配置下，Django自带的安全特性对XSS、CSRF、SQL注入、点击劫持等类型漏洞可以起到较好防护效果。应尽量避免关闭这些安全特性。\n  ","date":"2021-10-30T22:00:08+08:00","image":"https://zcj-git520.github.io/p/python%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/1_hu88cf376361c4b459010ac189c2b354f8_10188_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/python%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/","title":"Python安全指南"},{"content":"文章来源 鹅厂(腾讯)代码安全指南\n通用安全指南 C/C++使用错误 【必须】不得直接使用无长度限制的字符拷贝函数 不应直接使用legacy的字符串拷贝、输入函数，如strcpy、strcat、sprintf、wcscpy、mbscpy等，这些函数的特征是：可以输出一长串字符串，而不限制长度。如果环境允许，应当使用其_s安全版本替代，或者使用n版本函数（如：snprintf，vsnprintf）。\n若使用形如sscanf之类的函数时，在处理字符串输入时应当通过%10s这样的方式来严格限制字符串长度，同时确保字符串末尾有\\0。如果环境允许，应当使用_s安全版本。\n但是注意，虽然MSVC 2015时默认引入结尾为0版本的snprintf（行为等同于C99定义的snprintf）。但更早期的版本中，MSVC的snprintf可能是_snprintf的宏。而_snprintf是不保证\\0结尾的（见本节后半部分）。\n（MSVC） Beginning with the UCRT in Visual Studio 2015 and Windows 10, snprintf is no longer identical to _snprintf. The snprintf function behavior is now C99 standard compliant. 从Visual Studio 2015和Windows 10中的UCRT开始，snprintf不再与_snprintf相同。snprintf函数行为现在符合C99标准。 请参考：https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/snprintf-snprintf-snprintf-l-snwprintf-snwprintf-l?redirectedfrom=MSDN\u0026amp;view=vs-2019 因此，在使用n系列拷贝函数时，要确保正确计算缓冲区长度，同时，如果你不确定是否代码在各个编译器下都能确保末尾有0时，建议可以适当增加1字节输入缓冲区，并将其置为\\0，以保证输出的字符串结尾一定有\\0。\n// Good char buf[101] = {0}; snprintf(buf, sizeof(buf) - 1, \u0026#34;foobar ...\u0026#34;, ...); 一些需要注意的函数，例如strncpy和_snprintf是不安全的。 strncpy不应当被视为strcpy的n系列函数，它只是恰巧与其他n系列函数名字很像而已。strncpy在复制时，如果复制的长度超过n，不会在结尾补\\0。\n同样，MSVC _snprintf系列函数在超过或等于n时也不会以0结尾。如果后续使用非0结尾的字符串，可能泄露相邻的内容或者导致程序崩溃。\n// Bad char a[4] = {0}; _snprintf(a, 4, \u0026#34;%s\u0026#34;, \u0026#34;AAAA\u0026#34;); foo = strlen(a); 上述代码在MSVC中执行后， a[4] == \u0026lsquo;A\u0026rsquo;，因此字符串未以0结尾。a的内容是\u0026quot;AAAA\u0026quot;，调用strlen(a)则会越界访问。因此，正确的操作举例如下：\n// Good char a[4] = {0}; _snprintf(a, sizeof(a), \u0026#34;%s\u0026#34;, \u0026#34;AAAA\u0026#34;); a[sizeof(a) - 1] = \u0026#39;\\0\u0026#39;; foo = strlen(a); 在 C++ 中，强烈建议用 string、vector 等更高封装层次的基础组件代替原始指针和动态数组，对提高代码的可读性和安全性都有很大的帮助。\n关联漏洞:\n中风险-信息泄露\n低风险-拒绝服务\n高风险-缓冲区溢出\n【必须】创建进程类的函数的安全规范 system、WinExec、CreateProcess、ShellExecute等启动进程类的函数，需要严格检查其参数。\n启动进程需要加上双引号，错误例子：\n// Bad WinExec(\u0026#34;D:\\\\program files\\\\my folder\\\\foobar.exe\u0026#34;, SW_SHOW); 当存在D:\\program files\\my.exe的时候，my.exe会被启动。而foobar.exe不会启动。\n// Good WinExec(\u0026#34;\\\u0026#34;D:\\\\program files\\\\my folder\\\\foobar.exe\\\u0026#34;\u0026#34;, SW_SHOW); 另外，如果启动时从用户输入、环境变量读取组合命令行时，还需要注意是否可能存在命令注入。\n// Bad std::string cmdline = \u0026#34;calc \u0026#34;; cmdline += user_input; system(cmdline.c_str()); 比如，当用户输入1+1 \u0026amp;\u0026amp; ls时，执行的实际上是calc 1+1和ls 两个命令，导致命令注入。\n需要检查用户输入是否含有非法数据。\n// Good std::string cmdline = \u0026#34;ls \u0026#34;; cmdline += user_input; if(cmdline.find_first_not_of(\u0026#34;1234567890.+-*/e \u0026#34;) == std::string::npos) system(cmdline.c_str()); else warning(...); 关联漏洞:\n高风险-代码执行\n高风险-权限提升\n【必须】尽量减少使用 _alloca 和可变长度数组 _alloca 和可变长度数组使用的内存量在编译期间不可知。尤其是在循环中使用时，根据编译器的实现不同，可能会导致：（1）栈溢出，即拒绝服务； （2）缺少栈内存测试的编译器实现可能导致申请到非栈内存，并导致内存损坏。这在栈比较小的程序上，例如IoT设备固件上影响尤为大。对于 C++，可变长度数组也属于非标准扩展，在代码规范中禁止使用。\n错误示例：\n// Bad for (int i = 0; i \u0026lt; 100000; i++) { char* foo = (char *)_alloca(0x10000); ..do something with foo ..; } void Foo(int size) { char msg[size]; // 不可控的栈溢出风险！ } 正确示例：\n// Good // 改用动态分配的堆内存 for (int i = 0; i \u0026lt; 100000; i++) { char * foo = (char *)malloc(0x10000); ..do something with foo ..; if (foo_is_no_longer_needed) { free(foo); foo = NULL; } } void Foo(int size) { std::string msg(size, \u0026#39;\\0\u0026#39;); // C++  char* msg = malloc(size); // C } 关联漏洞:\n低风险-拒绝服务\n高风险-内存破坏\n【必须】printf系列参数必须对应 所有printf系列函数，如sprintf，snprintf，vprintf等必须对应控制符号和参数。\n错误示例：\n// Bad const int buf_size = 1000; char buffer_send_to_remote_client[buf_size] = {0}; snprintf(buffer_send_to_remote_client, buf_size, \u0026#34;%d: %p\u0026#34;, id, some_string); // %p 应为 %s  buffer_send_to_remote_client[buf_size - 1] = \u0026#39;\\0\u0026#39;; send_to_remote(buffer_send_to_remote_client); 正确示例：\n// Good const int buf_size = 1000; char buffer_send_to_remote_client[buf_size] = {0}; snprintf(buffer_send_to_remote_client, buf_size, \u0026#34;%d: %s\u0026#34;, id, some_string); buffer_send_to_remote_client[buf_size - 1] = \u0026#39;\\0\u0026#39;; send_to_remote(buffer_send_to_remote_client); 前者可能会让client的攻击者获取部分服务器的原始指针地址，可以用于破坏ASLR保护。\n关联漏洞:\n中风险-信息泄露\n【必须】防止泄露指针（包括%p）的值 所有printf系列函数，要防止格式化完的字符串泄露程序布局信息。例如，如果将带有%p的字符串泄露给程序，则可能会破坏ASLR的防护效果。使得攻击者更容易攻破程序。\n%p的值只应当在程序内使用，而不应当输出到外部或被外部以某种方式获取。\n错误示例：\n// Bad // 如果这是暴露给客户的一个API： uint64_t GetUniqueObjectId(const Foo* pobject) { return (uint64_t)pobject; } 正确示例：\n// Good uint64_t g_object_id = 0; void Foo::Foo() { this-\u0026gt;object_id_ = g_object_id++; } // 如果这是暴露给客户的一个API： uint64_t GetUniqueObjectId(const Foo* object) { if (object) return object-\u0026gt;object_id_; else error(...); } 关联漏洞:\n中风险-信息泄露\n【必须】不应当把用户可修改的字符串作为printf系列函数的“format”参数 如果用户可以控制字符串，则通过 %n %p 等内容，最坏情况下可以直接执行任意恶意代码。\n在以下情况尤其需要注意： WIFI名，设备名……\n错误：\nsnprintf(buf, sizeof(buf), wifi_name); 正确：\nsnprinf(buf, sizeof(buf), \u0026#34;%s\u0026#34;, wifi_name); 关联漏洞:\n高风险-代码执行\n高风险-内存破坏\n中风险-信息泄露\n低风险-拒绝服务\n【必须】对数组delete时需要使用delete[] delete []操作符用于删除数组。delete操作符用于删除非数组对象。它们分别调用operator delete[]和operator delete。\n// Bad Foo* b = new Foo[5]; delete b; // trigger assert in DEBUG mode 在new[]返回的指针上调用delete将是取决于编译器的未定义行为。代码中存在对未定义行为的依赖是错误的。\n// Good Foo* b = new Foo[5]; delete[] b; 在 C++ 代码中，使用 string、vector、智能指针（比如std::unique_ptr\u0026lt;T[]\u0026gt;）等可以消除绝大多数 delete[] 的使用场景，并且代码更清晰。\n关联漏洞:\n高风险-内存破坏\n中风险-逻辑漏洞\n低风险-内存泄漏\n低风险-拒绝服务\n【必须】注意隐式符号转换 两个无符号数相减为负数时，结果应当为一个很大的无符号数，但是小于int的无符号数在运算时可能会有预期外的隐式符号转换。\n// 1 unsigned char a = 1; unsigned char b = 2; if (a - b \u0026lt; 0) // a - b = -1 (signed int)  a = 6; else a = 8; // 2 unsigned char a = 1; unsigned short b = 2; if (a - b \u0026lt; 0) // a - b = -1 (signed int)  a = 6; else a = 8; 上述结果均为a=6\n// 3 unsigned int a = 1; unsigned short b = 2; if (a - b \u0026lt; 0) // a - b = 0xffffffff (unsigned int)  a = 6; else a = 8; // 4 unsigned int a = 1; unsigned int b = 2; if (a - b \u0026lt; 0) // a - b = 0xffffffff (unsigned int)  a = 6; else a = 8; 上述结果均为a=8\n如果预期为8，则错误代码：\n// Bad unsigned short a = 1; unsigned short b = 2; if (a - b \u0026lt; 0) // a - b = -1 (signed int)  a = 6; else a = 8; 正确代码：\n// Good unsigned short a = 1; unsigned short b = 2; if ((unsigned int)a - (unsigned int)b \u0026lt; 0) // a - b = 0xffff (unsigned short)  a = 6; else a = 8; 关联漏洞:\n中风险-逻辑漏洞\n【必须】注意八进制问题 代码对齐时应当使用空格或者编辑器自带的对齐功能，谨慎在数字前使用0来对齐代码，以免不当将某些内容转换为八进制。\n例如，如果预期为20字节长度的缓冲区，则下列代码存在错误。buf2为020（OCT）长度，实际只有16（DEC）长度，在memcpy后越界：\n// Bad char buf1[1024] = {0}; char buf2[0020] = {0}; memcpy(buf2, somebuf, 19); 应当在使用8进制时明确注明这是八进制。\n// Good int access_mask = 0777; // oct, rwxrwxrwx 关联漏洞:\n中风险-逻辑漏洞\n不推荐的编程习惯 【必须】switch中应有default switch中应该有default，以处理各种预期外的情况。这可以确保switch接受用户输入，或者后期在其他开发者修改函数后确保switch仍可以覆盖到所有情况，并确保逻辑正常运行。\n// Bad int Foo(int bar) { switch (bar \u0026amp; 7) { case 0: return Foobar(bar); break; case 1: return Foobar(bar * 2); break; } } 例如上述代码switch的取值可能从0～7，所以应当有default：\n// Good int Foo(int bar) { switch (bar \u0026amp; 7) { case 0: return Foobar(bar); break; case 1: return Foobar(bar * 2); break; default: return -1; } } 关联漏洞:\n中风险-逻辑漏洞\n中风险-内存泄漏\n【必须】不应当在Debug或错误信息中提供过多内容 包含过多信息的Debug消息不应当被用户获取到。Debug信息可能会泄露一些值，例如内存数据、内存地址等内容，这些内容可以帮助攻击者在初步控制程序后，更容易地攻击程序。\n// Bad int Foo(int* bar) { if (bar \u0026amp;\u0026amp; *bar == 5) { OutputDebugInfoToUser(\u0026#34;Wrong value for bar %p = %d\\n\u0026#34;, bar, *bar); } } 而应该：\n// Good int foo(int* bar) { #ifdef DEBUG  if (bar \u0026amp;\u0026amp; *bar == 5) { OutputDebugInfo(\u0026#34;Wrong value for bar.\\n\u0026#34;, bar, *bar); } #endif  } 关联漏洞:\n中风险-信息泄漏\n【必须】不应该在客户端代码中硬编码对称加密秘钥 不应该在客户端代码中硬编码对称加密秘钥。例如：不应在客户端代码使用硬编码的 AES/ChaCha20-Poly1305/SM1 密钥，使用固定密钥的程序基本和没有加密一样。\n如果业务需求是认证加密数据传输，应优先考虑直接用 HTTPS 协议。\n如果是其它业务需求，可考虑由服务器端生成对称秘钥，客户端通过 HTTPS 等认证加密通信渠道从服务器拉取。\n或者根据用户特定的会话信息，比如登录认证过程可以根据用户名用户密码业务上下文等信息，使用 HKDF 等算法衍生出对称秘钥。\n又或者使用 RSA/ECDSA + ECDHE 等进行认证秘钥协商，生成对称秘钥。\n// Bad char g_aes_key[] = {...}; void Foo() { .... AES_func(g_aes_key, input_data, output_data); } 可以考虑在线为每个用户获取不同的密钥：\n// Good char* g_aes_key; void Foo() { .... AES_encrypt(g_aes_key, input_data, output_data); } void Init() { g_aes_key = get_key_from_https(user_id, ...); } 关联漏洞:\n中风险-信息泄露\n【必须】返回栈上变量的地址 函数不可以返回栈上的变量的地址，其内容在函数返回后就会失效。\n// Bad char* Foo(char* sz, int len){ char a[300] = {0}; if (len \u0026gt; 100) { memcpy(a, sz, 100); } a[len] = \u0026#39;\\0\u0026#39;; return a; // WRONG } 而应当使用堆来传递非简单类型变量。\n// Good char* Foo(char* sz, int len) { char* a = new char[300]; if (len \u0026gt; 100) { memcpy(a, sz, 100); } a[len] = \u0026#39;\\0\u0026#39;; return a; // OK } 对于 C++ 程序来说，强烈建议返回 string、vector 等类型，会让代码更加简单和安全。\n关联漏洞:\n高风险-内存破坏\n【必须】有逻辑联系的数组必须仔细检查 例如下列程序将字符串转换为week day，但是两个数组并不一样长，导致程序可能会越界读一个int。\n// Bad int nWeekdays[] = {1, 2, 3, 4, 5, 6}; const char* sWeekdays[] = {\u0026#34;Mon\u0026#34;, \u0026#34;Tue\u0026#34;, \u0026#34;Wed\u0026#34;, \u0026#34;Thu\u0026#34;, \u0026#34;Fri\u0026#34;, \u0026#34;Sat\u0026#34;, \u0026#34;Sun\u0026#34;}; for (int x = 0; x \u0026lt; ARRAY_SIZE(sWeekdays); x++) { if (strcmp(sWeekdays[x], input) == 0) return nWeekdays[x]; } 应当确保有关联的nWeekdays和sWeekdays数据统一。\n// Good const int nWeekdays[] = {1, 2, 3, 4, 5, 6, 7}; const char* sWeekdays[] = {\u0026#34;Mon\u0026#34;, \u0026#34;Tue\u0026#34;, \u0026#34;Wed\u0026#34;, \u0026#34;Thu\u0026#34;, \u0026#34;Fri\u0026#34;, \u0026#34;Sat\u0026#34;, \u0026#34;Sun\u0026#34;}; assert(ARRAY_SIZE(nWeekdays) == ARRAY_SIZE(sWeekdays)); for (int x = 0; x \u0026lt; ARRAY_SIZE(sWeekdays); x++) { if (strcmp(sWeekdays[x], input) == 0) { return nWeekdays[x]; } } 关联漏洞:\n高风险-内存破坏\n【必须】避免函数的声明和实现不同 在头文件、源代码、文档中列举的函数声明应当一致，不应当出现定义内容错位的情况。\n错误：\nfoo.h\nint CalcArea(int width, int height); foo.cc\nint CalcArea(int height, int width) { // Different from foo.h  if (height \u0026gt; real_height) { return 0; } return height * width; } 正确： foo.h\nint CalcArea(int height, int width); foo.cc\nint CalcArea (int height, int width) { if (height \u0026gt; real_height) { return 0; } return height * width; } 关联漏洞:\n中风险-逻辑问题\n【必须】检查复制粘贴的重复代码（相同代码通常代表错误） 当开发中遇到较长的句子时，如果你选择了复制粘贴语句，请记得检查每一行代码，不要出现上下两句一模一样的情况，这通常代表代码哪里出现了错误：\n// Bad void Foobar(SomeStruct\u0026amp; foobase, SomeStruct\u0026amp; foo1, SomeStruct\u0026amp; foo2) { foo1.bar = (foo1.bar \u0026amp; 0xffff) | (foobase.base \u0026amp; 0xffff0000); foo1.bar = (foo1.bar \u0026amp; 0xffff) | (foobase.base \u0026amp; 0xffff0000); } 如上例，通常可能是：\n// Good void Foobar(SomeStruct\u0026amp; foobase, SomeStruct\u0026amp; foo1, SomeStruct\u0026amp; foo2) { foo1.bar = (foo1.bar \u0026amp; 0xffff) | (foobase.base \u0026amp; 0xffff0000); foo2.bar = (foo2.bar \u0026amp; 0xffff) | (foobase.base \u0026amp; 0xffff0000); } 最好是把重复的代码片段提取成函数，如果函数比较短，可以考虑定义为 inline 函数，在减少冗余的同时也能确保不会影响性能。\n关联漏洞:\n中风险-逻辑问题\n【必须】左右一致的重复判断/永远为真或假的判断（通常代表错误） 这通常是由于自动完成或例如Visual Assistant X之类的补全插件导致的问题。\n// Bad if (foo1.bar == foo1.bar) { … } 可能是：\n// Good if (foo1.bar == foo2.bar) { … } 关联漏洞:\n中风险-逻辑问题\n【必须】函数每个分支都应有返回值 函数的每个分支都应该有返回值，否则如果函数走到无返回值的分支，其结果是未知的。\n// Bad int Foo(int bar) { if (bar \u0026gt; 100) { return 10; } else if (bar \u0026gt; 10) { return 1; } } 上述例子当bar\u0026lt;10时，其结果是未知的值。\n// Good int Foo(int bar) { if (bar \u0026gt; 100) { return 10; } else if (bar \u0026gt; 10) { return 1; } return 0; } 开启适当级别的警告（GCC 中为 -Wreturn-type 并已包含在 -Wall 中）并设置为错误，可以在编译阶段发现这类错误。\n关联漏洞:\n中风险-逻辑问题\n中风险-信息泄漏\n【必须】不得使用栈上未初始化的变量 在栈上声明的变量要注意是否在使用它之前已经初始化了\n// Bad void Foo() { int foo; if (Bar()) { foo = 1; } Foobar(foo); // foo可能没有初始化 } 最好在声明的时候就立刻初始化变量，或者确保每个分支都初始化它。开启相应的编译器警告（GCC 中为 -Wuninitialized），并把设置为错误级别，可以在编译阶段发现这类错误。\n// Good void Foo() { int foo = 0; if (Bar()) { foo = 1; } Foobar(foo); } 关联漏洞:\n中风险-逻辑问题\n中风险-信息泄漏\n【建议】不得直接使用刚分配的未初始化的内存（如realloc） 一些刚申请的内存通常是直接从堆上分配的，可能包含有旧数据的，直接使用它们而不初始化，可能会导致安全问题。例如，CVE-2019-13751。应确保初始化变量，或者确保未初始化的值不会泄露给用户。\n// Bad char* Foo() { char* a = new char[100]; a[99] = \u0026#39;\\0\u0026#39;; memcpy(a, \u0026#34;char\u0026#34;, 4); return a; } // Good char* Foo() { char* a = new char[100]; memcpy(a, \u0026#34;char\u0026#34;, 4); a[4] = \u0026#39;\\0\u0026#39;; return a; } 在 C++ 中，再次强烈推荐用 string、vector 代替手动内存分配。\n关联漏洞:\n中风险-逻辑问题\n中风险-信息泄漏\n【必须】校验内存相关函数的返回值 与内存分配相关的函数需要检查其返回值是否正确，以防导致程序崩溃或逻辑错误。\n// Bad void Foo() { char* bar = mmap(0, 0x800000, .....); *(bar + 0x400000) = \u0026#39;\\x88\u0026#39;; // Wrong } 如上例mmap如果失败，bar的值将是0xffffffff (ffffffff)，第二行将会往0x3ffffff写入字符，导致越界写。\n// Good void Foo() { char* bar = mmap(0, 0x800000, .....); if(bar == MAP_FAILED) { return; } *(bar + 0x400000) = \u0026#39;\\x88\u0026#39;; } 关联漏洞:\n中风险-逻辑问题\n高风险-越界操作\n【必须】不要在if里面赋值 if里赋值通常代表代码存在错误。\n// Bad void Foo() { if (bar = 0x99) ... } 通常应该是：\n// Good void Foo() { if (bar == 0x99) ... } 建议在构建系统中开启足够的编译器警告（GCC 中为 -Wparentheses 并已包含在 -Wall 中），并把该警告设置为错误。\n关联漏洞:\n中风险-逻辑问题\n【建议】确认if里面的按位操作 if里，非bool类型和非bool类型的按位操作可能代表代码存在错误。\n// Bad void Foo() { int bar = 0x1; // binary 01  int foobar = 0x2; // binary 10  if (foobar \u0026amp; bar) // result = 00, false  ... } 上述代码可能应该是：\n// Good void foo() { int bar = 0x1; int foobar = 0x2; if (foobar \u0026amp;\u0026amp; bar) // result : true  ... } 关联漏洞:\n中风险-逻辑问题\n多线程 【必须】变量应确保线程安全性 当一个变量可能被多个线程使用时，应当使用原子操作或加锁操作。\n// Bad char g_somechar; void foo_thread1() { g_somechar += 3; } void foo_thread2() { g_somechar += 1; } 对于可以使用原子操作的，应当使用一些可以确保内存安全的操作，如：\n// Good volatile char g_somechar; void foo_thread1() { __sync_fetch_and_add(\u0026amp;g_somechar, 3); } void foo_thread2() { __sync_fetch_and_add(\u0026amp;g_somechar, 1); } 对于 C 代码，C11 后推荐使用 atomic 标准库。 对于 C++代码，C++11 后，推荐使用 std::atomic。\n关联漏洞:\n高风险-内存破坏\n中风险-逻辑问题\n【必须】注意signal handler导致的条件竞争 竞争条件经常出现在信号处理程序中，因为信号处理程序支持异步操作。攻击者能够利用信号处理程序争用条件导致软件状态损坏，从而可能导致拒绝服务甚至代码执行。\n 当信号处理程序中发生不可重入函数或状态敏感操作时，就会出现这些问题。因为信号处理程序中随时可以被调用。比如，当在信号处理程序中调用free时，通常会出现另一个信号争用条件，从而导致双重释放。即使给定指针在释放后设置为NULL，在释放内存和将指针设置为NULL之间仍然存在竞争的可能。 为多个信号设置了相同的信号处理程序，这尤其有问题——因为这意味着信号处理程序本身可能会重新进入。例如，malloc()和free()是不可重入的，因为它们可能使用全局或静态数据结构来管理内存，并且它们被syslog()等看似无害的函数间接使用；这些函数可能会导致内存损坏和代码执行。  // Bad char *log_message; void Handler(int signum) { syslog(LOG_NOTICE, \u0026#34;%s\\n\u0026#34;, log_m_essage); free(log_message); sleep(10); exit(0); } int main (int argc, char* argv[]) { log_message = strdup(argv[1]); signal(SIGHUP, Handler); signal(SIGTERM, Handler); sleep(10); } 可以借由下列操作规避问题：\n 避免在多个处理函数中共享某些变量。 在信号处理程序中使用同步操作。 屏蔽不相关的信号，从而提供原子性。 避免在信号处理函数中调用不满足异步信号安全的函数。  关联漏洞:\n高风险-内存破坏\n中风险-逻辑问题\n【建议】注意Time-of-check Time-of-use (TOCTOU) 条件竞争 TOCTOU： 软件在使用某个资源之前检查该资源的状态，但是该资源的状态可以在检查和使用之间更改，从而使检查结果无效。当资源处于这种意外状态时，这可能会导致软件执行错误操作。\n当攻击者可以影响检查和使用之间的资源状态时，此问题可能与安全相关。这可能发生在共享资源(如文件、内存，甚至多线程程序中的变量)上。在编程时需要注意避免出现TOCTOU问题。\n例如，下面的例子中，该文件可能已经在检查和lstat之间进行了更新，特别是因为printf有延迟。\nstruct stat *st; lstat(\u0026#34;...\u0026#34;, st); printf(\u0026#34;foo\u0026#34;); if (st-\u0026gt;st_mtimespec == ...) { printf(\u0026#34;Now updating things\\n\u0026#34;); UpdateThings(); } TOCTOU难以修复，但是有以下缓解方案：\n 限制对来自多个进程的文件的交叉操作。 如果必须在多个进程或线程之间共享对资源的访问，那么请尝试限制”检查“（CHECK）和”使用“（USE）资源之间的时间量，使他们相距尽量不要太远。这不会从根本上解决问题，但可能会使攻击更难成功。 在Use调用之后重新检查资源，以验证是否正确执行了操作。 确保一些环境锁定机制能够被用来有效保护资源。但要确保锁定是检查之前进行的，而不是在检查之后进行的，以便检查时的资源与使用时的资源相同。  关联漏洞:\n高风险-内存破坏\n中风险-逻辑问题\n加密解密 4.1 【必须】不得明文存储用户密码等敏感数据 用户密码应该使用 Argon2, scrypt, bcrypt, pbkdf2 等算法做哈希之后再存入存储系统, https://password-hashing.net/\nhttps://libsodium.gitbook.io/doc/password_hashing/default_phf#example-2-password-storage\n用户敏感数据，应该做到传输过程中加密，存储状态下加密 传输过程中加密，可以使用 HTTPS 等认证加密通信协议\n存储状态下加密，可以使用 SQLCipher 等类似方案。\n4.2 【必须】内存中的用户密码等敏感数据应该安全抹除 例如用户密码等，即使是临时使用，也应在使用完成后应当将内容彻底清空。\n错误：\n#include \u0026lt;openssl/crypto.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; { ... string user_password(100, \u0026#39;\\0\u0026#39;); snprintf(\u0026amp;user_password, \u0026#34;password: %s\u0026#34;, user_password.size(), password_from_input); ... } 正确：\n{ ... string user_password(100, \u0026#39;\\0\u0026#39;); snprintf(\u0026amp;user_password, \u0026#34;password: %s\u0026#34;, user_password.size(), password_from_input); ... OPENSSL_cleanse(\u0026amp;user_password[0], user_password.size()); } 关联漏洞:\n高风险-敏感信息泄露\n4.3 【必须】rand() 类函数应正确初始化 rand类函数的随机性并不高。而且在使用前需要使用srand()来初始化。未初始化的随机数可能导致某些内容可预测。\n// Bad int main() { int foo = rand(); return 0; } 上述代码执行完成后，foo的值是固定的。它等效于 srand(1); rand();。\n// Good  int main() { srand(time(0)); int foo = rand(); return 0; } 关联漏洞:\n高风险-逻辑漏洞\n4.4 【必须】在需要高强度安全加密时不应使用弱PRNG函数 在需要生成 AES/SM1/HMAC 等算法的密钥/IV/Nonce， RSA/ECDSA/ECDH 等算法的私钥，这类需要高安全性的业务场景，必须使用密码学安全的随机数生成器 (Cryptographically Secure PseudoRandom Number Generator (CSPRNG) ), 不得使用 rand() 等无密码学安全性保证的普通随机数生成器。\n推荐使用的 CSPRNG 有：\n  OpenSSL 中的 RAND_bytes() 函数, https://www.openssl.org/docs/man1.1.1/man3/RAND_bytes.html\n  libsodium 中的 randombytes_buf() 函数\n  Linux kernel 的 getrandom() 系统调用, https://man7.org/linux/man-pages/man2/getrandom.2.html . 或者读 /dev/urandom 文件, 或者 /dev/random 文件。\n  Apple IOS 的 SecRandomCopyBytes(), https://developer.apple.com/documentation/security/1399291-secrandomcopybytes\n  Windows 下的 BCryptGenRandom(), CryptGenRandom(), RtlGenRandom()\n  #include \u0026lt;openssl/aes.h\u0026gt;#include \u0026lt;openssl/crypto.h\u0026gt;#include \u0026lt;openssl/rand.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; { unsigned char key[16]; if (1 != RAND_bytes(\u0026amp;key[0], sizeof(key))) { //... 错误处理  return -1; } AES_KEY aes_key; if (0 != AES_set_encrypt_key(\u0026amp;key[0], sizeof(key) * 8, \u0026amp;aes_key)) { // ... 错误处理  return -1; } ... OPENSSL_cleanse(\u0026amp;key[0], sizeof(key)); } rand()类函数的随机性并不高。敏感操作时，如设计加密算法时，不得使用rand()或者类似的简单线性同余伪随机数生成器来作为随机数发生器。符合该定义的比特序列的特点是，序列中“1”的数量约等于“0”的数量；同理，“01”、“00”、“10”、“11”的数量大致相同，以此类推。\n例如 C 标准库中的 rand() 的实现只是简单的线性同余算法，生成的伪随机数具有较强的可预测性。\n当需要实现高强度加密，例如涉及通信安全时，不应当使用 rand() 作为随机数发生器。\n实际应用中，C++11 标准提供的random_device保证加密的安全性和随机性 但是 C++ 标准并不保证这一点。跨平台的代码可以考虑用 OpenSSL 等保证密码学安全的库里的随机数发生器。\n关联漏洞:\n高风险-敏感数据泄露\n4.5 【必须】自己实现的rand范围不应过小 如果在弱安全场景相关的算法中自己实现了PRNG，请确保rand出来的随机数不会很小或可预测。\n// Bad int32_t val = ((state[0] * 1103515245U) + 12345U) \u0026amp; 999999; 上述例子可能想生成0~999999共100万种可能的随机数，但是999999的二进制是11110100001000111111，与\u0026amp;运算后，0位一直是0，所以生成出的范围明显会小于100万种。\n// Good int32_t val = ((state[0] * 1103515245U) + 12345U) % 1000000; // Good int32_t val = ((state[0] * 1103515245U) + 12345U) \u0026amp; 0x7fffffff; 关联漏洞:\n高风险-逻辑漏洞\n文件操作 【必须】避免路径穿越问题 在进行文件操作时，需要判断外部传入的文件名是否合法，如果文件名中包含 ../ 等特殊字符，则会造成路径穿越，导致任意文件的读写。\n错误：\nvoid Foo() { char file_path[PATH_MAX] = \u0026#34;/home/user/code/\u0026#34;; // 如果传入的文件名包含../可导致路径穿越  // 例如\u0026#34;../file.txt\u0026#34;，则可以读取到上层目录的file.txt文件  char name[20] = \u0026#34;../file.txt\u0026#34;; memcpy(file_path + strlen(file_path), name, sizeof(name)); int fd = open(file_path, O_RDONLY); if (fd != -1) { char data[100] = {0}; int num = 0; memset(data, 0, sizeof(data)); num = read(fd, data, sizeof(data)); if (num \u0026gt; 0) { write(STDOUT_FILENO, data, num); } close(fd); } } 正确：\nvoid Foo() { char file_path[PATH_MAX] = \u0026#34;/home/user/code/\u0026#34;; char name[20] = \u0026#34;../file.txt\u0026#34;; // 判断传入的文件名是否非法，例如\u0026#34;../file.txt\u0026#34;中包含非法字符../，直接返回  if (strstr(name, \u0026#34;..\u0026#34;) != NULL){ // 包含非法字符  return; } memcpy(file_path + strlen(file_path), name, sizeof(name)); int fd = open(file_path, O_RDONLY); if (fd != -1) { char data[100] = {0}; int num = 0; memset(data, 0, sizeof(data)); num = read(fd, data, sizeof(data)); if (num \u0026gt; 0) { write(STDOUT_FILENO, data, num); } close(fd); } } 关联漏洞:\n高风险-逻辑漏洞\n【必须】避免相对路径导致的安全问题（DLL、EXE劫持等问题） 在程序中，使用相对路径可能导致一些安全风险，例如DLL、EXE劫持等问题。\n例如以下代码，可能存在劫持问题：\nint Foo() { // 传入的是dll文件名，如果当前目录下被写入了恶意的同名dll，则可能导致dll劫持  HINSTANCE hinst = ::LoadLibrary(\u0026#34;dll_nolib.dll\u0026#34;); if (hinst != NULL) { cout\u0026lt;\u0026lt;\u0026#34;dll loaded!\u0026#34; \u0026lt;\u0026lt; endl; } return 0; } 针对DLL劫持的安全编码的规范：\n1）调用LoadLibrary，LoadLibraryEx，CreateProcess，ShellExecute等进行模块加载的函数时，指明模块的完整（全）路径，禁止使用相对路径，这样就可避免从其它目录加载DLL。 2）在应用程序的开头调用SetDllDirectory(TEXT(\u0026quot;\u0026quot;)); 从而将当前目录从DLL的搜索列表中删除。结合SetDefaultDllDirectories，AddDllDirectory，RemoveDllDirectory这几个API配合使用，可以有效的规避DLL劫持问题。这些API只能在打了KB2533623补丁的Windows7，2008上使用。\n关联漏洞:\n中风险-逻辑漏洞\n【必须】文件权限控制 在创建文件时，需要根据文件的敏感级别设置不同的访问权限，以防止敏感数据被其他恶意程序读取或写入。\n错误：\nint Foo() { // 不要设置为777权限，以防止被其他恶意程序操作  if (creat(\u0026#34;file.txt\u0026#34;, 0777) \u0026lt; 0) { printf(\u0026#34;文件创建失败！\\n\u0026#34;); } else { printf(\u0026#34;文件创建成功！\\n\u0026#34;); } return 0; } 关联漏洞:\n中风险-逻辑漏洞\n内存操作 【必须】防止各种越界写（向前/向后） 错误1：\nint a[5]; a[5] = 0; 错误2：\nint a[5]; int b = user_controlled_value; a[b] = 3; 关联漏洞:\n高风险-内存破坏\n【必须】防止任意地址写 任意地址写会导致严重的安全隐患，可能导致代码执行。因此，在编码时必须校验写入的地址。\n错误：\nvoid Write(MyStruct dst_struct) { char payload[10] = { 0 }; memcpy(dst_struct.buf, payload, sizeof(payload)); } int main() { MyStruct dst_stuct; dst_stuct.buf = (char*)user_controlled_value; Write(dst_stuct); return 0; } 关联漏洞:\n高风险-内存破坏\n数字操作 【必须】防止整数溢出 在计算时需要考虑整数溢出的可能，尤其在进行内存操作时，需要对分配、拷贝等大小进行合法校验，防止整数溢出导致的漏洞。\n错误（该例子在计算时产生整数溢出）\nconst int kMicLen = 4; // 整数溢出 void Foo() { int len = 1; char payload[10] = { 0 }; char dst[10] = { 0 }; // Bad, 由于len小于4字节，导致计算拷贝长度时，整数溢出  // len - MIC_LEN == 0xfffffffd  memcpy(dst, payload, len - kMicLen); } 正确例子\nvoid Foo() { int len = 1; char payload[10] = { 0 }; char dst[10] = { 0 }; int size = len - kMicLen; // 拷贝前对长度进行判断  if (size \u0026gt; 0 \u0026amp;\u0026amp; size \u0026lt; 10) { memcpy(dst, payload, size); printf(\u0026#34;memcpy good\\n\u0026#34;); } } 关联漏洞:\n高风险-内存破坏\n【必须】防止Off-By-One 在进行计算或者操作时，如果使用的最大值或最小值不正确，使得该值比正确值多1或少1，可能导致安全风险。\n错误：\nchar firstname[20]; char lastname[20]; char fullname[40]; fullname[0] = \u0026#39;\\0\u0026#39;; strncat(fullname, firstname, 20); // 第二次调用strncat()可能会追加另外20个字符。如果这20个字符没有终止空字符，则存在安全问题 strncat(fullname, lastname, 20); 正确：\nchar firstname[20]; char lastname[20]; char fullname[40]; fullname[0] = \u0026#39;\\0\u0026#39;; // 当使用像strncat()函数时，必须在缓冲区的末尾为终止空字符留下一个空字节，避免off-by-one strncat(fullname, firstname, sizeof(fullname) - strlen(fullname) - 1); strncat(fullname, lastname, sizeof(fullname) - strlen(fullname) - 1); 对于 C++ 代码，再次强烈建议使用 string、vector 等组件代替原始指针和数组操作。\n关联漏洞:\n高风险-内存破坏\n【必须】避免大小端错误 在一些涉及大小端数据处理的场景，需要进行大小端判断，例如从大端设备取出的值，要以大端进行处理，避免端序错误使用。\n关联漏洞:\n中风险-逻辑漏洞\n【必须】检查除以零异常 在进行除法运算时，需要判断被除数是否为零，以防导致程序不符合预期或者崩溃。\n错误：\ndouble divide(double x, double y) { return x / y; } int divide(int x, int y) { return x / y; } 正确：\ndouble divide(double x, double y) { if (y == 0) { throw DivideByZero; } return x / y; } 关联漏洞:\n低风险-拒绝服务\n【必须】防止数字类型的错误强转 在有符号和无符号数字参与的运算中，需要注意类型强转可能导致的逻辑错误，建议指定参与计算时数字的类型或者统一类型参与计算。\n错误例子\nint Foo() { int len = 1; unsigned int size = 9; // 1 \u0026lt; 9 - 10 ? 由于运算中无符号和有符号混用，导致计算结果以无符号计算  if (len \u0026lt; size - 10) { printf(\u0026#34;Bad\\n\u0026#34;); } else { printf(\u0026#34;Good\\n\u0026#34;); } } 正确例子\nvoid Foo() { // 统一两者计算类型为有符号  int len = 1; int size = 9; if (len \u0026lt; size - 10) { printf(\u0026#34;Bad\\n\u0026#34;); } else { printf(\u0026#34;Good\\n\u0026#34;); } } 关联漏洞:\n高风险-内存破坏\n中风险-逻辑漏洞\n【必须】比较数据大小时加上最小/最大值的校验 在进行数据大小比较时，要合理地校验数据的区间范围，建议根据数字类型，对其进行最大和最小值的判断，以防止非预期错误。\n错误：\nvoid Foo(int index) { int a[30] = {0}; // 此处index是int型，只考虑了index小于数组大小，但是并未判断是否大于0  if (index \u0026lt; 30) { // 如果index为负数，则越界  a[index] = 1; } } 正确：\nvoid Foo(int index) { int a[30] = {0}; // 判断index的最大最小值  if (index \u0026gt;=0 \u0026amp;\u0026amp; index \u0026lt; 30) { a[index] = 1; } } 关联漏洞:\n高风险-内存破坏\n指针操作 【建议】检查在pointer上使用sizeof 除了测试当前指针长度，否则一般不会在pointer上使用sizeof。\n正确：\nsize_t pointer_length = sizeof(void*); 可能错误：\nsize_t structure_length = sizeof(Foo*); 可能是：\nsize_t structure_length = sizeof(Foo); 关联漏洞:\n中风险-逻辑漏洞\n【必须】检查直接将数组和0比较的代码 错误：\nint a[3]; ...; if (a \u0026gt; 0) ...; 该判断永远为真，等价于:\nint a[3]; ...; if (\u0026amp;a[0]) ...; 可能是：\nint a[3]; ...; if(a[0] \u0026gt; 0) ...; 开启足够的编译器警告（GCC 中为 -Waddress，并已包含在 -Wall 中），并设置为错误，可以在编译期间发现该问题。\n关联漏洞:\n中风险-逻辑漏洞\n【必须】不应当向指针赋予写死的地址 特殊情况需要特殊对待（比如开发硬件固件时可能需要写死）\n但是如果是系统驱动开发之类的，写死可能会导致后续的问题。\n关联漏洞:\n高风险-内存破坏\n【必须】检查空指针 错误：\n*foo = 100; if (!foo) { ERROR(\u0026#34;foobar\u0026#34;); } 正确：\nif (!foo) { ERROR(\u0026#34;foobar\u0026#34;); } *foo = 100; 错误：\nvoid Foo(char* bar) { *bar = \u0026#39;\\0\u0026#39;; } 正确：\nvoid Foo(char* bar) { if(bar) *bar = \u0026#39;\\0\u0026#39;; else ...; } 关联漏洞:\n低风险-拒绝服务\n【必须】释放完后置空指针 在对指针进行释放后，需要将该指针设置为NULL，以防止后续free指针的误用，导致UAF等其他内存破坏问题。尤其是在结构体、类里面存储的原始指针。\n错误：\nvoid foo() { char* p = (char*)malloc(100); memcpy(p, \u0026#34;hello\u0026#34;, 6); // 此时p所指向的内存已被释放，但是p所指的地址仍然不变  printf(\u0026#34;%s\\n\u0026#34;, p); free(p); // 未设置为NULL，可能导致UAF等内存错误  if (p != NULL) { // 没有起到防错作用  printf(\u0026#34;%s\\n\u0026#34;, p); // 错误使用已经释放的内存  } } 正确：\nvoid foo() { char* p = (char*)malloc(100); memcpy(p, \u0026#34;hello\u0026#34;, 6); // 此时p所指向的内存已被释放，但是p所指的地址仍然不变  printf(\u0026#34;%s\\n\u0026#34;, p); free(p); //释放后将指针赋值为空  p = NULL; if (p != NULL) { // 没有起到防错作用  printf(\u0026#34;%s\\n\u0026#34;, p); // 错误使用已经释放的内存  } } 对于 C++ 代码，使用 string、vector、智能指针等代替原始内存管理机制，可以大量减少这类错误。\n关联漏洞:\n高风险-内存破坏\n【必须】防止错误的类型转换（type confusion） 在对指针、对象或变量进行操作时，需要能够正确判断所操作对象的原始类型。如果使用了与原始类型不兼容的类型进行访问，则存在安全隐患。\n错误：\nconst int NAME_TYPE = 1; const int ID_TYPE = 2; // 该类型根据 msg_type 进行区分，如果在对MessageBuffer进行操作时没有判断目标对象，则存在类型混淆 struct MessageBuffer { int msg_type; union { const char *name; int name_id; }; }; void Foo() { struct MessageBuffer buf; const char* default_message = \u0026#34;Hello World\u0026#34;; // 设置该消息类型为 NAME_TYPE，因此buf预期的类型为 msg_type + name  buf.msg_type = NAME_TYPE; buf.name = default_message; printf(\u0026#34;Pointer of buf.name is %p\\n\u0026#34;, buf.name); // 没有判断目标消息类型是否为ID_TYPE，直接修改nameID，导致类型混淆  buf.name_id = user_controlled_value; if (buf.msg_type == NAME_TYPE) { printf(\u0026#34;Pointer of buf.name is now %p\\n\u0026#34;, buf.name); // 以NAME_TYPE作为类型操作，可能导致非法内存读写  printf(\u0026#34;Message: %s\\n\u0026#34;, buf.name); } else { printf(\u0026#34;Message: Use ID %d\\n\u0026#34;, buf.name_id); } } 正确（判断操作的目标是否是预期类型）：\nvoid Foo() { struct MessageBuffer buf; const char* default_message = \u0026#34;Hello World\u0026#34;; // 设置该消息类型为 NAME_TYPE，因此buf预期的类型为 msg_type + name  buf.msg_type = NAME_TYPE; buf.name = default_msessage; printf(\u0026#34;Pointer of buf.name is %p\\n\u0026#34;, buf.name); // 判断目标消息类型是否为 ID_TYPE，不是预期类型则做对应操作  if (buf.msg_type == ID_TYPE) buf.name_id = user_controlled_value; if (buf.msg_type == NAME_TYPE) { printf(\u0026#34;Pointer of buf.name is now %p\\n\u0026#34;, buf.name); printf(\u0026#34;Message: %s\\n\u0026#34;, buf.name); } else { printf(\u0026#34;Message: Use ID %d\\n\u0026#34;, buf.name_id); } } 关联漏洞:\n高风险-内存破坏\n【必须】智能指针使用安全 在使用智能指针时，防止其和原始指针的混用，否则可能导致对象生命周期问题，例如 UAF 等安全风险。\n错误例子：\nclass Foo { public: explicit Foo(int num) { data_ = num; }; void Function() { printf(\u0026#34;Obj is %p, data = %d\\n\u0026#34;, this, data_); }; private: int data_; }; std::unique_ptr\u0026lt;Foo\u0026gt; fool_u_ptr = nullptr; Foo* pfool_raw_ptr = nullptr; void Risk() { fool_u_ptr = make_unique\u0026lt;Foo\u0026gt;(1); // 从独占智能指针中获取原始指针,\u0026lt;Foo\u0026gt;(1)  pfool_raw_ptr = fool_u_ptr.get(); // 调用\u0026lt;Foo\u0026gt;(1)的函数  pfool_raw_ptr-\u0026gt;Function(); // 独占智能指针重新赋值后会释放内存  fool_u_ptr = make_unique\u0026lt;Foo\u0026gt;(2); // 通过原始指针操作会导致UAF，pfool_raw_ptr指向的对象已经释放  pfool_raw_ptr-\u0026gt;Function(); } // 输出： // Obj is 0000027943087B80, data = 1 // Obj is 0000027943087B80, data = -572662307 正确，通过智能指针操作:\nvoid Safe() { fool_u_ptr = make_unique\u0026lt;Foo\u0026gt;(1); // 调用\u0026lt;Foo\u0026gt;(1)的函数  fool_u_ptr-\u0026gt;function(); fool_u_ptr = make_unique\u0026lt;Foo\u0026gt;(2); // 调用\u0026lt;Foo\u0026gt;(2)的函数  fool_u_ptr-\u0026gt;function(); } // 输出： // Obj is 000002C7BB550830, data = 1 // Obj is 000002C7BB557AF0, data = 2 关联漏洞:\n高风险-内存破坏\n","date":"2021-10-28T22:00:08+08:00","image":"https://zcj-git520.github.io/p/c/c-%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/1_hub729bb727716490d1309dfd2d43fb84b_10267_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/c/c-%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/","title":"c/c++安全指南"},{"content":"文章来源 鹅厂(腾讯)代码安全指南\n通用 内存管理 【必须】切片长度校验  在对slice进行操作时，必须判断长度是否合法，防止程序panic  // bad: 未判断data的长度，可导致 index out of range func decode(data []byte) bool { if data[0] == 'F' \u0026amp;\u0026amp; data[1] == 'U' \u0026amp;\u0026amp; data[2] == 'Z' \u0026amp;\u0026amp; data[3] == 'Z' \u0026amp;\u0026amp; data[4] == 'E' \u0026amp;\u0026amp; data[5] == 'R' { fmt.Println(\u0026quot;Bad\u0026quot;) return true } return false } // bad: slice bounds out of range func foo() { var slice = []int{0, 1, 2, 3, 4, 5, 6} fmt.Println(slice[:10]) } // good: 使用data前应判断长度是否合法 func decode(data []byte) bool { if len(data) == 6 { if data[0] == 'F' \u0026amp;\u0026amp; data[1] == 'U' \u0026amp;\u0026amp; data[2] == 'Z' \u0026amp;\u0026amp; data[3] == 'Z' \u0026amp;\u0026amp; data[4] == 'E' \u0026amp;\u0026amp; data[5] == 'R' { fmt.Println(\u0026quot;Good\u0026quot;) return true } } return false } 【必须】nil指针判断  进行指针操作时，必须判断该指针是否为nil，防止程序panic，尤其在进行结构体Unmarshal时  type Packet struct { PackeyType uint8 PackeyVersion uint8 Data *Data } type Data struct { Stat uint8 Len uint8 Buf [8]byte } func (p *Packet) UnmarshalBinary(b []byte) error { if len(b) \u0026lt; 2 { return io.EOF } p.PackeyType = b[0] p.PackeyVersion = b[1] // 若长度等于2，那么不会new Data if len(b) \u0026gt; 2 { p.Data = new(Data) } return nil } // bad: 未判断指针是否为nil func main() { packet := new(Packet) data := make([]byte, 2) if err := packet.UnmarshalBinary(data); err != nil { fmt.Println(\u0026quot;Failed to unmarshal packet\u0026quot;) return } fmt.Printf(\u0026quot;Stat: %v\\n\u0026quot;, packet.Data.Stat) } // good: 判断Data指针是否为nil func main() { packet := new(Packet) data := make([]byte, 2) if err := packet.UnmarshalBinary(data); err != nil { fmt.Println(\u0026quot;Failed to unmarshal packet\u0026quot;) return } if packet.Data == nil { return } fmt.Printf(\u0026quot;Stat: %v\\n\u0026quot;, packet.Data.Stat) } 【必须】整数安全   在进行数字运算操作时，需要做好长度限制，防止外部输入运算导致异常：\n 确保无符号整数运算时不会反转 确保有符号整数运算时不会出现溢出 确保整型转换时不会出现截断错误 确保整型转换时不会出现符号错误    以下场景必须严格进行长度限制：\n 作为数组索引 作为对象的长度或者大小 作为数组的边界（如作为循环计数器）    // bad: 未限制长度，导致整数溢出 func overflow(numControlByUser int32) { var numInt int32 = 0 numInt = numControlByUser + 1 // 对长度限制不当，导致整数溢出 fmt.Printf(\u0026quot;%d\\n\u0026quot;, numInt) // 使用numInt，可能导致其他错误 } func main() { overflow(2147483647) } // good func overflow(numControlByUser int32) { var numInt int32 = 0 numInt = numControlByUser + 1 if numInt \u0026lt; 0 { fmt.Println(\u0026quot;integer overflow\u0026quot;) return } fmt.Println(\u0026quot;integer ok\u0026quot;) } func main() { overflow(2147483647) } 【必须】make分配长度验证  在进行make分配内存时，需要对外部可控的长度进行校验，防止程序panic。  // bad func parse(lenControlByUser int, data []byte) { size := lenControlByUser // 对外部传入的size，进行长度判断以免导致panic buffer := make([]byte, size) copy(buffer, data) } // good func parse(lenControlByUser int, data []byte) ([]byte, error) { size := lenControlByUser // 限制外部可控的长度大小范围 if size \u0026gt; 64*1024*1024 { return nil, errors.New(\u0026quot;value too large\u0026quot;) } buffer := make([]byte, size) copy(buffer, data) return buffer, nil } 【必须】禁止SetFinalizer和指针循环引用同时使用  当一个对象从被GC选中到移除内存之前，runtime.SetFinalizer()都不会执行，即使程序正常结束或者发生错误。由指针构成的“循环引用”虽然能被GC正确处理，但由于无法确定Finalizer依赖顺序，从而无法调用runtime.SetFinalizer()，导致目标对象无法变成可达状态，从而造成内存无法被回收。  // bad func foo() { var a, b Data a.o = \u0026amp;b b.o = \u0026amp;a // 指针循环引用，SetFinalizer()无法正常调用 runtime.SetFinalizer(\u0026amp;a, func(d *Data) { fmt.Printf(\u0026quot;a %p final.\\n\u0026quot;, d) }) runtime.SetFinalizer(\u0026amp;b, func(d *Data) { fmt.Printf(\u0026quot;b %p final.\\n\u0026quot;, d) }) } func main() { for { foo() time.Sleep(time.Millisecond) } } 【必须】禁止重复释放channel  重复释放一般存在于异常流程判断中，如果恶意攻击者构造出异常条件使程序重复释放channel，则会触发运行时panic，从而造成DoS攻击。  // bad func foo(c chan int) { defer close(c) err := processBusiness() if err != nil { c \u0026lt;- 0 close(c) // 重复释放channel return } c \u0026lt;- 1 } // good func foo(c chan int) { defer close(c) // 使用defer延迟关闭channel err := processBusiness() if err != nil { c \u0026lt;- 0 return } c \u0026lt;- 1 } 【必须】确保每个协程都能退出  启动一个协程就会做一个入栈操作，在系统不退出的情况下，协程也没有设置退出条件，则相当于协程失去了控制，它占用的资源无法回收，可能会导致内存泄露。  // bad: 协程没有设置退出条件 func doWaiter(name string, second int) { for { time.Sleep(time.Duration(second) * time.Second) fmt.Println(name, \u0026quot; is ready!\u0026quot;) } } 【推荐】不使用unsafe包  由于unsafe包绕过了 Golang 的内存安全原则，一般来说使用该库是不安全的，可导致内存破坏，尽量避免使用该包。若必须要使用unsafe操作指针，必须做好安全校验。  // bad: 通过unsafe操作原始指针 func unsafePointer() { b := make([]byte, 1) foo := (*int)(unsafe.Pointer(uintptr(unsafe.Pointer(\u0026amp;b[0])) + uintptr(0xfffffffe))) fmt.Print(*foo + 1) } // [signal SIGSEGV: segmentation violation code=0x1 addr=0xc100068f55 pc=0x49142b] 【推荐】不使用slice作为函数入参  slice是引用类型，在作为函数入参时采用的是地址传递，对slice的修改也会影响原始数据  // bad: slice作为函数入参时是地址传递 func modify(array []int) { array[0] = 10 // 对入参slice的元素修改会影响原始数据 } func main() { array := []int{1, 2, 3, 4, 5} modify(array) fmt.Println(array) // output：[10 2 3 4 5] } // good: 函数使用数组作为入参，而不是slice func modify(array [5]int) { array[0] = 10 } func main() { // 传入数组，注意数组与slice的区别 array := [5]int{1, 2, 3, 4, 5} modify(array) fmt.Println(array) } 文件操作 【必须】 路径穿越检查  在进行文件操作时，如果对外部传入的文件名未做限制，可能导致任意文件读取或者任意文件写入，严重可能导致代码执行。  // bad: 任意文件读取 func handler(w http.ResponseWriter, r *http.Request) { path := r.URL.Query()[\u0026quot;path\u0026quot;][0] // 未过滤文件路径，可能导致任意文件读取 data, _ := ioutil.ReadFile(path) w.Write(data) // 对外部传入的文件名变量，还需要验证是否存在../等路径穿越的文件名 data, _ = ioutil.ReadFile(filepath.Join(\u0026quot;/home/user/\u0026quot;, path)) w.Write(data) } // bad: 任意文件写入 func unzip(f string) { r, _ := zip.OpenReader(f) for _, f := range r.File { p, _ := filepath.Abs(f.Name) // 未验证压缩文件名，可能导致../等路径穿越，任意文件路径写入 ioutil.WriteFile(p, []byte(\u0026quot;present\u0026quot;), 0640) } } // good: 检查压缩的文件名是否包含..路径穿越特征字符，防止任意写入 func unzipGood(f string) bool { r, err := zip.OpenReader(f) if err != nil { fmt.Println(\u0026quot;read zip file fail\u0026quot;) return false } for _, f := range r.File { if !strings.Contains(f.Name, \u0026quot;..\u0026quot;) { p, _ := filepath.Abs(f.Name) ioutil.WriteFile(p, []byte(\u0026quot;present\u0026quot;), 0640) } else { return false } } return true } 【必须】 文件访问权限  根据创建文件的敏感性设置不同级别的访问权限，以防止敏感数据被任意权限用户读取。例如，设置文件权限为：-rw-r-----  ioutil.WriteFile(p, []byte(\u0026quot;present\u0026quot;), 0640) 系统接口 1.3.1【必须】命令执行检查\n 使用exec.Command、exec.CommandContext、syscall.StartProcess、os.StartProcess等函数时，第一个参数（path）直接取外部输入值时，应使用白名单限定可执行的命令范围，不允许传入bash、cmd、sh等命令； 使用exec.Command、exec.CommandContext等函数时，通过bash、cmd、sh等创建shell，-c后的参数（arg）拼接外部输入，应过滤\\n $ \u0026amp; ; | ' \u0026quot; ( ) `等潜在恶意字符；  // bad func foo() { userInputedVal := \u0026quot;\u0026amp;\u0026amp; echo 'hello'\u0026quot; // 假设外部传入该变量值 cmdName := \u0026quot;ping \u0026quot; + userInputedVal // 未判断外部输入是否存在命令注入字符，结合sh可造成命令注入 cmd := exec.Command(\u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, cmdName) output, _ := cmd.CombinedOutput() fmt.Println(string(output)) cmdName := \u0026quot;ls\u0026quot; // 未判断外部输入是否是预期命令 cmd := exec.Command(cmdName) output, _ := cmd.CombinedOutput() fmt.Println(string(output)) } // good func checkIllegal(cmdName string) bool { if strings.Contains(cmdName, \u0026quot;\u0026amp;\u0026quot;) || strings.Contains(cmdName, \u0026quot;|\u0026quot;) || strings.Contains(cmdName, \u0026quot;;\u0026quot;) || strings.Contains(cmdName, \u0026quot;$\u0026quot;) || strings.Contains(cmdName, \u0026quot;'\u0026quot;) || strings.Contains(cmdName, \u0026quot;`\u0026quot;) || strings.Contains(cmdName, \u0026quot;(\u0026quot;) || strings.Contains(cmdName, \u0026quot;)\u0026quot;) || strings.Contains(cmdName, \u0026quot;\\\u0026quot;\u0026quot;) { return true } return false } func main() { userInputedVal := \u0026quot;\u0026amp;\u0026amp; echo 'hello'\u0026quot; cmdName := \u0026quot;ping \u0026quot; + userInputedVal if checkIllegal(cmdName) { // 检查传给sh的命令是否有特殊字符 return // 存在特殊字符直接return } cmd := exec.Command(\u0026quot;sh\u0026quot;, \u0026quot;-c\u0026quot;, cmdName) output, _ := cmd.CombinedOutput() fmt.Println(string(output)) } 通信安全 【必须】网络通信采用TLS方式  明文传输的通信协议目前已被验证存在较大安全风险，被中间人劫持后可能导致许多安全风险，因此必须采用至少TLS的安全通信方式保证通信安全，例如gRPC/Websocket都使用TLS1.3。  // good func main() { http.HandleFunc(\u0026quot;/\u0026quot;, func(w http.ResponseWriter, req *http.Request) { w.Header().Add(\u0026quot;Strict-Transport-Security\u0026quot;, \u0026quot;max-age=63072000; includeSubDomains\u0026quot;) w.Write([]byte(\u0026quot;This is an example server.\\n\u0026quot;)) }) // 服务器配置证书与私钥 log.Fatal(http.ListenAndServeTLS(\u0026quot;:443\u0026quot;, \u0026quot;yourCert.pem\u0026quot;, \u0026quot;yourKey.pem\u0026quot;, nil)) } 【推荐】TLS启用证书验证  TLS证书应当是有效的、未过期的，且配置正确的域名，生产环境的服务端应启用证书验证。  // bad import ( \u0026quot;crypto/tls\u0026quot; \u0026quot;net/http\u0026quot; ) func doAuthReq(authReq *http.Request) *http.Response { tr := \u0026amp;http.Transport{ TLSClientConfig: \u0026amp;tls.Config{InsecureSkipVerify: true}, } client := \u0026amp;http.Client{Transport: tr} res, _ := client.Do(authReq) return res } // good import ( \u0026quot;crypto/tls\u0026quot; \u0026quot;net/http\u0026quot; ) func doAuthReq(authReq *http.Request) *http.Response { tr := \u0026amp;http.Transport{ TLSClientConfig: \u0026amp;tls.Config{InsecureSkipVerify: false}, } client := \u0026amp;http.Client{Transport: tr} res, _ := client.Do(authReq) return res } 敏感数据保护 【必须】敏感信息访问  禁止将敏感信息硬编码在程序中，既可能会将敏感信息暴露给攻击者，也会增加代码管理和维护的难度 使用配置中心系统统一托管密钥等敏感信息  【必须】敏感数据输出  只输出必要的最小数据集，避免多余字段暴露引起敏感信息泄露 不能在日志保存密码（包括明文密码和密文密码）、密钥和其它敏感信息 对于必须输出的敏感信息，必须进行合理脱敏展示  // bad func serve() { http.HandleFunc(\u0026quot;/register\u0026quot;, func(w http.ResponseWriter, r *http.Request) { r.ParseForm() user := r.Form.Get(\u0026quot;user\u0026quot;) pw := r.Form.Get(\u0026quot;password\u0026quot;) log.Printf(\u0026quot;Registering new user %s with password %s.\\n\u0026quot;, user, pw) }) http.ListenAndServe(\u0026quot;:80\u0026quot;, nil) } // good func serve1() { http.HandleFunc(\u0026quot;/register\u0026quot;, func(w http.ResponseWriter, r *http.Request) { r.ParseForm() user := r.Form.Get(\u0026quot;user\u0026quot;) pw := r.Form.Get(\u0026quot;password\u0026quot;) log.Printf(\u0026quot;Registering new user %s.\\n\u0026quot;, user) // ... use(pw) }) http.ListenAndServe(\u0026quot;:80\u0026quot;, nil) }  避免通过GET方法、代码注释、自动填充、缓存等方式泄露敏感信息  【必须】敏感数据存储  敏感数据应使用SHA2、RSA等算法进行加密存储 敏感数据应使用独立的存储层，并在访问层开启访问控制 包含敏感信息的临时文件或缓存一旦不再需要应立刻删除  【必须】异常处理和日志记录  应合理使用panic、recover、defer处理系统异常，避免出错信息输出到前端  defer func () { if r := recover(); r != nil { fmt.Println(\u0026quot;Recovered in start()\u0026quot;) } }()  对外环境禁止开启debug模式，或将程序运行日志输出到前端  // bad dlv --listen=:2345 --headless=true --api-version=2 debug test.go // good dlv debug test.go 加密解密 【必须】不得硬编码密码/密钥  在进行用户登陆，加解密算法等操作时，不得在代码里硬编码密钥或密码，可通过变换算法或者配置等方式设置密码或者密钥。  // bad const ( user = \u0026quot;dbuser\u0026quot; password = \u0026quot;s3cretp4ssword\u0026quot; ) func connect() *sql.DB { connStr := fmt.Sprintf(\u0026quot;postgres://%s:%s@localhost/pqgotest\u0026quot;, user, password) db, err := sql.Open(\u0026quot;postgres\u0026quot;, connStr) if err != nil { return nil } return db } // bad var ( commonkey = []byte(\u0026quot;0123456789abcdef\u0026quot;) ) func AesEncrypt(plaintext string) (string, error) { block, err := aes.NewCipher(commonkey) if err != nil { return \u0026quot;\u0026quot;, err } } 1.6.2【必须】密钥存储安全  在使用对称密码算法时，需要保护好加密密钥。当算法涉及敏感、业务数据时，可通过非对称算法协商加密密钥。其他较为不敏感的数据加密，可以通过变换算法等方式保护密钥。  1.6.3【推荐】不使用弱密码算法  在使用加密算法时，不建议使用加密强度较弱的算法。  // bad crypto/des，crypto/md5，crypto/sha1，crypto/rc4等。 // good crypto/rsa，crypto/aes等。 正则表达式 【推荐】使用regexp进行正则表达式匹配  正则表达式编写不恰当可被用于DoS攻击，造成服务不可用，推荐使用regexp包进行正则表达式匹配。regexp保证了线性时间性能和优雅的失败：对解析器、编译器和执行引擎都进行了内存限制。但regexp不支持以下正则表达式特性，如业务依赖这些特性，则regexp不适合使用。  回溯引用Backreferences 查看Lookaround    // good matched, err := regexp.MatchString(`a.b`, \u0026quot;aaxbb\u0026quot;) fmt.Println(matched) // true fmt.Println(err) // nil 后台 输入校验 【必须】按类型进行数据校验  所有外部输入的参数，应使用validator进行白名单校验，校验内容包括但不限于数据长度、数据范围、数据类型与格式，校验不通过的应当拒绝  // good import ( \u0026quot;fmt\u0026quot; \u0026quot;github.com/go-playground/validator/v10\u0026quot; ) var validate *validator.Validate func validateVariable() { myEmail := \u0026quot;abc@tencent.com\u0026quot; errs := validate.Var(myEmail, \u0026quot;required,email\u0026quot;) if errs != nil { fmt.Println(errs) return //停止执行 } // 验证通过，继续执行 ... } func main() { validate = validator.New() validateVariable() }  无法通过白名单校验的应使用html.EscapeString、text/template或bluemonday对\u0026lt;, \u0026gt;, \u0026amp;, ',\u0026quot;等字符进行过滤或编码  import ( \u0026quot;text/template\u0026quot; ) // TestHTMLEscapeString HTML特殊字符转义 func main(inputValue string) string { escapedResult := template.HTMLEscapeString(inputValue) return escapedResult } SQL操作 【必须】SQL语句默认使用预编译并绑定变量  使用database/sql的prepare、Query或使用GORM等ORM执行SQL操作  import ( \u0026quot;github.com/jinzhu/gorm\u0026quot; _ \u0026quot;github.com/jinzhu/gorm/dialects/sqlite\u0026quot; ) type Product struct { gorm.Model Code string Price uint } ... var product Product ... db.First(\u0026amp;product, 1)  使用参数化查询，禁止拼接SQL语句，另外对于传入参数用于order by或表名的需要通过校验  // bad import ( \u0026quot;database/sql\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;net/http\u0026quot; ) func handler(db *sql.DB, req *http.Request) { q := fmt.Sprintf(\u0026quot;SELECT ITEM,PRICE FROM PRODUCT WHERE ITEM_CATEGORY='%s' ORDER BY PRICE\u0026quot;, req.URL.Query()[\u0026quot;category\u0026quot;]) db.Query(q) } // good func handlerGood(db *sql.DB, req *http.Request) { // 使用?占位符 q := \u0026quot;SELECT ITEM,PRICE FROM PRODUCT WHERE ITEM_CATEGORY='?' ORDER BY PRICE\u0026quot; db.Query(q, req.URL.Query()[\u0026quot;category\u0026quot;]) } 网络请求 【必须】资源请求过滤验证   使用\u0026quot;net/http\u0026quot;下的方法http.Get(url)、http.Post(url, contentType, body)、http.Head(url)、http.PostForm(url, data)、http.Do(req)时，如变量值外部可控（指从参数中动态获取），应对请求目标进行严格的安全校验。\n  如请求资源域名归属固定的范围，如只允许a.qq.com和b.qq.com，应做白名单限制。如不适用白名单，则推荐的校验逻辑步骤是：\n  第 1 步、只允许HTTP或HTTPS协议\n  第 2 步、解析目标URL，获取其HOST\n  第 3 步、解析HOST，获取HOST指向的IP地址转换成Long型\n  第 4 步、检查IP地址是否为内网IP，网段有：\n// 以RFC定义的专有网络为例，如有自定义私有网段亦应加入禁止访问列表。 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16 127.0.0.0/8   第 5 步、请求URL\n  第 6 步、如有跳转，跳转后执行1，否则绑定经校验的ip和域名，对URL发起请求\n    官方库encoding/xml不支持外部实体引用，使用该库可避免xxe漏洞\n  import ( \u0026quot;encoding/xml\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; ) func main() { type Person struct { XMLName xml.Name `xml:\u0026quot;person\u0026quot;` Id int `xml:\u0026quot;id,attr\u0026quot;` UserName string `xml:\u0026quot;name\u0026gt;first\u0026quot;` Comment string `xml:\u0026quot;,comment\u0026quot;` } v := \u0026amp;Person{Id: 13, UserName: \u0026quot;John\u0026quot;} v.Comment = \u0026quot; Need more details. \u0026quot; enc := xml.NewEncoder(os.Stdout) enc.Indent(\u0026quot; \u0026quot;, \u0026quot; \u0026quot;) if err := enc.Encode(v); err != nil { fmt.Printf(\u0026quot;error: %v\\n\u0026quot;, err) } } 服务器端渲染 【必须】模板渲染过滤验证  使用text/template或者html/template渲染模板时禁止将外部输入参数引入模板，或仅允许引入白名单内字符。  // bad func handler(w http.ResponseWriter, r *http.Request) { r.ParseForm() x := r.Form.Get(\u0026quot;name\u0026quot;) var tmpl = `\u0026lt;!DOCTYPE html\u0026gt;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt; \u0026lt;form action=\u0026quot;/\u0026quot; method=\u0026quot;post\u0026quot;\u0026gt; First name:\u0026lt;br\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;name\u0026quot; value=\u0026quot;\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;submit\u0026quot; value=\u0026quot;Submit\u0026quot;\u0026gt; \u0026lt;/form\u0026gt;\u0026lt;p\u0026gt;` + x + ` \u0026lt;/p\u0026gt;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;` t := template.New(\u0026quot;main\u0026quot;) t, _ = t.Parse(tmpl) t.Execute(w, \u0026quot;Hello\u0026quot;) } // good import ( \u0026quot;fmt\u0026quot; \u0026quot;github.com/go-playground/validator/v10\u0026quot; ) var validate *validator.Validate validate = validator.New() func validateVariable(val) { errs := validate.Var(val, \u0026quot;gte=1,lte=100\u0026quot;) // 限制必须是1-100的正整数 if errs != nil { fmt.Println(errs) return false } return true } func handler(w http.ResponseWriter, r *http.Request) { r.ParseForm() x := r.Form.Get(\u0026quot;name\u0026quot;) if validateVariable(x) { var tmpl = `\u0026lt;!DOCTYPE html\u0026gt;\u0026lt;html\u0026gt;\u0026lt;body\u0026gt; \u0026lt;form action=\u0026quot;/\u0026quot; method=\u0026quot;post\u0026quot;\u0026gt; First name:\u0026lt;br\u0026gt; \u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;name\u0026quot; value=\u0026quot;\u0026quot;\u0026gt; \u0026lt;input type=\u0026quot;submit\u0026quot; value=\u0026quot;Submit\u0026quot;\u0026gt; \u0026lt;/form\u0026gt;\u0026lt;p\u0026gt;` + x + ` \u0026lt;/p\u0026gt;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;` t := template.New(\u0026quot;main\u0026quot;) t, _ = t.Parse(tmpl) t.Execute(w, \u0026quot;Hello\u0026quot;) } else { // ... } } Web跨域 【必须】跨域资源共享CORS限制请求来源  CORS请求保护不当可导致敏感信息泄漏，因此应当严格设置Access-Control-Allow-Origin使用同源策略进行保护。  // good c := cors.New(cors.Options{ AllowedOrigins: []string{\u0026quot;http://qq.com\u0026quot;, \u0026quot;https://qq.com\u0026quot;}, AllowCredentials: true, Debug: false, }) // 引入中间件 handler = c.Handler(handler) 响应输出 【必须】设置正确的HTTP响应包类型  响应头Content-Type与实际响应内容，应保持一致。如：API响应数据类型是json，则响应头使用application/json；若为xml，则设置为text/xml。  【必须】添加安全响应头  所有接口、页面，添加响应头 X-Content-Type-Options: nosniff。 所有接口、页面，添加响应头X-Frame-Options 。按需合理设置其允许范围，包括：DENY、SAMEORIGIN、ALLOW-FROM origin。用法参考：MDN文档  【必须】外部输入拼接到HTTP响应头中需进行过滤  应尽量避免外部可控参数拼接到HTTP响应头中，如业务需要则需要过滤掉\\r、\\n等换行符，或者拒绝携带换行符号的外部输入。  【必须】外部输入拼接到response页面前进行编码处理  直出html页面或使用模板生成html页面的，推荐使用text/template自动编码，或者使用html.EscapeString或text/template对\u0026lt;, \u0026gt;, \u0026amp;, ',\u0026quot;等字符进行编码。  import ( \u0026quot;html/template\u0026quot; ) func outtemplate(w http.ResponseWriter, r *http.Request) { param1 := r.URL.Query().Get(\u0026quot;param1\u0026quot;) tmpl := template.New(\u0026quot;hello\u0026quot;) tmpl, _ = tmpl.Parse(`{{define \u0026quot;T\u0026quot;}}{{.}}{{end}}`) tmpl.ExecuteTemplate(w, \u0026quot;T\u0026quot;, param1) } 会话管理 【必须】安全维护session信息  用户登录时应重新生成session，退出登录后应清理session。  import ( \u0026quot;github.com/gorilla/handlers\u0026quot; \u0026quot;github.com/gorilla/mux\u0026quot; \u0026quot;net/http\u0026quot; ) // 创建cookie func setToken(res http.ResponseWriter, req *http.Request) { expireToken := time.Now().Add(time.Minute * 30).Unix() expireCookie := time.Now().Add(time.Minute * 30) //... cookie := http.Cookie{ Name: \u0026quot;Auth\u0026quot;, Value: signedToken, Expires: expireCookie, // 过期失效 HttpOnly: true, Path: \u0026quot;/\u0026quot;, Domain: \u0026quot;127.0.0.1\u0026quot;, Secure: true, } http.SetCookie(res, \u0026amp;cookie) http.Redirect(res, req, \u0026quot;/profile\u0026quot;, 307) } // 删除cookie func logout(res http.ResponseWriter, req *http.Request) { deleteCookie := http.Cookie{ Name: \u0026quot;Auth\u0026quot;, Value: \u0026quot;none\u0026quot;, Expires: time.Now(), } http.SetCookie(res, \u0026amp;deleteCookie) return } 【必须】CSRF防护  涉及系统敏感操作或可读取敏感信息的接口应校验Referer或添加csrf_token。  // good import ( \u0026quot;github.com/gorilla/csrf\u0026quot; \u0026quot;github.com/gorilla/mux\u0026quot; \u0026quot;net/http\u0026quot; ) func main() { r := mux.NewRouter() r.HandleFunc(\u0026quot;/signup\u0026quot;, ShowSignupForm) r.HandleFunc(\u0026quot;/signup/post\u0026quot;, SubmitSignupForm) // 使用csrf_token验证 http.ListenAndServe(\u0026quot;:8000\u0026quot;, csrf.Protect([]byte(\u0026quot;32-byte-long-auth-key\u0026quot;))(r)) } 访问控制 【必须】默认鉴权   除非资源完全可对外开放，否则系统默认进行身份认证，使用白名单的方式放开不需要认证的接口或页面。\n  根据资源的机密程度和用户角色，以最小权限原则，设置不同级别的权限，如完全公开、登录可读、登录可写、特定用户可读、特定用户可写等\n  涉及用户自身相关的数据的读写必须验证登录态用户身份及其权限，避免越权操作\n-- 伪代码 selectidfromtablewhereid=:idanduserid=session.userid  没有独立账号体系的外网服务使用QQ或微信登录，内网服务使用统一登录服务登录，其他使用账号密码登录的服务需要增加验证码等二次验证\n  1.9 并发保护 1.9.1【必须】禁止在闭包中直接调用循环变量  在循环中启动协程，当协程中使用到了循环的索引值，由于多个协程同时使用同一个变量会产生数据竞争，造成执行结果异常。  // bad func main() { runtime.GOMAXPROCS(runtime.NumCPU()) var group sync.WaitGroup for i := 0; i \u0026lt; 5; i++ { group.Add(1) go func() { defer group.Done() fmt.Printf(\u0026quot;%-2d\u0026quot;, i) // 这里打印的i不是所期望的 }() } group.Wait() } // good func main() { runtime.GOMAXPROCS(runtime.NumCPU()) var group sync.WaitGroup for i := 0; i \u0026lt; 5; i++ { group.Add(1) go func(j int) { defer func() { if r := recover(); r != nil { fmt.Println(\u0026quot;Recovered in start()\u0026quot;) } group.Done() }() fmt.Printf(\u0026quot;%-2d\u0026quot;, j) // 闭包内部使用局部变量 }(i) // 把循环变量显式地传给协程 } group.Wait() } 【必须】禁止并发写map  并发写map容易造成程序崩溃并异常退出，建议加锁保护  // bad func main() { m := make(map[int]int) // 并发读写 go func() { for { _ = m[1] } }() go func() { for { m[2] = 1 } }() select {} } 【必须】确保并发安全 敏感操作如果未作并发安全限制，可导致数据读写异常，造成业务逻辑限制被绕过。可通过同步锁或者原子操作进行防护。\n通过同步锁共享内存\n// good var count int func Count(lock *sync.Mutex) { lock.Lock() // 加写锁 count++ fmt.Println(count) lock.Unlock() // 解写锁，任何一个Lock()或RLock()均需要保证对应有Unlock()或RUnlock() } func main() { lock := \u0026amp;sync.Mutex{} for i := 0; i \u0026lt; 10; i++ { go Count(lock) // 传递指针是为了防止函数内的锁和调用锁不一致 } for { lock.Lock() c := count lock.Unlock() runtime.Gosched() // 交出时间片给协程 if c \u0026gt; 10 { break } } }  使用sync/atomic执行原子操作  // good import ( \u0026quot;sync\u0026quot; \u0026quot;sync/atomic\u0026quot; ) func main() { type Map map[string]string var m atomic.Value m.Store(make(Map)) var mu sync.Mutex // used only by writers read := func(key string) (val string) { m1 := m.Load().(Map) return m1[key] } insert := func(key, val string) { mu.Lock() // 与潜在写入同步 defer mu.Unlock() m1 := m.Load().(Map) // 导入struct当前数据 m2 := make(Map) // 创建新值 for k, v := range m1 { m2[k] = v } m2[key] = val m.Store(m2) // 用新的替代当前对象 } _, _ = read, insert } ","date":"2021-10-24T22:00:08+08:00","image":"https://zcj-git520.github.io/p/go%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/1_hu7c5d570e6f1bb8cc35e9c2f13acb3eec_11753_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/go%E5%AE%89%E5%85%A8%E6%8C%87%E5%8D%97/","title":"Go安全指南"},{"content":"uber-go/guide 的中文翻译 English Uber go 语言编码规范 Uber 是一家美国硅谷的科技公司，也是 go 语言的早期 adopter。其开源了很多 golang 项目，诸如被 gopher 圈熟知的 zap、jaeger 等。2018 年年末 Uber 将内部的 go 风格规范 开源到 GitHub，经过一年的积累和更新，该规范已经初具规模，并受到广大 gopher 的关注。本文是该规范的中文版本。本版本会根据原版实时更新。\n目录  uber- go/guide 的中文翻译 English Uber go 语言编码规范 版本 目录 介绍 指导原则  指向 interface 的指针 Interface 合理性验证 接收器 (receiver) 与接口 零值 Mutex 是有效的 在边界处拷贝 Slices 和 Maps  接收 Slices 和 Maps 返回 slices 或 maps   使用 defer 释放资源 Channel 的 size 要么是 1，要么是无缓冲的 枚举从 1 开始 使用 time 处理时间  使用 time.Time 表达瞬时时间 使用 time.Duration 表达时间段 对外部系统使用 time.Time 和 time.Duration   错误类型 错误包装 (Error Wrapping) 处理类型断言失败 不要 panic 使用 go.uber.org/atomic 避免可变全局变量 避免在公共结构中嵌入类型 避免使用内置名称 避免使用 init() 追加时优先指定切片容量 主函数退出方式(Exit)  一次性退出     性能  优先使用 strconv 而不是 fmt 避免字符串到字节的转换 指定容器容量  指定Map容量提示 指定切片容量     规范  一致性 相似的声明放在一组 import 分组 包名 函数名 导入别名 函数分组与顺序 减少嵌套 不必要的 else 顶层变量声明 对于未导出的顶层常量和变量，使用_作为前缀 结构体中的嵌入 使用字段名初始化结构体 本地变量声明 nil 是一个有效的 slice 缩小变量作用域 避免参数语义不明确(Avoid Naked Parameters) 使用原始字符串字面值，避免转义 初始化结构体  使用字段名初始化结构 省略结构中的零值字段 对零值结构使用 var 初始化 Struct 引用   初始化 Maps 字符串 string format 命名 Printf 样式的函数   编程模式  表驱动测试 功能选项   Linting  Lint Runners   Stargazers over time  介绍 样式 (style) 是支配我们代码的惯例。术语样式有点用词不当，因为这些约定涵盖的范围不限于由 gofmt 替我们处理的源文件格式。\n本指南的目的是通过详细描述在 Uber 编写 go 代码的注意事项来管理这种复杂性。这些规则的存在是为了使代码库易于管理，同时仍然允许工程师更有效地使用 go 语言功能。\n该指南最初由 Prashant Varanasi 和 Simon Newton 编写，目的是使一些同事能快速使用 go。多年来，该指南已根据其他人的反馈进行了修改。\n本文档记录了我们在 Uber 遵循的 go 代码中的惯用约定。其中许多是 go 的通用准则，而其他扩展准则依赖于下面外部的指南：\n [Effective go](https:// golang.org/doc/effective_ go.html) [ go Common Mistakes](https://github.com/ golang/ go/wiki/CommonMistakes) [ go Code Review Comments](https://github.com/ golang/ go/wiki/CodeReviewComments)  所有代码都应该通过 golint和 go vet的检查并无错误。我们建议您将编辑器设置为：\n 保存时运行  goimports 运行  golint 和  go vet 检查错误  您可以在以下 go 编辑器工具支持页面中找到更为详细的信息： \u0026lt;https://github.com/ golang/ go/wiki/IDEsAndTextEditorPlugins\u0026gt;\n指导原则 指向 interface 的指针 您几乎不需要指向接口类型的指针。您应该将接口作为值进行传递，在这样的传递过程中，实质上传递的底层数据仍然可以是指针。\n接口实质上在底层用两个字段表示：\n 一个指向某些特定类型信息的指针。您可以将其视为\u0026quot;type\u0026quot;。 数据指针。如果存储的数据是指针，则直接存储。如果存储的数据是一个值，则存储指向该值的指针。  如果希望接口方法修改基础数据，则必须使用指针传递(将对象指针赋值给接口变量)。\n go type F interface { f() } type S1 struct{} func (s S1) f() {} type S2 struct{} func (s *S2) f() {} // f1.f()无法修改底层数据 // f2.f() 可以修改底层数据,给接口变量f2赋值时使用的是对象指针 var f1 F = S1{} var f2 F = \u0026amp;S2{} Interface 合理性验证 在编译时验证接口的符合性。这包括：\n 将实现特定接口的导出类型作为接口API 的一部分进行检查 实现同一接口的(导出和非导出)类型属于实现类型的集合 任何违反接口合理性检查的场景,都会终止编译,并通知给用户  补充:上面3条是编译器对接口的检查机制, 大体意思是错误使用接口会在编译期报错. 所以可以利用这个机制让部分问题在编译期暴露.\ngo // 如果Handler没有实现http.Handler,会在运行时报错 type Handler struct { // ... } func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { ... }  go type Handler struct { // ... } // 用于触发编译期的接口的合理性检查机制 // 如果Handler没有实现http.Handler,会在编译期报错 var _ http.Handler = (*Handler)(nil) func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { // ... } 如果 *Handler 与 http.Handler 的接口不匹配, 那么语句 var _ http.Handler = (*Handler)(nil) 将无法编译通过.\n赋值的右边应该是断言类型的零值。 对于指针类型（如 *Handler）、切片和映射，这是 nil； 对于结构类型，这是空结构。\ngo type LogHandler struct { h http.Handler log *zap.Logger } var _ http.Handler = LogHandler{} func (h LogHandler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { // ... } 接收器 (receiver) 与接口 使用值接收器的方法既可以通过值调用，也可以通过指针调用。\n带指针接收器的方法只能通过指针或 addressable values调用.\ngolang.org/ref/spec#Method_values\n例如，\ngo type S struct { data string } func (s S) Read() string { return s.data } func (s *S) Write(str string) { s.data = str } sVals := map[int]S{1: {\u0026quot;A\u0026quot;}} // 你只能通过值调用 Read sVals[1].Read() // 这不能编译通过： // sVals[1].Write(\u0026quot;test\u0026quot;) sPtrs := map[int]*S{1: {\u0026quot;A\u0026quot;}} // 通过指针既可以调用 Read，也可以调用 Write 方法 sPtrs[1].Read() sPtrs[1].Write(\u0026quot;test\u0026quot;) 类似的,即使方法有了值接收器,也同样可以用指针接收器来满足接口.\ngo type F interface { f() } type S1 struct{} func (s S1) f() {} type S2 struct{} func (s *S2) f() {} s1Val := S1{} s1Ptr := \u0026amp;S1{} s2Val := S2{} s2Ptr := \u0026amp;S2{} var i F i = s1Val i = s1Ptr i = s2Ptr // 下面代码无法通过编译。因为 s2Val 是一个值，而 S2 的 f 方法中没有使用值接收器 // i = s2Val [Effective go](https:// golang.org/doc/effective_ go.html) 中有一段关于 [pointers vs. values](https:// golang.org/doc/effective_ go.html#pointers_vs_values) 的精彩讲解。\n补充:\n 一个类型可以有值接收器方法集和指针接收器方法集  值接收器方法集是指针接收器方法集的子集,反之不是   规则  值对象只可以使用值接收器方法集 指针对象可以使用 值接收器方法集 + 指针接收器方法集   接口的匹配(或者叫实现)  类型实现了接口的所有方法,叫匹配 具体的讲,要么是类型的值方法集匹配接口,要么是指针方法集匹配接口    具体的匹配分两种:\n 值方法集和接口匹配  给接口变量赋值的不管是值还是指针对象,都ok,因为都包含值方法集   指针方法集和接口匹配  只能将指针对象赋值给接口变量,因为只有指针方法集和接口匹配 如果将值对象赋值给接口变量,会在编译期报错(会触发接口合理性检查机制)    为啥 i = s2Val 会报错,因为值方法集和接口不匹配.\n零值 Mutex 是有效的 零值 sync.Mutex 和 sync.RWMutex 是有效的。所以指向 mutex 的指针基本是不必要的。\ngo mu := new(sync.Mutex) mu.Lock() go var mu sync.Mutex mu.Lock() 如果你使用结构体指针，mutex 可以非指针形式作为结构体的组成字段，或者更好的方式是直接嵌入到结构体中。 如果是私有结构体类型或是要实现 Mutex 接口的类型，我们可以使用嵌入 mutex 的方法：\ngo type smap struct { sync.Mutex // only for unexported types（仅适用于非导出类型） data map[string]string } func newSMap() *smap { return \u0026amp;smap{ data: make(map[string]string), } } func (m *smap) Get(k string) string { m.Lock() defer m.Unlock() return m.data[k] } go type SMap struct { mu sync.Mutex // 对于导出类型，请使用私有锁 data map[string]string } func NewSMap() *SMap { return \u0026amp;SMap{ data: make(map[string]string), } } func (m *SMap) Get(k string) string { m.mu.Lock() defer m.mu.Unlock() return m.data[k] } 在边界处拷贝 Slices 和 Maps slices 和 maps 包含了指向底层数据的指针，因此在需要复制它们时要特别注意。\n接收 Slices 和 Maps 请记住，当 map 或 slice 作为函数参数传入时，如果您存储了对它们的引用，则用户可以对其进行修改。\ngo func (d *Driver) SetTrips(trips []Trip) { d.trips = trips } trips := ... d1.SetTrips(trips) // 你是要修改 d1.trips 吗？ trips[0] = ... go func (d *Driver) SetTrips(trips []Trip) { d.trips = make([]Trip, len(trips)) copy(d.trips, trips) } trips := ... d1.SetTrips(trips) // 这里我们修改 trips[0]，但不会影响到 d1.trips trips[0] = ... 返回 slices 或 maps 同样，请注意用户对暴露内部状态的 map 或 slice 的修改。\ngo type Stats struct { mu sync.Mutex counters map[string]int } // Snapshot 返回当前状态。 func (s *Stats) Snapshot() map[string]int { s.mu.Lock() defer s.mu.Unlock() return s.counters } // snapshot 不再受互斥锁保护 // 因此对 snapshot 的任何访问都将受到数据竞争的影响 // 影响 stats.counters snapshot := stats.Snapshot() go type Stats struct { mu sync.Mutex counters map[string]int } func (s *Stats) Snapshot() map[string]int { s.mu.Lock() defer s.mu.Unlock() result := make(map[string]int, len(s.counters)) for k, v := range s.counters { result[k] = v } return result } // snapshot 现在是一个拷贝 snapshot := stats.Snapshot() 使用 defer 释放资源 使用 defer 释放资源，诸如文件和锁。\ngo p.Lock() if p.count \u0026lt; 10 { p.Unlock() return p.count } p.count++ newCount := p.count p.Unlock() return newCount // 当有多个 return 分支时，很容易遗忘 unlock go p.Lock() defer p.Unlock() if p.count \u0026lt; 10 { return p.count } p.count++ return p.count // 更可读 Defer 的开销非常小，只有在您可以证明函数执行时间处于纳秒级的程度时，才应避免这样做。使用 defer 提升可读性是值得的，因为使用它们的成本微不足道。尤其适用于那些不仅仅是简单内存访问的较大的方法，在这些方法中其他计算的资源消耗远超过 defer。\nChannel 的 size 要么是 1，要么是无缓冲的 channel 通常 size 应为 1 或是无缓冲的。默认情况下，channel 是无缓冲的，其 size 为零。任何其他尺寸都必须经过严格的审查。我们需要考虑如何确定大小，考虑是什么阻止了 channel 在高负载下和阻塞写时的写入，以及当这种情况发生时系统逻辑有哪些变化。(翻译解释：按照原文意思是需要界定通道边界，竞态条件，以及逻辑上下文梳理)\ngo // 应该足以满足任何情况！ c := make(chan int, 64) go // 大小：1 c := make(chan int, 1) // 或者 // 无缓冲 channel，大小为 0 c := make(chan int) 枚举从 1 开始 在 go 中引入枚举的标准方法是声明一个自定义类型和一个使用了 iota 的 const 组。由于变量的默认值为 0，因此通常应以非零值开头枚举。\ngo type Operation int const ( Add Operation = iota Subtract Multiply ) // Add=0, Subtract=1, Multiply=2 go type Operation int const ( Add Operation = iota + 1 Subtract Multiply ) // Add=1, Subtract=2, Multiply=3 在某些情况下，使用零值是有意义的（枚举从零开始），例如，当零值是理想的默认行为时。\ngo type Lo goutput int const ( LogToStdout Lo goutput = iota LogToFile LogToRemote ) // LogToStdout=0, LogToFile=1, LogToRemote=2 使用 time 处理时间 时间处理很复杂。关于时间的错误假设通常包括以下几点。\n 一天有 24 小时 一小时有 60 分钟 一周有七天 一年 365 天 还有更多  例如，1 表示在一个时间点上加上 24 小时并不总是产生一个新的日历日。\n因此，在处理时间时始终使用 \u0026quot;time\u0026quot; 包，因为它有助于以更安全、更准确的方式处理这些不正确的假设。\ngolang.org/pkg/time/\n使用 time.Time 表达瞬时时间 在处理时间的瞬间时使用 time.Time，在比较、添加或减去时间时使用 time.Time 中的方法。\ngolang.org/pkg/time/#Time\ngo func isActive(now, start, stop int) bool { return start \u0026lt;= now \u0026amp;\u0026amp; now \u0026lt; stop } go func isActive(now, start, stop time.Time) bool { return (start.Before(now) || start.Equal(now)) \u0026amp;\u0026amp; now.Before(stop) } 使用 time.Duration 表达时间段 在处理时间段时使用 time.Duration .\ngolang.org/pkg/time/#Duration\ngo func poll(delay int) { for { // ... time.Sleep(time.Duration(delay) * time.Millisecond) } } poll(10) // 是几秒钟还是几毫秒? go func poll(delay time.Duration) { for { // ... time.Sleep(delay) } } poll(10*time.Second) 回到第一个例子，在一个时间瞬间加上 24 小时，我们用于添加时间的方法取决于意图。如果我们想要下一个日历日(当前天的下一天)的同一个时间点，我们应该使用 Time.AddDate。但是，如果我们想保证某一时刻比前一时刻晚 24 小时，我们应该使用 [Time.Add]。\ngolang.org/pkg/time/#Time.AddDate [Time.Add]: https:// golang.org/pkg/time/#Time.Add\ngo newDay := t.AddDate(0 /* years */, 0 /* months */, 1 /* days */) maybeNewDay := t.Add(24 * time.Hour) 对外部系统使用 time.Time 和 time.Duration 尽可能在与外部系统的交互中使用 time.Duration 和 time.Time 例如 :\n  Command-line 标志: flag 通过 [time.ParseDuration] 支持 time.Duration\n  JSON: [encoding/json] 通过其 [UnmarshalJSON method] 方法支持将 time.Time 编码为 [RFC 3339] 字符串\n  SQL: [database/sql] 支持将 DATETIME 或 TIMESTAMP 列转换为 time.Time，如果底层驱动程序支持则返回\n  YAML: [ gopkg.in/yaml.v2] 支持将 time.Time 作为 [RFC 3339] 字符串，并通过 [time.ParseDuration] 支持 time.Duration。\ngolang.org/pkg/flag/ [time.ParseDuration]: https:// golang.org/pkg/time/#ParseDuration [encoding/json]: https:// golang.org/pkg/encoding/json/ [RFC 3339]: https://tools.ietf.org/html/rfc3339 [UnmarshalJSON method]: https:// golang.org/pkg/time/#Time.UnmarshalJSON [database/sql]: https:// golang.org/pkg/database/sql/ [ gopkg.in/yaml.v2]: https:// godoc.org/ gopkg.in/yaml.v2\n  当不能在这些交互中使用 time.Duration 时，请使用 int 或 float64，并在字段名称中包含单位。\n例如，由于 encoding/json 不支持 time.Duration，因此该单位包含在字段的名称中。\ngo // {\u0026quot;interval\u0026quot;: 2} type Config struct { Interval int `json:\u0026quot;interval\u0026quot;` } go // {\u0026quot;intervalMillis\u0026quot;: 2000} type Config struct { IntervalMillis int `json:\u0026quot;intervalMillis\u0026quot;` } 当在这些交互中不能使用 time.Time 时，除非达成一致，否则使用 string 和 [RFC 3339] 中定义的格式时间戳。默认情况下，Time.UnmarshalText 使用此格式，并可通过 [time.RFC3339] 在 Time.Format 和 time.Parse 中使用。\ngolang.org/pkg/time/#Time.UnmarshalText [time.RFC3339]: https:// golang.org/pkg/time/#RFC3339\n尽管这在实践中并不成问题，但请记住，\u0026quot;time\u0026quot; 包不支持解析闰秒时间戳（8728），也不在计算中考虑闰秒（[15190]）。如果您比较两个时间瞬间，则差异将不包括这两个瞬间之间可能发生的闰秒。\ngolang/ go/issues/8728 [15190]: https://github.com/ golang/ go/issues/15190\n错误类型 go 中有多种声明错误（Error) 的选项：\n errors.New 对于简单静态字符串的错误 [fmt.Errorf] 用于格式化的错误字符串 实现 Error() 方法的自定义类型 用 [\u0026quot;pkg/errors\u0026quot;.Wrap] 的 Wrapped errors  返回错误时，请考虑以下因素以确定最佳选择：\n  这是一个不需要额外信息的简单错误吗？如果是这样，errors.New 足够了。\n  客户需要检测并处理此错误吗？如果是这样，则应使用自定义类型并实现该 Error() 方法。\n  您是否正在传播下游函数返回的错误？如果是这样，请查看本文后面有关错误包装 section on error wrapping 部分的内容。\n  否则 [fmt.Errorf] 就可以了。\ngolang.org/pkg/errors/#New [fmt.Errorf]: https:// golang.org/pkg/fmt/#Errorf [\u0026quot;pkg/errors\u0026quot;.Wrap]: https:// godoc.org/github.com/pkg/errors#Wrap\n  如果客户端需要检测错误，并且您已使用创建了一个简单的错误 errors.New，请使用一个错误变量。\ngo // package foo func Open() error { return errors.New(\u0026quot;could not open\u0026quot;) } // package bar func use() { if err := foo.Open(); err != nil { if err.Error() == \u0026quot;could not open\u0026quot; { // handle } else { panic(\u0026quot;unknown error\u0026quot;) } } } go // package foo var ErrCouldNotOpen = errors.New(\u0026quot;could not open\u0026quot;) func Open() error { return ErrCouldNotOpen } // package bar if err := foo.Open(); err != nil { if errors.Is(err, foo.ErrCouldNotOpen) { // handle } else { panic(\u0026quot;unknown error\u0026quot;) } } 如果您有可能需要客户端检测的错误，并且想向其中添加更多信息（例如，它不是静态字符串），则应使用自定义类型。\ngo func open(file string) error { return fmt.Errorf(\u0026quot;file %q not found\u0026quot;, file) } func use() { if err := open(\u0026quot;testfile.txt\u0026quot;); err != nil { if strings.Contains(err.Error(), \u0026quot;not found\u0026quot;) { // handle } else { panic(\u0026quot;unknown error\u0026quot;) } } } go type errNotFound struct { file string } func (e errNotFound) Error() string { return fmt.Sprintf(\u0026quot;file %q not found\u0026quot;, e.file) } func open(file string) error { return errNotFound{file: file} } func use() { if err := open(\u0026quot;testfile.txt\u0026quot;); err != nil { if _, ok := err.(errNotFound); ok { // handle } else { panic(\u0026quot;unknown error\u0026quot;) } } } 直接导出自定义错误类型时要小心，因为它们已成为程序包公共 API 的一部分。最好公开匹配器功能以检查错误。\ngo // package foo type errNotFound struct { file string } func (e errNotFound) Error() string { return fmt.Sprintf(\u0026quot;file %q not found\u0026quot;, e.file) } func IsNotFoundError(err error) bool { _, ok := err.(errNotFound) return ok } func Open(file string) error { return errNotFound{file: file} } // package bar if err := foo.Open(\u0026quot;foo\u0026quot;); err != nil { if foo.IsNotFoundError(err) { // handle } else { panic(\u0026quot;unknown error\u0026quot;) } } 错误包装 (Error Wrapping) 一个（函数/方法）调用失败时，有三种主要的错误传播方式：\n 如果没有要添加的其他上下文，并且您想要维护原始错误类型，则返回原始错误。 添加上下文，使用 [\u0026quot;pkg/errors\u0026quot;.Wrap] 以便错误消息提供更多上下文 ,\u0026quot;pkg/errors\u0026quot;.Cause 可用于提取原始错误。 如果调用者不需要检测或处理的特定错误情况，使用 [fmt.Errorf]。  建议在可能的地方添加上下文，以使您获得诸如“调用服务 foo：连接被拒绝”之类的更有用的错误，而不是诸如“连接被拒绝”之类的模糊错误。\n在将上下文添加到返回的错误时，请避免使用“failed to”之类的短语以保持上下文简洁，这些短语会陈述明显的内容，并随着错误在堆栈中的渗透而逐渐堆积：\ngo s, err := store.New() if err != nil { return fmt.Errorf( \u0026quot;failed to create new store: %v\u0026quot;, err) } go s, err := store.New() if err != nil { return fmt.Errorf( \u0026quot;new store: %v\u0026quot;, err) } failed to x: failed to y: failed to create new store: the error x: y: new store: the error 但是，一旦将错误发送到另一个系统，就应该明确消息是错误消息（例如使用err标记，或在日志中以”Failed”为前缀）。\n另请参见 [Don\u0026rsquo;t just check errors, handle them gracefully]. 不要只是检查错误，要优雅地处理错误\ngodoc.org/github.com/pkg/errors#Cause [Don\u0026rsquo;t just check errors, handle them gracefully]: https://dave.cheney.net/2016/04/27/dont-just-check-errors-handle-them-gracefully\n处理类型断言失败 type assertion 的单个返回值形式针对不正确的类型将产生 panic。因此，请始终使用“comma ok”的惯用法。\ngolang.org/ref/spec#Type_assertions\ngo t := i.(string) go t, ok := i.(string) if !ok { // 优雅地处理错误 } 不要 panic 在生产环境中运行的代码必须避免出现 panic。panic 是 cascading failures 级联失败的主要根源 。如果发生错误，该函数必须返回错误，并允许调用方决定如何处理它。\ngo func run(args []string) { if len(args) == 0 { panic(\u0026quot;an argument is required\u0026quot;) } // ... } func main() { run(os.Args[1:]) } go func run(args []string) error { if len(args) == 0 { return errors.New(\u0026quot;an argument is required\u0026quot;) } // ... return nil } func main() { if err := run(os.Args[1:]); err != nil { fmt.Fprintln(os.Stderr, err) os.Exit(1) } } panic/recover 不是错误处理策略。仅当发生不可恢复的事情（例如：nil 引用）时，程序才必须 panic。程序初始化是一个例外：程序启动时应使程序中止的不良情况可能会引起 panic。\ngo var _statusTemplate = template.Must(template.New(\u0026quot;name\u0026quot;).Parse(\u0026quot;_statusHTML\u0026quot;)) 即使在测试代码中，也优先使用t.Fatal或者t.FailNow而不是 panic 来确保失败被标记。\ngo // func TestFoo(t *testing.T) f, err := ioutil.TempFile(\u0026quot;\u0026quot;, \u0026quot;test\u0026quot;) if err != nil { panic(\u0026quot;failed to set up test\u0026quot;) } go // func TestFoo(t *testing.T) f, err := ioutil.TempFile(\u0026quot;\u0026quot;, \u0026quot;test\u0026quot;) if err != nil { t.Fatal(\u0026quot;failed to set up test\u0026quot;) } 使用 go.uber.org/atomic\n使用 [sync/atomic] 包的原子操作对原始类型 (int32, int64等）进行操作，因为很容易忘记使用原子操作来读取或修改变量。\ngo.uber.org/atomic 通过隐藏基础类型为这些操作增加了类型安全性。此外，它包括一个方便的atomic.Bool类型。\ngodoc.org/ go.uber.org/atomic [sync/atomic]: https:// golang.org/pkg/sync/atomic/\ngo type foo struct { running int32 // atomic } func (f* foo) start() { if atomic.SwapInt32(\u0026amp;f.running, 1) == 1 { // already running… return } // start the Foo } func (f *foo) isRunning() bool { return f.running == 1 // race! } go type foo struct { running atomic.Bool } func (f *foo) start() { if f.running.Swap(true) { // already running… return } // start the Foo } func (f *foo) isRunning() bool { return f.running.Load() } 避免可变全局变量 使用选择依赖注入方式避免改变全局变量。 既适用于函数指针又适用于其他值类型\ngo // sign. go var _timeNow = time.Now func sign(msg string) string { now := _timeNow() return signWithTime(msg, now) } go // sign. go type signer struct { now func() time.Time } func newSigner() *signer { return \u0026amp;signer{ now: time.Now, } } func (s *signer) Sign(msg string) string { now := s.now() return signWithTime(msg, now) } go // sign_test. go func TestSign(t *testing.T) { oldTimeNow := _timeNow _timeNow = func() time.Time { return someFixedTime } defer func() { _timeNow = oldTimeNow }() assert.Equal(t, want, sign(give)) } go // sign_test. go func TestSigner(t *testing.T) { s := newSigner() s.now = func() time.Time { return someFixedTime } assert.Equal(t, want, s.Sign(give)) } 避免在公共结构中嵌入类型 这些嵌入的类型泄漏实现细节、禁止类型演化和模糊的文档。\n假设您使用共享的 AbstractList 实现了多种列表类型，请避免在具体的列表实现中嵌入 AbstractList。 相反，只需手动将方法写入具体的列表，该列表将委托给抽象列表。\ngo type AbstractList struct {} // 添加将实体添加到列表中。 func (l *AbstractList) Add(e Entity) { // ... } // 移除从列表中移除实体。 func (l *AbstractList) Remove(e Entity) { // ... } go // ConcreteList 是一个实体列表。 type ConcreteList struct { *AbstractList } go // ConcreteList 是一个实体列表。 type ConcreteList struct { list *AbstractList } // 添加将实体添加到列表中。 func (l *ConcreteList) Add(e Entity) { l.list.Add(e) } // 移除从列表中移除实体。 func (l *ConcreteList) Remove(e Entity) { l.list.Remove(e) } go 允许 类型嵌入 作为继承和组合之间的折衷。 外部类型获取嵌入类型的方法的隐式副本。 默认情况下，这些方法委托给嵌入实例的同一方法。\ngolang.org/doc/effective_ go.html#embedding\n结构还获得与类型同名的字段。 所以，如果嵌入的类型是 public，那么字段是 public。为了保持向后兼容性，外部类型的每个未来版本都必须保留嵌入类型。\n很少需要嵌入类型。 这是一种方便，可以帮助您避免编写冗长的委托方法。\n即使嵌入兼容的抽象列表 interface，而不是结构体，这将为开发人员提供更大的灵活性来改变未来，但仍然泄露了具体列表使用抽象实现的细节。\ngo // AbstractList 是各种实体列表的通用实现。 type AbstractList interface { Add(Entity) Remove(Entity) } // ConcreteList 是一个实体列表。 type ConcreteList struct { AbstractList } go // ConcreteList 是一个实体列表。 type ConcreteList struct { list AbstractList } // 添加将实体添加到列表中。 func (l *ConcreteList) Add(e Entity) { l.list.Add(e) } // 移除从列表中移除实体。 func (l *ConcreteList) Remove(e Entity) { l.list.Remove(e) } 无论是使用嵌入式结构还是使用嵌入式接口，嵌入式类型都会限制类型的演化.\n 向嵌入式接口添加方法是一个破坏性的改变。 删除嵌入类型是一个破坏性的改变。 即使使用满足相同接口的替代方法替换嵌入类型，也是一个破坏性的改变。  尽管编写这些委托方法是乏味的，但是额外的工作隐藏了实现细节，留下了更多的更改机会，还消除了在文档中发现完整列表接口的间接性操作。\n避免使用内置名称 go语言规范language specification 概述了几个内置的， 不应在 go项目中使用的名称标识[predeclared identifiers]。\n根据上下文的不同，将这些标识符作为名称重复使用， 将在当前作用域（或任何嵌套作用域）中隐藏原始标识符，或者混淆代码。 在最好的情况下，编译器会报错；在最坏的情况下，这样的代码可能会引入潜在的、难以恢复的错误。\ngolang.org/ref/spec [predeclared identifiers]: https:// golang.org/ref/spec#Predeclared_identifiers\ngo var error string // `error` 作用域隐式覆盖 // or func handleErrorMessage(error string) { // `error` 作用域隐式覆盖 } go var errorMessage string // `error` 指向内置的非覆盖 // or func handleErrorMessage(msg string) { // `error` 指向内置的非覆盖 } go type Foo struct { // 虽然这些字段在技术上不构成阴影，但`error`或`string`字符串的重映射现在是不明确的。 error error string string } func (f Foo) Error() error { // `error` 和 `f.error` 在视觉上是相似的 return f.error } func (f Foo) String() string { // `string` and `f.string` 在视觉上是相似的 return f.string } go type Foo struct { // `error` and `string` 现在是明确的。 err error str string } func (f Foo) Error() error { return f.err } func (f Foo) String() string { return f.str } 注意，编译器在使用预先分隔的标识符时不会生成错误， 但是诸如 go vet之类的工具会正确地指出这些和其他情况下的隐式问题。\n避免使用 init() 尽可能避免使用init()。当init()是不可避免或可取的，代码应先尝试：\n 无论程序环境或调用如何，都要完全确定。 避免依赖于其他init()函数的顺序或副作用。虽然init()顺序是明确的，但代码可以更改， 因此init()函数之间的关系可能会使代码变得脆弱和容易出错。 避免访问或操作全局或环境状态，如机器信息、环境变量、工作目录、程序参数/输入等。 避免I/O，包括文件系统、网络和系统调用。  不能满足这些要求的代码可能属于要作为main()调用的一部分（或程序生命周期中的其他地方）， 或者作为main()本身的一部分写入。特别是，打算由其他程序使用的库应该特别注意完全确定性， 而不是执行“init magic”\ngo type Foo struct { // ... } var _defaultFoo Foo func init() { _defaultFoo = Foo{ // ... } } go var _defaultFoo = Foo{ // ... } // or, 为了更好的可测试性: var _defaultFoo = defaultFoo() func defaultFoo() Foo { return Foo{ // ... } } go type Config struct { // ... } var _config Config func init() { // Bad: 基于当前目录 cwd, _ := os.Getwd() // Bad: I/O raw, _ := ioutil.ReadFile( path.Join(cwd, \u0026quot;config\u0026quot;, \u0026quot;config.yaml\u0026quot;), ) yaml.Unmarshal(raw, \u0026amp;_config) } go type Config struct { // ... } func loadConfig() Config { cwd, err := os.Getwd() // handle err raw, err := ioutil.ReadFile( path.Join(cwd, \u0026quot;config\u0026quot;, \u0026quot;config.yaml\u0026quot;), ) // handle err var config Config yaml.Unmarshal(raw, \u0026amp;config) return config } 考虑到上述情况，在某些情况下，init()可能更可取或是必要的，可能包括：\n  不能表示为单个赋值的复杂表达式。\n  可插入的钩子，如database/sql、编码类型注册表等。\n  对google Cloud Functions和其他形式的确定性预计算的优化。\ngoogle.com/functions/docs/bestpractices/tips#use_global_variables_to_reuse_objects_in_future_invocations\n  追加时优先指定切片容量 追加时优先指定切片容量\n在尽可能的情况下，在初始化要追加的切片时为make()提供一个容量值。\ngo for n := 0; n \u0026lt; b.N; n++ { data := make([]int, 0) for k := 0; k \u0026lt; size; k++{ data = append(data, k) } } go for n := 0; n \u0026lt; b.N; n++ { data := make([]int, 0, size) for k := 0; k \u0026lt; size; k++{ data = append(data, k) } } BenchmarkBad-4 100000000 2.48s Benchmark good-4 100000000 0.21s 主函数退出方式(Exit) go程序使用os.Exit 或者 [log.Fatal*] 立即退出 (使用panic不是退出程序的好方法，请 don\u0026rsquo;t panic.)\ngolang.org/pkg/os/#Exit [log.Fatal*]: https:// golang.org/pkg/log/#Fatal\n**仅在main（）**中调用其中一个 os.Exit 或者 log.Fatal*。所有其他函数应将错误返回到信号失败中。\ngo func main() { body := readFile(path) fmt.Println(body) } func readFile(path string) string { f, err := os.Open(path) if err != nil { log.Fatal(err) } b, err := ioutil.ReadAll(f) if err != nil { log.Fatal(err) } return string(b) } go func main() { body, err := readFile(path) if err != nil { log.Fatal(err) } fmt.Println(body) } func readFile(path string) (string, error) { f, err := os.Open(path) if err != nil { return \u0026quot;\u0026quot;, err } b, err := ioutil.ReadAll(f) if err != nil { return \u0026quot;\u0026quot;, err } return string(b), nil } 原则上：退出的具有多种功能的程序存在一些问题：\n 不明显的控制流：任何函数都可以退出程序，因此很难对控制流进行推理。 难以测试：退出程序的函数也将退出调用它的测试。这使得函数很难测试，并引入了跳过  go test 尚未运行的其他测试的风险。 跳过清理：当函数退出程序时，会跳过已经进入defer队列里的函数调用。这增加了跳过重要清理任务的风险。  一次性退出 如果可能的话，你的main（）函数中最多一次 调用 os.Exit或者log.Fatal。如果有多个错误场景停止程序执行，请将该逻辑放在单独的函数下并从中返回错误。 这会缩短 main()函数，并将所有关键业务逻辑放入一个单独的、可测试的函数中。\ngo package main func main() { args := os.Args[1:] if len(args) != 1 { log.Fatal(\u0026quot;missing file\u0026quot;) } name := args[0] f, err := os.Open(name) if err != nil { log.Fatal(err) } defer f.Close() // 如果我们调用log.Fatal 在这条线之后 // f.Close 将会被执行. b, err := ioutil.ReadAll(f) if err != nil { log.Fatal(err) } // ... } go package main func main() { if err := run(); err != nil { log.Fatal(err) } } func run() error { args := os.Args[1:] if len(args) != 1 { return errors.New(\u0026quot;missing file\u0026quot;) } name := args[0] f, err := os.Open(name) if err != nil { return err } defer f.Close() b, err := ioutil.ReadAll(f) if err != nil { return err } // ... } 性能 性能方面的特定准则只适用于高频场景。\n优先使用 strconv 而不是 fmt 将原语转换为字符串或从字符串转换时，strconv速度比fmt快。\ngo for i := 0; i \u0026lt; b.N; i++ { s := fmt.Sprint(rand.Int()) } go for i := 0; i \u0026lt; b.N; i++ { s := strconv.Itoa(rand.Int()) } BenchmarkFmtSprint-4 143 ns/op 2 allocs/op BenchmarkStrconv-4 64.2 ns/op 1 allocs/op 避免字符串到字节的转换 不要反复从固定字符串创建字节 slice。相反，请执行一次转换并捕获结果。\ngo for i := 0; i \u0026lt; b.N; i++ { w.Write([]byte(\u0026quot;Hello world\u0026quot;)) } go data := []byte(\u0026quot;Hello world\u0026quot;) for i := 0; i \u0026lt; b.N; i++ { w.Write(data) } BenchmarkBad-4 50000000 22.2 ns/op Benchmark good-4 500000000 3.25 ns/op 指定容器容量 尽可能指定容器容量，以便为容器预先分配内存。这将在添加元素时最小化后续分配（通过复制和调整容器大小）。\n指定Map容量提示 在尽可能的情况下，在使用 make() 初始化的时候提供容量信息\ngo make(map[T1]T2, hint) 向make()提供容量提示会在初始化时尝试调整map的大小，这将减少在将元素添加到map时为map重新分配内存。\n注意，与slices不同。map capacity提示并不保证完全的抢占式分配，而是用于估计所需的hashmap bucket的数量。 因此，在将元素添加到map时，甚至在指定map容量时，仍可能发生分配。\ngo m := make(map[string]os.FileInfo) files, _ := ioutil.ReadDir(\u0026quot;./files\u0026quot;) for _, f := range files { m[f.Name()] = f } go files, _ := ioutil.ReadDir(\u0026quot;./files\u0026quot;) m := make(map[string]os.FileInfo, len(files)) for _, f := range files { m[f.Name()] = f } m 是在没有大小提示的情况下创建的； 在运行时可能会有更多分配。\nm 是有大小提示创建的；在运行时可能会有更少的分配。\n指定切片容量 在尽可能的情况下，在使用make()初始化切片时提供容量信息，特别是在追加切片时。\ngo make([]T, length, capacity) 与maps不同，slice capacity不是一个提示：编译器将为提供给make()的slice的容量分配足够的内存， 这意味着后续的append()`操作将导致零分配（直到slice的长度与容量匹配，在此之后，任何append都可能调整大小以容纳其他元素）。\ngo for n := 0; n \u0026lt; b.N; n++ { data := make([]int, 0) for k := 0; k \u0026lt; size; k++{ data = append(data, k) } } go for n := 0; n \u0026lt; b.N; n++ { data := make([]int, 0, size) for k := 0; k \u0026lt; size; k++{ data = append(data, k) } } BenchmarkBad-4 100000000 2.48s Benchmark good-4 100000000 0.21s 规范 一致性 本文中概述的一些标准都是客观性的评估，是根据场景、上下文、或者主观性的判断；\n但是最重要的是，保持一致.\n一致性的代码更容易维护、是更合理的、需要更少的学习成本、并且随着新的约定出现或者出现错误后更容易迁移、更新、修复 bug\n相反，在一个代码库中包含多个完全不同或冲突的代码风格会导致维护成本开销、不确定性和认知偏差。所有这些都会直接导致速度降低、代码审查痛苦、而且增加 bug 数量。\n将这些标准应用于代码库时，建议在 package（或更大）级别进行更改，子包级别的应用程序通过将多个样式引入到同一代码中，违反了上述关注点。\n相似的声明放在一组 go 语言支持将相似的声明放在一个组内。\ngo import \u0026quot;a\u0026quot; import \u0026quot;b\u0026quot; go import ( \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; ) 这同样适用于常量、变量和类型声明：\ngo const a = 1 const b = 2 var a = 1 var b = 2 type Area float64 type Volume float64 go const ( a = 1 b = 2 ) var ( a = 1 b = 2 ) type ( Area float64 Volume float64 ) 仅将相关的声明放在一组。不要将不相关的声明放在一组。\ngo type Operation int const ( Add Operation = iota + 1 Subtract Multiply EnvVar = \u0026quot;MY_ENV\u0026quot; ) go type Operation int const ( Add Operation = iota + 1 Subtract Multiply ) const EnvVar = \u0026quot;MY_ENV\u0026quot; 分组使用的位置没有限制，例如：你可以在函数内部使用它们：\ngo func f() string { var red = color.New(0xff0000) var green = color.New(0x00ff00) var blue = color.New(0x0000ff) ... } go func f() string { var ( red = color.New(0xff0000) green = color.New(0x00ff00) blue = color.New(0x0000ff) ) ... } import 分组 导入应该分为两组：\n 标准库 其他库  默认情况下，这是 goimports 应用的分组。\ngo import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot; go.uber.org/atomic\u0026quot; \u0026quot; golang.org/x/sync/errgroup\u0026quot; ) go import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot; go.uber.org/atomic\u0026quot; \u0026quot; golang.org/x/sync/errgroup\u0026quot; ) 包名 当命名包时，请按下面规则选择一个名称：\n 全部小写。没有大写或下划线。 大多数使用命名导入的情况下，不需要重命名。 简短而简洁。请记住，在每个使用的地方都完整标识了该名称。 不用复数。例如net/url，而不是net/urls。 不要用“common”，“util”，“shared”或“lib”。这些是不好的，信息量不足的名称。  另请参阅 Package Names 和 [ go 包样式指南].\ngolang.org/package-names [ go 包样式指南]: https://rakyll.org/style-packages/\n函数名 我们遵循 go 社区关于使用 MixedCaps 作为函数名 的约定。有一个例外，为了对相关的测试用例进行分组，函数名可能包含下划线，如：TestMyFunction_WhatIsBeingTested.\ngolang.org/doc/effective_ go.html#mixed-caps\n导入别名 如果程序包名称与导入路径的最后一个元素不匹配，则必须使用导入别名。\ngo import ( \u0026quot;net/http\u0026quot; client \u0026quot;example.com/client- go\u0026quot; trace \u0026quot;example.com/trace/v2\u0026quot; ) 在所有其他情况下，除非导入之间有直接冲突，否则应避免导入别名。\ngo import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; nettrace \u0026quot; golang.net/x/trace\u0026quot; ) go import ( \u0026quot;fmt\u0026quot; \u0026quot;os\u0026quot; \u0026quot;runtime/trace\u0026quot; nettrace \u0026quot; golang.net/x/trace\u0026quot; ) 函数分组与顺序  函数应按粗略的调用顺序排序。 同一文件中的函数应按接收者分组。  因此，导出的函数应先出现在文件中，放在struct, const, var定义的后面。\n在定义类型之后，但在接收者的其余方法之前，可能会出现一个 newXYZ()/NewXYZ()\n由于函数是按接收者分组的，因此普通工具函数应在文件末尾出现。\ngo func (s *something) Cost() { return calcCost(s.weights) } type something struct{ ... } func calcCost(n []int) int {...} func (s *something) Stop() {...} func newSomething() *something { return \u0026amp;something{} } go type something struct{ ... } func newSomething() *something { return \u0026amp;something{} } func (s *something) Cost() { return calcCost(s.weights) } func (s *something) Stop() {...} func calcCost(n []int) int {...} 减少嵌套 代码应通过尽可能先处理错误情况/特殊情况并尽早返回或继续循环来减少嵌套。减少嵌套多个级别的代码的代码量。\ngo for _, v := range data { if v.F1 == 1 { v = process(v) if err := v.Call(); err == nil { v.Send() } else { return err } } else { log.Printf(\u0026quot;Invalid v: %v\u0026quot;, v) } } go for _, v := range data { if v.F1 != 1 { log.Printf(\u0026quot;Invalid v: %v\u0026quot;, v) continue } v = process(v) if err := v.Call(); err != nil { return err } v.Send() } 不必要的 else 如果在 if 的两个分支中都设置了变量，则可以将其替换为单个 if。\ngo var a int if b { a = 100 } else { a = 10 } go a := 10 if b { a = 100 } 顶层变量声明 在顶层，使用标准var关键字。请勿指定类型，除非它与表达式的类型不同。\ngo var _s string = F() func F() string { return \u0026quot;A\u0026quot; } go var _s = F() // 由于 F 已经明确了返回一个字符串类型，因此我们没有必要显式指定_s 的类型 // 还是那种类型 func F() string { return \u0026quot;A\u0026quot; } 如果表达式的类型与所需的类型不完全匹配，请指定类型。\ngo type myError struct{} func (myError) Error() string { return \u0026quot;error\u0026quot; } func F() myError { return myError{} } var _e error = F() // F 返回一个 myError 类型的实例，但是我们要 error 类型 对于未导出的顶层常量和变量，使用_作为前缀 在未导出的顶级vars和consts， 前面加上前缀_，以使它们在使用时明确表示它们是全局符号。\n例外：未导出的错误值，应以err开头。\n基本依据：顶级变量和常量具有包范围作用域。使用通用名称可能很容易在其他文件中意外使用错误的值。\ngo // foo. go const ( defaultPort = 8080 defaultUser = \u0026quot;user\u0026quot; ) // bar. go func Bar() { defaultPort := 9090 ... fmt.Println(\u0026quot;Default port\u0026quot;, defaultPort) // We will not see a compile error if the first line of // Bar() is deleted. } go // foo. go const ( _defaultPort = 8080 _defaultUser = \u0026quot;user\u0026quot; ) 结构体中的嵌入 嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部，并且必须有一个空行将嵌入式字段与常规字段分隔开。\ngo type Client struct { version int http.Client } go type Client struct { http.Client version int } 内嵌应该提供切实的好处，比如以语义上合适的方式添加或增强功能。 它应该在对用户不利影响的情况下完成这项工作（另请参见：避免在公共结构中嵌入类型Avoid Embedding Types in Public Structs）。\n嵌入 不应该:\n 纯粹是为了美观或方便。 使外部类型更难构造或使用。 影响外部类型的零值。如果外部类型有一个有用的零值，则在嵌入内部类型之后应该仍然有一个有用的零值。 作为嵌入内部类型的副作用，从外部类型公开不相关的函数或字段。 公开未导出的类型。 影响外部类型的复制形式。 更改外部类型的API或类型语义。 嵌入内部类型的非规范形式。 公开外部类型的实现详细信息。 允许用户观察或控制类型内部。 通过包装的方式改变内部函数的一般行为，这种包装方式会给用户带来一些意料之外情况。  简单地说，有意识地和有目的地嵌入。一种很好的测试体验是， \u0026ldquo;是否所有这些导出的内部方法/字段都将直接添加到外部类型\u0026rdquo; 如果答案是some或no，不要嵌入内部类型-而是使用字段。\ngo type A struct { // Bad: A.Lock() and A.Unlock() 现在可用 // 不提供任何功能性好处，并允许用户控制有关A的内部细节。 sync.Mutex } go type countingWriteCloser struct { // good: Write() 在外层提供用于特定目的， // 并且委托工作到内部类型的Write()中。 io.WriteCloser count int } func (w *countingWriteCloser) Write(bs []byte) (int, error) { w.count += len(bs) return w.WriteCloser.Write(bs) } go type Book struct { // Bad: 指针更改零值的有用性 io.ReadWriter // other fields } // later var b Book b.Read(...) // panic: nil pointer b.String() // panic: nil pointer b.Write(...) // panic: nil pointer go type Book struct { // good: 有用的零值 bytes.Buffer // other fields } // later var b Book b.Read(...) // ok b.String() // ok b.Write(...) // ok go type Client struct { sync.Mutex sync.WaitGroup bytes.Buffer url.URL } go type Client struct { mtx sync.Mutex wg sync.WaitGroup buf bytes.Buffer url url.URL } 使用字段名初始化结构体 初始化结构体时，应该指定字段名称。现在由  go vet 强制执行。\ngolang.org/cmd/vet/\ngo k := User{\u0026quot;John\u0026quot;, \u0026quot;Doe\u0026quot;, true} go k := User{ FirstName: \u0026quot;John\u0026quot;, LastName: \u0026quot;Doe\u0026quot;, Admin: true, } 例外：如果有 3 个或更少的字段，则可以在测试表中省略字段名称。\ngo tests := []struct{ op Operation want string }{ {Add, \u0026quot;add\u0026quot;}, {Subtract, \u0026quot;subtract\u0026quot;}, } 本地变量声明 如果将变量明确设置为某个值，则应使用短变量声明形式 (:=)。\ngo var s = \u0026quot;foo\u0026quot; go s := \u0026quot;foo\u0026quot; 但是，在某些情况下，var 使用关键字时默认值会更清晰。例如，声明空切片。\ngolang/ go/wiki/CodeReviewComments#declaring-empty-slices\ngo func f(list []int) { filtered := []int{} for _, v := range list { if v \u0026gt; 10 { filtered = append(filtered, v) } } } go func f(list []int) { var filtered []int for _, v := range list { if v \u0026gt; 10 { filtered = append(filtered, v) } } } nil 是一个有效的 slice nil 是一个有效的长度为 0 的 slice，这意味着，\n  您不应明确返回长度为零的切片。应该返回nil 来代替。\n  goodgo if x == \u0026quot;\u0026quot; { return []int{} } go if x == \u0026quot;\u0026quot; { return nil }   要检查切片是否为空，请始终使用len(s) == 0。而非 nil。\n  goodgo func isEmpty(s []string) bool { return s == nil } go func isEmpty(s []string) bool { return len(s) == 0 }   零值切片（用var声明的切片）可立即使用，无需调用make()创建。\n  goodgo nums := []int{} // or, nums := make([]int) if add1 { nums = append(nums, 1) } if add2 { nums = append(nums, 2) } go var nums []int if add1 { nums = append(nums, 1) } if add2 { nums = append(nums, 2) } 记住，虽然nil切片是有效的切片，但它不等于长度为0的切片（一个为nil，另一个不是），并且在不同的情况下（例如序列化），这两个切片的处理方式可能不同。\n缩小变量作用域 如果有可能，尽量缩小变量作用范围。除非它与 减少嵌套的规则冲突。\ngo err := ioutil.WriteFile(name, data, 0644) if err != nil { return err } go if err := ioutil.WriteFile(name, data, 0644); err != nil { return err } 如果需要在 if 之外使用函数调用的结果，则不应尝试缩小范围。\ngo if data, err := ioutil.ReadFile(name); err == nil { err = cfg.Decode(data) if err != nil { return err } fmt.Println(cfg) return nil } else { return err } go data, err := ioutil.ReadFile(name) if err != nil { return err } if err := cfg.Decode(data); err != nil { return err } fmt.Println(cfg) return nil 避免参数语义不明确(Avoid Naked Parameters) 函数调用中的意义不明确的参数可能会损害可读性。当参数名称的含义不明显时，请为参数添加 C 样式注释 (/* ... */)\ngo // func printInfo(name string, isLocal, done bool) printInfo(\u0026quot;foo\u0026quot;, true, true) go // func printInfo(name string, isLocal, done bool) printInfo(\u0026quot;foo\u0026quot;, true /* isLocal */, true /* done */) 对于上面的示例代码，还有一种更好的处理方式是将上面的 bool 类型换成自定义类型。将来，该参数可以支持不仅仅局限于两个状态（true/false）。\ngo type Region int const ( UnknownRegion Region = iota Local ) type Status int const ( StatusReady Status= iota + 1 StatusDone // Maybe we will have a StatusInProgress in the future. ) func printInfo(name string, region Region, status Status) 使用原始字符串字面值，避免转义 go 支持使用 [原始字符串字面值](https:// golang.org/ref/spec#raw_string_lit)，也就是 \u0026quot; ` \u0026quot; 来表示原生字符串，在需要转义的场景下，我们应该尽量使用这种方案来替换。\n可以跨越多行并包含引号。使用这些字符串可以避免更难阅读的手工转义的字符串。\ngo wantError := \u0026quot;unknown name:\\\u0026quot;test\\\u0026quot;\u0026quot; go wantError := `unknown error:\u0026quot;test\u0026quot;` 初始化结构体 使用字段名初始化结构 初始化结构时，几乎应该始终指定字段名。目前由 go vet强制执行。\ngolang.org/cmd/vet/\ngo k := User{\u0026quot;John\u0026quot;, \u0026quot;Doe\u0026quot;, true} go k := User{ FirstName: \u0026quot;John\u0026quot;, LastName: \u0026quot;Doe\u0026quot;, Admin: true, } 例外：当有3个或更少的字段时，测试表中的字段名may可以省略。\ngo tests := []struct{ op Operation want string }{ {Add, \u0026quot;add\u0026quot;}, {Subtract, \u0026quot;subtract\u0026quot;}, } 省略结构中的零值字段 初始化具有字段名的结构时，除非提供有意义的上下文，否则忽略值为零的字段。 也就是，让我们自动将这些设置为零值\ngo user := User{ FirstName: \u0026quot;John\u0026quot;, LastName: \u0026quot;Doe\u0026quot;, MiddleName: \u0026quot;\u0026quot;, Admin: false, } go user := User{ FirstName: \u0026quot;John\u0026quot;, LastName: \u0026quot;Doe\u0026quot;, } 这有助于通过省略该上下文中的默认值来减少阅读的障碍。只指定有意义的值。\n在字段名提供有意义上下文的地方包含零值。例如，表驱动测试 中的测试用例可以受益于字段的名称，即使它们是零值的。\ngo tests := []struct{ give string want int }{ {give: \u0026quot;0\u0026quot;, want: 0}, // ... } 对零值结构使用 var 如果在声明中省略了结构的所有字段，请使用 var 声明结构。\ngo user := User{} go var user User 这将零值结构与那些具有类似于为[初始化 Maps]创建的,区别于非零值字段的结构区分开来， 并与我们更喜欢的declare empty slices方式相匹配。\n初始化 Struct 引用 在初始化结构引用时，请使用\u0026amp;T{}代替new(T)，以使其与结构体初始化一致。\ngo sval := T{Name: \u0026quot;foo\u0026quot;} // inconsistent sptr := new(T) sptr.Name = \u0026quot;bar\u0026quot; go sval := T{Name: \u0026quot;foo\u0026quot;} sptr := \u0026amp;T{Name: \u0026quot;bar\u0026quot;} 初始化 Maps 对于空 map 请使用 make(..) 初始化， 并且 map 是通过编程方式填充的。 这使得 map 初始化在表现上不同于声明，并且它还可以方便地在 make 后添加大小提示。\ngo var ( // m1 读写安全; // m2 在写入时会 panic m1 = map[T1]T2{} m2 map[T1]T2 ) go var ( // m1 读写安全; // m2 在写入时会 panic m1 = make(map[T1]T2) m2 map[T1]T2 ) 声明和初始化看起来非常相似的。\n声明和初始化看起来差别非常大。\n在尽可能的情况下，请在初始化时提供 map 容量大小，详细请看 指定Map容量提示。\n另外，如果 map 包含固定的元素列表，则使用 map literals(map 初始化列表) 初始化映射。\ngo m := make(map[T1]T2, 3) m[k1] = v1 m[k2] = v2 m[k3] = v3 go m := map[T1]T2{ k1: v1, k2: v2, k3: v3, } 基本准则是：在初始化时使用 map 初始化列表 来添加一组固定的元素。否则使用 make (如果可以，请尽量指定 map 容量)。\n字符串 string format 如果你在函数外声明Printf-style 函数的格式字符串，请将其设置为const常量。\n这有助于 go vet对格式字符串执行静态分析。\ngo msg := \u0026quot;unexpected values %v, %v\\n\u0026quot; fmt.Printf(msg, 1, 2) go const msg = \u0026quot;unexpected values %v, %v\\n\u0026quot; fmt.Printf(msg, 1, 2) 命名 Printf 样式的函数 声明Printf-style 函数时，请确保 go vet可以检测到它并检查格式字符串。\n这意味着您应尽可能使用预定义的Printf-style 函数名称。 go vet将默认检查这些。有关更多信息，请参见 Printf 系列。\ngolang.org/cmd/vet/#hdr-Printf_family\n如果不能使用预定义的名称，请以 f 结束选择的名称：Wrapf，而不是Wrap。 go vet可以要求检查特定的 Printf 样式名称，但名称必须以f结尾。\n$ go vet -printfuncs=wrapf,statusf 另请参阅 go vet: Printf family check.\ngo-vet-printf-family-check/\n编程模式 表驱动测试 当测试逻辑是重复的时候，通过 subtests 使用 table 驱动的方式编写 case 代码看上去会更简洁。\ngolang.org/subtests\ngo // func TestSplitHostPort(t *testing.T) host, port, err := net.SplitHostPort(\u0026quot;192.0.2.0:8000\u0026quot;) require.NoError(t, err) assert.Equal(t, \u0026quot;192.0.2.0\u0026quot;, host) assert.Equal(t, \u0026quot;8000\u0026quot;, port) host, port, err = net.SplitHostPort(\u0026quot;192.0.2.0:http\u0026quot;) require.NoError(t, err) assert.Equal(t, \u0026quot;192.0.2.0\u0026quot;, host) assert.Equal(t, \u0026quot;http\u0026quot;, port) host, port, err = net.SplitHostPort(\u0026quot;:8000\u0026quot;) require.NoError(t, err) assert.Equal(t, \u0026quot;\u0026quot;, host) assert.Equal(t, \u0026quot;8000\u0026quot;, port) host, port, err = net.SplitHostPort(\u0026quot;1:8\u0026quot;) require.NoError(t, err) assert.Equal(t, \u0026quot;1\u0026quot;, host) assert.Equal(t, \u0026quot;8\u0026quot;, port) go // func TestSplitHostPort(t *testing.T) tests := []struct{ give string wantHost string wantPort string }{ { give: \u0026quot;192.0.2.0:8000\u0026quot;, wantHost: \u0026quot;192.0.2.0\u0026quot;, wantPort: \u0026quot;8000\u0026quot;, }, { give: \u0026quot;192.0.2.0:http\u0026quot;, wantHost: \u0026quot;192.0.2.0\u0026quot;, wantPort: \u0026quot;http\u0026quot;, }, { give: \u0026quot;:8000\u0026quot;, wantHost: \u0026quot;\u0026quot;, wantPort: \u0026quot;8000\u0026quot;, }, { give: \u0026quot;1:8\u0026quot;, wantHost: \u0026quot;1\u0026quot;, wantPort: \u0026quot;8\u0026quot;, }, } for _, tt := range tests { t.Run(tt.give, func(t *testing.T) { host, port, err := net.SplitHostPort(tt.give) require.NoError(t, err) assert.Equal(t, tt.wantHost, host) assert.Equal(t, tt.wantPort, port) }) } 很明显，使用 test table 的方式在代码逻辑扩展的时候，比如新增 test case，都会显得更加的清晰。\n我们遵循这样的约定：将结构体切片称为tests。 每个测试用例称为tt。此外，我们鼓励使用give和want前缀说明每个测试用例的输入和输出值。\ngo tests := []struct{ give string wantHost string wantPort string }{ // ... } for _, tt := range tests { // ... } 功能选项 功能选项是一种模式，您可以在其中声明一个不透明 Option 类型，该类型在某些内部结构中记录信息。您接受这些选项的可变编号，并根据内部结构上的选项记录的全部信息采取行动。\n将此模式用于您需要扩展的构造函数和其他公共 API 中的可选参数，尤其是在这些功能上已经具有三个或更多参数的情况下。\ngo // package db func Open( addr string, cache bool, logger *zap.Logger ) (*Connection, error) { // ... } go // package db type Option interface { // ... } func WithCache(c bool) Option { // ... } func WithLogger(log *zap.Logger) Option { // ... } // Open creates a connection. func Open( addr string, opts ...Option, ) (*Connection, error) { // ... } 必须始终提供缓存和记录器参数，即使用户希望使用默认值。\ngo db.Open(addr, db.DefaultCache, zap.NewNop()) db.Open(addr, db.DefaultCache, log) db.Open(addr, false /* cache */, zap.NewNop()) db.Open(addr, false /* cache */, log) 只有在需要时才提供选项。\ngo db.Open(addr) db.Open(addr, db.WithLogger(log)) db.Open(addr, db.WithCache(false)) db.Open( addr, db.WithCache(false), db.WithLogger(log), ) Our suggested way of implementing this pattern is with an Option interface that holds an unexported method, recording options on an unexported options struct.\n我们建议实现此模式的方法是使用一个 Option 接口，该接口保存一个未导出的方法，在一个未导出的 options 结构上记录选项。\ngo type options struct { cache bool logger *zap.Logger } type Option interface { apply(*options) } type cacheOption bool func (c cacheOption) apply(opts *options) { opts.cache = bool(c) } func WithCache(c bool) Option { return cacheOption(c) } type loggerOption struct { Log *zap.Logger } func (l loggerOption) apply(opts *options) { opts.logger = l.Log } func WithLogger(log *zap.Logger) Option { return loggerOption{Log: log} } // Open creates a connection. func Open( addr string, opts ...Option, ) (*Connection, error) { options := options{ cache: defaultCache, logger: zap.NewNop(), } for _, o := range opts { o.apply(\u0026amp;options) } // ... } 注意: 还有一种使用闭包实现这个模式的方法，但是我们相信上面的模式为作者提供了更多的灵活性，并且更容易对用户进行调试和测试。特别是，在不可能进行比较的情况下它允许在测试和模拟中对选项进行比较。此外，它还允许选项实现其他接口，包括 fmt.Stringer，允许用户读取选项的字符串表示形式。\n还可以参考下面资料：\n  Self-referential functions and the design of options\n  Functional options for friendly APIs\n  Linting 比任何 \u0026ldquo;blessed\u0026rdquo; linter 集更重要的是，lint在一个代码库中始终保持一致。\n我们建议至少使用以下linters，因为我认为它们有助于发现最常见的问题，并在不需要规定的情况下为代码质量建立一个高标准：\n  errcheck 以确保错误得到处理\n  goimports 格式化代码和管理 imports\n  [ golint] 指出常见的文体错误\n  [ govet] 分析代码中的常见错误\n  [staticcheck] 各种静态分析检查\ngodoc.org/ golang.org/x/tools/cmd/ goimports [ golint]: https://github.com/ golang/lint [ govet]: https:// golang.org/cmd/vet/ [staticcheck]: https://staticcheck.io/\n  Lint Runners 我们推荐 golangci-lint 作为 go-to lint的运行程序，这主要是因为它在较大的代码库中的性能以及能够同时配置和使用许多规范。这个repo有一个示例配置文件[. golangci.yml]和推荐的linter设置。\ngolangci-lint 有[various-linters]可供使用。建议将上述linters作为基本set，我们鼓励团队添加对他们的项目有意义的任何附加linters。\ngolangci/ golangci-lint [. golangci.yml]: https://github.com/uber- go/guide/blob/master/. golangci.yml [various-linters]: https:// golangci-lint.run/usage/linters/\nStargazers over time [![Stargazers over time](https://starchart.cc/xxjwxc/uber_ go_guide_cn.svg)](https://starchart.cc/xxjwxc/uber_ go_guide_cn)\n","date":"2021-10-20T22:00:08+08:00","image":"https://zcj-git520.github.io/p/uber-go-%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/1_hu7c5d570e6f1bb8cc35e9c2f13acb3eec_11753_120x120_fill_q75_box_smart1.jpg","permalink":"https://zcj-git520.github.io/p/uber-go-%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/","title":"Uber go 语言编码规范"},{"content":"虚拟地址空间布局  程序通过编译成为一堆的机器指令写入可执行文件，程序在运行是会将可执行文件加载在计算机的内存中 在虚拟地址空间分布中处于代码段。 程序中的局部变量、函数的参数、函数的返回值等数据会保存在虚拟地址的栈中(栈是先进后出的数据结构) 栈空间的编译器分配和释放。 程序的全局变量和静态变量会保存在虚拟地址的数据段 动态分配内存的地址会保存在虚拟地址空间的堆上。堆空间是动态开辟的内存空间，需要主动开辟和释放。或者 调用GC释放 \r  堆内存管理  堆内存空间不是编译器分配，而是有程序动态分配的内存空间。  手动垃圾回收  需要程序主动释放没有用的数据所在的堆空间。如：c++中调用new()函数向计算机申请开辟内存空间后，使用delete或delete[]释放不需要的 堆内存空间。这一类是手动内存分配和释放。手动内存分配使用不恰当也会造成：内存泄露 悬挂指针的问题   过早释放会造成悬挂指针（野指针）：提前释放了动态的堆内存的空间，当程序访问这段地址时会报错。因为这段提前释放的内存空间被清空、 重新分配或者被操作系统回收。释放指针时将指针赋值为NULL，在访问时对指针进行判断是否为NULL 不释放内存会造成内存泄漏：堆内存需要手动释放，当程序运行结束不释放，这段内存就会被一直占用。如果 一直在分配不释放会一直占用计算机的内存，直到内存被占完。将new与delete配套使用，使用工具检测或者打印出堆信息  自动垃圾回收（GC）  在程序运行过程中自动释放没有用的数据所在的堆空间（垃圾回收).在虚拟内存空间中能从栈或者数据段的根节点追踪不到的数据为没用的数据 （内存垃圾），常用的算法：标记法, 计数法  标记法回收  标记法：将栈或者数据段作为根（root）进行追踪,将能追踪得的数据（堆空间）进行标记。没有被标记的数据 （堆空间）就是垃圾，将这部分垃圾进行回收。三色抽象：   垃圾回收开始时，将所有数据为白色 垃圾回收开始时，将所有的栈或者数据段的根节点设置为灰色 在根据根节点进行追踪，直到所有的数据节点追踪结束后将根节点置为黑色，在将根节点的下一节点作为根节点进行追踪 所有的数据节点都追踪完后，会剩下黑色和白色的数据节点。黑色表示有用的数据。白色为无用的数据。将白色的数据进行回收（堆空间的释放） \r   标记法实现简单，但是会造成内存的碎片化(内存块中是可使用小内存块，造成大内存块不能使用这块内存，这些小小内存块也不能使用) 因为内存碎片化的问题诞生了   标记整理法，就是标记法之后，将有用的数据堆内存空间移动在一起，释放更多连续的堆空间,但是这种做法带来 很大的开销，因为需要不断的扫描内存和移动内存 复制回收法。将堆内存分为from和To两个相同的堆内存空间。程序执行时，使用from的堆空间。垃圾回收时会扫描from 的堆内存空间，将有用的数据复制到To的堆空间上。垃圾回收结束时，将To堆空间设置为From堆空间。将原来的from 堆空间全部回收后置为Ton堆空间。但是复制回收法只会使用一般的堆内存空间，造成堆内存空间利用率不高 \r 分代法回收：大部分对象都会在年轻时候死亡（弱分代假说）把新建的对象称之为新生代对象。经过特定次数的GC(垃圾回收)数据依然有用的对象称为 老年代对象。而大部分会在新生代对象就会垃圾回收了，在结合复制回收法使用 \r  计数法回收  引用计数指的是对象被引用的次数，程序在运行过程中会更新引用次数。对象引用越多，计数越大，当计数为0时，回收该对象（堆内存空间） 引用计数法可以在运行中更新对象的计数，可以及时判断计数为 0的对象，然后对其及时回收， 但是频繁的更新引用计数也会带来资源消耗 \r  垃圾回收模式  增量式的垃圾回收模式：SWT是用户承程序停下工作处理垃圾回收，但是为了提高cpu执行效率，会减少SWT的时间，经垃圾回收工作分多次进行（用户程序与垃圾回收交替执行） 三色不变式：在增量式垃圾回收模式在进行垃圾回收时，会造成用户程序对标色的数据进行更改，当在次执行垃圾回收时，可能会将有用的数据当作垃圾回收了，在标色法中，当黑色数据节点可以引用白色的数据节点，但是没有灰色节点能引用这个白色节点，白色数据节点就被当作垃圾被回收 避免这样的发生，在垃圾回收时建立读写屏障。在三色中确保黑色的数据节点不引用白色的数据节点，就不会误判有用的数据当作垃圾回收了，这种叫做：强三色不变式 如果当黑色的数据节点能引用白色数据节点，同时确保回收节点也能引用白色节点，也能避免有用的数据被当作垃圾回收，这叫：弱三色不变式 \r 并行垃圾回收：在多核下，使用多线程对垃圾回收，需要做好的负载均衡和规避数重复处理带来的问题，如在复制回收中，可能将同样的数据从from复制到to 并发垃圾回收：垃圾回收与用户程序并发执行，可能会造成垃圾回收与用户程序的资源竞争等问题等 主体并发回收：在时刻使用swt回收，在莫时刻又使用并发垃圾回收 主体并发增量式回收: 是融合了增量式的垃圾回收模式和主体并发回收模式 \r  参考文献 1.https://www.zhihu.com/people/kylin-lab\n","date":"2021-10-18T22:00:38+08:00","image":"https://zcj-git520.github.io/p/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/6_hu61bd622d583377d86db238f2ea3bdaa9_262966_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","title":"内存管理"},{"content":"go Channel  （Do not communicate by sharing memory; instead, share memory by communicating）  CSP并发模型  CSP 即通信顺序进程、交谈循序程序，又被译为交换消息的循序程序(communicating sequential processes)，它是一种用来描述并发性系统之间进行交互的模型。 go Channe是一种特殊的类型，是有特定类型的队列。是链接goroutine(协程)的通信机制，通过通信共享内存而不是通过共享内存而实现通信. Channel 收发操作均遵循了先进先出的设计，具体规则如下：  先从 Channel 读取数据的 Goroutine 会先接收到数据； 先向 Channel 发送数据的 Goroutine 会得到先发送数据的权利；    \r\nchannel 数据结构定义： type hchan struct { // 队列中存储的数量 qcount uint // total data in the queue //环形队列的大小(最大存储数量 ) dataqsiz uint // size of the circular queue // 存放环形队列的数据，数组 buf unsafe.Pointer // points to an array of dataqsiz elements // 元素的大小 elemsize uint16 // 是否关闭的标识 closed uint32 // 元素的类型(指向类型的元数据 ) elemtype *_type // element type // 当前发送数据在环形队列的索引 sendx uint // send index // 当前接受数据在环形队列的索引 recvx uint // receive index // 接收者等待队列（\u0026lt;-ch）阻塞在channel的协程队列 recvq waitq // list of recv waiters // 发送者等待队列（ch\u0026lt;- data）阻塞在channel的协程队列 sendq waitq // list of send waiters //锁保护hchan中的所有字段，以及几个 //在这个通道上阻塞sudogs中的字段 //保持这个锁时不要改变另一个G的状态 //(特别是，不要准备一个G)，因为这可能会死锁 //栈收缩。 lock mutex // 保护hchan中的所有字段，保持协程的状态不被更改，避免造成栈收缩引起的死锁，使用互斥锁解决程序中可能存在的线程竞争问题是很常见的 } 发送者/接收者等待队列的结构：一个双向链表 type waitq struct { first *sudog last *sudog } channel sudog(等待队列)结构如下 type sudog struct { // The following fields are protected by the hchan.lock of the // channel this sudog is blocking on. shrinkstack depends on // this for sudogs involved in channel ops. //以下字段受hchan保护。锁的 //这个sudog正在阻塞。shrinkstack取决于 //这是为涉及通道操作的sudogs。 g *g // 等待的协程协程 next *sudog prev *sudog // 数据元素(可以指向堆栈)，等待发送/接收的数据 elem unsafe.Pointer // data element (may point to stack) // The following fields are never accessed concurrently. // For channels, waitlink is only accessed by g. // For semaphores, all fields (including the ones above) // are only accessed when holding a semaRoot lock. //下面的字段永远不会并发访问。 //对于通道，waitlink只被g访问。 //对于信号量，所有的字段(包括上面的字段) //只在持有semaRoot锁时访问。 acquiretime int64 releasetime int64 ticket uint32 // isSelect indicates g is participating in a select, so // g.selectDone must be CAS'd to win the wake-up race. // 表示g被选择 isSelect bool // success indicates whether communication over channel c // succeeded. It is true if the goroutine was awoken because a // value was delivered over channel c, and false if awoken // because c was closed. //成功表示是否通过通道c通信 // 成功了。 如果 goroutine 被唤醒是因为一个 // 值通过通道 c 传递，如果被唤醒则返回 false // 因为 c 被关闭了 success bool // c 因关闭而唤醒 parent *sudog // semaRoot binary tree waitlink *sudog // g.waiting list or semaRoot waittail *sudog // semaRoot // 等待的channel被唤醒 c *hchan // channel }  结构如图所示 \r  channel 创建  channel 和 切片、map一样，需要使用make(chan type, int )才能使用,应为make()会调用makeChan()初始化  makech函数源码如下: // 参数类型：创建chan的类型和环型缓冲区的数量 func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size \u0026gt;= 1\u0026lt;\u0026lt;16 { throw(\u0026quot;makechan: invalid channel element type\u0026quot;) } if hchanSize%maxAlign != 0 || elem.align \u0026gt; maxAlign { throw(\u0026quot;makechan: bad alignment\u0026quot;) } //判断环型缓冲区是否溢出 mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u0026gt; maxAlloc-hchanSize || size \u0026lt; 0 { panic(plainError(\u0026quot;makechan: size out of range\u0026quot;)) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG's are referenced from their owning thread so they can't be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch { case mem == 0: // Queue or element size is zero. // 当队列或者元素大小为0时，定义无缓冲chan（同步chan） c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. // Race 竞争检查利用这个地址来进行同步操作 c.buf = c.raceaddr() case elem.ptrdata == 0: // Elements do not contain pointers. // Allocate hchan and buf in one call. // 元素不包含指针时。一次分配 hchan 和 buf 的内存。 c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers. // 定义带缓存的chan或者异步的chan c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) // chan元素的大小 c.elemtype = elem // chan元素的类型 c.dataqsiz = uint(size) // chan缓存区大小 lockInit(\u0026amp;c.lock, lockRankHchan) //初始化互斥锁 if debugChan { print(\u0026quot;makechan: chan=\u0026quot;, c, \u0026quot;; elemsize=\u0026quot;, elem.size, \u0026quot;; dataqsiz=\u0026quot;, size, \u0026quot;\\n\u0026quot;) } return c }  channel创建过程：   编译检查、缓冲区大小检查，判断是否溢出 判断chan的类型\n1、当创建无缓冲chan时,调用mallocgc()在堆上为chan开辟hchanSize的buf缓存内存空间\n2、创建带缓冲的chan时,判断元素的类型是否为指针类型，若不是，则mallocgc()在堆上为chan和buf缓冲区数组开辟一段大小为 hchanSize+mem连续的内存空间。若是则调用mallocgc()在堆上分别为chan和buf缓冲区分配连续内存空间。 \r  channel 发送数据与接收数据 channel 发送数据  chan \u0026lt;- data  chan发送数据源码如下: func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool { // 判断chan是否被初始化，向chan为nil的chan发送数据将会永久阻塞 if c == nil { if !block { return false } // 使当前的groutine休眠 gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(\u0026quot;unreachable\u0026quot;) } if debugChan { print(\u0026quot;chansend: chan=\u0026quot;, c, \u0026quot;\\n\u0026quot;) } // 检查在没有获取锁的情况下会导致发送失败的非阻塞操作 if raceenabled { racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) } // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from 'ready for sending' to // 'not ready for sending', even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn't closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread's view of c.closed and full(). if !block \u0026amp;\u0026amp; c.closed == 0 \u0026amp;\u0026amp; full(c) { return false } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } // 获得同步锁 lock(\u0026amp;c.lock) // 当chan关闭时,释放锁，并panic // 向也关闭的chan发送消息,会引发panic if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026quot;send on closed channel\u0026quot;)) } // 如果接收队列中有等待的接收者，直接发送给接收者（有缓存区时，会绕过缓存区） if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } if c.qcount \u0026lt; c.dataqsiz { // 没有接收者，当有缓存区时，将要发送的元素放入队列中 // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) // 获取缓存地址 if raceenabled { racenotify(c, c.sendx, nil) } typedmemmove(c.elemtype, qp, ep) c.sendx++ // 指向下一个存储的位置 if c.sendx == c.dataqsiz { c.sendx = 0 } c.qcount++ // 缓存数量相加 unlock(\u0026amp;c.lock) return true } if !block { unlock(\u0026amp;c.lock) return false } // 缓存区满了，将当前发送协程加入到等待send队列 // Block on the channel. Some receiver will complete our operation for us. gp := getg() // 获取当前的g发送协程 mysg := acquireSudog()// 创建sudog等待队列 mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil // 把当前的发送协程与等待队列绑定 mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil // 加入到发送等待队列中 c.sendq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we're about // to park on a channel. The window between when this G's status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren't considered as roots of the // stack tracer. KeepAlive(ep) // someone woke us up. // 发送协程被唤醒，解除等待队列的阻塞状态 // 判断的等待队列是否在休眠 if mysg != gp.waiting { throw(\u0026quot;G waiting list is corrupted\u0026quot;) } gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } mysg.c = nil releaseSudog(mysg) // 释放等待队列 if closed { if c.closed == 0 { throw(\u0026quot;chansend: spurious wakeup\u0026quot;) } panic(plainError(\u0026quot;send on closed channel\u0026quot;)) } return true }  channel 发送数据总结   判断chan是否被初始化，向chan为nil的chan发送数据将会永久阻塞 检查在没有获取锁， 在没有获取锁的情况下会导致发送失败的非阻塞操作 检查chan是否关闭，向也关闭的chan发送消息,会引发panic 如果接收队列中有等待的接收者，直接发送给接收者（有缓存区时，会绕过缓存区） 没有接收者，当有缓存区时，将要发送的元素放入队列中 缓存区满了，将当前协程加入到send等待队列，并阻塞 当发送协程被唤醒，解除等待队列的阻塞状态，释放等待队列 \r  channel 接收数据  \u0026lt;- data  chan 接收数据源码如下: func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) { // raceenabled: don't need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan { print(\u0026quot;chanrecv: chan=\u0026quot;, c, \u0026quot;\\n\u0026quot;) } // 判断chan是否初始化，若没有初始化，接收channel数据将阻塞 if c == nil { if !block { return } gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(\u0026quot;unreachable\u0026quot;) } // 检查chan是否为空，是否关闭 // Fast path: check for failed non-blocking operation without acquiring the lock. if !block \u0026amp;\u0026amp; empty(c) { // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate \u0026quot;open and empty\u0026quot;. To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. if atomic.Load(\u0026amp;c.closed) == 0 { // chan关闭，就返回 // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. return } // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. if empty(c) { // 如果chan为空 // The channel is irreversibly closed and empty. // // channel 不可逆的关闭了且为空 if raceenabled { raceacquire(c.raceaddr()) } if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } } var t0 int64 if blockprofilerate \u0026gt; 0 { t0 = cputicks() } lock(\u0026amp;c.lock) // chan 关闭了，清理缓冲区 if c.closed != 0 \u0026amp;\u0026amp; c.qcount == 0 { if raceenabled { raceacquire(c.raceaddr()) } unlock(\u0026amp;c.lock) if ep != nil { typedmemclr(c.elemtype, ep) } return true, false } // 找到一个等待的发件人。如果缓冲区大小为 0，则直接从发送方接收值。否则，从队列的头部接收 // 并将发送者的值添加到队列的尾部（两者都映射到 // 相同的缓冲区槽，因为队列已满） // 如果是无缓冲队列，直接从发送方取值 // 如果是待缓冲的区，就从缓冲区头部获取值，并将发送着的值保存在缓冲区后 if sg := c.sendq.dequeue(); sg != nil { // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender's value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true, true } // 没有发送的协程，但是缓冲区有元素，直接获取缓冲区头部的值 if c.qcount \u0026gt; 0 { // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled { racenotify(c, c.recvx, nil) } if ep != nil { typedmemmove(c.elemtype, ep, qp) } typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz { c.recvx = 0 } c.qcount-- unlock(\u0026amp;c.lock) return true, true } if !block { unlock(\u0026amp;c.lock) return false, false } // 当没有发送数据的的协程，且缓冲区值，就将接收的协程放入等待队列中 // no sender available: block on this channel. gp := getg() // 获取当前接收协程 mysg := acquireSudog() // 创建等待队列 mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg // 将接送写协程与等待队列绑定 mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil // 放入在协程的等待队列中 c.recvq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we're about // to park on a channel. The window between when this G's status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(\u0026amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(\u0026amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) //当接收协程被唤醒时，解除阻塞状态 // someone woke us up if mysg != gp.waiting { throw(\u0026quot;G waiting list is corrupted\u0026quot;) } gp.waiting = nil gp.activeStackChans = false if mysg.releasetime \u0026gt; 0 { blockevent(mysg.releasetime-t0, 2) } success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) // 释放等待队列内存 return true, success }  channel 发送数据总结   判断chan是否初始化，若没有初始化，接收channel数据将阻塞 检查chan是否为空，是否关闭 当有发送协程，如果是无缓冲队列，直接从发送方取值,如果是待缓冲的区，就从缓冲区头部获取值，并将发送着的值保存在缓冲区后 当没有发送协程，但是有缓冲区有元素，直接获取缓冲区头部的值 当没有发送数据的的协程，且缓冲区值，就将接收的协程放入等待队列中 当接收协程被唤醒时，解除阻塞状态，释放等待队列内存 \r  channel 关闭  close(chan)  chan 关闭源码如下: func closechan(c *hchan) { // 判断chan是否初始化，没有初始化，关闭没有初始化的chan,直接panic if c == nil { panic(plainError(\u0026quot;close of nil channel\u0026quot;)) } // 判断chan是否也被关闭，关闭也关闭的chan,也会发送panic lock(\u0026amp;c.lock) if c.closed != 0 { unlock(\u0026amp;c.lock) panic(plainError(\u0026quot;close of closed channel\u0026quot;)) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) } c.closed = 1 var glist gList // 释放所有的接收chan，并将所有的接收队列加入到待清除队列 glist 中 // release all readers for { sg := c.recvq.dequeue() if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } // 释放所有的发送chan,发送者的等待队列 sendq 中的 sudog 放入待清除队列 glist 中 // release all writers (they will panic) for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026amp;c.lock) 最后会为所有被阻塞的 goroutine 调用 goready 触发调度。将所有 glist 中的 goroutine 状态从 _Gwaiting 设置为 _Grunnable 状态，等待调度器的调度。 // Ready all Gs now that we've dropped the channel lock. for !glist.empty() { gp := glist.pop() gp.schedlink = 0 goready(gp, 3) } }  channel 关闭总结   判断chan是否初始化，没有初始化，关闭没有初始化的chan,直接panic 判断chan是否也被关闭，关闭也关闭的chan,也会发送panic 先释放所有的接收chan，并将所有的接收队列加入到待清除队列 glist 中 释放所有的发送chan,发送者的等待队列 sendq 中的 sudog 放入待清除队列 glist 中 最后会为所有被阻塞的 goroutine 调用 goready 触发调度。将所有 glist 中的goroutine 状态从 _Gwaiting 设置为 _Grunnable 状态，等待调度器的调度。  ","date":"2021-10-15T22:00:38+08:00","image":"https://zcj-git520.github.io/p/go-channel%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/3_huc32f323c0433538c753e80bb5a9a01bb_276268_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/go-channel%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/","title":"Go Channel的深入理解"},{"content":"问题  在收集服务的访问记录时，需要将访问记录保存，定义结构体如下    type accessData struct { RemoteAddr string // 远程访问主机地址 RequestURI string //访问的路由 ServerName string // 访问的服务名称 AccessDate string //访问的时间 RunStatus bool //服务是否正常运行 RunError error //运行报错：报错信息. ServerParam interface{} // 访问服务的参数 }   通过结构体转json，同时通过get请求得到图下结果 \r\n  \u0026ldquo;RunError\u0026rdquo;: {},被json转为{}的字符， 打印结构体，发现错误信息是有的：{192.168.1.101:53364 /v1/alarms/out/d GetOutAlarms 2021-10-12 10:09:42 false 没有这个报警🆔id },说明是error 转json问题\n问题分析与解决  问题分析查看error类型定义发现：error类型只是一个接口。它可以包含任何实现它的具体类型的值 解决：将结构体中错误转化为字符串类型，同时用err.Error()返回是错误的字符串  type accessData struct { RemoteAddr string // 远程访问主机地址 RequestURI string //访问的路由 ServerName string // 访问的服务名称 AccessDate string //访问的时间 RunStatus bool //服务是否正常运行 RunError string //运行报错：报错信息. ServerParam interface{} // 访问服务的参数 } type error interface { Error() string }   结果如图\n  \r\n  ","date":"2021-10-09T22:00:38+08:00","image":"https://zcj-git520.github.io/p/golang/2_hu3607656af67f333528ae9e7b0ed06a62_30106_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/golang/","title":"go error类型转json"},{"content":"go 协程goroutine  协程是用户级的线程，有用户自己调度，使用协程使得程序调度更加灵活。同时比线程更轻量，占用的栈内存更少。go语言天生支持高并发，go使用协程goroutine的调度器。goroutine 的栈内存最小值为2kb(_StackMin = 2048),它不是固定不变的，可以随需求增大和缩小。goroutine 维护着很大的内存，无需频繁开辟内存，goroutine是使用M:n模型，在用户态切换协程，加上创建协程代价低，使得cpu的利用率大大提升，cup的性能大幅度的被利用。  goroutine 调度器GPM模型 G  G 就是goroutine协程  type g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). // 记录该goroutine使用的栈 stack stack // offset known to runtime/cgo //下面两个成员用于栈溢出检查，实现栈的自动伸缩，抢占调度也会用到stackguard0 stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink _panic *_panic // innermost panic - offset known to liblink _defer *_defer // innermost defer // 此goroutine正在被哪个工作线程执行 m *m // current m; offset known to arm liblink //这个字段跟调度切换有关，G切换时用来保存上下文，保存什么，看下面gobuf结构体 sched gobuf syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc stktopsp uintptr // expected sp at top of stack, to check in traceback param unsafe.Pointer // passed parameter on wakeup，wakeup唤醒时传递的参数 // 状态Gidle,Grunnable,Grunning,Gsyscall,Gwaiting,Gdead atomicstatus uint32 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus goid int64 //schedlink字段指向全局运行队列中的下一个g， //所有位于全局运行队列中的g形成一个链表 schedlink guintptr waitsince int64 // approx time when the g become blocked waitreason waitReason // if status==Gwaiting，g被阻塞的原因 //抢占信号，stackguard0 = stackpreempt，如果需要抢占调度，设置preempt为true preempt bool // preemption signal, duplicates stackguard0 = stackpreempt paniconfault bool // panic (instead of crash) on unexpected fault address preemptscan bool // preempted g does scan for gc gcscandone bool // g has scanned stack; protected by _Gscan bit in status gcscanvalid bool // false at start of gc cycle, true if G has not run since last scan; TODO: remove? throwsplit bool // must not split stack raceignore int8 // ignore race detection events sysblocktraced bool // StartTrace has emitted EvGoInSyscall about this goroutine sysexitticks int64 // cputicks when syscall has returned (for tracing) traceseq uint64 // trace event sequencer tracelastp puintptr // last P emitted an event for this goroutine // 如果调用了 LockOsThread，那么这个 g 会绑定到某个 m 上 lockedm muintptr sig uint32 writebuf []byte sigcode0 uintptr sigcode1 uintptr sigpc uintptr // 创建这个goroutine的go表达式的pc gopc uintptr // pc of go statement that created this goroutine ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) startpc uintptr // pc of goroutine function racectx uintptr waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order cgoCtxt []uintptr // cgo traceback context labels unsafe.Pointer // profiler labels timer *timer // cached timer for time.Sleep,为 time.Sleep 缓存的计时器 selectDone uint32 // are we participating in a select and did someone win the race? // Per-G GC state // gcAssistBytes is this G's GC assist credit in terms of // bytes allocated. If this is positive, then the G has credit // to allocate gcAssistBytes bytes without assisting. If this // is negative, then the G must correct this by performing // scan work. We track this in bytes to make it fast to update // and check for debt in the malloc hot path. The assist ratio // determines how this corresponds to scan work debt. gcAssistBytes int64 }  保存着goroutine所有信息以及栈信息，gobuf结构体：cpu里的寄存器信息  P processor处理器  调度协程G和线程M的关联  P 的结构体如下： type p struct { //allp中的索引 id int32 //p的状态 status uint32 // one of pidle/prunning/... link puintptr schedtick uint32 // incremented on every scheduler call-\u0026gt;每次scheduler调用+1 syscalltick uint32 // incremented on every system call-\u0026gt;每次系统调用+1 sysmontick sysmontick // last tick observed by sysmon //指向绑定的 m，如果 p 是 idle 的话，那这个指针是 nil m muintptr // back-link to associated m (nil if idle) mcache *mcache raceprocctx uintptr //不同大小可用defer结构池 deferpool [5][]*_defer // pool of available defer structs of different sizes (see panic.go) deferpoolbuf [5][32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. goidcache uint64 goidcacheend uint64 //本地运行队列，可以无锁访问 // Queue of runnable goroutines. Accessed without lock. runqhead uint32 //队列头 runqtail uint32 //队列尾 //数组实现的循环队列 runq [256]guintptr // runnext, if non-nil, is a runnable G that was ready'd by // the current G and should be run next instead of what's in // runq if there's time remaining in the running G's time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready'd // goroutines to the end of the run queue. // runnext 非空时，代表的是一个 runnable 状态的 G， //这个 G 被 当前 G 修改为 ready 状态，相比 runq 中的 G 有更高的优先级。 //如果当前 G 还有剩余的可用时间，那么就应该运行这个 G //运行之后，该 G 会继承当前 G 的剩余时间 runnext guintptr // Available G's (status == Gdead) //空闲的g gFree struct { gList n int32 } sudogcache []*sudog sudogbuf [128]*sudog tracebuf traceBufPtr // traceSweep indicates the sweep events should be traced. // This is used to defer the sweep start event until a span // has actually been swept. traceSweep bool // traceSwept and traceReclaimed track the number of bytes // swept and reclaimed by sweeping in the current sweep loop. traceSwept, traceReclaimed uintptr palloc persistentAlloc // per-P to avoid mutex _ uint32 // Alignment for atomic fields below // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker (atomic) gcBgMarkWorker guintptr // (atomic) gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which this mark // worker started. gcMarkWorkerStartTime int64 // gcw is this P's GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork // wbBuf is this P's GC write barrier buffer. // // TODO: Consider caching this in the running G. wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point pad cpu.CacheLinePad }  记录着P的信息，以及G的状态等。同时P是有着本地队列，存放着带待运行的G,本地队列不能超过256个。 P的数量：是由环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。在程序启动式创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个  M 是内核态线程的抽象  主要的工作执行协程G或者在调度G到P中  M的结构体如下： type m struct { // 系统管理的一个g，执行调度代码时使用的。比如执行用户的goroutine时，就需要把把用户 // 的栈信息换到内核线程的栈，以便能够执行用户goroutine g0 *g // goroutine with scheduling stack morebuf gobuf // gobuf arg to morestack divmod uint32 // div/mod denominator for arm - known to liblink // Fields not known to debuggers. procid uint64 // for debuggers, but offset not hard-coded //处理signal的 g gsignal *g // signal-handling g goSigStack gsignalStack // Go-allocated signal handling stack sigmask sigset // storage for saved signal mask //线程的本地存储TLS，这里就是为什么OS线程能运行M关键地方 tls [6]uintptr // thread-local storage (for x86 extern register) //go 关键字运行的函数 mstartfn func() //当前运行的用户goroutine的g结构体对象 curg *g // current running goroutine caughtsig guintptr // goroutine running during fatal signal //当前工作线程绑定的P，如果没有就为nil p puintptr // attached p for executing go code (nil if not executing go code) //暂存与当前M潜在关联的P nextp puintptr //M之前调用的P oldp puintptr // the p that was attached before executing a syscall id int64 mallocing int32 throwing int32 //当前M是否关闭抢占式调度 preemptoff string // if != \u0026quot;\u0026quot;, keep curg running on this m locks int32 dying int32 profilehz int32 //M的自旋状态，为true时M处于自旋状态，正在从其他线程偷G; 为false，休眠状态 spinning bool // m is out of work and is actively looking for work blocked bool // m is blocked on a note newSigstack bool // minit on C thread called sigaltstack printlock int8 incgo bool // m is executing a cgo call freeWait uint32 // if == 0, safe to free g0 and delete m (atomic) fastrand [2]uint32 needextram bool traceback uint8 ncgocall uint64 // number of cgo calls in total ncgo int32 // number of cgo calls currently in progress cgoCallersUse uint32 // if non-zero, cgoCallers in use temporarily cgoCallers *cgoCallers // cgo traceback if crashing in cgo call //没有goroutine运行时，工作线程睡眠 //通过这个来唤醒工作线程 park note // 休眠锁 //记录所有工作线程的链表 alllink *m // on allm schedlink muintptr //当前线程内存分配的本地缓存 mcache *mcache //当前M锁定的G， lockedg guintptr createstack [32]uintptr // stack that created this thread. lockedExt uint32 // tracking for external LockOSThread lockedInt uint32 // tracking for internal lockOSThread nextwaitm muintptr // next m waiting for lock waitunlockf func(*g, unsafe.Pointer) bool waitlock unsafe.Pointer waittraceev byte waittraceskip int startingtrace bool syscalltick uint32 //操作系统线程id thread uintptr // thread handle freelink *m // on sched.freem // these are here because they are too large to be on the stack // of low-level NOSPLIT functions. libcall libcall libcallpc uintptr // for cpu profiler libcallsp uintptr libcallg guintptr syscall libcall // stores syscall parameters on windows vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call) vdsoPC uintptr // PC for traceback while in VDSO call dlogPerM mOS }  记录着M的线程的信息，包括一些P,G以及信号和自旋锁等信息 m 数量：可以通过SetMaxThreads函数，设置 M 的最大数量，默认为10000(sched.maxmcount = 10000)，和P一样在程序启动时创建。  全局队列（gQueue）  P的本地队列可以存放着不超过256个待执行的G,P是有限的，当G过多时，即当P本地队列存放不下时，就需要将G存放在全局队列中。  全局队列结构如下： type gQueue struct { head guintptr //队列头 tail guintptr //队列尾 } G、P、M、gQueue关系  P与M没有数量关系，当一个M处于阻塞时，P先找空闲M,没有空闲的M就创建新的M G优先存放在P本地队列中，当P中G满时，会将P中前一半G存放在全局中。当P空闲时时，会从全局中拿取G放在本地队列。全局没有G时，会从其P的本地队列中拿取一半到本地队列。 关系如图所示：\n\r  创建goroutine newproc()函数  goroutine 是由函数newproc函数进行创建的，newproc源码如下  // 参数：协程函数的参数占的字节数和协程入口函数的funcval指针 func newproc(siz int32, fn *funcval) { // 获得协程参数的地址= fn函数地址+偏移值 argp := add(unsafe.Pointer(\u0026amp;fn), sys.PtrSize) gp := getg() // 获得当前G的指针 //调用者的pc，也就是执行完此函数返回调用者时的下一条指令地址 pc := getcallerpc() // 切换到（系统栈）g0栈中 systemstack(func() { //执行调用newproc1()函数执行创建协程 newg := newproc1(fn, argp, siz, gp, pc) _p_ := getg().m.p.ptr() // 把当前的G存放在runq队列中 runqput(_p_, newg, true) // 如果当前由空闲的P,没有睡眠的M,主协程开始运行时 if mainStarted { wakep() // 创建m,并设置为活跃状态 } }) }  在newproc函数中为什么要切换在g0栈中执行呢？是因为newproc1()函数不支持栈增长，协程的栈空间小(几KB)，为了防止运行协程函数时栈溢出，需要在g0的栈上运行，g0是分配在线程的栈空间(4MB)上。g0的栈空间很大，运行协程函数时栈不溢出。  newproc1()函数  newproc1()是创建协程 源码如下：  参数：协程入口、参数首地址、参数大小、父协程指针、返回地址 func newproc1(fn *funcval, argp unsafe.Pointer, narg int32, callergp *g, callerpc uintptr) *g { _g_ := getg() // 获得当前的G if fn == nil { _g_.m.throwing = -1 // do not dump full stacks throw(\u0026quot;go of nil func value\u0026quot;) } // 为了保证数据一致性会禁止当前m被抢占 acquirem() // disable preemption because it can be holding p in a local var siz := narg siz = (siz + 7) \u0026amp;^ 7 // We could allocate a larger initial stack if necessary. // Not worth it: this is almost always an error. // 4*sizeof(uintreg): extra space added below // sizeof(uintreg): caller's LR (arm) or return address (x86, in gostartcall). if siz \u0026gt;= _StackMin-4*sys.RegSize-sys.RegSize { throw(\u0026quot;newproc: function arguments too large for new goroutine\u0026quot;) } _p_ := _g_.m.p.ptr() // 尝试获取一个空闲的G,如果没有空闲的G,就会创建新的G,分配栈空间,并添加到全局allgs中 newg := gfget(_p_) // 如果没有空闲的G if newg == nil { // 就会创建新的G,分配栈空间大小为最小的2KB newg = malg(_StackMin) // 设置状态为等待 casgstatus(newg, _Gidle, _Gdead) //并添加到全局allgs中 allgadd(newg) // publishes with a g-\u0026gt;status of Gdead so GC scanner doesn't look at uninitialized stack. } if newg.stack.hi == 0 { throw(\u0026quot;newproc1: newg missing stack\u0026quot;) } if readgstatus(newg) != _Gdead { throw(\u0026quot;newproc1: new g is not Gdead\u0026quot;) } totalSize := 4*sys.RegSize + uintptr(siz) + sys.MinFrameSize // extra space in case of reads slightly beyond frame totalSize += -totalSize \u0026amp; (sys.SpAlign - 1) // align to spAlign sp := newg.stack.hi - totalSize spArg := sp if usesLR { // caller's LR *(*uintptr)(unsafe.Pointer(sp)) = 0 prepGoExitFrame(sp) spArg += sys.MinFrameSize } if narg \u0026gt; 0 { // 如果协程入口函数由参数，会将参数移动在协程栈中 memmove(unsafe.Pointer(spArg), argp, uintptr(narg)) // This is a stack-to-stack copy. If write barriers // are enabled and the source stack is grey (the // destination is always black), then perform a // barrier copy. We do this *after* the memmove // because the destination stack may have garbage on // it. if writeBarrier.needed \u0026amp;\u0026amp; !_g_.m.curg.gcscandone { f := findfunc(fn.fn) stkmap := (*stackmap)(funcdata(f, _FUNCDATA_ArgsPointerMaps)) if stkmap.nbit \u0026gt; 0 { // We're in the prologue, so it's always stack map index 0. bv := stackmapdata(stkmap, 0) bulkBarrierBitmap(spArg, spArg, uintptr(bv.n)*sys.PtrSize, 0, bv.bytedata) } } } // 初始化newg.sched调度相关的信息 memclrNoHeapPointers(unsafe.Pointer(\u0026amp;newg.sched), unsafe.Sizeof(newg.sched)) newg.sched.sp = sp //设置为协程栈指针 newg.stktopsp = sp // 设置为指向协程入口函数的入口，当协程调度执行时，运行协程函数 newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function newg.sched.g = guintptr(unsafe.Pointer(newg)) gostartcallfn(\u0026amp;newg.sched, fn) // 设置为父协程调用newproc函数结束后的返回地址 newg.gopc = callerpc newg.ancestors = saveAncestors(callergp) // 设置startpc为协程入孔函数的起始地址 newg.startpc = fn.fn if _g_.m.curg != nil { newg.labels = _g_.m.curg.labels } if isSystemGoroutine(newg, false) { atomic.Xadd(\u0026amp;sched.ngsys, +1) } // 设置协程为运行状态 casgstatus(newg, _Gdead, _Grunnable) if _p_.goidcache == _p_.goidcacheend { // Sched.goidgen is the last allocated id, // this batch must be [sched.goidgen+1, sched.goidgen+GoidCacheBatch]. // At startup sched.goidgen=0, so main goroutine receives goid=1. _p_.goidcache = atomic.Xadd64(\u0026amp;sched.goidgen, _GoidCacheBatch) _p_.goidcache -= _GoidCacheBatch - 1 _p_.goidcacheend = _p_.goidcache + _GoidCacheBatch } // 给协程赋予一个唯一的goid newg.goid = int64(_p_.goidcache) _p_.goidcache++ if raceenabled { newg.racectx = racegostart(callerpc) } if trace.enabled { traceGoCreate(newg, newg.startpc) } // 允许当前m被抢占 releasem(_g_.m) return newg } 图示如下\n\r\n 总结goroutine创建过程   为了保证数据一致性会禁止当前m被抢占 尝试获取一个空闲的G,如果没有空闲的G,就会创建新的G,分配栈空间,状态为等待并添加到全局allgs中 如果协程入口函数由参数，会将参数移动在协程栈中 初始化newg.sched调度相关的信息，设置状态运行 得到唯一的goid, 并添加到runq队列中 如果当前有空闲的P,没有睡眠的M,并且主协程开始运行时，就会创建新的活跃的M 当g运行结束后，设置允许当前m被抢占  goroutine的让出与恢复、调度、抢占、监控 goroutine 让出与恢复  协程的让出是由函数gopark()执行的  源码如下： func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) { if reason != waitReasonSleep { checkTimeouts() // timeouts may expire while two goroutines keep the scheduler busy } // 禁止当前m被抢占 mp := acquirem() gp := mp.curg status := readgstatus(gp) // 判断协程的是否在运行状态 if status != _Grunning \u0026amp;\u0026amp; status != _Gscanrunning { throw(\u0026quot;gopark: bad g status\u0026quot;) } mp.waitlock = lock mp.waitunlockf = unlockf gp.waitreason = reason mp.waittraceev = traceEv mp.waittraceskip = traceskip // 解除对m的抢占 releasem(mp) // can't do anything that might move the G between Ms here. // 不能做任何可能在 Ms 之间移动 G 的事情。 // 保存协程，切换在go mcall(park_m) } func park_m(gp *g) { _g_ := getg() if trace.enabled { traceGoPark(_g_.m.waittraceev, _g_.m.waittraceskip) } //更改协程由运行状态到等待状态 casgstatus(gp, _Grunning, _Gwaiting) dropg() \u0026quot;\u0026quot;\u0026quot; func dropg() { _g_ := getg() // 把m当前执行的置为nil(m不在运行这个当前写协程，协程就挂起了) setMNoWB(\u0026amp;_g_.m.curg.m, nil) setGNoWB(\u0026amp;_g_.m.curg, nil) } \u0026quot;\u0026quot;\u0026quot; if fn := _g_.m.waitunlockf; fn != nil { ok := fn(gp, _g_.m.waitlock) _g_.m.waitunlockf = nil _g_.m.waitlock = nil if !ok { if trace.enabled { traceGoUnpark(gp, 2) } casgstatus(gp, _Gwaiting, _Grunnable) execute(gp, true) // Schedule it back, never returns. } } schedule() // 寻找下一个G } //在G中由定时调用回调函数f type timer struct { // If this timer is on a heap, which P's heap it is on. // puintptr rather than *p to match uintptr in the versions // of this struct defined in other packages. pp puintptr // Timer wakes up at when, and then at when+period, ... (period \u0026gt; 0 only) // each time calling f(arg, now) in the timer goroutine, so f must be // a well-behaved function and not block. // // when must be positive on an active timer. when int64 period int64 f func(interface{}, uintptr) arg interface{} seq uintptr // What to set the when field to in timerModifiedXX status. nextwhen int64 // The status field holds one of the values below. status uint32 } // Mark gp ready to run. // 将等待协程状态置为运行的状态 func ready(gp *g, traceskip int, next bool) { if trace.enabled { traceGoUnpark(gp, traceskip) } status := readgstatus(gp) // Mark runnable. _g_ := getg() //// 禁止当前m被抢占 mp := acquirem() // disable preemption because it can be holding p in a local var if status\u0026amp;^_Gscan != _Gwaiting { dumpgstatus(gp) throw(\u0026quot;bad g-\u0026gt;status in ready\u0026quot;) } // status is Gwaiting or Gscanwaiting, make Grunnable and put on runq casgstatus(gp, _Gwaiting, _Grunnable) // 把协程等待的转态置为可运行状态 runqput(_g_.m.p.ptr(), gp, next) // 添加在运行队列中 wakep()// 如果没有可执行的M,就创建新的m releasem(mp) // 释放当前的m } 如图所示 \r\n 总结   gopark()是让出函数，禁止当前m被抢占，判断当前的协程状态是否为运行状态。 dropg()让当前的m不在执行当前的G,修改当前g的状态为等待(协程挂起)，调用schedule() 寻找下一个可执行G timers 等待的g中数据结构，定时调用回调函数f，将g置为了运行状态 ready()函数是将唤醒等待G,将G的状态更改为可运行状态，并添加在运行的队列中m，如果没有可执行的M,就创建新的m  goroutine 监控  使用checkTimers()检查到时间运行的唤醒g  源码如下 checkTimers(pp *p, now int64) (rnow, pollUntil int64, ran bool) { // If it's not yet time for the first timer, or the first adjusted // timer, then there is nothing to do. next := int64(atomic.Load64(\u0026amp;pp.timer0When)) nextAdj := int64(atomic.Load64(\u0026amp;pp.timerModifiedEarliest)) if next == 0 || (nextAdj != 0 \u0026amp;\u0026amp; nextAdj \u0026lt; next) { next = nextAdj } if next == 0 { // No timers to run or adjust. return now, 0, false } if now == 0 { now = nanotime() } if now \u0026lt; next { // Next timer is not ready to run, but keep going // if we would clear deleted timers. // This corresponds to the condition below where // we decide whether to call clearDeletedTimers. if pp != getg().m.p.ptr() || int(atomic.Load(\u0026amp;pp.deletedTimers)) \u0026lt;= int(atomic.Load(\u0026amp;pp.numTimers)/4) { return now, next, false } } lock(\u0026amp;pp.timersLock) if len(pp.timers) \u0026gt; 0 { adjusttimers(pp, now) for len(pp.timers) \u0026gt; 0 { // Note that runtimer may temporarily unlock // pp.timersLock. if tw := runtimer(pp, now); tw != 0 { if tw \u0026gt; 0 { pollUntil = tw } break } ran = true } } // If this is the local P, and there are a lot of deleted timers, // clear them out. We only do this for the local P to reduce // lock contention on timersLock. if pp == getg().m.p.ptr() \u0026amp;\u0026amp; int(atomic.Load(\u0026amp;pp.deletedTimers)) \u0026gt; len(pp.timers)/4 { clearDeletedTimers(pp) } unlock(\u0026amp;pp.timersLock) return now, pollUntil, ran }  协程的监控是由专门的监控协程程来运行，监控协程是由主协程创建而来 ，监控协程与gpm中的协程不一样，它不是由gpm进行调度，当然了也不需要P, 监控timer，并按需调整g的休眠时间，如果没有可执行的M,就创建新的m执行被唤醒的G, 确保被唤醒g被执行。 如图 \r  goroutine 抢占  对运行过长的g进行抢占，即当g运行时间超过运行阈值的g强制让出m 运行时间是由P的结构syscalltick、schedtick、timer0When等记录。 通过栈增长时：当stackguard = stackPreempt,不执行栈增长，而是执行协程调度, 这样就让协程让出栈。 这种抢占依赖栈增长，有缺陷。所以有asyncPreempt通过信号方式进行异步抢占\n如图所示 \r  goroutine 调度  调用schedule()函数进行协程的调度  源码如下： func schedule() { _g_ := getg() // 获得当前的G if _g_.m.locks != 0 { throw(\u0026quot;schedule: holding locks\u0026quot;) } // 判断当前的M和当前的G是否绑定 if _g_.m.lockedg != 0 { // 如果当前的M绑定G,就阻塞m(休眠M) stoplockedm() execute(_g_.m.lockedg.ptr(), false) // Never returns. } // We should not schedule away from a g that is executing a cgo call, // since the cgo call is using the m's g0 stack. if _g_.m.incgo { throw(\u0026quot;schedule: in cgo\u0026quot;) } top: pp := _g_.m.p.ptr() pp.preempt = false // 判断Gc是否在等待执行 if sched.gcwaiting != 0 { //是在等待执行，先执行gc，执行完在执行后续操作 gcstopm() goto top } if pp.runSafePointFn != 0 { runSafePointFn() } // Sanity check: if we are spinning, the run queue should be empty. // Check this before calling checkTimers, as that might call // goready to put a ready goroutine on the local run queue. if _g_.m.spinning \u0026amp;\u0026amp; (pp.runnext != 0 || pp.runqhead != pp.runqtail) { throw(\u0026quot;schedule: spinning with local work\u0026quot;) } //检查是否有要被执行的Timer checkTimers(pp, 0) var gp *g var inheritTime bool // Normal goroutines will check for need to wakeP in ready, // but GCworkers and tracereaders will not, so the check must // be done here instead. // 普通的 goroutine 会检查是否需要在准备好时唤醒， // 但 GCworkers 和跟踪读取器不会，所以检查必须 // 在这里完成。 tryWakeP := false if trace.enabled || trace.shutdown { gp = traceReader() if gp != nil { casgstatus(gp, _Gwaiting, _Grunnable) traceGoUnpark(gp, 0) tryWakeP = true } } if gp == nil \u0026amp;\u0026amp; gcBlackenEnabled != 0 { gp = gcController.findRunnableGCWorker(_g_.m.p.ptr()) tryWakeP = tryWakeP || gp != nil } if gp == nil { // Check the global runnable queue once in a while to ensure fairness. // Otherwise two goroutines can completely occupy the local runqueue // by constantly respawning each other. / 每隔一段时间检查一下全局可运行队列以确保公平。 // 否则两个 goroutine 可以完全占用本地运行队列 // 通过不断相互重生。 // 有%61的概率把G从全局运行队列中搬移到本地可运行队列，保障本地可运行队列 有G运行，全局队列也能放在本都队列中 if _g_.m.p.ptr().schedtick%61 == 0 \u0026amp;\u0026amp; sched.runqsize \u0026gt; 0 { lock(\u0026amp;sched.lock) gp = globrunqget(_g_.m.p.ptr(), 1) unlock(\u0026amp;sched.lock) } } if gp == nil { // 没有待运行的G 就现在本地可运行队列查找 gp, inheritTime = runqget(_g_.m.p.ptr()) // We can see gp != nil here even if the M is spinning, // if checkTimers added a local goroutine via goready. } if gp == nil { // 本地队列没有，就调用findrunnable()，直到有待执行的g才返回(先在本地 运行队列，全局队列、等待的io, 其他的P) gp, inheritTime = findrunnable() // blocks until work is available } // This thread is going to run a goroutine and is not spinning anymore, // so if it was marked as spinning we need to reset it now and potentially // start a new spinning M. if _g_.m.spinning { resetspinning() } if sched.disable.user \u0026amp;\u0026amp; !schedEnabled(gp) { // Scheduling of this goroutine is disabled. Put it on // the list of pending runnable goroutines for when we // re-enable user scheduling and look again. lock(\u0026amp;sched.lock) if schedEnabled(gp) { // Something re-enabled scheduling while we // were acquiring the lock. unlock(\u0026amp;sched.lock) } else { sched.disable.runnable.pushBack(gp) sched.disable.n++ unlock(\u0026amp;sched.lock) goto top } } // If about to schedule a not-normal goroutine (a GCworker or tracereader), // wake a P if there is one. if tryWakeP { wakep() } // 判断获得的G有没有绑定的M,有就阻塞g, 再次进行调度 if gp.lockedm != 0 { // Hands off own p to the locked m, // then blocks waiting for a new p. startlockedm(gp) goto top } // 使用execute函数让m执行g execute(gp, inheritTime) } 如图所示 \r\n 总结   判断当前的M和当前的G是否绑定，如果当前的M绑定G,就阻塞m(休眠M) 判断Gc是否在等待执行，是在等待执行，先执行gc，执行完在执行后续操作 检查是否有要被执行的Timer 普通的 goroutine 会检查是否需要在准备好时唤醒，但 GCworkers 和跟踪读取器不会，所以检查必须 有%61的概率把G从全局运行队列中搬移到本地可运行队列，保障本地可运行队列有G运行，全局队列也能放在本都队列中 没有待运行的G就现在本地可运行队列查找，本地队列没有，就调用findrunnable()，直到有待执行的g才返回(先在本地 运行队列，全局队列、等待的io, 其他的P中分配G) 判断获得的G有没有绑定的M,有就阻塞g, 再次进行调度 使用execute函数让m执行g,待运行g绑定m,调用gogo(\u0026amp;gp.sched)协程的现场恢复等  调度器的设计策略  减少线程的创建与销毁cup的开销，GPM是线程的复用。即当没有 可运行的G时，将M休眠,P空闲。当有可执行G是找空闲的P，在将M唤醒，执行G，直到 main.main 退出，runtime.main 执行 Defer 和 Panic 处理，或调用 runtime.exit 退出程序 work stealing 机制：当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。 hand off 机制：\n1.当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。\n2.利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。 3.抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。\n4.全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。 调度如图所示\n\r  参考文献 1、https://www.jianshu.com/p/fa696563c38a 2.https://www.zhihu.com/people/kylin-lab\n","date":"2021-10-06T22:00:38+08:00","image":"https://zcj-git520.github.io/p/go-goroutine%E4%B8%8Egmp%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/1_huda718813a1636432ee91da972c85e460_240629_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/go-goroutine%E4%B8%8Egmp%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/","title":"go goroutine与gmp模型的深入理解"},{"content":"理解进程与线程 进程  进程是程序一次动态执行过程、进程是操作系统分配资源(内存、io资源、cpu等)和资源调度的基本单位。程序是指令、数据及其组织形式的描述，进程是程序的实体。 进程是由 进程控制块PCB、相关程序段和该程序段进行操作的数据结构集三个部分组成。 进程的五中状态：创建、就绪、运行、阻塞、终止 五种状态转换如图所示： \r  线程  线程是cup调度和分配的基本单位也是cup执行的最小单位, 有独立的栈空间，共享堆空间。  进程与线程的关系  一个进程可以创建和撤销多个线程， 一个进程必须有一个线程(主线程), 线程共享进程所有资源，进程是线程的容器，关系如图所示：\n\r  并发与并行 并发  并发：多进程(线程)程序在一个核cup串行运行，当一个进程(线程)阻塞的时候，切换到另外等待执行的进程(线程) 如图\n\r  并行  并行：多线程程序在多核cup并行运行，如图\n\r  用户态和内核态(用户空间和内核空间) 特权级划分  cpu一共有0～4四个特权级，R0级最高，R3级最低。用户态指的是：程序运行在R3级以上，通常在应用程序中运行，内核态是指：程序运行在R0级以上，通常在内核中运行。一般来说，我们写的应用程序就是运行在R3级衣以上。  3中种用户态与内核态的切换   系统调用：用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。\n  异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。\n  外围设备的中断： 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作的完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。\n  用户态与内核态结构如图：\n\r\n  用户态与内核态的切换是需要开销\n  来源：linux用户态和内核态理解(https://www.cnblogs.com/weifeng1463/p/11660260.html)\n  进程与线程用户态到内核态的开销   多进程(线程)可以提高cpu的利用率，减少程序阻塞带来cpu闲置的情况，也就是提升cpu的运行时间片，但是过多的创建进程(线程)也会花费额外的cpu时间片进行进程(线程)的花销。进程的创建、就绪、运行、阻塞、终止，这些都会带来cup花销。例如在32位的操作系统中创建一个进程需要开辟4GB的虚拟内存空间，创建一个线程需要占用约4MB的内存。\n\r\n  进程(线程)的调度也会带来cup的花销。cup进程(线程)的调度就是进程(线程)切换，进程(线程)的切换就会进行线程在内核态的调度。cup切换的内核态的线程，不操作用户态的线程，用户态线程通过系统调用触发内核线程。\n  为减少cpu内核态线程之间的切换，操作系统中使用(用户态进程(线程):内核态进程(线程))1:1，用户态直接通过系统，直接与内核态的线程一一对应。如图\n\r\n  用户态一个进程(线程)对应一个内核态的进程(线程)是减少了内核态中进程(线程)切换的花销，但是也增加了内核态中进程(线程)创建的开销。减少内核态中进程(线程)切换与创建带来的开销，操作系统中使用(用户态进程(线程):内核态进程(线程))N:1，减少内核态中进程(线程)的创建，同时在用户态进行线程的之间的切换，不牵连内核态线程的切换，减少cup的花销。 \r\n  虽然N:1减少内核态中进程(线程)切换与创建带来的开销，但是当用户态的进程(线程)阻塞时，其他进程(线程)就只能等待，这造成与单线程一样的问题。操作系统结合1:1和n:1模型的有点形成n:m模型，内核态中进程(线程)进入阻塞状态时， 用户态的进程(线程)切换另一个内核态中的线程。\n\r\n  协程  协程和线程一样有独立的栈空间，共享堆空间，是用户级的线程，是有用户自己调度。一个线程可以创建多个协程，协程是轻量级的线程。创建一个协程只需要占用4~5kB的虚拟内存，创建协程的开销相比进程与线程低太多了。\n\r  参考文献 1、https://zhuanlan.zhihu.com/p/337978321 2、https://www.jianshu.com/p/fa696563c38a\n","date":"2021-09-28T22:00:38+08:00","image":"https://zcj-git520.github.io/p/c/c/10_hu5bb3a4baa791897c79c1df91e792ef0e_243913_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/c/c-/","title":"进程、线程、协程"},{"content":"goland 基础之map map的内部结构  go map是使用的哈希表构建的 map的结构可分为：hmap的结构体和bmap(桶)，hmap结构体记录这map的基础信息(包括map存储个数， 桶的个数，hash种子，桶的数据，扩容时旧桶的数据以及迁移个数（map扩容不是一次性迁移完）) 源码如下    定义hmap的结构： type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler's definition. // map 存储元素的计数 count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 // map的状态标识，桶是否在增改，扩容或者缩容 //桶的个数/采用的与运算法计算桶的个数，桶的个数为2的整数次幂 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) //溢出的桶的数量的近似值 noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed //指向桶数据的指针 buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. // 指向旧桶数据的指针 oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing //扩容计数 nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) // 保存溢出桶的链表和未使用的溢出桶数组的首地址 extra *mapextra // optional fields } // 桶的实现结构 type bmap struct { // 当前版本bucketCnt的值是8，一个桶最多存储8个key-value对 tophash [bucketCnt]uint8 }  bmap存储结构如图所示\n\r 前8个是hash值，8个key和8个value、后面是溢出桶的指针 溢出桶是减少map扩容次数，溢出桶的结构与bmap桶的结构一样的 溢出桶的基础结构：    type mapextra struct { // If both key and elem do not contain pointers and are inline, then we mark bucket // type as containing no pointers. This avoids scanning such maps. // However, bmap.overflow is a pointer. In order to keep overflow buckets // alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow. // overflow and oldoverflow are only used if key and elem do not contain pointers. // overflow contains overflow buckets for hmap.buckets. // oldoverflow contains overflow buckets for hmap.oldbuckets. // The indirection allows to store a pointer to the slice in hiter. overflow *[]*bmap //记录已经被使用的溢出桶 oldoverflow *[]*bmap // 扩容阶段旧的溢出桶 // nextOverflow holds a pointer to a free overflow bucket. nextOverflow *bmap //指向下一个空闲的溢出桶 }  当桶的个数大于2的4次方时就会使用溢出桶源码如下  func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) { // 桶的个数 base := bucketShift(b) nbuckets := base // For small b, overflow buckets are unlikely. // Avoid the overhead of the calculation. if b \u0026gt;= 4 { // 使用溢出桶 // Add on the estimated number of overflow buckets // required to insert the median number of elements // used with this value of b. nbuckets += bucketShift(b - 4)//计算溢出桶的数量和不是溢出桶的数量的和 sz := t.bucket.size * nbuckets up := roundupsize(sz) if up != sz { nbuckets = up / t.bucket.size //得出桶的数量 } } if dirtyalloc == nil { // 没有被创建桶，申请创建桶的，返回桶的首地址 buckets = newarray(t.bucket, int(nbuckets)) } else { // dirtyalloc was previously generated by // the above newarray(t.bucket, int(nbuckets)) // but may not be empty. buckets = dirtyalloc size := t.bucket.size * nbuckets if t.bucket.ptrdata != 0 { memclrHasPointers(buckets, size) } else { memclrNoHeapPointers(buckets, size) } } if base != nbuckets { // We preallocated some overflow buckets. // To keep the overhead of tracking these overflow buckets to a minimum, // we use the convention that if a preallocated overflow bucket's overflow // pointer is nil, then there are more available by bumping the pointer. // We need a safe non-nil pointer for the last overflow bucket; just use buckets. //空闲桶的地址 nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize))) last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize))) last.setoverflow(t, (*bmap)(buckets)) } return buckets, nextOverflow }  如图所示\n\r 使用map时需要make(map[type]type,len,cap)才能使用。 make 源码如下：    func makemap(t *maptype, hint int, h *hmap) *hmap { // 判断是否超过内存的限制 mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u0026gt; maxAlloc { hint = 0 } // initialize Hmap if h == nil { h = new(hmap) } h.hash0 = fastrand()// 获取随机的hash值 // Find the size parameter B which will hold the requested # of elements. // For hint \u0026lt; 0 overLoadFactor returns false since hint \u0026lt; bucketCnt. B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // allocate initial hash table // if B == 0, the buckets field is allocated lazily later (in mapassign) // If hint is large zeroing this memory could take a while. if h.B != 0 { var nextOverflow *bmap // 创建map的存储数据，返回的桶的数据的地址，下一个溢出桶的地址 h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h }   map的完整结构如图： \r\nmap扩容 扩容条件     当负载因子(loadFactorNum*(bucketShift(B)/loadFactorDen\u0026gt;6.5 -\u0026gt; 翻倍扩容\n  当负载因子小于6.5，但是溢出桶的数量大于2的15次方 -\u0026gt; 等量扩容\n  源代码如下：\n    // overLoadFactor reports whether count items placed in 1\u0026lt;\u0026lt;B buckets is over loadFactor. // 负载因子大于6.5 func overLoadFactor(count int, B uint8) bool { return count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } // 溢出桶过多时 func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \u0026quot;too many\u0026quot; means (approximately) as many overflow buckets as regular buckets. // See incrnoverflow for more details. if B \u0026gt; 15 { B = 15 } // The compiler doesn't see here that B \u0026lt; 16; mask B to generate shorter shift code. return noverflow \u0026gt;= uint16(1)\u0026lt;\u0026lt;(B\u0026amp;15) } // 扩容源码 func hashGrow(t *maptype, h *hmap) { // If we've hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \u0026quot;grow\u0026quot; laterally. bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { //等量扩容 bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)// 从新分配数据地址 flags := h.flags \u0026amp;^ (iterator | oldIterator) if h.flags\u0026amp;iterator != 0 { // 迭代的时候搬迁旧桶 flags |= oldIterator } // commit the grow (atomic wrt gc) h.B += bigger // 桶的个数 h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 // 溢出桶钻便为旧溢出桶 if h.extra != nil \u0026amp;\u0026amp; h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\u0026quot;oldoverflow is not nil\u0026quot;) } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 参考文献 1.https://www.zhihu.com/people/kylin-lab\n","date":"2021-09-20T22:00:38+08:00","image":"https://zcj-git520.github.io/p/go-map%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/3_hu50c7ad8b87ebb1655f26b2166388bb8a_150234_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/go-map%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/","title":"go map的深入理解"},{"content":"服务器配置(服务器平台：x86) Rsyslog简介  Rsyslog是一个 syslogd 的多线程增强版，在syslog的基础上扩展了很多其他功能，如数据库支持(MySQL, PostgreSQL、Oracle等)、日志内容筛选、定义日志格式模板等。除了默认的udp协议外，rsyslog还支持tcp协议来接收日志。 目前的linux的发行版都切换为rsyslog  安装Rsyslog  Linux的发行版中预先安装了Rsyslog,无需安装，rsyslogd –v 查看版本 若未安装，以下是安装步骤： 1.ubuntu：sudo apt install rsyslog 2.CentOS：yum install rsyslog  Rsyslog.conf配置文件详解 配置文件位置：/etc/rsyslog.conf #### MODULES #### #定义日志的模块。 $ModLoad imuxsock #imuxsock为模块名，支持本地系统日志的模块。 $ModLoad imjournal #imjournal为模块名，支持对系统日志的访问。 #$ModLoad imklog #imklog为模块名，支持内核日志的模块。 #$ModLoad immark #immark为模块名，支持日志标记。 # Provides UDP syslog reception #提供udp syslog的接收。 #$ModLoad imudp #imudp为模块名，支持udp协议。 #$UDPServerRun 514 #允许514端口接收使用udp和tcp转发来的日志。 # Provides TCP syslog reception #提供tcp syslog的接收。 #$ModLoad imtcp #imtcp为模块名，支持tcp协议。 #$InputTCPServerRun 514 #### GLOBAL DIRECTIVES #### #定义全局日志格式的指令。 # Where to place auxiliary files $WorkDirectory /var/lib/rsyslog #工作目录。 # Use default timestamp format $ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat #定义日志格式默认模板。 $IncludeConfig /etc/rsyslog.d/*.conf #所有配置文件路径。 $OmitLocalLogging on #省略本地登录。 # File to store the position in the journal $IMJournalStateFile imjournal.state #### RULES #### #kern.* /dev/console #记录所有日志类型的info级别以及大于info级别的信息到messages文件，但是mail邮件信息，authpriv验证方面的信息和corn时间和任务相关信息除外。 *.info;mail.none;authpriv.none;cron.none /var/log/messages # authpriv验证相关的所有信息存放在/var/log/secure。 authpriv.* /var/log/secure #邮件的所有信息存在/var/log/maillog；这里有一个“-”符号表示是使用异步的方式记录 mail.* -/var/log/maillog #任务计划有关的信息存放在/var/log/cron。 cron.* /var/log/cron #记录所有的≥emerg级别信息，发送给每个登录到系统的日志。 *.emerg :omusrmsg:* #记录uucp，news.crit等存放在/var/log/spooler uucp,news.crit /var/log/spooler #本地服务器的启动的所有日志存放在/var/log/boot.log local7.* /var/log/boot.log 以下为：rsyslog 客服端的配置 #发送日志，@表示传输协议（@表示udp，@@表示tcp），后面是ip和端口。 #*.* @@remote-host:514 配置服务器  使用sudo vi /etc/rsyslog.conf 打开配置文件  选择传输的协议 1.使用udp传输日志，配置时将前面的#去掉即可\n$ModLoad imudp\n$UDPServerRun 514\n2.使用tcp传输协议, 将#去点即可\n$ModLoad imtcp\n$InputTCPServerRun 514\n配置如图：\r\n 注明：\n514/5014端口号可以自己配置，默认为514.\nrsyslog后台进程是可以同时监听TCP/UDP连接的  配置接收日志模板  在GLOBAL DIRECTIVES内容块的前面增加接收日志模板 模板如下：\n$template RemoteLogs,\u0026quot;/var/log/%HOSTNAME%/%PROGRAMNAME%.log\u0026quot;\n*.* ?RemoteLogs\n\u0026amp; ~ 注明：\n1、$template RemoteLogs指令（“RemoteLogs” 可以为其它的描述的名字）迫使rsyslog后台进程隔开本地/var/log/下文件去写日志信息。而日志文件名则依据发送远程日志的机器名及应用程序名来定义。\n2、*.* ?RemoteLogs）暗含运行用模板RemoteLogs于所有的接收日志。\n3、\u0026amp; ~则告诉rsyslog后台进程停止进一步的去处理日志信息,即不对它们进行本地化写入，它是代表一个重定向规则。如果没有这一行，则意味着接收到的日志会写入两次，一次如前两行写的方式写，第二次则以本地日志记录的方式写入。运行这个规则的另一个结论则是日志服务器自己的日志信息只会写入到依照机器主机名命名的文件中。 \r 设置后，会按照模板格式保存日志 \r  设置完成，保存 检查Rsyslog配置  使用命令：rsyslogd -f /etc/rsyslog.conf -N1 配置信息正确有如下提示: \r 若配置信息有误，则需要在更改配置文件  重启RSyslog服务  Debian,Ubuntu或CentOS/RHEL 6使用:sudo service rsyslog restart Fedora 或 CentOS/RHEL 7使用：sudo systemctl restart rsyslog 使用：sudo lsof -i :[端口号]，查看服务是否开启和tcp/udp连接情况 \r 或使用sudo netstat -pantu | grep rsyslog \r  查看日志  启动客户端，进入配置文件模板中日志保存的位置：\n\r\n\r 若没有生成日志文件，需要使用：sudo tcpdump host 客户端ip 查看是否转发日志，有则是保存模板出问题，没有可能的服务端配置或者客户端配置出问题\n\r  客户端配置 平台：x86  平台是使用的rsyslog 使用sudo vi /etc/rsyslog.conf 打开配置文件 配置：\n发送日志，@表示传输协议（@表示udp，@@表示tcp），后面是ip和端口。\n*.* @@remote-host:514  \r\n 检查与重启服务和x86服务器平台一样  平台开发板  板子是使用的syslog 使用命令：ps进行查看进程\n\r 找到syslogd服务，若未找到，可能不支持syslog服务 使用命令：syslogd –h 查看syslogd支持的服务\n\r  配置客户端 1.结束之前的syslogd服务，通过使用kill 进程号 结束进程\n\r 2.通过syslogd提供的服务是通过 -L –R 服务器的ip:port\n注明：默认端口为：514,端口号应该与服务器配置的端口号一致\n3.启动syslogd服务：/sbin/syslogd -f /etc/syslog.conf -L -R 172.16.193.204:514 4.通过tcpdump host 172.16.193.204 查看日志是否被转发到服务器\n\r\n 注明：开发板的syslog支持UDP传输，需要开发板的日志文件需要在服务器打开UDP  ","date":"2021-09-20T22:00:38+08:00","image":"https://zcj-git520.github.io/p/syslog%E6%97%A5%E5%BF%97%E8%BD%AC%E5%8F%91%E9%85%8D%E7%BD%AE/8_hu442c80cfdca83249146ebd0d5822289f_88346_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/syslog%E6%97%A5%E5%BF%97%E8%BD%AC%E5%8F%91%E9%85%8D%E7%BD%AE/","title":"syslog日志转发配置"},{"content":"切片的内部结构  切片的结构可分为：数组，数据（元素）的地址\u0026amp;data、也存元素个数len、可以存储多少元素cap 源码如下    定义切片的结构： type slice struct { array unsafe.Pointer len int cap int }  如图所示  \ravatar\r\n var data [] int 声明一个切片，相当于生成切片的结构，data地址指针为nil, len和cap都为0。这就很清楚为什么，nil切片不可以直接使用了😄 结构如图  \ravatar\r\n 使用切片时需要make([]type,len,cap)或者初始化[]type{}才能使用，这是因为在在生成切片的结构时，同时也开辟了一段新的内存，类型为type, 结构长度为cap,同时值进行初始化。 make 源码如下：    func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 判断是否越界 if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 || len \u0026gt; cap { // NOTE: Produce a 'len out of range' error instead of a // 'cap out of range' error when someone does make([]T, bignumber). // 'cap out of range' is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 { panicmakeslicelen() // 越界直接 panic } panicmakeslicecap() // 越界直接 panic } return mallocgc(mem, et, true) //开辟内存 }  \ravatar\r\n   也可以通过底层数组初始化，切片的data指针指向就是相同类型的底层数组；通过slince := array[n:m],表示定义了一个类型和array相同，len为m-n,cap默认为array的长度的切片。切片和数组都指向了相同的地址。多个切片可以共用同一个底层数组。 \ravatar\r\n  通过append 函数向切片增加切片的元素，增加了len, cap 不变。\n切片扩容   在资源充裕的条件下，切片是可以通过append不断增加元素，当len个数增加到cap一样时，在增加元素时，就需要增加切片的容量cap，那问题来了，切片是怎么扩容的呢？\n扩容规则（预估规则）     当需要扩容的数量比之前cap的两倍都大，则扩容为需要扩容的数量\n  当需要扩容的数量比之前cap的两倍都大小，之前的cap小于1024 直接扩大之前的2倍\n  当需要扩容的数量比之前cap的两倍都大小，之前的cap大于1024 直接扩大之前的1.25倍\n  伪代码如下\n if oldcap2 \u0026lt; newcap 时， 扩容为newcap else{ if oldcap \u0026lt; 1024 newcap = 2oldcap ; else newcap = 1.25*oldcap }\n   源代码如下：\n    newcap := old.cap doublecap := newcap + newcap //两倍的oldcap if cap \u0026gt; doublecap { //当需要扩容的数量比之前cap的两倍都大，则扩容为需要扩容的数量 newcap = cap } else { //当需要扩容的数量比之前cap的两倍都大小，之前的cap小于1024 直接扩大之前的2倍 if old.cap \u0026lt; 1024 { newcap = doublecap } else { // Check 0 \u0026lt; newcap to detect overflow // and prevent an infinite loop. 当需要扩容的数量比之前cap的两倍都大小，之前的cap大于1024 直接扩大之前的1.25倍 for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u0026lt;= 0 { newcap = cap } } } 扩容调整  在预估扩容后，会根据内存对齐（减少内存浪费）在进行调整，代码：capmem := roundupsize(uintptr(newcap) * uintptr(et.size))newcap就是前文中计算出的newcap，et.size代表slice中一个元素的大小，capmem计算出来的就是此次扩容需要申请的内存大小。roundupsize函数就是处理内存对齐的函数 源码如下   var overflow bool var lenmem, newlenmem, capmem uintptr switch { case et.size == 1: //例如byte 大小为1， 扩容的大小为向上取整的数值 lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u0026gt; maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) \u0026gt; maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) case isPowerOfTwo(et.size): //处理2的倍数 var shift uintptr if sys.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.Ctz64(uint64(et.size))) \u0026amp; 63 } else { shift = uintptr(sys.Ctz32(uint32(et.size))) \u0026amp; 31 } lenmem = uintptr(old.len) \u0026lt;\u0026lt; shift newlenmem = uintptr(cap) \u0026lt;\u0026lt; shift capmem = roundupsize(uintptr(newcap) \u0026lt;\u0026lt; shift) overflow = uintptr(newcap) \u0026gt; (maxAlloc \u0026gt;\u0026gt; shift) newcap = int(capmem \u0026gt;\u0026gt; shift) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } // The check of overflow in addition to capmem \u0026gt; maxAlloc is needed // to prevent an overflow which can be used to trigger a segfault // on 32bit architectures with this example program: // // type T [1\u0026lt;\u0026lt;27 + 1]int64 // // var d T // var s []T // // func main() { // s = append(s, d, d, d, d) // print(len(s), \u0026quot;\\n\u0026quot;) // } if overflow || capmem \u0026gt; maxAlloc { panic(errorString(\u0026quot;growslice: cap out of range\u0026quot;)) } ### 扩容后内存分配 * 分配 大于cap的内存，没有数据指针，memclrNoHeapPointers创建 * 源码如下： \u0026gt; var p unsafe.Pointer if et.ptrdata == 0 { p = mallocgc(capmem, nil, false) // The append() that calls growslice is going to overwrite from old.len to cap (which will be the new length). // Only clear the part that will not be overwritten. memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // Note: can't use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory. p = mallocgc(capmem, et, true) //分配内存地址 if lenmem \u0026gt; 0 \u0026amp;\u0026amp; writeBarrier.enabled { // Only shade the pointers in old.array since we know the destination slice p // only contains nil pointers because it has been cleared during alloc. bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem-et.size+et.ptrdata) } } memmove(p, old.array, lenmem) //数据迁移 return slice{p, old.len, newcap} } ","date":"2021-09-15T22:00:38+08:00","image":"https://zcj-git520.github.io/p/go-%E5%88%87%E7%89%87%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/s4_hu1fce009c184102799b4a69d72efc8ec2_68940_120x120_fill_box_smart1_3.png","permalink":"https://zcj-git520.github.io/p/go-%E5%88%87%E7%89%87%E7%9A%84%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3/","title":"go 切片的深入理解"},{"content":"为什么写博客  总结开发中遇到的问题。工作过后发现自己并不擅长对知识点的总结，导致总是遇到相同的问题，过段时间需要重新查找解决方案 记录学习的知识，不断的温习。学的东西过于碎片化，导致知识不成体系。时间长了，碎片的知识也忘记了 提升自己的专业技能。通过写博客提升自己的能力 形成自己的技术栈，遇到的志同道合的朋友  为什么选择hugo来搭建自己的博客  Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 操作简单，使用Markdown直接生成静态网页 免费且以维护, 在github上就可供他人访问，无需购买服务器，维护简单 发表文章直接push到自己仓库即可  下载hogo的源码  git clone https://github.com/gohugoio/hugo.git\ngit branch 查看单前代码的分支\ngit branch -a 查看全部分支\ngit checkout branch 切换分支\ngit branch 分支名 创建自己的本地分子\n 编译源码  在master分支下，在main.go 的目录下使用命令: go build 在目录下生成hugo.exe 在cmd下使用hugo 查看是否编译成功 编译成功 会打印hugo的版本 安装成功  生成站点  使用命令：hugo new site /目录 cd /目录 查看到   ▸ archetypes/ ▸ content/ ▸ layouts/ ▸ static/ config.toml   创建站点成功  创建md文章  使用命令: hugo new 文章名.md 在content/ 下生成该md文件  选择博客主题模板  hugo 提供很多的主题博客模板：https://themes.gohugo.io/ 创建theme文件夹，将主题模板放在里面 ：mkdir themes 进入该文件夹：cd themes 下载主题，使用git clone 主题模板 ：git clone https://github.com/spf13/hyde.git  配置config.toml文件  config.toul 文件hugo 的配置文件，可以配置主题模板，个人信息等(主题模板中相应的配置文件)如   baseurl = \u0026quot;http://****.com/\u0026quot; //发布的网站 languageCode = \u0026quot;ja\u0026quot; //使用的语言 title = \u0026quot;xxxx.COM\u0026quot; //网站名称等 [Params] subtitle = \u0026quot;I would like to be a layer 3 switch.\u0026quot; facebook = \u0026quot;https://facebook.com/foobar\u0026quot; twitter = \u0026quot;https://twitter.com/foobar\u0026quot; github = \u0026quot;https://github.com/foobar\u0026quot; profile = \u0026quot;/images/profile.png\u0026quot; copyright = \u0026quot;Written by Asuka Suzuki\u0026quot; analytics = \u0026quot;UA-XXXXXXXX-X\u0026quot;    运行 本地运行  使用命令：hugo server \u0026ndash;buildDrafts 配置正确则会出现： http://localhost:1313/ (bind address 127.0.0.1) 点击在浏览器中运行  推送到gitgub  首先在GitHub上创建一个Repository，命名为：github用户名.github.io 修改config.toml 配置文件：将baseurl = \u0026ldquo;http://github用户名.github.io\u0026rdquo; 使用命令：hugo \u0026ndash;buildDrafts 在本地生成public的文件夹 \u0026ndash;buildDrafts 参数的主用是将你的文章在主题中出现   cd public 进入到public文件夹 $ git init 初始化本地仓库 $ git remote add origin https://github.com/github用户名/github用户名.github.io //添加原创仓库 或者直接 git clone $ git add -A $ git commit -m \u0026quot;first commit\u0026quot; $ git push -u origin master //推到远端   使用 \u0026ldquo;http://github用户名.github.io\u0026quot;就可访问  ","date":"2021-09-04T10:05:40+08:00","permalink":"https://zcj-git520.github.io/p/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%BB%BD%E5%8D%9A%E5%AE%A2/","title":"我的第一份博客"}]