[{"content":"问题  在收集服务的访问记录时，需要将访问记录保存，定义结构体如下    type accessData struct { RemoteAddr string // 远程访问主机地址 RequestURI string //访问的路由 ServerName string // 访问的服务名称 AccessDate string //访问的时间 RunStatus bool //服务是否正常运行 RunError error //运行报错：报错信息. ServerParam interface{} // 访问服务的参数 }   通过结构体转json，同时通过get请求得到图下结果 \ravatar\r\n  \u0026ldquo;RunError\u0026rdquo;: {},被json转为{}的字符， 打印结构体，发现错误信息是有的：{192.168.1.101:53364 /v1/alarms/out/d GetOutAlarms 2021-10-12 10:09:42 false 没有这个报警🆔id },说明是error 转json问题\n问题分析与解决  问题分析查看error类型定义发现：error类型只是一个接口。它可以包含任何实现它的具体类型的值 解决：将结构体中错误转化为字符串类型，同时用err.Error()返回是错误的字符串  type accessData struct { RemoteAddr string // 远程访问主机地址 RequestURI string //访问的路由 ServerName string // 访问的服务名称 AccessDate string //访问的时间 RunStatus bool //服务是否正常运行 RunError string //运行报错：报错信息. ServerParam interface{} // 访问服务的参数 } type error interface { Error() string }   结果如图\n  \ravatar\r\n  ","date":"2021-10-09T22:00:38+08:00","permalink":"https://zcj-git520.github.io/p/golang/","title":"go error类型转json"},{"content":"go 协程goroutine  协程是用户级的线程，有用户自己调度，使用协程使得程序调度更加灵活。同时比线程更轻量，占用的栈内存更少。go语言天生支持高并发，go使用协程goroutine的调度器。goroutine 的栈内存最小值为2kb(_StackMin = 2048),它不是固定不变的，可以随需求增大和缩小。goroutine 维护着很大的内存，无需频繁开辟内存，goroutine是使用M:n模型，在用户态切换协程，加上创建协程代价低，使得cpu的利用率大大提升，cup的性能大幅度的被利用。  goroutine 调度器GPM模型 G  G 就是goroutine协程  type g struct { // Stack parameters. // stack describes the actual stack memory: [stack.lo, stack.hi). // stackguard0 is the stack pointer compared in the Go stack growth prologue. // It is stack.lo+StackGuard normally, but can be StackPreempt to trigger a preemption. // stackguard1 is the stack pointer compared in the C stack growth prologue. // It is stack.lo+StackGuard on g0 and gsignal stacks. // It is ~0 on other goroutine stacks, to trigger a call to morestackc (and crash). // 记录该goroutine使用的栈 stack stack // offset known to runtime/cgo //下面两个成员用于栈溢出检查，实现栈的自动伸缩，抢占调度也会用到stackguard0 stackguard0 uintptr // offset known to liblink stackguard1 uintptr // offset known to liblink _panic *_panic // innermost panic - offset known to liblink _defer *_defer // innermost defer // 此goroutine正在被哪个工作线程执行 m *m // current m; offset known to arm liblink //这个字段跟调度切换有关，G切换时用来保存上下文，保存什么，看下面gobuf结构体 sched gobuf syscallsp uintptr // if status==Gsyscall, syscallsp = sched.sp to use during gc syscallpc uintptr // if status==Gsyscall, syscallpc = sched.pc to use during gc stktopsp uintptr // expected sp at top of stack, to check in traceback param unsafe.Pointer // passed parameter on wakeup，wakeup唤醒时传递的参数 // 状态Gidle,Grunnable,Grunning,Gsyscall,Gwaiting,Gdead atomicstatus uint32 stackLock uint32 // sigprof/scang lock; TODO: fold in to atomicstatus goid int64 //schedlink字段指向全局运行队列中的下一个g， //所有位于全局运行队列中的g形成一个链表 schedlink guintptr waitsince int64 // approx time when the g become blocked waitreason waitReason // if status==Gwaiting，g被阻塞的原因 //抢占信号，stackguard0 = stackpreempt，如果需要抢占调度，设置preempt为true preempt bool // preemption signal, duplicates stackguard0 = stackpreempt paniconfault bool // panic (instead of crash) on unexpected fault address preemptscan bool // preempted g does scan for gc gcscandone bool // g has scanned stack; protected by _Gscan bit in status gcscanvalid bool // false at start of gc cycle, true if G has not run since last scan; TODO: remove? throwsplit bool // must not split stack raceignore int8 // ignore race detection events sysblocktraced bool // StartTrace has emitted EvGoInSyscall about this goroutine sysexitticks int64 // cputicks when syscall has returned (for tracing) traceseq uint64 // trace event sequencer tracelastp puintptr // last P emitted an event for this goroutine // 如果调用了 LockOsThread，那么这个 g 会绑定到某个 m 上 lockedm muintptr sig uint32 writebuf []byte sigcode0 uintptr sigcode1 uintptr sigpc uintptr // 创建这个goroutine的go表达式的pc gopc uintptr // pc of go statement that created this goroutine ancestors *[]ancestorInfo // ancestor information goroutine(s) that created this goroutine (only used if debug.tracebackancestors) startpc uintptr // pc of goroutine function racectx uintptr waiting *sudog // sudog structures this g is waiting on (that have a valid elem ptr); in lock order cgoCtxt []uintptr // cgo traceback context labels unsafe.Pointer // profiler labels timer *timer // cached timer for time.Sleep,为 time.Sleep 缓存的计时器 selectDone uint32 // are we participating in a select and did someone win the race? // Per-G GC state // gcAssistBytes is this G's GC assist credit in terms of // bytes allocated. If this is positive, then the G has credit // to allocate gcAssistBytes bytes without assisting. If this // is negative, then the G must correct this by performing // scan work. We track this in bytes to make it fast to update // and check for debt in the malloc hot path. The assist ratio // determines how this corresponds to scan work debt. gcAssistBytes int64 }  保存着goroutine所有信息以及栈信息，gobuf结构体：cpu里的寄存器信息  P processor处理器  调度协程G和线程M的关联  P 的结构体如下： type p struct { //allp中的索引 id int32 //p的状态 status uint32 // one of pidle/prunning/... link puintptr schedtick uint32 // incremented on every scheduler call-\u0026gt;每次scheduler调用+1 syscalltick uint32 // incremented on every system call-\u0026gt;每次系统调用+1 sysmontick sysmontick // last tick observed by sysmon //指向绑定的 m，如果 p 是 idle 的话，那这个指针是 nil m muintptr // back-link to associated m (nil if idle) mcache *mcache raceprocctx uintptr //不同大小可用defer结构池 deferpool [5][]*_defer // pool of available defer structs of different sizes (see panic.go) deferpoolbuf [5][32]*_defer // Cache of goroutine ids, amortizes accesses to runtime·sched.goidgen. goidcache uint64 goidcacheend uint64 //本地运行队列，可以无锁访问 // Queue of runnable goroutines. Accessed without lock. runqhead uint32 //队列头 runqtail uint32 //队列尾 //数组实现的循环队列 runq [256]guintptr // runnext, if non-nil, is a runnable G that was ready'd by // the current G and should be run next instead of what's in // runq if there's time remaining in the running G's time // slice. It will inherit the time left in the current time // slice. If a set of goroutines is locked in a // communicate-and-wait pattern, this schedules that set as a // unit and eliminates the (potentially large) scheduling // latency that otherwise arises from adding the ready'd // goroutines to the end of the run queue. // runnext 非空时，代表的是一个 runnable 状态的 G， //这个 G 被 当前 G 修改为 ready 状态，相比 runq 中的 G 有更高的优先级。 //如果当前 G 还有剩余的可用时间，那么就应该运行这个 G //运行之后，该 G 会继承当前 G 的剩余时间 runnext guintptr // Available G's (status == Gdead) //空闲的g gFree struct { gList n int32 } sudogcache []*sudog sudogbuf [128]*sudog tracebuf traceBufPtr // traceSweep indicates the sweep events should be traced. // This is used to defer the sweep start event until a span // has actually been swept. traceSweep bool // traceSwept and traceReclaimed track the number of bytes // swept and reclaimed by sweeping in the current sweep loop. traceSwept, traceReclaimed uintptr palloc persistentAlloc // per-P to avoid mutex _ uint32 // Alignment for atomic fields below // Per-P GC state gcAssistTime int64 // Nanoseconds in assistAlloc gcFractionalMarkTime int64 // Nanoseconds in fractional mark worker (atomic) gcBgMarkWorker guintptr // (atomic) gcMarkWorkerMode gcMarkWorkerMode // gcMarkWorkerStartTime is the nanotime() at which this mark // worker started. gcMarkWorkerStartTime int64 // gcw is this P's GC work buffer cache. The work buffer is // filled by write barriers, drained by mutator assists, and // disposed on certain GC state transitions. gcw gcWork // wbBuf is this P's GC write barrier buffer. // // TODO: Consider caching this in the running G. wbBuf wbBuf runSafePointFn uint32 // if 1, run sched.safePointFn at next safe point pad cpu.CacheLinePad }  记录着P的信息，以及G的状态等。同时P是有着本地队列，存放着带待运行的G,本地队列不能超过256个。 P的数量：是由环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。在程序启动式创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个  M 是内核态线程的抽象  主要的工作执行协程G或者在调度G到P中  M的结构体如下： type m struct { // 系统管理的一个g，执行调度代码时使用的。比如执行用户的goroutine时，就需要把把用户 // 的栈信息换到内核线程的栈，以便能够执行用户goroutine g0 *g // goroutine with scheduling stack morebuf gobuf // gobuf arg to morestack divmod uint32 // div/mod denominator for arm - known to liblink // Fields not known to debuggers. procid uint64 // for debuggers, but offset not hard-coded //处理signal的 g gsignal *g // signal-handling g goSigStack gsignalStack // Go-allocated signal handling stack sigmask sigset // storage for saved signal mask //线程的本地存储TLS，这里就是为什么OS线程能运行M关键地方 tls [6]uintptr // thread-local storage (for x86 extern register) //go 关键字运行的函数 mstartfn func() //当前运行的用户goroutine的g结构体对象 curg *g // current running goroutine caughtsig guintptr // goroutine running during fatal signal //当前工作线程绑定的P，如果没有就为nil p puintptr // attached p for executing go code (nil if not executing go code) //暂存与当前M潜在关联的P nextp puintptr //M之前调用的P oldp puintptr // the p that was attached before executing a syscall id int64 mallocing int32 throwing int32 //当前M是否关闭抢占式调度 preemptoff string // if != \u0026quot;\u0026quot;, keep curg running on this m locks int32 dying int32 profilehz int32 //M的自旋状态，为true时M处于自旋状态，正在从其他线程偷G; 为false，休眠状态 spinning bool // m is out of work and is actively looking for work blocked bool // m is blocked on a note newSigstack bool // minit on C thread called sigaltstack printlock int8 incgo bool // m is executing a cgo call freeWait uint32 // if == 0, safe to free g0 and delete m (atomic) fastrand [2]uint32 needextram bool traceback uint8 ncgocall uint64 // number of cgo calls in total ncgo int32 // number of cgo calls currently in progress cgoCallersUse uint32 // if non-zero, cgoCallers in use temporarily cgoCallers *cgoCallers // cgo traceback if crashing in cgo call //没有goroutine运行时，工作线程睡眠 //通过这个来唤醒工作线程 park note // 休眠锁 //记录所有工作线程的链表 alllink *m // on allm schedlink muintptr //当前线程内存分配的本地缓存 mcache *mcache //当前M锁定的G， lockedg guintptr createstack [32]uintptr // stack that created this thread. lockedExt uint32 // tracking for external LockOSThread lockedInt uint32 // tracking for internal lockOSThread nextwaitm muintptr // next m waiting for lock waitunlockf func(*g, unsafe.Pointer) bool waitlock unsafe.Pointer waittraceev byte waittraceskip int startingtrace bool syscalltick uint32 //操作系统线程id thread uintptr // thread handle freelink *m // on sched.freem // these are here because they are too large to be on the stack // of low-level NOSPLIT functions. libcall libcall libcallpc uintptr // for cpu profiler libcallsp uintptr libcallg guintptr syscall libcall // stores syscall parameters on windows vdsoSP uintptr // SP for traceback while in VDSO call (0 if not in call) vdsoPC uintptr // PC for traceback while in VDSO call dlogPerM mOS }  记录着M的线程的信息，包括一些P,G以及信号和自旋锁等信息 m 数量：可以通过SetMaxThreads函数，设置 M 的最大数量，默认为10000(sched.maxmcount = 10000)，和P一样在程序启动时创建。  全局队列（gQueue）  P的本地队列可以存放着不超过256个待执行的G,P是有限的，当G过多时，即当P本地队列存放不下时，就需要将G存放在全局队列中。  全局队列结构如下： type gQueue struct { head guintptr //队列头 tail guintptr //队列尾 } G、P、M、gQueue关系  P与M没有数量关系，当一个M处于阻塞时，P先找空闲M,没有空闲的M就创建新的M G优先存放在P本地队列中，当P中G满时，会将P中前一半G存放在全局中。当P空闲时时，会从全局中拿取G放在本地队列。全局没有G时，会从其P的本地队列中拿取一半到本地队列。 关系如图所示：\n\ravatar\r  创建goroutine newproc()函数  goroutine 是由函数newproc函数进行创建的，newproc源码如下  // 参数：协程函数的参数占的字节数和协程入口函数的funcval指针 func newproc(siz int32, fn *funcval) { // 获得协程参数的地址= fn函数地址+偏移值 argp := add(unsafe.Pointer(\u0026amp;fn), sys.PtrSize) gp := getg() // 获得当前G的指针 //调用者的pc，也就是执行完此函数返回调用者时的下一条指令地址 pc := getcallerpc() // 切换到（系统栈）g0栈中 systemstack(func() { //执行调用newproc1()函数执行创建协程 newg := newproc1(fn, argp, siz, gp, pc) _p_ := getg().m.p.ptr() // 把当前的G存放在runq队列中 runqput(_p_, newg, true) // 如果当前由空闲的P,没有睡眠的M,主协程开始运行时 if mainStarted { wakep() // 创建m,并设置为活跃状态 } }) }  在newproc函数中为什么要切换在g0栈中执行呢？是因为newproc1()函数不支持栈增长，协程的栈空间小(几KB)，为了防止运行协程函数时栈溢出，需要在g0的栈上运行，g0是分配在线程的栈空间(4MB)上。g0的栈空间很大，运行协程函数时栈不溢出。  newproc1()函数  newproc1()是创建协程 源码如下：  参数：协程入口、参数首地址、参数大小、父协程指针、返回地址 func newproc1(fn *funcval, argp unsafe.Pointer, narg int32, callergp *g, callerpc uintptr) *g { _g_ := getg() // 获得当前的G if fn == nil { _g_.m.throwing = -1 // do not dump full stacks throw(\u0026quot;go of nil func value\u0026quot;) } // 为了保证数据一致性会禁止当前m被抢占 acquirem() // disable preemption because it can be holding p in a local var siz := narg siz = (siz + 7) \u0026amp;^ 7 // We could allocate a larger initial stack if necessary. // Not worth it: this is almost always an error. // 4*sizeof(uintreg): extra space added below // sizeof(uintreg): caller's LR (arm) or return address (x86, in gostartcall). if siz \u0026gt;= _StackMin-4*sys.RegSize-sys.RegSize { throw(\u0026quot;newproc: function arguments too large for new goroutine\u0026quot;) } _p_ := _g_.m.p.ptr() // 尝试获取一个空闲的G,如果没有空闲的G,就会创建新的G,分配栈空间,并添加到全局allgs中 newg := gfget(_p_) // 如果没有空闲的G if newg == nil { // 就会创建新的G,分配栈空间大小为最小的2KB newg = malg(_StackMin) // 设置状态为等待 casgstatus(newg, _Gidle, _Gdead) //并添加到全局allgs中 allgadd(newg) // publishes with a g-\u0026gt;status of Gdead so GC scanner doesn't look at uninitialized stack. } if newg.stack.hi == 0 { throw(\u0026quot;newproc1: newg missing stack\u0026quot;) } if readgstatus(newg) != _Gdead { throw(\u0026quot;newproc1: new g is not Gdead\u0026quot;) } totalSize := 4*sys.RegSize + uintptr(siz) + sys.MinFrameSize // extra space in case of reads slightly beyond frame totalSize += -totalSize \u0026amp; (sys.SpAlign - 1) // align to spAlign sp := newg.stack.hi - totalSize spArg := sp if usesLR { // caller's LR *(*uintptr)(unsafe.Pointer(sp)) = 0 prepGoExitFrame(sp) spArg += sys.MinFrameSize } if narg \u0026gt; 0 { // 如果协程入口函数由参数，会将参数移动在协程栈中 memmove(unsafe.Pointer(spArg), argp, uintptr(narg)) // This is a stack-to-stack copy. If write barriers // are enabled and the source stack is grey (the // destination is always black), then perform a // barrier copy. We do this *after* the memmove // because the destination stack may have garbage on // it. if writeBarrier.needed \u0026amp;\u0026amp; !_g_.m.curg.gcscandone { f := findfunc(fn.fn) stkmap := (*stackmap)(funcdata(f, _FUNCDATA_ArgsPointerMaps)) if stkmap.nbit \u0026gt; 0 { // We're in the prologue, so it's always stack map index 0. bv := stackmapdata(stkmap, 0) bulkBarrierBitmap(spArg, spArg, uintptr(bv.n)*sys.PtrSize, 0, bv.bytedata) } } } // 初始化newg.sched调度相关的信息 memclrNoHeapPointers(unsafe.Pointer(\u0026amp;newg.sched), unsafe.Sizeof(newg.sched)) newg.sched.sp = sp //设置为协程栈指针 newg.stktopsp = sp // 设置为指向协程入口函数的入口，当协程调度执行时，运行协程函数 newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function newg.sched.g = guintptr(unsafe.Pointer(newg)) gostartcallfn(\u0026amp;newg.sched, fn) // 设置为父协程调用newproc函数结束后的返回地址 newg.gopc = callerpc newg.ancestors = saveAncestors(callergp) // 设置startpc为协程入孔函数的起始地址 newg.startpc = fn.fn if _g_.m.curg != nil { newg.labels = _g_.m.curg.labels } if isSystemGoroutine(newg, false) { atomic.Xadd(\u0026amp;sched.ngsys, +1) } // 设置协程为运行状态 casgstatus(newg, _Gdead, _Grunnable) if _p_.goidcache == _p_.goidcacheend { // Sched.goidgen is the last allocated id, // this batch must be [sched.goidgen+1, sched.goidgen+GoidCacheBatch]. // At startup sched.goidgen=0, so main goroutine receives goid=1. _p_.goidcache = atomic.Xadd64(\u0026amp;sched.goidgen, _GoidCacheBatch) _p_.goidcache -= _GoidCacheBatch - 1 _p_.goidcacheend = _p_.goidcache + _GoidCacheBatch } // 给协程赋予一个唯一的goid newg.goid = int64(_p_.goidcache) _p_.goidcache++ if raceenabled { newg.racectx = racegostart(callerpc) } if trace.enabled { traceGoCreate(newg, newg.startpc) } // 允许当前m被抢占 releasem(_g_.m) return newg } 图示如下\n\ravatar\r\n 总结goroutine创建过程   为了保证数据一致性会禁止当前m被抢占 尝试获取一个空闲的G,如果没有空闲的G,就会创建新的G,分配栈空间,状态为等待并添加到全局allgs中 如果协程入口函数由参数，会将参数移动在协程栈中 初始化newg.sched调度相关的信息，设置状态运行 得到唯一的goid, 并添加到runq队列中 如果当前有空闲的P,没有睡眠的M,并且主协程开始运行时，就会创建新的活跃的M 当g运行结束后，设置允许当前m被抢占  调度器的设计策略  减少线程的创建与销毁cup的开销，GPM是线程的复用。即当没有 可运行的G时，将M休眠,P空闲。当有可执行G是找空闲的P，在将M唤醒，执行G，直到 main.main 退出，runtime.main 执行 Defer 和 Panic 处理，或调用 runtime.exit 退出程序 work stealing 机制：当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。 hand off 机制：\n1.当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。\n2.利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS = 核数/2，则最多利用了一半的 CPU 核进行并行。 3.抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms，防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。\n4.全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。 调度如图所示\n\ravatar\r  参考文献 1、[典藏版]Golang调度器GPM原理与调度全分析\n","date":"2021-10-06T22:00:38+08:00","permalink":"https://zcj-git520.github.io/p/go-goroutine%E4%B8%8Egmp%E6%A8%A1%E5%9E%8B/","title":"go goroutine与gmp模型"},{"content":"理解进程与线程 进程  进程是程序一次动态执行过程、进程是操作系统分配资源(内存、io资源、cpu等)和资源调度的基本单位。程序是指令、数据及其组织形式的描述，进程是程序的实体。 进程是由 进程控制块PCB、相关程序段和该程序段进行操作的数据结构集三个部分组成。 进程的五中状态：创建、就绪、运行、阻塞、终止 五种状态转换如图所示：\n\ravatar\r  线程  线程是cup调度和分配的基本单位也是cup执行的最小单位, 有独立的栈空间，共享堆空间。  进程与线程的关系  一个进程可以创建和撤销多个线程， 一个进程必须有一个线程(主线程), 线程共享进程所有资源，进程是线程的容器，关系如图所示：\n\ravatar\r  并发与并行 并发  并发：多进程(线程)程序在一个核cup串行运行，当一个进程(线程)阻塞的时候，切换到另外等待执行的进程(线程) 如图\n\ravatar\r  并行  并行：多线程程序在多核cup并行运行，如图\n\ravatar\r  用户态和内核态(用户空间和内核空间) 特权级划分  cpu一共有0～4四个特权级，R0级最高，R3级最低。用户态指的是：程序运行在R3级以上，通常在应用程序中运行，内核态是指：程序运行在R0级以上，通常在内核中运行。一般来说，我们写的应用程序就是运行在R3级衣以上。  3中种用户态与内核态的切换  系统调用：用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。 异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。 外围设备的中断： 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作的完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 用户态与内核态结构如图：\n\ravatar\r 用户态与内核态的切换是需要开销 来源：linux用户态和内核态理解(https://www.cnblogs.com/weifeng1463/p/11660260.html)  进程与线程用户态到内核态的开销  多进程(线程)可以提高cpu的利用率，减少程序阻塞带来cpu闲置的情况，也就是提升cpu的运行时间片，但是过多的创建进程(线程)也会花费额外的cpu时间片进行进程(线程)的花销。进程的创建、就绪、运行、阻塞、终止，这些都会带来cup花销。例如在32位的操作系统中创建一个进程需要开辟4GB的虚拟内存空间，创建一个线程需要占用约4MB的内存。\n\ravatar\r 进程(线程)的调度也会带来cup的花销。cup进程(线程)的调度就是进程(线程)切换，进程(线程)的切换就会进行线程在内核态的调度。cup切换的内核态的线程，不操作用户态的线程，用户态线程通过系统调用触发内核线程。 为减少cpu内核态线程之间的切换，操作系统中使用(用户态进程(线程):内核态进程(线程))1:1，用户态直接通过系统，直接与内核态的线程一一对应。如图\n\ravatar\r 用户态一个进程(线程)对应一个内核态的进程(线程)是减少了内核态中进程(线程)切换的花销，但是也增加了内核态中进程(线程)创建的开销。减少内核态中进程(线程)切换与创建带来的开销，操作系统中使用(用户态进程(线程):内核态进程(线程))N:1，减少内核态中进程(线程)的创建，同时在用户态进行线程的之间的切换，不牵连内核态线程的切换，减少cup的花销。 \ravatar\r 虽然N:1减少内核态中进程(线程)切换与创建带来的开销，但是当用户态的进程(线程)阻塞时，其他进程(线程)就只能等待，这造成与单线程一样的问题。操作系统结合1:1和n:1模型的有点形成n:m模型，内核态中进程(线程)进入阻塞状态时， 用户态的进程(线程)切换另一个内核态中的线程。\n\ravatar\r  协程  协程和线程一样有独立的栈空间，共享堆空间，是用户级的线程，是有用户自己调度。一个线程可以创建多个协程，协程是轻量级的线程。创建一个协程只需要占用4~5kB的虚拟内存，创建协程的开销相比进程与线程低太多了。\n\ravatar\r  参考文献 1、干货 | 进程、线程、协程 10 张图讲明白了！ 2、[典藏版]Golang调度器GPM原理与调度全分析\n","date":"2021-09-28T22:00:38+08:00","permalink":"https://zcj-git520.github.io/p/c/c-/","title":"进程、线程、协程"},{"content":"goland 基础之map map的内部结构  go map是使用的哈希表构建的 map的结构可分为：hmap的结构体和bmap(桶)，hmap结构体记录这map的基础信息(包括map存储个数， 桶的个数，hash种子，桶的数据，扩容时旧桶的数据以及迁移个数（map扩容不是一次性迁移完）) 源码如下    定义hmap的结构： type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler's definition. // map 存储元素的计数 count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 // map的状态标识，桶是否在增改，扩容或者缩容 //桶的个数/采用的与运算法计算桶的个数，桶的个数为2的整数次幂 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) //溢出的桶的数量的近似值 noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed //指向桶数据的指针 buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. // 指向旧桶数据的指针 oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing //扩容计数 nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) // 保存溢出桶的链表和未使用的溢出桶数组的首地址 extra *mapextra // optional fields } // 桶的实现结构 type bmap struct { // 当前版本bucketCnt的值是8，一个桶最多存储8个key-value对 tophash [bucketCnt]uint8 }  bmap存储结构如图所示\n\ravatar\r 前8个是hash值，8个key和8个value、后面是溢出桶的指针 溢出桶是减少map扩容次数，溢出桶的结构与bmap桶的结构一样的 溢出桶的基础结构：    type mapextra struct { // If both key and elem do not contain pointers and are inline, then we mark bucket // type as containing no pointers. This avoids scanning such maps. // However, bmap.overflow is a pointer. In order to keep overflow buckets // alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow. // overflow and oldoverflow are only used if key and elem do not contain pointers. // overflow contains overflow buckets for hmap.buckets. // oldoverflow contains overflow buckets for hmap.oldbuckets. // The indirection allows to store a pointer to the slice in hiter. overflow *[]*bmap //记录已经被使用的溢出桶 oldoverflow *[]*bmap // 扩容阶段旧的溢出桶 // nextOverflow holds a pointer to a free overflow bucket. nextOverflow *bmap //指向下一个空闲的溢出桶 }  当桶的个数大于2的4次方时就会使用溢出桶源码如下  func makeBucketArray(t *maptype, b uint8, dirtyalloc unsafe.Pointer) (buckets unsafe.Pointer, nextOverflow *bmap) { // 桶的个数 base := bucketShift(b) nbuckets := base // For small b, overflow buckets are unlikely. // Avoid the overhead of the calculation. if b \u0026gt;= 4 { // 使用溢出桶 // Add on the estimated number of overflow buckets // required to insert the median number of elements // used with this value of b. nbuckets += bucketShift(b - 4)//计算溢出桶的数量和不是溢出桶的数量的和 sz := t.bucket.size * nbuckets up := roundupsize(sz) if up != sz { nbuckets = up / t.bucket.size //得出桶的数量 } } if dirtyalloc == nil { // 没有被创建桶，申请创建桶的，返回桶的首地址 buckets = newarray(t.bucket, int(nbuckets)) } else { // dirtyalloc was previously generated by // the above newarray(t.bucket, int(nbuckets)) // but may not be empty. buckets = dirtyalloc size := t.bucket.size * nbuckets if t.bucket.ptrdata != 0 { memclrHasPointers(buckets, size) } else { memclrNoHeapPointers(buckets, size) } } if base != nbuckets { // We preallocated some overflow buckets. // To keep the overhead of tracking these overflow buckets to a minimum, // we use the convention that if a preallocated overflow bucket's overflow // pointer is nil, then there are more available by bumping the pointer. // We need a safe non-nil pointer for the last overflow bucket; just use buckets. //空闲桶的地址 nextOverflow = (*bmap)(add(buckets, base*uintptr(t.bucketsize))) last := (*bmap)(add(buckets, (nbuckets-1)*uintptr(t.bucketsize))) last.setoverflow(t, (*bmap)(buckets)) } return buckets, nextOverflow }  如图所示 \ravatar\r 使用map时需要make(map[type]type,len,cap)才能使用。 make 源码如下：    func makemap(t *maptype, hint int, h *hmap) *hmap { // 判断是否超过内存的限制 mem, overflow := math.MulUintptr(uintptr(hint), t.bucket.size) if overflow || mem \u0026gt; maxAlloc { hint = 0 } // initialize Hmap if h == nil { h = new(hmap) } h.hash0 = fastrand()// 获取随机的hash值 // Find the size parameter B which will hold the requested # of elements. // For hint \u0026lt; 0 overLoadFactor returns false since hint \u0026lt; bucketCnt. B := uint8(0) for overLoadFactor(hint, B) { B++ } h.B = B // allocate initial hash table // if B == 0, the buckets field is allocated lazily later (in mapassign) // If hint is large zeroing this memory could take a while. if h.B != 0 { var nextOverflow *bmap // 创建map的存储数据，返回的桶的数据的地址，下一个溢出桶的地址 h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h }  map的完整结构如图：   \ravatar\r 。\n map扩容 扩容条件   当负载因子(loadFactorNum*(bucketShift(B)/loadFactorDen\u0026gt;6.5 -\u0026gt; 翻倍扩容\n  当负载因子小于6.5，但是溢出桶的数量大于2的15次方 -\u0026gt; 等量扩容\n  源代码如下：\n    // overLoadFactor reports whether count items placed in 1\u0026lt;\u0026lt;B buckets is over loadFactor. // 负载因子大于6.5 func overLoadFactor(count int, B uint8) bool { return count \u0026gt; bucketCnt \u0026amp;\u0026amp; uintptr(count) \u0026gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } // 溢出桶过多时 func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { // If the threshold is too low, we do extraneous work. // If the threshold is too high, maps that grow and shrink can hold on to lots of unused memory. // \u0026quot;too many\u0026quot; means (approximately) as many overflow buckets as regular buckets. // See incrnoverflow for more details. if B \u0026gt; 15 { B = 15 } // The compiler doesn't see here that B \u0026lt; 16; mask B to generate shorter shift code. return noverflow \u0026gt;= uint16(1)\u0026lt;\u0026lt;(B\u0026amp;15) } // 扩容源码 func hashGrow(t *maptype, h *hmap) { // If we've hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \u0026quot;grow\u0026quot; laterally. bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { //等量扩容 bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil)// 从新分配数据地址 flags := h.flags \u0026amp;^ (iterator | oldIterator) if h.flags\u0026amp;iterator != 0 { // 迭代的时候搬迁旧桶 flags |= oldIterator } // commit the grow (atomic wrt gc) h.B += bigger // 桶的个数 h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 // 溢出桶钻便为旧溢出桶 if h.extra != nil \u0026amp;\u0026amp; h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\u0026quot;oldoverflow is not nil\u0026quot;) } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } ","date":"2021-09-20T22:00:38+08:00","permalink":"https://zcj-git520.github.io/p/go-%E5%9F%BA%E7%A1%80%E4%B9%8Bmap/","title":"go 基础之map"},{"content":"切片的内部结构  切片的结构可分为：数组，数据（元素）的地址\u0026amp;data、也存元素个数len、可以存储多少元素cap 源码如下    定义切片的结构： type slice struct { array unsafe.Pointer len int cap int }  如图所示  \ravatar\r\n var data [] int 声明一个切片，相当于生成切片的结构，data地址指针为nil, len和cap都为0。这就很清楚为什么，nil切片不可以直接使用了😄 结构如图  \ravatar\r\n 使用切片时需要make([]type,len,cap)或者初始化[]type{}才能使用，这是因为在在生成切片的结构时，同时也开辟了一段新的内存，类型为type, 结构长度为cap,同时值进行初始化。 make 源码如下：    func makeslice(et *_type, len, cap int) unsafe.Pointer { mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 判断是否越界 if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 || len \u0026gt; cap { // NOTE: Produce a 'len out of range' error instead of a // 'cap out of range' error when someone does make([]T, bignumber). // 'cap out of range' is true too, but since the cap is only being // supplied implicitly, saying len is clearer. // See golang.org/issue/4085. mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u0026gt; maxAlloc || len \u0026lt; 0 { panicmakeslicelen() // 越界直接 panic } panicmakeslicecap() // 越界直接 panic } return mallocgc(mem, et, true) //开辟内存 }  \ravatar\r\n   也可以通过底层数组初始化，切片的data指针指向就是相同类型的底层数组；通过slince := array[n:m],表示定义了一个类型和array相同，len为m-n,cap默认为array的长度的切片。切片和数组都指向了相同的地址。多个切片可以共用同一个底层数组。 \ravatar\r\n  通过append 函数向切片增加切片的元素，增加了len, cap 不变。\n切片扩容   在资源充裕的条件下，切片是可以通过append不断增加元素，当len个数增加到cap一样时，在增加元素时，就需要增加切片的容量cap，那问题来了，切片是怎么扩容的呢？\n扩容规则（预估规则）     当需要扩容的数量比之前cap的两倍都大，则扩容为需要扩容的数量\n  当需要扩容的数量比之前cap的两倍都大小，之前的cap小于1024 直接扩大之前的2倍\n  当需要扩容的数量比之前cap的两倍都大小，之前的cap大于1024 直接扩大之前的1.25倍\n  伪代码如下\n if oldcap2 \u0026lt; newcap 时， 扩容为newcap else{ if oldcap \u0026lt; 1024 newcap = 2oldcap ; else newcap = 1.25*oldcap }\n   源代码如下：\n    newcap := old.cap doublecap := newcap + newcap //两倍的oldcap if cap \u0026gt; doublecap { //当需要扩容的数量比之前cap的两倍都大，则扩容为需要扩容的数量 newcap = cap } else { //当需要扩容的数量比之前cap的两倍都大小，之前的cap小于1024 直接扩大之前的2倍 if old.cap \u0026lt; 1024 { newcap = doublecap } else { // Check 0 \u0026lt; newcap to detect overflow // and prevent an infinite loop. 当需要扩容的数量比之前cap的两倍都大小，之前的cap大于1024 直接扩大之前的1.25倍 for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { newcap += newcap / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u0026lt;= 0 { newcap = cap } } } 扩容调整  在预估扩容后，会根据内存对齐（减少内存浪费）在进行调整，代码：capmem := roundupsize(uintptr(newcap) * uintptr(et.size))newcap就是前文中计算出的newcap，et.size代表slice中一个元素的大小，capmem计算出来的就是此次扩容需要申请的内存大小。roundupsize函数就是处理内存对齐的函数 源码如下   var overflow bool var lenmem, newlenmem, capmem uintptr switch { case et.size == 1: //例如byte 大小为1， 扩容的大小为向上取整的数值 lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u0026gt; maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) \u0026gt; maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) case isPowerOfTwo(et.size): //处理2的倍数 var shift uintptr if sys.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.Ctz64(uint64(et.size))) \u0026amp; 63 } else { shift = uintptr(sys.Ctz32(uint32(et.size))) \u0026amp; 31 } lenmem = uintptr(old.len) \u0026lt;\u0026lt; shift newlenmem = uintptr(cap) \u0026lt;\u0026lt; shift capmem = roundupsize(uintptr(newcap) \u0026lt;\u0026lt; shift) overflow = uintptr(newcap) \u0026gt; (maxAlloc \u0026gt;\u0026gt; shift) newcap = int(capmem \u0026gt;\u0026gt; shift) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } // The check of overflow in addition to capmem \u0026gt; maxAlloc is needed // to prevent an overflow which can be used to trigger a segfault // on 32bit architectures with this example program: // // type T [1\u0026lt;\u0026lt;27 + 1]int64 // // var d T // var s []T // // func main() { // s = append(s, d, d, d, d) // print(len(s), \u0026quot;\\n\u0026quot;) // } if overflow || capmem \u0026gt; maxAlloc { panic(errorString(\u0026quot;growslice: cap out of range\u0026quot;)) } ### 扩容后内存分配 * 分配 大于cap的内存，没有数据指针，memclrNoHeapPointers创建 * 源码如下： \u0026gt; var p unsafe.Pointer if et.ptrdata == 0 { p = mallocgc(capmem, nil, false) // The append() that calls growslice is going to overwrite from old.len to cap (which will be the new length). // Only clear the part that will not be overwritten. memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // Note: can't use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory. p = mallocgc(capmem, et, true) //分配内存地址 if lenmem \u0026gt; 0 \u0026amp;\u0026amp; writeBarrier.enabled { // Only shade the pointers in old.array since we know the destination slice p // only contains nil pointers because it has been cleared during alloc. bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(old.array), lenmem-et.size+et.ptrdata) } } memmove(p, old.array, lenmem) //数据迁移 return slice{p, old.len, newcap} } ","date":"2021-09-15T22:00:38+08:00","image":"https://zcj-git520.github.io/s4.png","permalink":"https://zcj-git520.github.io/p/go-%E5%9F%BA%E7%A1%80%E4%B9%8B%E5%88%87%E7%89%87/","title":"go 基础之切片"},{"content":"为什么写博客  总结开发中遇到的问题。工作过后发现自己并不擅长对知识点的总结，导致总是遇到相同的问题，过段时间需要重新查找解决方案 记录学习的知识，不断的温习。学的东西过于碎片化，导致知识不成体系。时间长了，碎片的知识也忘记了 提升自己的专业技能。通过写博客提升自己的能力 形成自己的技术栈，遇到的志同道合的朋友  为什么选择hugo来搭建自己的博客  Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 操作简单，使用Markdown直接生成静态网页 免费且以维护, 在github上就可供他人访问，无需购买服务器，维护简单 发表文章直接push到自己仓库即可  下载hogo的源码  git clone https://github.com/gohugoio/hugo.git\ngit branch 查看单前代码的分支\ngit branch -a 查看全部分支\ngit checkout branch 切换分支\ngit branch 分支名 创建自己的本地分子\n 编译源码  在master分支下，在main.go 的目录下使用命令: go build 在目录下生成hugo.exe 在cmd下使用hugo 查看是否编译成功 编译成功 会打印hugo的版本 安装成功  生成站点  使用命令：hugo new site /目录 cd /目录 查看到   ▸ archetypes/ ▸ content/ ▸ layouts/ ▸ static/ config.toml   创建站点成功  创建md文章  使用命令: hugo new 文章名.md 在content/ 下生成该md文件  选择博客主题模板  hugo 提供很多的主题博客模板：https://themes.gohugo.io/ 创建theme文件夹，将主题模板放在里面 ：mkdir themes 进入该文件夹：cd themes 下载主题，使用git clone 主题模板 ：git clone https://github.com/spf13/hyde.git  配置config.toml文件  config.toul 文件hugo 的配置文件，可以配置主题模板，个人信息等(主题模板中相应的配置文件)如   baseurl = \u0026quot;http://****.com/\u0026quot; //发布的网站 languageCode = \u0026quot;ja\u0026quot; //使用的语言 title = \u0026quot;xxxx.COM\u0026quot; //网站名称等 [Params] subtitle = \u0026quot;I would like to be a layer 3 switch.\u0026quot; facebook = \u0026quot;https://facebook.com/foobar\u0026quot; twitter = \u0026quot;https://twitter.com/foobar\u0026quot; github = \u0026quot;https://github.com/foobar\u0026quot; profile = \u0026quot;/images/profile.png\u0026quot; copyright = \u0026quot;Written by Asuka Suzuki\u0026quot; analytics = \u0026quot;UA-XXXXXXXX-X\u0026quot;    运行 本地运行  使用命令：hugo server \u0026ndash;buildDrafts 配置正确则会出现： http://localhost:1313/ (bind address 127.0.0.1) 点击在浏览器中运行  推送到gitgub  首先在GitHub上创建一个Repository，命名为：github用户名.github.io 修改config.toml 配置文件：将baseurl = \u0026ldquo;http://github用户名.github.io\u0026rdquo; 使用命令：hugo \u0026ndash;buildDrafts 在本地生成public的文件夹 \u0026ndash;buildDrafts 参数的主用是将你的文章在主题中出现   cd public 进入到public文件夹 $ git init 初始化本地仓库 $ git remote add origin https://github.com/github用户名/github用户名.github.io //添加原创仓库 或者直接 git clone $ git add -A $ git commit -m \u0026quot;first commit\u0026quot; $ git push -u origin master //推到远端   使用 \u0026ldquo;http://github用户名.github.io\u0026quot;就可访问  ","date":"2021-09-04T10:05:40+08:00","permalink":"https://zcj-git520.github.io/p/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E4%BB%BD%E5%8D%9A%E5%AE%A2/","title":"我的第一份博客"}]